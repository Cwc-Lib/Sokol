{"version":3,"sources":["../sokol-samples/wgpu/HandmadeMath.h","../sokol\\sokol_gfx.h","../sokol-samples/wgpu/cube-wgpu.c","E:/Data/setting/Sokol_Mine/_cwc\\cube-wgpu.glsl.h","../sokol-samples/wgpu/wgpu_entry.c","../sokol-samples/wgpu/wgpu_entry_wasm.c"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0vBA;AAEA;AAAA;AAAA;AACA;AAAA;;;;;;;;AAMA;AAEA;AAAA;AAAA;AACA;AAAA;;;;;;;;AAMA;AAEA;AAAA;AAAA;AACA;AAAA;;;;;;;;AAmDA;AAEA;AAAA;AAAA;AACA;AAAA;;;;;;;;AAMA;AAOA;AAAA;AAAA;AAGA;AAAA;;;;;;;;;AAgCA;AAEA;AAAA;AAAA;AAAA;AAEA;AAAA;;;;;;;;AAkKA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;;;;;;;;AA5IA;AAEA;AAAA;AAAA;AAAA;AAEA;AAAA;;;;;;;;;;;AAqFA;AAEA;AAAA;AAAA;AAGA;AAAA;;AAOA;AAAA;;AALA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;;;;;;;;;;;AAuDA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;;;;;;;;;;;;;;AA4BA;AAEA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAAA;;;;;;;;;;AAsGA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;;;;;;;;AAiMA;AAEA;AAAA;;;;;;;;;;AAMA;AAEA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAEA;AAAA;;;;;;;;;;;AAwDA;AAgBA;;AAAA;AAAA;;;;AAGA;;AAAA;AAAA;;;;AAEA;AAEA;;AAAA;AAAA;;;;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAFA;AAAA;AAAA;;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AATA;AAAA;AAAA;;AAHA;AAAA;AAAA;;AAgBA;AAAA;;;;;;;;;;;;;;;;;;AAsGA;AAEA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAAA;;;;;;;;;;;;;;;;;;;AAkBA;AAEA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkBA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAAA;;;;;;;;;;;;ACq8XA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AACA;AAAA;AAOA;AAAA;;AAMA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAAA;AACA;;AAvBA;AAAA;;;;;;;;;;;;;;;;;;;;AAhxCA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;;AAFA;AAAA;;;;;;;;;AArmBA;AAAA;AAMA;;;;;;;;;AA+4DA;AAAA;;AAAA;AAAA;;AAEA;AAAA;AACA;AAAA;;AASA;AAEA;AACA;AAAA;AAAA;;AAXA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAMA;AACA;AAAA;AAAA;;;;;;AA3DA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AACA;AAAA;AACA;AAAA;;;AAGA;AACA;AACA;AACA;;;;;;;;;;AA5nCA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAIA;AAAA;;;AADA;AACA;AAAA;;;;;;;;;;;;;;;;;;AAUA;;AAAA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAJA;AAAA;AAAA;;AAQA;;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAJA;AAAA;AAAA;;AAQA;;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAJA;AAAA;AAAA;;AAQA;;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAJA;AAAA;AAAA;;AAQA;;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAJA;AAAA;AAAA;;AAQA;;;;;;;;AAjuBA;AAAA;AAMA;;;;;AAtEA;AAMA;;;;;;;;;;AAolBA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AACA;;AAbA;AAAA;;;;;;;;;;AA1GA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAOA;AAEA;AAAA;;AARA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAMA;AAAA;;;;;;;;;;;;;;AA0HA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;;AAJA;AAAA;;;;;;;;;;;;;AAmDA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AADA;AAAA;;;;;;;;;;AA5nBA;AAAA;AAAA;;;;;;;;AAhBA;AAAA;AAMA;;;;;;;;AA0lBA;AAAA;AAAA;AACA;AAAA;;AACA;AAAA;;AADA;AAAA;;;;;;;;;;AAkgCA;AAAA;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAIA;;AAEA;AAAA;AAAA;;;;;;;;AAkBA;AAAA;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAIA;;AAEA;AAAA;AAAA;;;;;;;;AAKA;AAAA;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAIA;;AAEA;AAAA;AAAA;;;;;;;;;;;AAjNA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;;;;;;;;;;AA+NA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;;;AACA;AAAA;AAAA;AAAA;AAAA;;AAGA;AAAA;;AAEA;AAAA;AAAA;AAAA;;AACA;;AADA;AAAA;AAAA;AAAA;;AACA;;AADA;AAAA;;;;;;;;;;;;;;;AA5MA;AAAA;AAKA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AAUA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;;;AAGA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAGA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AALA;AAAA;AAAA;;AALA;AAAA;AAAA;;AAaA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAGA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AALA;AAAA;AAAA;;AAfA;AAAA;AAAA;;AAuBA;AAAA;;;;;;;;;;AAuLA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;;;AACA;AAAA;AAAA;AAAA;AAAA;;AAGA;AAAA;;AAEA;AAAA;AAAA;AAAA;;AACA;;AADA;AAAA;AAAA;AAAA;;AACA;;AADA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA7LA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;;;AACA;;AAGA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AAEA;;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;;AAGA;AAAA;AAAA;;;;;AAAA;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAAA;AAAA;AAAA;;;AAAA;AAAA;AAAA;AARA;AAAA;AAAA;;;AAKA;AAAA;;;AAQA;AACA;AACA;;AAAA;AAAA;;;;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;;AAHA;AAAA;AAAA;;AAMA;;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;;AAGA;AAAA;AAAA;;;;;AAAA;AAAA;AAAA;;;;;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AATA;AAAA;AAAA;;;AAKA;AAAA;;;AAOA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAHA;AAAA;AAAA;;AAOA;AAAA;;;;;;;;;;;;;AAsHA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AAGA;AAAA;AAAA;;AAIA;AAAA;AAAA;;;AAEA;AAAA;AAAA;AAAA;;AACA;;AADA;AAAA;AAAA;AAAA;;AACA;;AADA;AAAA;;;;;;;;;;;AA3kCA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAIA;AAAA;;;AADA;AACA;AAAA;;;;;;;;;;AAGA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAIA;AAAA;;;AADA;AACA;AAAA;;;;;;;;;;AAGA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAIA;AAAA;;;AADA;AACA;AAAA;;;;;;;;;;AAGA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAIA;AAAA;;;AADA;AACA;AAAA;;;;;;;;;;AAGA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAIA;AAAA;;;AADA;AACA;AAAA;;;;;;;;;;;;AAq3CA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AACA;AAAA;AACA;AAAA;;AACA;AAAA;AAOA;AAAA;AAAA;;AAJA;AAIA;AAAA;AAAA;;;;;;;;;;;;;;AAoBA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AACA;AAAA;AACA;AAAA;;AACA;AAAA;AAOA;AAAA;AAAA;;AAJA;AAIA;AAAA;AAAA;;;;;;;;;;;;;;AAIA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AACA;AAAA;AACA;AAAA;;AACA;AAAA;AAOA;AAAA;AAAA;;AAJA;AAIA;AAAA;AAAA;;;;;;;;;;AArjEA;AAAA;AAMA;;;;;;;;AA0BA;AAAA;AAMA;;;;;;;;AA0BA;AAAA;AAMA;;;;;;;;AA0BA;AAAA;AAMA;;;;;;;;AA0BA;AAAA;AAAA;;;;;;;;;;;;;AA+hEA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAEA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAEA;;AAPA;AAAA;;;;;;;;;;;;;;AAhpUA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AANA;AAAA;AAAA;;AASA;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;;AAIA;;AAHA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAEA;;;;;;;;;;;;;;AA4oQA;AAAA;AAAA;AAAA;AAAA;AAMA;;;;;;;;;;AAtCA;AAAA;AAAA;AAAA;;;;;;;;;AAskEA;AAAA;;AAAA;AAAA;;AACA;AACA;AAAA;;AACA;AAeA;;AAXA;AAAA;;AAWA;;AAPA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAEA;;;;;;;;;;;;;AAjkCA;AAEA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AACA;AAAA;AAAA;AAgCA;AAAA;AAAA;;AA9BA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AACA;AAAA;;;AAEA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAGA;AAAA;;;;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAEA;AAAA;AAAA;AAEA;AAAA;AAAA;;;;;;;;AA79BA;AAAA;AAMA;;;;;;;;;;;;;;;;;;;;;AAq/DA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AACA;AAiEA;;AA7DA;AAEA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAEA;AACA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AALA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAGA;AAAA;;AASA;AACA;AAAA;AAAA;AAAA;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAFA;AAAA;;;;AAKA;AACA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAJA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAGA;AAAA;;AAQA;AACA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAJA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AAGA;AAAA;;AAOA;AAAA;;AASA;;AARA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;;;;;;;;;;;;;;;;;;;AA5lCA;AAGA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AACA;AAAA;AAAA;AA2EA;AAAA;AAAA;;AAzEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAGA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;AACA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AAKA;AAAA;;AAbA;AAAA;AAAA;;AAkBA;AAAA;AAAA;AAAA;AAAA;;;;;AAEA;AAAA;;AAIA;AAAA;;AAEA;AAAA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AAKA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AAIA;AAAA;;AAXA;AAAA;AAAA;;AAgBA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;AAIA;AAAA;;AAXA;AAAA;AAAA;;AAcA;AAAA;AAAA;AAEA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;AAhiCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;;;;;;;;;;;;;;;AAuiEA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AACA;AAaA;;AATA;AAAA;;AASA;;AAFA;AAAA;AAAA;AAAA;AAAA;AAEA;;;;;;;;;;;;;;;;AArhCA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;;AATA;AAAA;;;;;;;;;;;;;;;;AAhiCA;AAAA;AAAA;AAAA;AAAA;AAMA;;;;;;;;;;;;AA4iEA;AAAA;;AAAA;AAAA;;AAEA;AAAA;;AACA;;AAGA;AAAA;;AAcA;;AAVA;AAAA;;AAUA;;AANA;AAAA;;AAMA;;AAFA;AAAA;AAAA;AAAA;AAEA;;;;;;;;;;;;AAtjEA;AAAA;AAAA;AAAA;AAMA;;;;;AAmjEA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AASA;;AALA;AACA;AACA;AACA;AAEA;;;;;AAzqEA;AAMA;;;;;AAsqEA;AAAA;;AACA;AAEA;AAAA;AAAA;AACA;;AAJA;AAAA;;;;;;AAtjEA;AAMA;;;;;;;;;;;;;;;;;;;AChsYA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAKA;AA+BA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAOA;AAQA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAQA;AAAA;AAAA;AAGA;AAAA;AAGA;AAFA;AAIA;AAAA;AADA;AAEA;AAAA;AANA;AASA;AATA;AAAA;AAAA;AAWA;AAAA;AAAA;AAAA;AAXA;AAeA;AAAA;AAfA;AAAA;AAAA;AAAA;AAAA;AAoBA;AAAA;AACA;AADA;AAEA;AAFA;AAIA;;;;;ACoMA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AD/LA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AAGA;AACA;;;;;;;;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AASA;;;;;;;;;;;;ADwnYA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AAAA;AAAA;;AAGA;;;;;;;;;;;;;;;;;AAj3CA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAGA;AAGA;AACA;AAAA;AACA;AACA;AAAA;AACA;AAIA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAIA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AACA;;AADA;AAAA;;;;;;AA9iBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AAmZA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;;AAFA;AAAA;;;;;;;;;;;;;;;;;;;AA5XA;AAAA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAGA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AACA;;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AALA;AAAA;AAAA;;AAFA;AAAA;;AAYA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAGA;AACA;;AAAA;AAAA;;;;AACA;;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AALA;AAAA;AAAA;;AADA;AAAA;;AAUA;AACA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AACA;;AADA;AAAA;;;;;;;;;;;;;;;AA4CA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAIA;AACA;AAGA;;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;;;;;;AADA;AAAA;;;AAEA;AAoBA;;AAdA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;;;;;;;;AAqIA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAEA;;AAHA;AAAA;;;;;;;;;;;;;;;AAkCA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAIA;AAGA;;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;;;;;;AADA;AAAA;;;AAEA;AAoBA;;AAdA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;;;;;;;;AAv9NA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;;;;;;;;AAOA;AAAA;AACA;AAAA;AAAA;AACA;;;;;;;;AAeA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;;;;;;;;AAfA;AAAA;AACA;AAAA;AAAA;AACA;;;;;;;;AA6BA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;;;;;;;;AA7BA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;;;;;;;;;;;AA1oCA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;;AANA;AAAA;;;;;;;;;;;;;;;;;;;;;;;AA+0PA;AAAA;;AAaA;;AATA;AAAA;;AACA;AACA;AAAA;;AAEA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;;;;;;;;;;;;;;;;;;;;;;AA0LA;AAAA;;AAaA;;AATA;AAAA;;AAEA;AAAA;;AAEA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;;;;;;;;AA2NA;AAAA;;AAEA;;AAFA;AAAA;;;;;;AA7BA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;AAAA;AACA;AACA;AAAA;;AAIA;;AAHA;AAAA;AACA;AAEA;;;;;;;AAxbA;AAAA;;AACA;AAAA;AACA;;AAEA;AAAA;;AACA;AAAA;AACA;;AAEA;AAAA;;AACA;AAAA;AACA;;AAEA;;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;;AAJA;AAAA;AAAA;;AAOA;;;;;;AAgMA;;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;;AAJA;AAAA;AAAA;;AAOA;;;;;;AAqHA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;;AAAA;AAAA;;AACA;;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AADA;AAAA;AAAA;;AAGA;AACA;;;;;;;;;;;AA1kQA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AADA;AAAA;;;;;;;;;;AA5DA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AACA;;AALA;AAAA;;;;;;;;;;AAwhTA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AACA;;AALA;AAAA;;;;;;;;;AA7yCA;AAAA;;AAEA;;AAFA;AAAA;;;;;;;;;;AAWA;AACA;;;;;;;;;;AA4vDA;AAAA;;AAAA;AAAA;;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;;;;;AAHA;AAAA;AAIA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;;;AAFA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;;;;;;;;;;AAl4BA;AAAA;AAAA;AAAA;;;;;AAs1BA;AACA;;;;;;;;;;;AAGA;AAAA;;AAIA;;AAHA;AAAA;AACA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAEA;;;;;AAGA;AAAA;;AAEA;AACA;AAAA;;AAKA;;;;;;;;;;AAlJA;;;;AAEA;;;;AACA;;;;AACA;;;;AACA;;;;AAGA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAGA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAGA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAGA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAGA;;;;AACA;;;;AAGA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAGA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAGA;;;;AACA;;;;AACA;;;;AAGA;;;;AACA;;;;AACA;;;;AACA;;;;AAGA;;;;AACA;;;;AACA;;;;AAGA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAEA;;;;AAEA;AAAA;;;;;;;;;;;;;;;;AAttDA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAmBA;;AAfA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AASA;AAAA;AAAA;AAAA;AAAA;AAGA;;AAXA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAMA;;;;;;;;;;;AAh+QA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;;;;;;;;;;AAwiPA;AACA;AAAA;;;AACA;AAAA;;AAGA;AAAA;;AAEA;AAAA;;AAGA;AAAA;;AAFA;AAAA;AAAA;AAEA;AAAA;;;;;;;;AAiBA;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;AAAA;;;AAEA;AAAA;;;;;;;;AA6HA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAmBA;AAAA;;;;AAGA;AAAA;;;;;;;;;;;;;;;AAogFA;AAAA;;AAAA;AAAA;;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAgBA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AALA;AAAA;AAAA;;AASA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAEA;;AAAA;AAAA;;;;AACA;AAAA;;AAAA;AAAA;AAAA;AAAA;AACA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAIA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;AAGA;;AAZA;AAAA;AAAA;;;AAqBA;;;AA5BA;AAAA;AAAA;;AA+BA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;;AAMA;;AATA;AAAA;AAAA;;AAnCA;AAAA;AAAA;;AAgDA;AAAA;;;;;;;;;;AAj+BA;AAAA;AAAA;AAAA;;;;;;;;;;AAzzQA;;;AACA;;;;AACA;AAAA;AAAA;;;;AACA;AAAA;AAAA;;;;AACA;AAAA;AAAA;;;;AACA;AAAA;AAAA;;;;AACA;AAAA;AAAA;;;;AAEA;AAAA;;;AAGA;AAAA;;;;;;;;;;;;;;;;;;;;AAmiPA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAEA;AACA;;AAAA;AAAA;;;;;AACA;AAAA;;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;;;;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;AACA;;AAIA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;AAIA;AACA;;AAAA;AAAA;AAAA;;;;AAEA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAbA;AAAA;AAAA;;AAgBA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;;AA7CA;AAAA;AAAA;;;AAEA;AAAA;;;AA2CA;AAAA;;;AAEA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;AA3mRA;;AAAA;AAAA;;;;;AACA;AAAA;;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;;;;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;;;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AANA;AAAA;AAAA;;AAQA;AAAA;AAAA;AAAA;;;;;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAPA;AAAA;AAAA;;AAbA;AAAA;AAAA;;;AAGA;AAAA;;;AASA;AAAA;;;AAWA;;;;;;;;;;;AAy8BA;AAAA;;AAAA;AAAA;;AACA;AAAA;;;AAIA;AAAA;AAEA;AAAA;AAAA;AAKA;;AAFA;AAEA;;;;;;;;;AA8hNA;;;AACA;;;;AACA;;;;AACA;;;;AACA;AAAA;;;AAEA;AAAA;;;;;;;;AAhiNA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAEA;AAAA;;;;AAGA;AAAA;;;;;;;;;;;AAuySA;AAAA;;AAAA;AAAA;;AACA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;;AAAA;AAAA;;;;;;AACA;AAAA;AAAA;AACA;AAAA;AAAA;;AAGA;AAAA;AAAA;AAAA;AAAA;;AALA;AAAA;AAAA;;AAOA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AAoBA;AAAA;;AAnBA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;;AAGA;AAAA;AAAA;AACA;AAAA;AAAA;;;;;;AAPA;AAAA;AAAA;;;AAOA;AAAA;;;AAUA;AAAA;;;;;;;;;;;;;;AA7+BA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AApuBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AADA;AAAA;AAEA;AAAA;AAAA;AAAA;AAFA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAHA;AAMA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AAGA;AAEA;AACA;;AACA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;;;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;;;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;AAVA;AAAA;AAAA;;AAaA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAzBA;AAAA;AAAA;;AA4BA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAGA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AADA;AAAA;AAAA;;AAKA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAEA;;AAHA;AAAA;;;;;;;;;;;;;;;AA5sRA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AADA;AAAA;AAAA;;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AAAA;AAAA;;AAGA;;;;;;;;AAyhPA;AAAA;AAAA;AAAA;;;;;;;;AAIA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAIA;AAAA;;;;AAGA;AAAA;;;;;;;;AA7BA;AAAA;AAAA;AAAA;;;;;;;;AA2CA;AAAA;AAAA;AAAA;;;;;;;;AAIA;;;AACA;;;;AACA;;;;AACA;;;;AACA;AAAA;;;AAEA;AAAA;;;;;;;;AAsFA;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;AAAA;;;AAEA;AAAA;;;;;;;;AAGA;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;AAAA;;;AAEA;AAAA;;;;;;;;AAGA;;;AACA;;;;AACA;;;;AACA;;;;AACA;AAAA;;;AAEA;AAAA;;;;;;;;AAGA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AAEA;;;;AACA;;;;AAEA;AAAA;;;;AAEA;AAAA;;;;;;;;;AAGA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;;AAGA;AAAA;;AAFA;AAAA;AAAA;AAEA;AAAA;;;;;;;;AApLA;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;AAAA;;;AAEA;AAAA;;;;;;;;;;;AAqsEA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AADA;AAAA;;;;;;;;;;;;;AAKA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AADA;AAAA;;;;;;;;;;;;;AAKA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AADA;AAAA;;;;;;;;;;;;;AAKA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AADA;AAAA;;;;;;;;;;;;;AAKA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AADA;AAAA;;;;;;;;;;AA/7CA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;;AAGA;;AAFA;AAAA;AAEA;;;;;;;;;;AA6GA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;AAAA;;AAKA;AAAA;AAAA;AAAA;AACA;;AALA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AACA;;;;;;;;;AAsFA;AAAA;;AAAA;AAAA;;AACA;;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;;AAEA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;AARA;AAAA;AAAA;;AAWA;;;;;;;;AAgIA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAIA;;AAHA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;;;;;;;;;;;AA8DA;AAAA;;AAAA;AAAA;;AACA;;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;AACA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAPA;AAAA;AAAA;;AAUA;AAAA;AAAA;AAAA;;AAIA;;AAHA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAeA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;AAEA;AAAA;;AAAA;AAAA;;AACA;AAAA;;;AAEA;AAEA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAVA;AAAA;AAAA;;AAaA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;;;AAKA;AAAA;;AAAA;AAAA;;;AAAA;AAAA;AAAA;;;AAAA;AACA;AAAA;;AAAA;AAAA;;;AAAA;AAAA;AAAA;;;AAAA;AACA;AAAA;;AAAA;AAAA;;;AAAA;AAAA;AAAA;;;AAAA;AAGA;AAEA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAEA;AACA;AAAA;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;;;AANA;AAAA;;;;AAQA;AAAA;;AAGA;AAEA;AAFA;AAKA;;AARA;AAAA;;;;;;;;;AAt7CA;;;AAGA;;;;AAEA;;;;AAEA;AAAA;;;AAGA;AAAA;;;;;;;;AAq7DA;AAAA;AAAA;;;;;;;;AA3lBA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AADA;AAAA;;;;;;;;;;;;AAPA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAFA;AAAA;;;;;;;;;;;AAwLA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;;AAPA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAuCA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAGA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAIA;;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADA;AAAA;AAAA;;AAKA;AAAA;;;AACA;AAAA;;AACA;;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;;AAHA;AAAA;;;AAMA;AAAA;AAAA;;;AAEA;AAAA;;AAWA;AAAA;AAAA;AAEA;;AAZA;AAAA;;AACA;;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAKA;;;;;;;;;;;;;;;;;AAtEA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AAEA;AACA;;AAAA;AAAA;AAAA;;;;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AANA;AAAA;AAAA;;AASA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;;AACA;AAAA;;AADA;AAAA;;;;;;;;;;;;;;;;;;;;AAuDA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAEA;AAFA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;;AAXA;AAAA;;;;;;;;;;;;;AAcA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;;;;;;AACA;AAKA;;AAFA;AAEA;;;;;;AA7MA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;;AALA;AAAA;;;;;;;;;;;AAQA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AAGA;AACA;AAKA;AACA;AAAA;AAAA;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AACA;AAEA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;;AACA;AAAA;AACA;AAEA;AAAA;AAEA;AAAA;AACA;AAAA;AAAA;AAIA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAGA;AACA;AACA;;AAlBA;AAAA;;;;;;;;AAt9BA;AAAA;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;;AAIA;;AAHA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAEA;;;;;;AA6OA;AAAA;AACA;AAAA;AAAA;AAAA;;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AACA;;AAHA;AAAA;;;;;;;;;;AGn3VA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;;AAJA;AAAA;;;;;;AAOA;AAAA;;;;;AAIA;AAAA;;;;;;AA0CA;AADA;AAAA;AAAA;AAAA;AAEA;AAFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAHA;;;;;;AATA;;;AACA;;;;AACA;;;;AAEA;;;AAEA;AAAA;;;;;;;;AAlCA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AACA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAMA;AAAA;;AAHA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAEA;AAAA;;;;;;;;;;AAGA;AAAA;;AAAA;AAAA;;AACA;AAAA;;AAKA;AAEA;AAAA;;AANA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAKA;AAAA;;;;;;;;AAGA;AAAA;;AACA;AAAA;;AADA;AAAA;;;;;;;;;;;;AA4BA;AAAA;;AAAA;AAAA;;AACA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AADA;AAAA;AAEA;AAFA;AAAA;AAAA;AAHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAWA;AAXA;AAaA;AAAA;AAAA;AACA;AAAA;AAAA;AAGA;AAAA;;AAiBA;;AAhBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AADA;AAAA;AAEA;AAFA;AAAA;AAAA;AAHA;AAAA;AAAA;AASA;AATA;AAAA;AAAA;AAAA;AAWA;AAXA;AAaA;AAAA;AAAA;AACA;AAAA;AAAA;AAEA;;;;;AAGA;AAAA;;AACA;AAAA;;AAEA;AAAA;AAAA;AACA;;;;;;;;;;;;;AChGA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AACA;;;;;AAGA;;;;;;;;AAmDA;AACA;AACA;AACA;;;;;;;;;AA1EA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;;;;;;;;;;;;AAGA;AACA;;;;;;;;;;;;;AAqCA;;;AAEA;AACA;AACA;;;;AAIA;AAAA;;AACA;AACA;AACA;AAAA;AACA;;;;;AAIA;AACA;AACA;AAAA;;;;;;AAGA","file":"_out/Web_Emsc_Debug/App.html","sourcesContent":["/*\r\n  HandmadeMath.h v1.2.0\r\n  \r\n  This is a single header file with a bunch of useful functions for\r\n  basic game math operations.\r\n  \r\n  =============================================================================\r\n  \r\n  You MUST\r\n  \r\n     #define HANDMADE_MATH_IMPLEMENTATION\r\n     \r\n  in EXACTLY one C or C++ file that includes this header, BEFORE the\r\n  include, like this:\r\n  \r\n     #define HANDMADE_MATH_IMPLEMENTATION\r\n     #include \"HandmadeMath.h\"\r\n     \r\n  All other files should just #include \"HandmadeMath.h\" without the #define.\r\n  \r\n  =============================================================================\r\n  \r\n  For overloaded and operator overloaded versions of the base C functions,\r\n  you MUST\r\n  \r\n     #define HANDMADE_MATH_CPP_MODE\r\n     \r\n  in EXACTLY one C or C++ file that includes this header, BEFORE the\r\n  include, like this:\r\n  \r\n     #define HANDMADE_MATH_IMPLEMENTATION\r\n     #define HANDMADE_MATH_CPP_MODE\r\n     #include \"HandmadeMath.h\"\r\n     \r\n  All other files should just #include \"HandmadeMath.h\" without the #define.\r\n  \r\n  =============================================================================\r\n  \r\n  To disable SSE intrinsics, you MUST\r\n  \r\n  #define HANDMADE_MATH_NO_SSE\r\n  \r\n  in EXACTLY one C or C++ file that includes this header, BEFORE the\r\n  include, like this:\r\n  \r\n     #define HANDMADE_MATH_IMPLEMENTATION\r\n     #define HANDMADE_MATH_CPP_MODE\r\n     #define HANDMADE_MATH_NO_SSE\r\n     #include \"HandmadeMath.h\"\r\n     \r\n     or\r\n     \r\n     #define HANDMADE_MATH_IMPLEMENTATION\r\n     #define HANDMADE_MATH_NO_SSE\r\n     #include \"HandmadeMath.h\"\r\n     \r\n  =============================================================================\r\n  \r\n  To disable inlining functions, you MUST\r\n  \r\n  #define HANDMADE_MATH_NO_INLINE\r\n  \r\n  in EXACTLY one C or C++ file that includes this header, BEFORE the\r\n  include, like this:\r\n  \r\n     #define HANDMADE_MATH_IMPLEMENTATION\r\n     #define HANDMADE_MATH_CPP_MODE\r\n     #define HANDMADE_MATH_NO_INLINE\r\n     #include \"HandmadeMath.h\"\r\n     \r\n  All other files should just #include \"HandmadeMath.h\" without the #define.\r\n  \r\n  =============================================================================\r\n  \r\n  To use HandmadeMath without the CRT, you MUST \r\n  \r\n     #define HMM_SINF MySinF\r\n     #define HMM_COSF MyCosF\r\n     #define HMM_TANF MyTanF\r\n     #define HMM_SQRTF MySqrtF\r\n     #define HMM_EXPF MyExpF\r\n     #define HMM_LOGF MyLogF\r\n     #define HMM_ACOSF MyACosF\r\n     #define HMM_ATANF MyATanF\r\n     #define HMM_ATAN2F MYATan2F\r\n     \r\n  Provide your own implementations of SinF, CosF, TanF, ACosF, ATanF, ATan2F, \r\n  ExpF, and LogF in EXACTLY one C or C++ file that includes this header,\r\n  BEFORE the include, like this:     \r\n  \r\n     #define HMM_SINF MySinF\r\n     #define HMM_COSF MyCosF\r\n     #define HMM_TANF MyTanF\r\n     #define HMM_SQRTF MySqrtF\r\n     #define HMM_EXPF MyExpF\r\n     #define HMM_LOGF MyLogF\r\n     #define HMM_ACOSF MyACosF\r\n     #define HMM_ATANF MyATanF\r\n     #define HMM_ATAN2F MyATan2F\r\n     #define HANDMADE_MATH_IMPLEMENTATION\r\n     #define HANDMADE_MATH_CPP_MODE\r\n     #include \"HandmadeMath.h\"\r\n     \r\n  If you do not define all five of these, HandmadeMath.h will use the\r\n  versions of these functions that are provided by the CRT.\r\n  \r\n  =============================================================================\r\n  \r\n  Version History:\r\n      0.2 (*) Updated documentation\r\n          (*) Better C compliance\r\n          (*) Prefix all handmade math functions \r\n          (*) Better operator overloading\r\n      0.2a\r\n          (*) Prefixed Macros\r\n      0.2b\r\n          (*) Disabled warning 4201 on MSVC as it is legal is C11\r\n          (*) Removed the f at the end of HMM_PI to get 64bit precision\r\n      0.3\r\n          (*) Added +=, -=, *=, /= for hmm_vec2, hmm_vec3, hmm_vec4\r\n      0.4\r\n          (*) SSE Optimized HMM_SqrtF\r\n          (*) SSE Optimized HMM_RSqrtF\r\n          (*) Removed CRT\r\n      0.5\r\n          (*) Added scalar multiplication and division for vectors\r\n              and matrices\r\n          (*) Added matrix subtraction and += for hmm_mat4\r\n          (*) Reconciled all headers and implementations\r\n          (*) Tidied up, and filled in a few missing operators\r\n      0.5.1\r\n          (*) Ensured column-major order for matrices throughout\r\n          (*) Fixed HMM_Translate producing row-major matrices\r\n      0.5.2\r\n          (*) Fixed SSE code in HMM_SqrtF\r\n          (*) Fixed SSE code in HMM_RSqrtF\r\n      0.6\r\n          (*) Added Unit testing\r\n          (*) Made HMM_Power faster\r\n          (*) Fixed possible efficiency problem with HMM_Normalize \r\n          (*) RENAMED HMM_LengthSquareRoot to HMM_LengthSquared\r\n          (*) RENAMED HMM_RSqrtF to HMM_RSquareRootF\r\n          (*) RENAMED HMM_SqrtF to HMM_SquareRootF\r\n          (*) REMOVED Inner function (user should use Dot now)\r\n          (*) REMOVED HMM_FastInverseSquareRoot function declaration\r\n      0.7 \r\n          (*) REMOVED HMM_LengthSquared in HANDMADE_MATH_IMPLEMENTATION (should\r\n              use HMM_LengthSquaredVec3, or HANDMADE_MATH_CPP_MODE for function\r\n              overloaded version)\r\n          (*) REMOVED HMM_Length in HANDMADE_MATH_IMPLEMENTATION (should use\r\n              HMM_LengthVec3, HANDMADE_MATH_CPP_MODE for function\r\n              overloaded version)\r\n          (*) REMOVED HMM_Normalize in HANDMADE_MATH_IMPLEMENTATION (should use\r\n              HMM_NormalizeVec3, or HANDMADE_MATH_CPP_MODE for function\r\n              overloaded version)\r\n          (*) Added HMM_LengthSquaredVec2\r\n          (*) Added HMM_LengthSquaredVec4\r\n          (*) Addd HMM_LengthVec2\r\n          (*) Added HMM_LengthVec4\r\n          (*) Added HMM_NormalizeVec2\r\n          (*) Added HMM_NormalizeVec4\r\n     1.0\r\n          (*) Lots of testing!\r\n     1.1\r\n          (*) Quaternion support\r\n          (*) Added type hmm_quaternion\r\n          (*) Added HMM_Quaternion\r\n          (*) Added HMM_QuaternionV4\r\n          (*) Added HMM_AddQuaternion\r\n          (*) Added HMM_SubtractQuaternion\r\n          (*) Added HMM_MultiplyQuaternion\r\n          (*) Added HMM_MultiplyQuaternionF\r\n          (*) Added HMM_DivideQuaternionF\r\n          (*) Added HMM_InverseQuaternion\r\n          (*) Added HMM_DotQuaternion\r\n          (*) Added HMM_NormalizeQuaternion\r\n          (*) Added HMM_Slerp\r\n          (*) Added HMM_QuaternionToMat4\r\n          (*) Added HMM_QuaternionFromAxisAngle\r\n     1.1.1\r\n          (*) Resolved compiler warnings on gcc and g++\r\n     1.1.2\r\n          (*) Fixed invalid HMMDEF's in the function definitions\r\n     1.1.3\r\n          (*) Fixed compile error in C mode\r\n     1.1.4\r\n          (*) Fixed SSE being included on platforms that don't support it\r\n          (*) Fixed divide-by-zero errors when normalizing zero vectors.\r\n     1.1.5\r\n          (*) Add Width and Height to HMM_Vec2\r\n          (*) Made it so you can supply your own SqrtF \r\n     1.2.0\r\n          (*) Added equality functions for HMM_Vec2, HMM_Vec3, and HMM_Vec4.\r\n              (*) Added HMM_EqualsVec2, HMM_EqualsVec3, and HMM_EqualsVec4\r\n              (*) Added C++ overloaded HMM_Equals for all three\r\n              (*) Added C++ == and != operators for all three\r\n          (*) SSE'd HMM_MultiplyMat4 (this is _WAY_ faster)\r\n          (*) SSE'd HMM_Transpose\r\n          \r\n  LICENSE\r\n  \r\n  This software is in the public domain. Where that dedication is not\r\n  recognized, you are granted a perpetual, irrevocable license to copy,\r\n  distribute, and modify this file as you see fit.\r\n  \r\n  CREDITS\r\n  \r\n  Written by Zakary Strange (zak@handmade.network && @strangezak)\r\n  \r\n  Functionality:\r\n   Matt Mascarenhas (@miblo_)\r\n   Aleph\r\n   FieryDrake (@fierydrake)\r\n   Gingerbill (@TheGingerBill)\r\n   Ben Visness (@bvisness) \r\n   Trinton Bullard (@Peliex_Dev)\r\n   \r\n  Fixes:\r\n   Jeroen van Rijn (@J_vanRijn)\r\n   Kiljacken (@Kiljacken)\r\n   Insofaras (@insofaras)\r\n   Daniel Gibson (@DanielGibson)\r\n*/\r\n\r\n\r\n/* let's figure out if SSE is really available (unless disabled anyway)\r\n   (it isn't on non-x86/x86_64 platforms or even x86 without explicit SSE support)\r\n   => only use \"#ifdef HANDMADE_MATH__USE_SSE\" to check for SSE support below this block! */\r\n#ifndef HANDMADE_MATH_NO_SSE\r\n\r\n# ifdef _MSC_VER\r\n   /* MSVC supports SSE in amd64 mode or _M_IX86_FP >= 1 (2 means SSE2) */\r\n#  if defined(_M_AMD64) || ( defined(_M_IX86_FP) && _M_IX86_FP >= 1 )\r\n#   define HANDMADE_MATH__USE_SSE 1\r\n#  endif\r\n# else /* not MSVC, probably GCC, clang, icc or something that doesn't support SSE anyway */\r\n#  ifdef __SSE__ /* they #define __SSE__ if it's supported */\r\n#   define HANDMADE_MATH__USE_SSE 1\r\n#  endif /*  __SSE__ */\r\n# endif /* not _MSC_VER */\r\n\r\n#endif /* #ifndef HANDMADE_MATH_NO_SSE */\r\n\r\n#include <stdint.h> // This is for types\r\n\r\n#ifdef HANDMADE_MATH__USE_SSE\r\n#include <xmmintrin.h>\r\n#endif\r\n\r\n#ifndef HANDMADE_MATH_H\r\n#define HANDMADE_MATH_H\r\n\r\n#ifdef _MSC_VER\r\n#pragma warning(disable:4201)\r\n#endif\r\n\r\n#ifdef __clang__\r\n#pragma clang diagnostic push\r\n#pragma clang diagnostic ignored \"-Wgnu-anonymous-struct\"\r\n#endif\r\n\r\n#ifdef __cplusplus\r\nextern \"C\"\r\n{\r\n#endif\r\n\r\n#ifdef HANDMADE_MATH_STATIC\r\n#define HMMDEF static\r\n#else\r\n#define HMMDEF extern\r\n#endif\r\n\r\n#ifdef HANDMADE_MATH_NO_INLINE\r\n#define HINLINE\r\n#elif _MSC_VER && !__INTEL_COMPILER\r\n#define HINLINE __inline\r\n#else\r\n#define HINLINE inline\r\n#endif\r\n\r\n#if !defined(HMM_SINF) || !defined(HMM_COSF) || !defined(HMM_TANF) || \\\r\n    !defined(HMM_SQRTF) || !defined(HMM_EXPF) || !defined(HMM_LOGF) || \\\r\n    !defined(HMM_ACOSF) || !defined(HMM_ATANF)|| !defined(HMM_ATAN2F)\r\n#include <math.h>    \r\n#endif\r\n    \r\n#ifndef HMM_SINF\r\n#define HMM_SINF sinf\r\n#endif    \r\n        \r\n#ifndef HMM_COSF\r\n#define HMM_COSF cosf\r\n#endif    \r\n        \r\n#ifndef HMM_TANF\r\n#define HMM_TANF tanf\r\n#endif        \r\n\r\n#ifndef HMM_SQRTF\r\n#define HMM_SQRTF sqrtf\r\n#endif    \r\n    \r\n#ifndef HMM_EXPF\r\n#define HMM_EXPF expf\r\n#endif\r\n\r\n#ifndef HMM_LOGF\r\n#define HMM_LOGF logf\r\n#endif\r\n\r\n#ifndef HMM_ACOSF\r\n#define HMM_ACOSF acosf\r\n#endif\r\n\r\n#ifndef HMM_ATANF\r\n#define HMM_ATANF atanf\r\n#endif\r\n\r\n#ifndef HMM_ATAN2F\r\n#define HMM_ATAN2F atan2f\r\n#endif\r\n\r\n#define HMM_PI32 3.14159265359f\r\n#define HMM_PI 3.14159265358979323846\r\n\r\n#define HMM_MIN(a, b) (a) > (b) ? (b) : (a)\r\n#define HMM_MAX(a, b) (a) < (b) ? (b) : (a)\r\n#define HMM_ABS(a) ((a) > 0 ? (a) : -(a))\r\n#define HMM_MOD(a, m) ((a) % (m)) >= 0 ? ((a) % (m)) : (((a) % (m)) + (m))\r\n#define HMM_SQUARE(x) ((x) * (x))\r\n\r\ntypedef union hmm_vec2\r\n{\r\n    struct\r\n    {\r\n        float X, Y;\r\n    };\r\n\r\n    struct\r\n    {\r\n        float U, V;\r\n    };\r\n\r\n    struct\r\n    {\r\n        float Left, Right;\r\n    };\r\n    \r\n    struct\r\n    {\r\n        float Width, Height;\r\n    };\r\n\r\n    float Elements[2];\r\n} hmm_vec2;\r\n\r\ntypedef union hmm_vec3\r\n{\r\n    struct\r\n    {\r\n        float X, Y, Z;\r\n    };\r\n\r\n    struct\r\n    {\r\n        float U, V, W;\r\n    };\r\n\r\n    struct\r\n    {\r\n        float R, G, B;\r\n    };\r\n\r\n    struct\r\n    {\r\n        hmm_vec2 XY;\r\n        float Ignored0_;\r\n    };\r\n\r\n    struct\r\n    {\r\n        float Ignored1_;\r\n        hmm_vec2 YZ;\r\n    };\r\n\r\n    struct\r\n    {\r\n        hmm_vec2 UV;\r\n        float Ignored2_;\r\n    };\r\n\r\n    struct\r\n    {\r\n        float Ignored3_;\r\n        hmm_vec2 VW;\r\n    };\r\n\r\n    float Elements[3];\r\n} hmm_vec3;\r\n\r\ntypedef union hmm_vec4\r\n{\r\n    struct\r\n    {\r\n        union\r\n        {\r\n            hmm_vec3 XYZ;\r\n            struct\r\n            {\r\n                float X, Y, Z;\r\n            };\r\n        };\r\n\r\n        float W;\r\n    };\r\n    struct\r\n    {\r\n        union\r\n        {\r\n            hmm_vec3 RGB;\r\n            struct\r\n            {\r\n                float R, G, B;\r\n            };\r\n        };\r\n\r\n        float A;\r\n    };\r\n\r\n    struct\r\n    {\r\n        hmm_vec2 XY;\r\n        float Ignored0_;\r\n        float Ignored1_;\r\n    };\r\n\r\n    struct\r\n    {\r\n        float Ignored2_;\r\n        hmm_vec2 YZ;\r\n        float Ignored3_;\r\n    };\r\n\r\n    struct\r\n    {\r\n        float Ignored4_;\r\n        float Ignored5_;\r\n        hmm_vec2 ZW;\r\n    };\r\n\r\n    float Elements[4];\r\n} hmm_vec4;\r\n\r\ntypedef union hmm_mat4\r\n{\r\n    float Elements[4][4];\r\n    \r\n    \r\n#ifdef HANDMADE_MATH__USE_SSE\r\n    __m128 Rows[4];\r\n#endif\r\n} hmm_mat4;\r\n\r\ntypedef union hmm_quaternion\r\n{\r\n    struct\r\n    {\r\n        union\r\n        {\r\n            hmm_vec3 XYZ;\r\n            struct\r\n            {\r\n                float X, Y, Z;\r\n            };\r\n        };\r\n        \r\n        float W;\r\n    };\r\n    \r\n    float Elements[4];\r\n} hmm_quaternion;\r\n\r\ntypedef int32_t hmm_bool;\r\n\r\ntypedef hmm_vec2 hmm_v2;\r\ntypedef hmm_vec3 hmm_v3;\r\ntypedef hmm_vec4 hmm_v4;\r\ntypedef hmm_mat4 hmm_m4;    \r\n\r\nHMMDEF float HMM_SinF(float Angle);\r\nHMMDEF float HMM_TanF(float Angle);\r\nHMMDEF float HMM_ATanF(float Theta);\r\nHMMDEF float HMM_ATan2F(float Theta, float Theta2);\r\nHMMDEF float HMM_CosF(float Angle);\r\nHMMDEF float HMM_ACosF(float Theta);\r\nHMMDEF float HMM_ExpF(float Float);\r\nHMMDEF float HMM_LogF(float Float);\r\n\r\nHMMDEF float HMM_ToRadians(float Degrees);\r\nHMMDEF float HMM_SquareRootF(float Float);\r\nHMMDEF float HMM_RSquareRootF(float Float);\r\n\r\nHMMDEF float HMM_LengthSquaredVec2(hmm_vec2 A);\r\nHMMDEF float HMM_LengthSquaredVec3(hmm_vec3 A);\r\nHMMDEF float HMM_LengthSquaredVec4(hmm_vec4 A);\r\n\r\nHMMDEF float HMM_LengthVec2(hmm_vec2 A);    \r\nHMMDEF float HMM_LengthVec3(hmm_vec3 A);    \r\nHMMDEF float HMM_LengthVec4(hmm_vec4 A);    \r\n\r\nHMMDEF float HMM_Power(float Base, int Exponent);\r\nHMMDEF float HMM_PowerF(float Base, float Exponent);\r\nHMMDEF float HMM_Lerp(float A, float Time, float B);\r\nHMMDEF float HMM_Clamp(float Min, float Value, float Max);\r\n\r\nHMMDEF hmm_vec2 HMM_NormalizeVec2(hmm_vec2 A);\r\nHMMDEF hmm_vec3 HMM_NormalizeVec3(hmm_vec3 A);\r\nHMMDEF hmm_vec4 HMM_NormalizeVec4(hmm_vec4 A);\r\n\r\nHMMDEF float HMM_DotVec2(hmm_vec2 VecOne, hmm_vec2 VecTwo);\r\nHMMDEF float HMM_DotVec3(hmm_vec3 VecOne, hmm_vec3 VecTwo);\r\nHMMDEF float HMM_DotVec4(hmm_vec4 VecOne, hmm_vec4 VecTwo);\r\n\r\nHMMDEF hmm_vec3 HMM_Cross(hmm_vec3 VecOne, hmm_vec3 VecTwo);\r\n\r\nHMMDEF hmm_vec2 HMM_Vec2(float X, float Y);\r\nHMMDEF hmm_vec2 HMM_Vec2i(int X, int Y);\r\nHMMDEF hmm_vec3 HMM_Vec3(float X, float Y, float Z);\r\nHMMDEF hmm_vec3 HMM_Vec3i(int X, int Y, int Z);\r\nHMMDEF hmm_vec4 HMM_Vec4(float X, float Y, float Z, float W);\r\nHMMDEF hmm_vec4 HMM_Vec4i(int X, int Y, int Z, int W);\r\nHMMDEF hmm_vec4 HMM_Vec4v(hmm_vec3 Vector, float W);\r\n\r\nHMMDEF hmm_vec2 HMM_AddVec2(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 HMM_AddVec3(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 HMM_AddVec4(hmm_vec4 Left, hmm_vec4 Right);\r\n\r\nHMMDEF hmm_vec2 HMM_SubtractVec2(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 HMM_SubtractVec3(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 HMM_SubtractVec4(hmm_vec4 Left, hmm_vec4 Right);\r\n\r\nHMMDEF hmm_vec2 HMM_MultiplyVec2(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec2 HMM_MultiplyVec2f(hmm_vec2 Left, float Right);\r\nHMMDEF hmm_vec3 HMM_MultiplyVec3(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec3 HMM_MultiplyVec3f(hmm_vec3 Left, float Right);\r\nHMMDEF hmm_vec4 HMM_MultiplyVec4(hmm_vec4 Left, hmm_vec4 Right);\r\nHMMDEF hmm_vec4 HMM_MultiplyVec4f(hmm_vec4 Left, float Right);\r\n\r\nHMMDEF hmm_vec2 HMM_DivideVec2(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec2 HMM_DivideVec2f(hmm_vec2 Left, float Right);\r\nHMMDEF hmm_vec3 HMM_DivideVec3(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec3 HMM_DivideVec3f(hmm_vec3 Left, float Right);\r\nHMMDEF hmm_vec4 HMM_DivideVec4(hmm_vec4 Left, hmm_vec4 Right);\r\nHMMDEF hmm_vec4 HMM_DivideVec4f(hmm_vec4 Left, float Right);\r\n\r\nHMMDEF hmm_bool HMM_EqualsVec2(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_bool HMM_EqualsVec3(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_bool HMM_EqualsVec4(hmm_vec4 Left, hmm_vec4 Right);\r\n\r\nHMMDEF hmm_mat4 HMM_Mat4(void);\r\nHMMDEF hmm_mat4 HMM_Mat4d(float Diagonal);\r\nHMMDEF hmm_mat4 HMM_AddMat4(hmm_mat4 Left, hmm_mat4 Right);\r\nHMMDEF hmm_mat4 HMM_SubtractMat4(hmm_mat4 Left, hmm_mat4 Right);\r\n\r\n#ifdef HANDMADE_MATH__USE_SSE\r\nHMMDEF __m128 HMM_LinearCombineSSE(__m128 Left, hmm_mat4 Right);\r\n#endif \r\n\r\nHMMDEF hmm_mat4 HMM_MultiplyMat4(hmm_mat4 Left, hmm_mat4 Right);\r\nHMMDEF hmm_mat4 HMM_MultiplyMat4f(hmm_mat4 Matrix, float Scalar);\r\nHMMDEF hmm_vec4 HMM_MultiplyMat4ByVec4(hmm_mat4 Matrix, hmm_vec4 Vector);\r\nHMMDEF hmm_mat4 HMM_DivideMat4f(hmm_mat4 Matrix, float Scalar);\r\n\r\nHMMDEF hmm_mat4 HMM_Transpose(hmm_mat4 Matrix);\r\n\r\nHMMDEF hmm_mat4 HMM_Orthographic(float Left, float Right, float Bottom, float Top, float Near, float Far);\r\nHMMDEF hmm_mat4 HMM_Perspective(float FOV, float AspectRatio, float Near, float Far);\r\n\r\nHMMDEF hmm_mat4 HMM_Translate(hmm_vec3 Translation);\r\nHMMDEF hmm_mat4 HMM_Rotate(float Angle, hmm_vec3 Axis);\r\nHMMDEF hmm_mat4 HMM_Scale(hmm_vec3 Scale);\r\n\r\nHMMDEF hmm_mat4 HMM_LookAt(hmm_vec3 Eye, hmm_vec3 Center, hmm_vec3 Up);\r\n\r\nHMMDEF hmm_quaternion HMM_Quaternion(float X, float Y, float Z, float W);\r\nHMMDEF hmm_quaternion HMM_QuaternionV4(hmm_vec4 Vector);\r\nHMMDEF hmm_quaternion HMM_AddQuaternion(hmm_quaternion Left, hmm_quaternion Right);\r\nHMMDEF hmm_quaternion HMM_SubtractQuaternion(hmm_quaternion Left, hmm_quaternion Right);\r\nHMMDEF hmm_quaternion HMM_MultiplyQuaternion(hmm_quaternion Left, hmm_quaternion Right);\r\nHMMDEF hmm_quaternion HMM_MultiplyQuaternionF(hmm_quaternion Left, float Multiplicative);\r\nHMMDEF hmm_quaternion HMM_DivideQuaternionF(hmm_quaternion Left, float Dividend);\r\nHMMDEF hmm_quaternion HMM_InverseQuaternion(hmm_quaternion Left);\r\nHMMDEF float HMM_DotQuaternion(hmm_quaternion Left, hmm_quaternion Right);\r\nHMMDEF hmm_quaternion HMM_NormalizeQuaternion(hmm_quaternion Left);\r\nHMMDEF hmm_quaternion HMM_NLerp(hmm_quaternion Left, float Time, hmm_quaternion Right);\r\nHMMDEF hmm_quaternion HMM_Slerp(hmm_quaternion Left, float Time, hmm_quaternion Right);\r\nHMMDEF hmm_mat4 HMM_QuaternionToMat4(hmm_quaternion Left);\r\nHMMDEF hmm_quaternion HMM_QuaternionFromAxisAngle(hmm_vec3 Axis, float AngleOfRotation);\r\n\r\n#ifdef __cplusplus\r\n}\r\n#endif\r\n\r\n#ifdef HANDMADE_MATH_CPP_MODE\r\n\r\nHMMDEF float HMM_Length(hmm_vec2 A);\r\nHMMDEF float HMM_Length(hmm_vec3 A);\r\nHMMDEF float HMM_Length(hmm_vec4 A);\r\n\r\nHMMDEF float HMM_LengthSquared(hmm_vec2 A);\r\nHMMDEF float HMM_LengthSquared(hmm_vec3 A);\r\nHMMDEF float HMM_LengthSquared(hmm_vec4 A);\r\n\r\nHMMDEF hmm_vec2 HMM_Normalize(hmm_vec2 A);\r\nHMMDEF hmm_vec3 HMM_Normalize(hmm_vec3 A);\r\nHMMDEF hmm_vec4 HMM_Normalize(hmm_vec4 A);\r\nHMMDEF hmm_quaternion HMM_Normalize(hmm_quaternion A);\r\n\r\nHMMDEF float HMM_Dot(hmm_vec2 VecOne, hmm_vec2 VecTwo);\r\nHMMDEF float HMM_Dot(hmm_vec3 VecOne, hmm_vec3 VecTwo);\r\nHMMDEF float HMM_Dot(hmm_vec4 VecOne, hmm_vec4 VecTwo);\r\nHMMDEF float HMM_Dot(hmm_quaternion QuatOne, hmm_quaternion QuatTwo);\r\n\r\nHMMDEF hmm_vec2 HMM_Add(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 HMM_Add(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 HMM_Add(hmm_vec4 Left, hmm_vec4 Right);\r\nHMMDEF hmm_mat4 HMM_Add(hmm_mat4 Left, hmm_mat4 Right);\r\nHMMDEF hmm_quaternion HMM_Add(hmm_quaternion Left, hmm_quaternion Right);\r\n\r\nHMMDEF hmm_vec2 HMM_Subtract(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 HMM_Subtract(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 HMM_Subtract(hmm_vec4 Left, hmm_vec4 Right);\r\nHMMDEF hmm_mat4 HMM_Subtract(hmm_mat4 Left, hmm_mat4 Right);\r\nHMMDEF hmm_quaternion HMM_Subtract(hmm_quaternion Left, hmm_quaternion Right);\r\n\r\nHMMDEF hmm_vec2 HMM_Multiply(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec2 HMM_Multiply(hmm_vec2 Left, float Right);\r\nHMMDEF hmm_vec3 HMM_Multiply(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec3 HMM_Multiply(hmm_vec3 Left, float Right);\r\nHMMDEF hmm_vec4 HMM_Multiply(hmm_vec4 Left, hmm_vec4 Right);\r\nHMMDEF hmm_vec4 HMM_Multiply(hmm_vec4 Left, float Right);\r\nHMMDEF hmm_mat4 HMM_Multiply(hmm_mat4 Left, hmm_mat4 Right);\r\nHMMDEF hmm_mat4 HMM_Multiply(hmm_mat4 Left, float Right);\r\nHMMDEF hmm_vec4 HMM_Multiply(hmm_mat4 Matrix, hmm_vec4 Vector);\r\nHMMDEF hmm_quaternion HMM_Multiply(hmm_quaternion Left, hmm_quaternion Right);\r\nHMMDEF hmm_quaternion HMM_Multiply(hmm_quaternion Left, float Right);\r\n\r\nHMMDEF hmm_vec2 HMM_Divide(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec2 HMM_Divide(hmm_vec2 Left, float Right);\r\nHMMDEF hmm_vec3 HMM_Divide(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec3 HMM_Divide(hmm_vec3 Left, float Right);\r\nHMMDEF hmm_vec4 HMM_Divide(hmm_vec4 Left, hmm_vec4 Right);\r\nHMMDEF hmm_vec4 HMM_Divide(hmm_vec4 Left, float Right);\r\nHMMDEF hmm_mat4 HMM_Divide(hmm_mat4 Left, float Right);\r\nHMMDEF hmm_quaternion HMM_Divide(hmm_quaternion Left, hmm_quaternion Right);\r\nHMMDEF hmm_quaternion HMM_Divide(hmm_quaternion Left, float Right);\r\n\r\nHMMDEF hmm_bool HMM_Equals(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_bool HMM_Equals(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_bool HMM_Equals(hmm_vec4 Left, hmm_vec4 Right);\r\n\r\nHMMDEF hmm_vec2 operator+(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 operator+(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 operator+(hmm_vec4 Left, hmm_vec4 Right);\r\nHMMDEF hmm_mat4 operator+(hmm_mat4 Left, hmm_mat4 Right);\r\nHMMDEF hmm_quaternion operator+(hmm_quaternion Left, hmm_quaternion Right);\r\n\r\nHMMDEF hmm_vec2 operator-(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 operator-(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 operator-(hmm_vec4 Left, hmm_vec4 Right);\r\nHMMDEF hmm_mat4 operator-(hmm_mat4 Left, hmm_mat4 Right);\r\nHMMDEF hmm_quaternion operator-(hmm_quaternion Left, hmm_quaternion Right);\r\n\r\nHMMDEF hmm_vec2 operator*(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 operator*(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 operator*(hmm_vec4 Left, hmm_vec4 Right);\r\nHMMDEF hmm_mat4 operator*(hmm_mat4 Left, hmm_mat4 Right);\r\nHMMDEF hmm_quaternion operator*(hmm_quaternion Left, hmm_quaternion Right);\r\n\r\nHMMDEF hmm_vec2 operator*(hmm_vec2 Left, float Right);\r\nHMMDEF hmm_vec3 operator*(hmm_vec3 Left, float Right);\r\nHMMDEF hmm_vec4 operator*(hmm_vec4 Left, float Right);\r\nHMMDEF hmm_mat4 operator*(hmm_mat4 Left, float Right);\r\nHMMDEF hmm_quaternion operator*(hmm_quaternion Left, float Right);\r\n\r\nHMMDEF hmm_vec2 operator*(float Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 operator*(float Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 operator*(float Left, hmm_vec4 Right);\r\nHMMDEF hmm_mat4 operator*(float Left, hmm_mat4 Right);\r\nHMMDEF hmm_quaternion operator*(float Left, hmm_quaternion Right);\r\n\r\nHMMDEF hmm_vec4 operator*(hmm_mat4 Matrix, hmm_vec4 Vector);\r\n\r\nHMMDEF hmm_vec2 operator/(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 operator/(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 operator/(hmm_vec4 Left, hmm_vec4 Right);\r\n\r\nHMMDEF hmm_vec2 operator/(hmm_vec2 Left, float Right);\r\nHMMDEF hmm_vec3 operator/(hmm_vec3 Left, float Right);\r\nHMMDEF hmm_vec4 operator/(hmm_vec4 Left, float Right);\r\nHMMDEF hmm_mat4 operator/(hmm_mat4 Left, float Right);\r\nHMMDEF hmm_quaternion operator/(hmm_quaternion Left, float Right);\r\n\r\nHMMDEF hmm_vec2 &operator+=(hmm_vec2 &Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 &operator+=(hmm_vec3 &Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 &operator+=(hmm_vec4 &Left, hmm_vec4 Right);\r\nHMMDEF hmm_mat4 &operator+=(hmm_mat4 &Left, hmm_mat4 Right);\r\nHMMDEF hmm_quaternion &operator+=(hmm_quaternion &Left, hmm_quaternion Right);\r\n\r\nHMMDEF hmm_vec2 &operator-=(hmm_vec2 &Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 &operator-=(hmm_vec3 &Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 &operator-=(hmm_vec4 &Left, hmm_vec4 Right);\r\nHMMDEF hmm_mat4 &operator-=(hmm_mat4 &Left, hmm_mat4 Right);\r\nHMMDEF hmm_quaternion &operator-=(hmm_quaternion &Left, hmm_quaternion Right);\r\n\r\nHMMDEF hmm_vec2 &operator*=(hmm_vec2 &Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 &operator*=(hmm_vec3 &Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 &operator*=(hmm_vec4 &Left, hmm_vec4 Right);\r\n\r\nHMMDEF hmm_vec2 &operator*=(hmm_vec2 &Left, float Right);\r\nHMMDEF hmm_vec3 &operator*=(hmm_vec3 &Left, float Right);\r\nHMMDEF hmm_vec4 &operator*=(hmm_vec4 &Left, float Right);\r\nHMMDEF hmm_mat4 &operator*=(hmm_mat4 &Left, float Right);\r\nHMMDEF hmm_quaternion &operator*=(hmm_quaternion &Left, float Right);\r\n\r\nHMMDEF hmm_vec2 &operator/=(hmm_vec2 &Left, hmm_vec2 Right);\r\nHMMDEF hmm_vec3 &operator/=(hmm_vec3 &Left, hmm_vec3 Right);\r\nHMMDEF hmm_vec4 &operator/=(hmm_vec4 &Left, hmm_vec4 Right);\r\n\r\nHMMDEF hmm_vec2 &operator/=(hmm_vec2 &Left, float Right);\r\nHMMDEF hmm_vec3 &operator/=(hmm_vec3 &Left, float Right);\r\nHMMDEF hmm_vec4 &operator/=(hmm_vec4 &Left, float Right);\r\nHMMDEF hmm_mat4 &operator/=(hmm_mat4 &Left, float Right);\r\nHMMDEF hmm_quaternion &operator/=(hmm_quaternion &Left, float Right);\r\n\r\nHMMDEF hmm_bool operator==(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_bool operator==(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_bool operator==(hmm_vec4 Left, hmm_vec4 Right);\r\n\r\nHMMDEF hmm_bool operator!=(hmm_vec2 Left, hmm_vec2 Right);\r\nHMMDEF hmm_bool operator!=(hmm_vec3 Left, hmm_vec3 Right);\r\nHMMDEF hmm_bool operator!=(hmm_vec4 Left, hmm_vec4 Right);\r\n\r\n#endif /* HANDMADE_MATH_CPP */\r\n\r\n#ifdef __clang__\r\n#pragma clang diagnostic pop\r\n#endif\r\n\r\n#endif /* HANDMADE_MATH_H */\r\n\r\n#ifdef HANDMADE_MATH_IMPLEMENTATION\r\n\r\n#ifdef __clang__\r\n#pragma clang diagnostic push\r\n#pragma clang diagnostic ignored \"-Wmissing-field-initializers\"\r\n#pragma clang diagnostic ignored \"-Wmissing-braces\"\r\n#endif\r\n\r\nHINLINE float\r\nHMM_SinF(float Angle)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = HMM_SINF(Angle);\r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_CosF(float Angle)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = HMM_COSF(Angle);\r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_TanF(float Radians)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = HMM_TANF(Radians);\r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_ACosF(float Radians)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = HMM_ACOSF(Radians);\r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_ATanF(float Radians)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = HMM_ATANF(Radians);\r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_Atan2F(float Left, float Right)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = HMM_ATAN2F(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_ExpF(float Float)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = HMM_EXPF(Float);\r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_LogF(float Float)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = HMM_LOGF(Float);\r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_ToRadians(float Degrees)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = Degrees * (HMM_PI32 / 180.0f);\r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_SquareRootF(float Value)\r\n{\r\n    float Result = 0.0f;\r\n\r\n#ifdef HANDMADE_MATH__USE_SSE\r\n    __m128 In = _mm_set_ss(Value);\r\n    __m128 Out = _mm_sqrt_ss(In);\r\n    Result = _mm_cvtss_f32(Out);\r\n#else\r\n    Result = HMM_SQRTF(Value);\r\n#endif \r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_RSquareRootF(float Value)\r\n{\r\n    float Result = 0.0f;\r\n\r\n#ifdef HANDMADE_MATH__USE_SSE\r\n    __m128 In = _mm_set_ss(Value);\r\n    __m128 Out = _mm_rsqrt_ss(In);\r\n    Result = _mm_cvtss_f32(Out);\r\n#else\r\n    Result = 1.0f/HMM_SquareRootF(Value);\r\n#endif\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_LengthSquaredVec2(hmm_vec2 A)\r\n{\r\n    float Result = 0.0f;\r\n    \r\n    Result = HMM_DotVec2(A, A);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_LengthSquaredVec3(hmm_vec3 A)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = HMM_DotVec3(A, A);\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE float \r\nHMM_LengthSquaredVec4(hmm_vec4 A)\r\n{\r\n    float Result = 0.0f;\r\n    \r\n    Result = HMM_DotVec4(A, A);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_LengthVec2(hmm_vec2 A)\r\n{\r\n    float Result = 0.0f;\r\n    \r\n    Result = HMM_SquareRootF(HMM_LengthSquaredVec2(A));\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_LengthVec3(hmm_vec3 A)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = HMM_SquareRootF(HMM_LengthSquaredVec3(A));\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE float \r\nHMM_LengthVec4(hmm_vec4 A)\r\n{\r\n    float Result = 0.0f;\r\n    \r\n    Result = HMM_SquareRootF(HMM_LengthSquaredVec4(A));\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_Power(float Base, int Exponent)\r\n{\r\n    float Result = 1.0f;\r\n    float Mul = Exponent < 0 ? 1.f / Base : Base;\r\n    unsigned int X = Exponent < 0 ? -Exponent : Exponent;\r\n    while (X)\r\n    {\r\n        if (X & 1)\r\n        {\r\n            Result *= Mul;\r\n        }\r\n        \r\n        Mul *= Mul;\r\n        X >>= 1;\r\n    }\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_PowerF(float Base, float Exponent)\r\n{\r\n    return HMM_EXPF(Exponent * HMM_LOGF(Base));\r\n}\r\n\r\nHINLINE float\r\nHMM_Lerp(float A, float Time, float B)\r\n{\r\n    float Result = 0;\r\n\r\n    Result = (1.0f - Time) * A + Time * B;\r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_Clamp(float Min, float Value, float Max)\r\n{\r\n    float Result = Value;\r\n\r\n    if(Result < Min)\r\n    {\r\n        Result = Min;\r\n    }\r\n    else if(Result > Max)\r\n    {\r\n        Result = Max;\r\n    }\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_NormalizeVec2(hmm_vec2 A)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    float VectorLength = HMM_LengthVec2(A);\r\n    \r\n    /* NOTE(kiljacken): We need a zero check to not divide-by-zero */\r\n    if (VectorLength != 0.0f)\r\n    {\r\n        Result.X = A.X * (1.0f / VectorLength);\r\n        Result.Y = A.Y * (1.0f / VectorLength);\r\n    }\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_NormalizeVec3(hmm_vec3 A)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    float VectorLength = HMM_LengthVec3(A);\r\n    \r\n    /* NOTE(kiljacken): We need a zero check to not divide-by-zero */\r\n    if (VectorLength != 0.0f)\r\n    {\r\n        Result.X = A.X * (1.0f / VectorLength);\r\n        Result.Y = A.Y * (1.0f / VectorLength);\r\n        Result.Z = A.Z * (1.0f / VectorLength);\r\n    }\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_NormalizeVec4(hmm_vec4 A)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    float VectorLength = HMM_LengthVec4(A);\r\n    \r\n    /* NOTE(kiljacken): We need a zero check to not divide-by-zero */\r\n    if (VectorLength != 0.0f)\r\n    {\r\n        Result.X = A.X * (1.0f / VectorLength);\r\n        Result.Y = A.Y * (1.0f / VectorLength);\r\n        Result.Z = A.Z * (1.0f / VectorLength);\r\n        Result.W = A.W * (1.0f / VectorLength);\r\n    }\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_DotVec2(hmm_vec2 VecOne, hmm_vec2 VecTwo)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = (VecOne.X * VecTwo.X) + (VecOne.Y * VecTwo.Y);\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_DotVec3(hmm_vec3 VecOne, hmm_vec3 VecTwo)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = (VecOne.X * VecTwo.X) + (VecOne.Y * VecTwo.Y) + (VecOne.Z * VecTwo.Z);\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_DotVec4(hmm_vec4 VecOne, hmm_vec4 VecTwo)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = (VecOne.X * VecTwo.X) + (VecOne.Y * VecTwo.Y) + (VecOne.Z * VecTwo.Z) + (VecOne.W * VecTwo.W);\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_Cross(hmm_vec3 VecOne, hmm_vec3 VecTwo)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result.X = (VecOne.Y * VecTwo.Z) - (VecOne.Z * VecTwo.Y);\r\n    Result.Y = (VecOne.Z * VecTwo.X) - (VecOne.X * VecTwo.Z);\r\n    Result.Z = (VecOne.X * VecTwo.Y) - (VecOne.Y * VecTwo.X);\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_Vec2(float X, float Y)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result.X = X;\r\n    Result.Y = Y;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_Vec2i(int X, int Y)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result.X = (float)X;\r\n    Result.Y = (float)Y;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_Vec3(float X, float Y, float Z)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result.X = X;\r\n    Result.Y = Y;\r\n    Result.Z = Z;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_Vec3i(int X, int Y, int Z)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result.X = (float)X;\r\n    Result.Y = (float)Y;\r\n    Result.Z = (float)Z;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_Vec4(float X, float Y, float Z, float W)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result.X = X;\r\n    Result.Y = Y;\r\n    Result.Z = Z;\r\n    Result.W = W;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_Vec4i(int X, int Y, int Z, int W)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result.X = (float)X;\r\n    Result.Y = (float)Y;\r\n    Result.Z = (float)Z;\r\n    Result.W = (float)W;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_Vec4v(hmm_vec3 Vector, float W)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result.XYZ = Vector;\r\n    Result.W = W;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_AddVec2(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result.X = Left.X + Right.X;\r\n    Result.Y = Left.Y + Right.Y;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_AddVec3(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result.X = Left.X + Right.X;\r\n    Result.Y = Left.Y + Right.Y;\r\n    Result.Z = Left.Z + Right.Z;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_AddVec4(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result.X = Left.X + Right.X;\r\n    Result.Y = Left.Y + Right.Y;\r\n    Result.Z = Left.Z + Right.Z;\r\n    Result.W = Left.W + Right.W;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_SubtractVec2(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result.X = Left.X - Right.X;\r\n    Result.Y = Left.Y - Right.Y;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_SubtractVec3(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result.X = Left.X - Right.X;\r\n    Result.Y = Left.Y - Right.Y;\r\n    Result.Z = Left.Z - Right.Z;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_SubtractVec4(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result.X = Left.X - Right.X;\r\n    Result.Y = Left.Y - Right.Y;\r\n    Result.Z = Left.Z - Right.Z;\r\n    Result.W = Left.W - Right.W;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_MultiplyVec2(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result.X = Left.X * Right.X;\r\n    Result.Y = Left.Y * Right.Y;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_MultiplyVec2f(hmm_vec2 Left, float Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result.X = Left.X * Right;\r\n    Result.Y = Left.Y * Right;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_MultiplyVec3(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result.X = Left.X * Right.X;\r\n    Result.Y = Left.Y * Right.Y;\r\n    Result.Z = Left.Z * Right.Z;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_MultiplyVec3f(hmm_vec3 Left, float Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result.X = Left.X * Right;\r\n    Result.Y = Left.Y * Right;\r\n    Result.Z = Left.Z * Right;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_MultiplyVec4(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result.X = Left.X * Right.X;\r\n    Result.Y = Left.Y * Right.Y;\r\n    Result.Z = Left.Z * Right.Z;\r\n    Result.W = Left.W * Right.W;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_MultiplyVec4f(hmm_vec4 Left, float Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result.X = Left.X * Right;\r\n    Result.Y = Left.Y * Right;\r\n    Result.Z = Left.Z * Right;\r\n    Result.W = Left.W * Right;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_DivideVec2(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result.X = Left.X / Right.X;\r\n    Result.Y = Left.Y / Right.Y;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_DivideVec2f(hmm_vec2 Left, float Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result.X = Left.X / Right;\r\n    Result.Y = Left.Y / Right;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_DivideVec3(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result.X = Left.X / Right.X;\r\n    Result.Y = Left.Y / Right.Y;\r\n    Result.Z = Left.Z / Right.Z;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_DivideVec3f(hmm_vec3 Left, float Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result.X = Left.X / Right;\r\n    Result.Y = Left.Y / Right;\r\n    Result.Z = Left.Z / Right;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_DivideVec4(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result.X = Left.X / Right.X;\r\n    Result.Y = Left.Y / Right.Y;\r\n    Result.Z = Left.Z / Right.Z;\r\n    Result.W = Left.W / Right.W;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_DivideVec4f(hmm_vec4 Left, float Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result.X = Left.X / Right;\r\n    Result.Y = Left.Y / Right;\r\n    Result.Z = Left.Z / Right;\r\n    Result.W = Left.W / Right;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_bool\r\nHMM_EqualsVec2(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_bool Result = 0;\r\n\r\n    Result = (Left.X == Right.X && Left.Y == Right.Y);\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_bool\r\nHMM_EqualsVec3(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_bool Result = 0;\r\n\r\n    Result = (Left.X == Right.X && Left.Y == Right.Y && Left.Z == Right.Z);\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_bool\r\nHMM_EqualsVec4(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_bool Result = 0;\r\n\r\n    Result = (Left.X == Right.X && Left.Y == Right.Y && Left.Z == Right.Z && Left.W == Right.W);\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Mat4(void)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Mat4d(float Diagonal)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4();\r\n\r\n    Result.Elements[0][0] = Diagonal;\r\n    Result.Elements[1][1] = Diagonal;\r\n    Result.Elements[2][2] = Diagonal;\r\n    Result.Elements[3][3] = Diagonal;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_AddMat4(hmm_mat4 Left, hmm_mat4 Right)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4();\r\n\r\n    int Columns;\r\n    for(Columns = 0; Columns < 4; ++Columns)\r\n    {\r\n        int Rows;\r\n        for(Rows = 0; Rows < 4; ++Rows)\r\n        {\r\n            Result.Elements[Columns][Rows] = Left.Elements[Columns][Rows] + Right.Elements[Columns][Rows];\r\n        }\r\n    }\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_SubtractMat4(hmm_mat4 Left, hmm_mat4 Right)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4();\r\n\r\n    int Columns;\r\n    for(Columns = 0; Columns < 4; ++Columns)\r\n    {\r\n        int Rows;\r\n        for(Rows = 0; Rows < 4; ++Rows)\r\n        {\r\n            Result.Elements[Columns][Rows] = Left.Elements[Columns][Rows] - Right.Elements[Columns][Rows];\r\n        }\r\n    }\r\n\r\n    return (Result);\r\n}\r\n\r\n#ifdef HANDMADE_MATH__USE_SSE\r\nHINLINE __m128\r\nHMM_LinearCombineSSE(__m128 Left, hmm_mat4 Right)\r\n{\r\n    __m128 Result = {};\r\n    Result = _mm_mul_ps(_mm_shuffle_ps(Left, Left, 0x00), Right.Rows[0]);\r\n    Result = _mm_add_ps(Result, _mm_mul_ps(_mm_shuffle_ps(Left, Left, 0x55), Right.Rows[1]));\r\n    Result = _mm_add_ps(Result, _mm_mul_ps(_mm_shuffle_ps(Left, Left, 0xaa), Right.Rows[2]));\r\n    Result = _mm_add_ps(Result, _mm_mul_ps(_mm_shuffle_ps(Left, Left, 0xff), Right.Rows[3]));\r\n    \r\n    return(Result);\r\n}\r\n#endif\r\n\r\nHINLINE hmm_mat4\r\nHMM_MultiplyMat4(hmm_mat4 Left, hmm_mat4 Right)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4();\r\n\r\n#ifdef HANDMADE_MATH__USE_SSE\r\n    \r\n    hmm_mat4 TransposedLeft = HMM_Transpose(Left);\r\n    hmm_mat4 TransposedRight = HMM_Transpose(Right);\r\n\r\n    Result.Rows[0] = HMM_LinearCombineSSE(TransposedLeft.Rows[0], TransposedRight);\r\n    Result.Rows[1] = HMM_LinearCombineSSE(TransposedLeft.Rows[1], TransposedRight);\r\n    Result.Rows[2] = HMM_LinearCombineSSE(TransposedLeft.Rows[2], TransposedRight);\r\n    Result.Rows[3] = HMM_LinearCombineSSE(TransposedLeft.Rows[3], TransposedRight);       \r\n    \r\n    Result = HMM_Transpose(Result);\r\n    \r\n#else\r\n    int Columns;\r\n    for(Columns = 0; Columns < 4; ++Columns)\r\n    {\r\n        int Rows;\r\n        for(Rows = 0; Rows < 4; ++Rows)\r\n        {\r\n            float Sum = 0;\r\n            int CurrentMatrice;\r\n            for(CurrentMatrice = 0; CurrentMatrice < 4; ++CurrentMatrice)\r\n            {\r\n                Sum += Left.Elements[CurrentMatrice][Rows] * Right.Elements[Columns][CurrentMatrice];\r\n            }\r\n\r\n            Result.Elements[Columns][Rows] = Sum;\r\n        }\r\n    }\r\n#endif \r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_MultiplyMat4f(hmm_mat4 Matrix, float Scalar)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4();\r\n\r\n    int Columns;\r\n    for(Columns = 0; Columns < 4; ++Columns)\r\n    {\r\n        int Rows;\r\n        for(Rows = 0; Rows < 4; ++Rows)\r\n        {\r\n            Result.Elements[Columns][Rows] = Matrix.Elements[Columns][Rows] * Scalar;\r\n        }\r\n    }\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_MultiplyMat4ByVec4(hmm_mat4 Matrix, hmm_vec4 Vector)\r\n{\r\n    hmm_vec4 Result = {0};\r\n    \r\n    int Columns, Rows;\r\n    for(Rows = 0; Rows < 4; ++Rows)\r\n    {\r\n        float Sum = 0;\r\n        for(Columns = 0; Columns < 4; ++Columns)\r\n        {\r\n            Sum += Matrix.Elements[Columns][Rows] * Vector.Elements[Columns];\r\n        }\r\n        \r\n        Result.Elements[Rows] = Sum;\r\n    }\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_DivideMat4f(hmm_mat4 Matrix, float Scalar)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4();\r\n\r\n    int Columns;\r\n    for(Columns = 0; Columns < 4; ++Columns)\r\n    {\r\n        int Rows;\r\n        for(Rows = 0; Rows < 4; ++Rows)\r\n        {\r\n            Result.Elements[Columns][Rows] = Matrix.Elements[Columns][Rows] / Scalar;\r\n        }\r\n    }\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Transpose(hmm_mat4 Matrix)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4();\r\n\r\n#ifdef HANDMADE_MATH__USE_SSE\r\n    Result = Matrix;\r\n    \r\n    _MM_TRANSPOSE4_PS(Result.Rows[0], Result.Rows[1], Result.Rows[2], Result.Rows[3]);    \r\n#else \r\n    int Columns;\r\n    for(Columns = 0; Columns < 4; ++Columns)\r\n    {\r\n        int Rows;\r\n        for(Rows = 0; Rows < 4; ++Rows)\r\n        {\r\n            Result.Elements[Rows][Columns] = Matrix.Elements[Columns][Rows];\r\n        }\r\n    }\r\n#endif \r\n        \r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Orthographic(float Left, float Right, float Bottom, float Top, float Near, float Far)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4d(1.0f);\r\n\r\n    Result.Elements[0][0] = 2.0f / (Right - Left);\r\n    Result.Elements[1][1] = 2.0f / (Top - Bottom);\r\n    Result.Elements[2][2] = 2.0f / (Near - Far);\r\n\r\n    Result.Elements[3][0] = (Left + Right) / (Left - Right);\r\n    Result.Elements[3][1] = (Bottom + Top) / (Bottom - Top);\r\n    Result.Elements[3][2] = (Far + Near) / (Near - Far);\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Perspective(float FOV, float AspectRatio, float Near, float Far)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4d(1.0f);\r\n\r\n    float TanThetaOver2 = HMM_TanF(FOV * (HMM_PI32 / 360.0f));\r\n    \r\n    Result.Elements[0][0] = 1.0f / TanThetaOver2;\r\n    Result.Elements[1][1] = AspectRatio / TanThetaOver2;\r\n    Result.Elements[2][3] = -1.0f;\r\n    Result.Elements[2][2] = (Near + Far) / (Near - Far);\r\n    Result.Elements[3][2] = (2.0f * Near * Far) / (Near - Far);\r\n    Result.Elements[3][3] = 0.0f;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Translate(hmm_vec3 Translation)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4d(1.0f);\r\n\r\n    Result.Elements[3][0] = Translation.X;\r\n    Result.Elements[3][1] = Translation.Y;\r\n    Result.Elements[3][2] = Translation.Z;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Rotate(float Angle, hmm_vec3 Axis)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4d(1.0f);\r\n    \r\n    Axis = HMM_NormalizeVec3(Axis);\r\n    \r\n    float SinTheta = HMM_SinF(HMM_ToRadians(Angle));\r\n    float CosTheta = HMM_CosF(HMM_ToRadians(Angle));\r\n    float CosValue = 1.0f - CosTheta;\r\n    \r\n    Result.Elements[0][0] = (Axis.X * Axis.X * CosValue) + CosTheta;\r\n    Result.Elements[0][1] = (Axis.X * Axis.Y * CosValue) + (Axis.Z * SinTheta);\r\n    Result.Elements[0][2] = (Axis.X * Axis.Z * CosValue) - (Axis.Y * SinTheta);\r\n    \r\n    Result.Elements[1][0] = (Axis.Y * Axis.X * CosValue) - (Axis.Z * SinTheta);\r\n    Result.Elements[1][1] = (Axis.Y * Axis.Y * CosValue) + CosTheta;\r\n    Result.Elements[1][2] = (Axis.Y * Axis.Z * CosValue) + (Axis.X * SinTheta);\r\n    \r\n    Result.Elements[2][0] = (Axis.Z * Axis.X * CosValue) + (Axis.Y * SinTheta);\r\n    Result.Elements[2][1] = (Axis.Z * Axis.Y * CosValue) - (Axis.X * SinTheta);\r\n    Result.Elements[2][2] = (Axis.Z * Axis.Z * CosValue) + CosTheta;\r\n    \r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Scale(hmm_vec3 Scale)\r\n{\r\n    hmm_mat4 Result = HMM_Mat4d(1.0f);\r\n\r\n    Result.Elements[0][0] = Scale.X;\r\n    Result.Elements[1][1] = Scale.Y;\r\n    Result.Elements[2][2] = Scale.Z;\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_LookAt(hmm_vec3 Eye, hmm_vec3 Center, hmm_vec3 Up)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    hmm_vec3 F = HMM_NormalizeVec3(HMM_SubtractVec3(Center, Eye));\r\n    hmm_vec3 S = HMM_NormalizeVec3(HMM_Cross(F, Up));\r\n    hmm_vec3 U = HMM_Cross(S, F);\r\n\r\n    Result.Elements[0][0] = S.X;\r\n    Result.Elements[0][1] = U.X;\r\n    Result.Elements[0][2] = -F.X;\r\n\r\n    Result.Elements[1][0] = S.Y;\r\n    Result.Elements[1][1] = U.Y;\r\n    Result.Elements[1][2] = -F.Y;\r\n\r\n    Result.Elements[2][0] = S.Z;\r\n    Result.Elements[2][1] = U.Z;\r\n    Result.Elements[2][2] = -F.Z;\r\n\r\n    Result.Elements[3][0] = -HMM_DotVec3(S, Eye);\r\n    Result.Elements[3][1] = -HMM_DotVec3(U, Eye);\r\n    Result.Elements[3][2] = HMM_DotVec3(F, Eye);\r\n    Result.Elements[3][3] = 1.0f;\r\n\r\n    return (Result);\r\n}\r\n\r\n\r\nHINLINE hmm_quaternion \r\nHMM_Quaternion(float X, float Y, float Z, float W)\r\n{\r\n    hmm_quaternion Result = {0};\r\n    \r\n    Result.X = X;\r\n    Result.Y = Y;\r\n    Result.Z = Z;\r\n    Result.W = W;\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion \r\nHMM_QuaternionV4(hmm_vec4 Vector)\r\n{\r\n    hmm_quaternion Result = {0};\r\n    \r\n    Result.X = Vector.X;\r\n    Result.Y = Vector.Y;\r\n    Result.Z = Vector.Z;\r\n    Result.W = Vector.W;\r\n    \r\n    return(Result);    \r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_AddQuaternion(hmm_quaternion Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result.X = Left.X + Right.X;\r\n    Result.Y = Left.Y + Right.Y;\r\n    Result.Z = Left.Z + Right.Z;\r\n    Result.W = Left.W + Right.W;\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_SubtractQuaternion(hmm_quaternion Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result.X = Left.X - Right.X;\r\n    Result.Y = Left.Y - Right.Y;\r\n    Result.Z = Left.Z - Right.Z;\r\n    Result.W = Left.W - Right.W;\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_MultiplyQuaternion(hmm_quaternion Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result.X = (Left.X * Right.W) + (Left.Y * Right.Z) - (Left.Z * Right.Y) + (Left.W * Right.X);\r\n    Result.Y = (-Left.X * Right.Z) + (Left.Y * Right.W) + (Left.Z * Right.X) + (Left.W * Right.Y);\r\n    Result.Z = (Left.X * Right.Y) - (Left.Y * Right.X) + (Left.Z * Right.W) + (Left.W * Right.Z);\r\n    Result.W = (-Left.X * Right.X) - (Left.Y * Right.Y) - (Left.Z * Right.Z) + (Left.W * Right.W);\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_MultiplyQuaternionF(hmm_quaternion Left, float Multiplicative)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result.X = Left.X * Multiplicative;\r\n    Result.Y = Left.Y * Multiplicative;\r\n    Result.Z = Left.Z * Multiplicative;\r\n    Result.W = Left.W * Multiplicative;\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_DivideQuaternionF(hmm_quaternion Left, float Dividend)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result.X = Left.X / Dividend;\r\n    Result.Y = Left.Y / Dividend;\r\n    Result.Z = Left.Z / Dividend;\r\n    Result.W = Left.W / Dividend;\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_InverseQuaternion(hmm_quaternion Left)\r\n{\r\n    hmm_quaternion Conjugate = {0};\r\n    hmm_quaternion Result = {0};\r\n    float Norm = 0;\r\n    float NormSquared = 0;\r\n\r\n    Conjugate.X = -Left.X;\r\n    Conjugate.Y = -Left.Y;\r\n    Conjugate.Z = -Left.Z;\r\n    Conjugate.W = Left.W;\r\n\r\n    Norm = HMM_SquareRootF(HMM_DotQuaternion(Left, Left));\r\n    NormSquared = Norm * Norm;\r\n\r\n    Result.X = Conjugate.X / NormSquared;\r\n    Result.Y = Conjugate.Y / NormSquared;\r\n    Result.Z = Conjugate.Z / NormSquared;\r\n    Result.W = Conjugate.W / NormSquared;\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_DotQuaternion(hmm_quaternion Left, hmm_quaternion Right)\r\n{\r\n    float Result = 0.0f;\r\n\r\n    Result = (Left.X * Right.X) + (Left.Y * Right.Y) + (Left.Z * Right.Z) + (Left.W * Right.W);\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_NormalizeQuaternion(hmm_quaternion Left)\r\n{\r\n    hmm_quaternion Result;\r\n\r\n    float Length = HMM_SquareRootF(HMM_DotQuaternion(Left, Left));\r\n    Result = HMM_DivideQuaternionF(Left, Length);\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_NLerp(hmm_quaternion Left, float Time, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result.X = HMM_Lerp(Left.X, Time, Right.X);\r\n    Result.Y = HMM_Lerp(Left.Y, Time, Right.Y);\r\n    Result.Z = HMM_Lerp(Left.Z, Time, Right.Z);\r\n    Result.W = HMM_Lerp(Left.W, Time, Right.W);\r\n\r\n    Result = HMM_NormalizeQuaternion(Result);\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_Slerp(hmm_quaternion Left, float Time, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result;\r\n    hmm_quaternion QuaternionLeft;\r\n    hmm_quaternion QuaternionRight;\r\n\r\n    float Cos_Theta = HMM_DotQuaternion(Left, Right);\r\n    float Angle = HMM_ACosF(Cos_Theta);\r\n    \r\n    float S1 = HMM_SinF((1.0f - Time) * Angle);\r\n    float S2 = HMM_SinF(Time * Angle);\r\n    float Is = 1.0f / HMM_SinF(Angle);\r\n\r\n    QuaternionLeft = HMM_MultiplyQuaternionF(Left, S1);\r\n    QuaternionRight = HMM_MultiplyQuaternionF(Right, S2);\r\n\r\n    Result = HMM_AddQuaternion(QuaternionLeft, QuaternionRight);\r\n    Result = HMM_MultiplyQuaternionF(Result, Is);\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_QuaternionToMat4(hmm_quaternion Left)\r\n{\r\n    hmm_mat4 Result;\r\n    Result = HMM_Mat4d(1);\r\n\r\n    hmm_quaternion NormalizedQuaternion = HMM_NormalizeQuaternion(Left);\r\n    \r\n    float XX, YY, ZZ,\r\n          XY, XZ, YZ,\r\n          WX, WY, WZ;\r\n\r\n    XX = NormalizedQuaternion.X * NormalizedQuaternion.X;\r\n    YY = NormalizedQuaternion.Y * NormalizedQuaternion.Y;\r\n    ZZ = NormalizedQuaternion.Z * NormalizedQuaternion.Z;\r\n    XY = NormalizedQuaternion.X * NormalizedQuaternion.Y;\r\n    XZ = NormalizedQuaternion.X * NormalizedQuaternion.Z;\r\n    YZ = NormalizedQuaternion.Y * NormalizedQuaternion.Z;\r\n    WX = NormalizedQuaternion.W * NormalizedQuaternion.X;\r\n    WY = NormalizedQuaternion.W * NormalizedQuaternion.Y;\r\n    WZ = NormalizedQuaternion.W * NormalizedQuaternion.Z;\r\n\r\n    Result.Elements[0][0] = 1.0f - 2.0f * (YY + ZZ);\r\n    Result.Elements[0][1] = 2.0f * (XY + WZ);\r\n    Result.Elements[0][2] = 2.0f * (XZ - WY);\r\n\r\n    Result.Elements[1][0] = 2.0f * (XY - WZ);\r\n    Result.Elements[1][1] = 1.0f - 2.0f * (XX + ZZ);\r\n    Result.Elements[1][2] = 2.0f * (YZ + WX);\r\n\r\n    Result.Elements[2][0] = 2.0f * (XZ + WY);\r\n    Result.Elements[2][1] = 2.0f * (YZ - WX);\r\n    Result.Elements[2][2] = 1.0f - 2.0f * (XX + YY);\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_QuaternionFromAxisAngle(hmm_vec3 Axis, float AngleOfRotation)\r\n{\r\n    hmm_quaternion Result = {0};\r\n    float AxisNorm = 0;\r\n    float SineOfRotation = 0;\r\n    hmm_vec3 RotatedVector;\r\n\r\n    AxisNorm = HMM_SquareRootF(HMM_DotVec3(Axis, Axis));\r\n    SineOfRotation = HMM_SinF(AngleOfRotation / 2.0f);\r\n    RotatedVector = HMM_MultiplyVec3f(Axis, SineOfRotation);\r\n\r\n    Result.W = HMM_CosF(AngleOfRotation / 2.0f);\r\n    Result.XYZ = HMM_DivideVec3f(RotatedVector, AxisNorm);\r\n\r\n    return(Result);\r\n}\r\n\r\n#ifdef HANDMADE_MATH_CPP_MODE\r\n\r\nHINLINE float \r\nHMM_Length(hmm_vec2 A)\r\n{\r\n    float Result = 0.0f;\r\n    \r\n    Result = HMM_LengthVec2(A);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float \r\nHMM_Length(hmm_vec3 A)\r\n{\r\n    float Result = 0.0f;\r\n    \r\n    Result = HMM_LengthVec3(A);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float \r\nHMM_Length(hmm_vec4 A)\r\n{\r\n    float Result = 0.0f;\r\n    \r\n    Result = HMM_LengthVec4(A);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float \r\nHMM_LengthSquared(hmm_vec2 A)\r\n{\r\n    float Result = 0.0f;\r\n    \r\n    Result = HMM_LengthSquaredVec2(A);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float \r\nHMM_LengthSquared(hmm_vec3 A)\r\n{\r\n    float Result = 0.0f;\r\n    \r\n    Result = HMM_LengthSquaredVec3(A);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float \r\nHMM_LengthSquared(hmm_vec4 A)\r\n{\r\n    float Result = 0.0f;\r\n    \r\n    Result = HMM_LengthSquaredVec4(A);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_vec2 \r\nHMM_Normalize(hmm_vec2 A)\r\n{\r\n    hmm_vec2 Result = {0};\r\n    \r\n    Result = HMM_NormalizeVec2(A);    \r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_vec3 \r\nHMM_Normalize(hmm_vec3 A)\r\n{\r\n    hmm_vec3 Result = {0};\r\n    \r\n    Result = HMM_NormalizeVec3(A);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_vec4 \r\nHMM_Normalize(hmm_vec4 A)\r\n{\r\n    hmm_vec4 Result = {0};\r\n    \r\n    Result = HMM_NormalizeVec4(A);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_Normalize(hmm_quaternion A)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_NormalizeQuaternion(A);\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE float \r\nHMM_Dot(hmm_vec2 VecOne, hmm_vec2 VecTwo)\r\n{\r\n    float Result = 0;\r\n    \r\n    Result = HMM_DotVec2(VecOne, VecTwo);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float \r\nHMM_Dot(hmm_vec3 VecOne, hmm_vec3 VecTwo)\r\n{\r\n    float Result = 0;\r\n    \r\n    Result = HMM_DotVec3(VecOne, VecTwo);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float \r\nHMM_Dot(hmm_vec4 VecOne, hmm_vec4 VecTwo)\r\n{\r\n    float Result = 0;\r\n    \r\n    Result = HMM_DotVec4(VecOne, VecTwo);\r\n    \r\n    return(Result);\r\n}\r\n\r\nHINLINE float\r\nHMM_Dot(hmm_quaternion QuatOne, hmm_quaternion QuatTwo)\r\n{\r\n    float Result = 0;\r\n\r\n    Result = HMM_DotQuaternion(QuatOne, QuatTwo);\r\n\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_Add(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_AddVec2(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_Add(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_AddVec3(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_Add(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_AddVec4(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Add(hmm_mat4 Left, hmm_mat4 Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_AddMat4(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_Add(hmm_quaternion Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_AddQuaternion(Left, Right);\r\n    return(Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_Subtract(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_SubtractVec2(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_Subtract(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_SubtractVec3(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_Subtract(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_SubtractVec4(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Subtract(hmm_mat4 Left, hmm_mat4 Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_SubtractMat4(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_Subtract(hmm_quaternion Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_SubtractQuaternion(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_Multiply(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_MultiplyVec2(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_Multiply(hmm_vec2 Left, float Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_MultiplyVec2f(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_Multiply(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_MultiplyVec3(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_Multiply(hmm_vec3 Left, float Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_MultiplyVec3f(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_Multiply(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_MultiplyVec4(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_Multiply(hmm_vec4 Left, float Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_MultiplyVec4f(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Multiply(hmm_mat4 Left, hmm_mat4 Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_MultiplyMat4(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Multiply(hmm_mat4 Left, float Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_MultiplyMat4f(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_Multiply(hmm_mat4 Matrix, hmm_vec4 Vector)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_MultiplyMat4ByVec4(Matrix, Vector);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_Multiply(hmm_quaternion Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_MultiplyQuaternion(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_Multiply(hmm_quaternion Left, float Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_MultiplyQuaternionF(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_Multiply(float Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_MultiplyQuaternionF(Right, Left);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_Divide(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_DivideVec2(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\nHMM_Divide(hmm_vec2 Left, float Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_DivideVec2f(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_Divide(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_DivideVec3(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\nHMM_Divide(hmm_vec3 Left, float Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_DivideVec3f(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_Divide(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_DivideVec4(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\nHMM_Divide(hmm_vec4 Left, float Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_DivideVec4f(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\nHMM_Divide(hmm_mat4 Left, float Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_DivideMat4f(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\nHMM_Divide(hmm_quaternion Left, float Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_DivideQuaternionF(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_bool\r\nHMM_Equals(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_bool Result = 0;\r\n\r\n    Result = HMM_EqualsVec2(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_bool\r\nHMM_Equals(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_bool Result = 0;\r\n\r\n    Result = HMM_EqualsVec3(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_bool\r\nHMM_Equals(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_bool Result = 0;\r\n\r\n    Result = HMM_EqualsVec4(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\noperator+(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_Add(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\noperator+(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_Add(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\noperator+(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_Add(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\noperator+(hmm_mat4 Left, hmm_mat4 Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_Add(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\noperator+(hmm_quaternion Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_Add(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\noperator-(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_Subtract(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\noperator-(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_Subtract(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\noperator-(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_Subtract(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\noperator-(hmm_mat4 Left, hmm_mat4 Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_Subtract(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\noperator-(hmm_quaternion Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_Subtract(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\noperator*(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_Multiply(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\noperator*(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_Multiply(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\noperator*(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = HMM_Multiply(Left, Right);\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\noperator*(hmm_vec2 Left, float Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_Multiply(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\noperator*(hmm_vec3 Left, float Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_Multiply(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\noperator*(hmm_vec4 Left, float Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_Multiply(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\noperator*(hmm_mat4 Left, float Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_Multiply(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\noperator*(float Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_Multiply(Right, Left);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\noperator*(float Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_Multiply(Right, Left);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\noperator*(float Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_Multiply(Right, Left);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\noperator*(float Left, hmm_mat4 Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_Multiply(Right, Left);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\noperator*(hmm_mat4 Left, hmm_mat4 Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_Multiply(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\noperator*(hmm_mat4 Matrix, hmm_vec4 Vector)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_Multiply(Matrix, Vector);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\noperator*(hmm_quaternion Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_Multiply(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\noperator*(hmm_quaternion Left, float Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_Multiply(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\noperator*(float Left, hmm_quaternion Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_Multiply(Right, Left);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\noperator/(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_Divide(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\noperator/(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n    \r\n    Result = HMM_Divide(Left, Right);\r\n\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\noperator/(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_Divide(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2\r\noperator/(hmm_vec2 Left, float Right)\r\n{\r\n    hmm_vec2 Result = {0};\r\n\r\n    Result = HMM_Divide(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec3\r\noperator/(hmm_vec3 Left, float Right)\r\n{\r\n    hmm_vec3 Result = {0};\r\n\r\n    Result = HMM_Divide(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec4\r\noperator/(hmm_vec4 Left, float Right)\r\n{\r\n    hmm_vec4 Result = {0};\r\n\r\n    Result = HMM_Divide(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_mat4\r\noperator/(hmm_mat4 Left, float Right)\r\n{\r\n    hmm_mat4 Result = {0};\r\n\r\n    Result = HMM_Divide(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_quaternion\r\noperator/(hmm_quaternion Left, float Right)\r\n{\r\n    hmm_quaternion Result = {0};\r\n\r\n    Result = HMM_Divide(Left, Right);\r\n    return (Result);\r\n}\r\n\r\nHINLINE hmm_vec2 &\r\noperator+=(hmm_vec2 &Left, hmm_vec2 Right)\r\n{    \r\n    return (Left = Left + Right);\r\n}\r\n\r\nHINLINE hmm_vec3 &\r\noperator+=(hmm_vec3 &Left, hmm_vec3 Right)\r\n{    \r\n    return (Left = Left + Right);\r\n}\r\n\r\nHINLINE hmm_vec4 &\r\noperator+=(hmm_vec4 &Left, hmm_vec4 Right)\r\n{    \r\n    return (Left = Left + Right);\r\n}\r\n\r\nHINLINE hmm_mat4 &\r\noperator+=(hmm_mat4 &Left, hmm_mat4 Right)\r\n{\r\n    return (Left = Left + Right);\r\n}\r\n\r\nHINLINE hmm_quaternion &\r\noperator+=(hmm_quaternion &Left, hmm_quaternion Right)\r\n{\r\n    return (Left = Left + Right);\r\n}\r\n\r\nHINLINE hmm_vec2 &\r\noperator-=(hmm_vec2 &Left, hmm_vec2 Right)\r\n{    \r\n    return (Left = Left - Right);\r\n}\r\n\r\nHINLINE hmm_vec3 &\r\noperator-=(hmm_vec3 &Left, hmm_vec3 Right)\r\n{    \r\n    return (Left = Left - Right);\r\n}\r\n\r\nHINLINE hmm_vec4 &\r\noperator-=(hmm_vec4 &Left, hmm_vec4 Right)\r\n{    \r\n    return (Left = Left - Right);\r\n}\r\n\r\nHINLINE hmm_mat4 &\r\noperator-=(hmm_mat4 &Left, hmm_mat4 Right)\r\n{\r\n    return (Left = Left - Right);\r\n}\r\n\r\nHINLINE hmm_quaternion &\r\noperator-=(hmm_quaternion &Left, hmm_quaternion Right)\r\n{\r\n    return (Left = Left - Right);\r\n}\r\n\r\nHINLINE hmm_vec2 &\r\noperator/=(hmm_vec2 &Left, hmm_vec2 Right)\r\n{    \r\n    return (Left = Left / Right);\r\n}\r\n\r\nHINLINE hmm_vec3 &\r\noperator/=(hmm_vec3 &Left, hmm_vec3 Right)\r\n{    \r\n    return (Left = Left / Right);\r\n}\r\n\r\nHINLINE hmm_vec4 &\r\noperator/=(hmm_vec4 &Left, hmm_vec4 Right)\r\n{    \r\n    return (Left = Left / Right);\r\n}\r\n\r\nHINLINE hmm_vec2 &\r\noperator/=(hmm_vec2 &Left, float Right)\r\n{\r\n    return (Left = Left / Right);\r\n}\r\n\r\nHINLINE hmm_vec3 &\r\noperator/=(hmm_vec3 &Left, float Right)\r\n{\r\n    return (Left = Left / Right);\r\n}\r\n\r\nHINLINE hmm_vec4 &\r\noperator/=(hmm_vec4 &Left, float Right)\r\n{\r\n    return (Left = Left / Right);\r\n}\r\n\r\nHINLINE hmm_mat4 &\r\noperator/=(hmm_mat4 &Left, float Right)\r\n{\r\n    return (Left = Left / Right);\r\n}\r\n\r\nHINLINE hmm_quaternion &\r\noperator/=(hmm_quaternion &Left, float Right)\r\n{\r\n    return (Left = Left / Right);\r\n}\r\n\r\nHINLINE hmm_vec2 &\r\noperator*=(hmm_vec2 &Left, hmm_vec2 Right)\r\n{    \r\n    return (Left = Left * Right);\r\n}\r\n\r\nHINLINE hmm_vec3 &\r\noperator*=(hmm_vec3 &Left, hmm_vec3 Right)\r\n{    \r\n    return (Left = Left * Right);\r\n}\r\n\r\nHINLINE hmm_vec4 &\r\noperator*=(hmm_vec4 &Left, hmm_vec4 Right)\r\n{    \r\n    return (Left = Left * Right);\r\n}\r\n\r\nHINLINE hmm_vec2 &\r\noperator*=(hmm_vec2 &Left, float Right)\r\n{\r\n    return (Left = Left * Right);\r\n}\r\n\r\nHINLINE hmm_vec3 &\r\noperator*=(hmm_vec3 &Left, float Right)\r\n{\r\n    return (Left = Left * Right);\r\n}\r\n\r\nHINLINE hmm_vec4 &\r\noperator*=(hmm_vec4 &Left, float Right)\r\n{\r\n    return (Left = Left * Right);\r\n}\r\n\r\nHINLINE hmm_mat4 &\r\noperator*=(hmm_mat4 &Left, float Right)\r\n{\r\n    return (Left = Left * Right);\r\n}\r\n\r\nHINLINE hmm_quaternion &\r\noperator*=(hmm_quaternion &Left, float Right)\r\n{\r\n    return (Left = Left * Right);\r\n}\r\n\r\nHINLINE hmm_bool\r\noperator==(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    return HMM_EqualsVec2(Left, Right);    \r\n}\r\n\r\nHINLINE hmm_bool\r\noperator==(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    return HMM_EqualsVec3(Left, Right);    \r\n}\r\n\r\nHINLINE hmm_bool\r\noperator==(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    return HMM_EqualsVec4(Left, Right);    \r\n}\r\n\r\n\r\nHINLINE hmm_bool \r\noperator!=(hmm_vec2 Left, hmm_vec2 Right)\r\n{\r\n    return !HMM_EqualsVec2(Left, Right);    \r\n}\r\n\r\nHINLINE hmm_bool \r\noperator!=(hmm_vec3 Left, hmm_vec3 Right)\r\n{\r\n    return !HMM_EqualsVec3(Left, Right);    \r\n}\r\n\r\nHINLINE hmm_bool \r\noperator!=(hmm_vec4 Left, hmm_vec4 Right)\r\n{\r\n    return !HMM_EqualsVec4(Left, Right);    \r\n}\r\n\r\n#endif /* HANDMADE_MATH_CPP_MODE */\r\n\r\n#ifdef __clang__\r\n#pragma clang diagnostic pop\r\n#endif\r\n#endif /* HANDMADE_MATH_IMPLEMENTATION */\r\n","#ifndef SOKOL_GFX_INCLUDED\r\n/*\r\n    sokol_gfx.h -- simple 3D API wrapper\r\n\r\n    Project URL: https://github.com/floooh/sokol\r\n\r\n    Do this:\r\n        #define SOKOL_IMPL\r\n    before you include this file in *one* C or C++ file to create the\r\n    implementation.\r\n\r\n    In the same place define one of the following to select the rendering\r\n    backend:\r\n        #define SOKOL_GLCORE33\r\n        #define SOKOL_GLES2\r\n        #define SOKOL_GLES3\r\n        #define SOKOL_D3D11\r\n        #define SOKOL_METAL\r\n        #define SOKOL_WGPU\r\n        #define SOKOL_DUMMY_BACKEND\r\n\r\n    I.e. for the GL 3.3 Core Profile it should look like this:\r\n\r\n    #include ...\r\n    #include ...\r\n    #define SOKOL_IMPL\r\n    #define SOKOL_GLCORE33\r\n    #include \"sokol_gfx.h\"\r\n\r\n    The dummy backend replaces the platform-specific backend code with empty\r\n    stub functions. This is useful for writing tests that need to run on the\r\n    command line.\r\n\r\n    Optionally provide the following defines with your own implementations:\r\n\r\n    SOKOL_ASSERT(c)     - your own assert macro (default: assert(c))\r\n    SOKOL_MALLOC(s)     - your own malloc function (default: malloc(s))\r\n    SOKOL_FREE(p)       - your own free function (default: free(p))\r\n    SOKOL_LOG(msg)      - your own logging function (default: puts(msg))\r\n    SOKOL_UNREACHABLE() - a guard macro for unreachable code (default: assert(false))\r\n    SOKOL_API_DECL      - public function declaration prefix (default: extern)\r\n    SOKOL_API_IMPL      - public function implementation prefix (default: -)\r\n    SOKOL_TRACE_HOOKS   - enable trace hook callbacks (search below for TRACE HOOKS)\r\n\r\n    If sokol_gfx.h is compiled as a DLL, define the following before\r\n    including the declaration or implementation:\r\n\r\n    SOKOL_DLL\r\n\r\n    On Windows, SOKOL_DLL will define SOKOL_API_DECL as __declspec(dllexport)\r\n    or __declspec(dllimport) as needed.\r\n\r\n    If you want to compile without deprecated structs and functions,\r\n    define:\r\n\r\n    SOKOL_NO_DEPRECATED\r\n\r\n    API usage validation macros:\r\n\r\n    SOKOL_VALIDATE_BEGIN()      - begin a validation block (default:_sg_validate_begin())\r\n    SOKOL_VALIDATE(cond, err)   - like assert but for API validation (default: _sg_validate(cond, err))\r\n    SOKOL_VALIDATE_END()        - end a validation block, return true if all checks in block passed (default: bool _sg_validate())\r\n\r\n    If you don't want validation errors to be fatal, define SOKOL_VALIDATE_NON_FATAL,\r\n    be aware though that this may spam SOKOL_LOG messages.\r\n\r\n    Optionally define the following to force debug checks and validations\r\n    even in release mode:\r\n\r\n    SOKOL_DEBUG         - by default this is defined if _DEBUG is defined\r\n\r\n\r\n    sokol_gfx DOES NOT:\r\n    ===================\r\n    - create a window or the 3D-API context/device, you must do this\r\n      before sokol_gfx is initialized, and pass any required information\r\n      (like 3D device pointers) to the sokol_gfx initialization call\r\n\r\n    - present the rendered frame, how this is done exactly usually depends\r\n      on how the window and 3D-API context/device was created\r\n\r\n    - provide a unified shader language, instead 3D-API-specific shader\r\n      source-code or shader-bytecode must be provided\r\n\r\n    For complete code examples using the various backend 3D-APIs, see:\r\n\r\n        https://github.com/floooh/sokol-samples\r\n\r\n    For an optional shader-cross-compile solution, see:\r\n\r\n        https://github.com/floooh/sokol-tools/blob/master/docs/sokol-shdc.md\r\n\r\n\r\n    STEP BY STEP\r\n    ============\r\n    --- to initialize sokol_gfx, after creating a window and a 3D-API\r\n        context/device, call:\r\n\r\n            sg_setup(const sg_desc*)\r\n\r\n    --- create resource objects (at least buffers, shaders and pipelines,\r\n        and optionally images and passes):\r\n\r\n            sg_buffer sg_make_buffer(const sg_buffer_desc*)\r\n            sg_image sg_make_image(const sg_image_desc*)\r\n            sg_shader sg_make_shader(const sg_shader_desc*)\r\n            sg_pipeline sg_make_pipeline(const sg_pipeline_desc*)\r\n            sg_pass sg_make_pass(const sg_pass_desc*)\r\n\r\n    --- start rendering to the default frame buffer with:\r\n\r\n            sg_begin_default_pass(const sg_pass_action* actions, int width, int height)\r\n\r\n    --- or start rendering to an offscreen framebuffer with:\r\n\r\n            sg_begin_pass(sg_pass pass, const sg_pass_action* actions)\r\n\r\n    --- set the pipeline state for the next draw call with:\r\n\r\n            sg_apply_pipeline(sg_pipeline pip)\r\n\r\n    --- fill an sg_bindings struct with the resource bindings for the next\r\n        draw call (1..N vertex buffers, 0 or 1 index buffer, 0..N image objects\r\n        to use as textures each on the vertex-shader- and fragment-shader-stage\r\n        and then call\r\n\r\n            sg_apply_bindings(const sg_bindings* bindings)\r\n\r\n        to update the resource bindings\r\n\r\n    --- optionally update shader uniform data with:\r\n\r\n            sg_apply_uniforms(sg_shader_stage stage, int ub_index, const void* data, int num_bytes)\r\n\r\n    --- kick off a draw call with:\r\n\r\n            sg_draw(int base_element, int num_elements, int num_instances)\r\n\r\n        In the case of no instancing: num_instances should be set to 1 and base_element/num_elements are\r\n        amounts of vertices. In the case of instancing (meaning num_instances > 1), num elements is the\r\n        number of vertices in one instance, while base_element remains unchanged. base_element is the index\r\n        of the first vertex to begin drawing from.\r\n\r\n    --- finish the current rendering pass with:\r\n\r\n            sg_end_pass()\r\n\r\n    --- when done with the current frame, call\r\n\r\n            sg_commit()\r\n\r\n    --- at the end of your program, shutdown sokol_gfx with:\r\n\r\n            sg_shutdown()\r\n\r\n    --- if you need to destroy resources before sg_shutdown(), call:\r\n\r\n            sg_destroy_buffer(sg_buffer buf)\r\n            sg_destroy_image(sg_image img)\r\n            sg_destroy_shader(sg_shader shd)\r\n            sg_destroy_pipeline(sg_pipeline pip)\r\n            sg_destroy_pass(sg_pass pass)\r\n\r\n    --- to set a new viewport rectangle, call\r\n\r\n            sg_apply_viewport(int x, int y, int width, int height, bool origin_top_left)\r\n\r\n    --- to set a new scissor rect, call:\r\n\r\n            sg_apply_scissor_rect(int x, int y, int width, int height, bool origin_top_left)\r\n\r\n        both sg_apply_viewport() and sg_apply_scissor_rect() must be called\r\n        inside a rendering pass\r\n\r\n        beginning a pass will reset the viewport to the size of the framebuffer used\r\n        in the new pass,\r\n\r\n    --- to update (overwrite) the content of buffer and image resources, call:\r\n\r\n            sg_update_buffer(sg_buffer buf, const void* ptr, int num_bytes)\r\n            sg_update_image(sg_image img, const sg_image_content* content)\r\n\r\n        Buffers and images to be updated must have been created with\r\n        SG_USAGE_DYNAMIC or SG_USAGE_STREAM\r\n\r\n        Only one update per frame is allowed for buffer and image resources.\r\n        The rationale is to have a simple countermeasure to avoid the CPU\r\n        scribbling over data the GPU is currently using, or the CPU having to\r\n        wait for the GPU\r\n\r\n        Buffer and image updates can be partial, as long as a rendering\r\n        operation only references the valid (updated) data in the\r\n        buffer or image.\r\n\r\n    --- to append a chunk of data to a buffer resource, call:\r\n\r\n            int sg_append_buffer(sg_buffer buf, const void* ptr, int num_bytes)\r\n\r\n        The difference to sg_update_buffer() is that sg_append_buffer()\r\n        can be called multiple times per frame to append new data to the\r\n        buffer piece by piece, optionally interleaved with draw calls referencing\r\n        the previously written data.\r\n\r\n        sg_append_buffer() returns a byte offset to the start of the\r\n        written data, this offset can be assigned to\r\n        sg_bindings.vertex_buffer_offsets[n] or\r\n        sg_bindings.index_buffer_offset\r\n\r\n        Code example:\r\n\r\n        for (...) {\r\n            const void* data = ...;\r\n            const int num_bytes = ...;\r\n            int offset = sg_append_buffer(buf, data, num_bytes);\r\n            bindings.vertex_buffer_offsets[0] = offset;\r\n            sg_apply_pipeline(pip);\r\n            sg_apply_bindings(&bindings);\r\n            sg_apply_uniforms(...);\r\n            sg_draw(...);\r\n        }\r\n\r\n        A buffer to be used with sg_append_buffer() must have been created\r\n        with SG_USAGE_DYNAMIC or SG_USAGE_STREAM.\r\n\r\n        If the application appends more data to the buffer then fits into\r\n        the buffer, the buffer will go into the \"overflow\" state for the\r\n        rest of the frame.\r\n\r\n        Any draw calls attempting to render an overflown buffer will be\r\n        silently dropped (in debug mode this will also result in a\r\n        validation error).\r\n\r\n        You can also check manually if a buffer is in overflow-state by calling\r\n\r\n            bool sg_query_buffer_overflow(sg_buffer buf)\r\n\r\n        NOTE: Due to restrictions in underlying 3D-APIs, appended chunks of\r\n        data will be 4-byte aligned in the destination buffer. This means\r\n        that there will be gaps in index buffers containing 16-bit indices\r\n        when the number of indices in a call to sg_append_buffer() is\r\n        odd. This isn't a problem when each call to sg_append_buffer()\r\n        is associated with one draw call, but will be problematic when\r\n        a single indexed draw call spans several appended chunks of indices.\r\n\r\n    --- to check at runtime for optional features, limits and pixelformat support,\r\n        call:\r\n\r\n            sg_features sg_query_features()\r\n            sg_limits sg_query_limits()\r\n            sg_pixelformat_info sg_query_pixelformat(sg_pixel_format fmt)\r\n\r\n    --- if you need to call into the underlying 3D-API directly, you must call:\r\n\r\n            sg_reset_state_cache()\r\n\r\n        ...before calling sokol_gfx functions again\r\n\r\n    --- you can inspect the original sg_desc structure handed to sg_setup()\r\n        by calling sg_query_desc(). This will return an sg_desc struct with\r\n        the default values patched in instead of any zero-initialized values\r\n\r\n    --- you can inspect various internal resource attributes via:\r\n\r\n            sg_buffer_info sg_query_buffer_info(sg_buffer buf)\r\n            sg_image_info sg_query_image_info(sg_image img)\r\n            sg_shader_info sg_query_shader_info(sg_shader shd)\r\n            sg_pipeline_info sg_query_pipeline_info(sg_pipeline pip)\r\n            sg_pass_info sg_query_pass_info(sg_pass pass)\r\n\r\n        ...please note that the returned info-structs are tied quite closely\r\n        to sokol_gfx.h internals, and may change more often than other\r\n        public API functions and structs.\r\n\r\n    --- you can ask at runtime what backend sokol_gfx.h has been compiled\r\n        for, or whether the GLES3 backend had to fall back to GLES2 with:\r\n\r\n            sg_backend sg_query_backend(void)\r\n\r\n    --- you can query the default resource creation parameters through the functions\r\n\r\n            sg_buffer_desc sg_query_buffer_defaults(const sg_buffer_desc* desc)\r\n            sg_image_desc sg_query_image_defaults(const sg_image_desc* desc)\r\n            sg_shader_desc sg_query_shader_defaults(const sg_shader_desc* desc)\r\n            sg_pipeline_desc sg_query_pipeline_defaults(const sg_pipeline_desc* desc)\r\n            sg_pass_desc sg_query_pass_defaults(const sg_pass_desc* desc)\r\n\r\n        These functions take a pointer to a desc structure which may contain\r\n        zero-initialized items for default values. These zero-init values\r\n        will be replaced with their concrete values in the returned desc\r\n        struct.\r\n\r\n    ON INITIALIZATION:\r\n    ==================\r\n    When calling sg_setup(), a pointer to an sg_desc struct must be provided\r\n    which contains initialization options. These options provide two types\r\n    of information to sokol-gfx:\r\n\r\n        (1) upper bounds and limits needed to allocate various internal\r\n            data structures:\r\n                - the max number of resources of each type that can\r\n                  be alive at the same time, this is used for allocating\r\n                  internal pools\r\n                - the max overall size of uniform data that can be\r\n                  updated per frame, including a worst-case alignment\r\n                  per uniform update (this worst-case alignment is 256 bytes)\r\n                - the max size of all dynamic resource updates (sg_update_buffer,\r\n                  sg_append_buffer and sg_update_image) per frame\r\n                - the max number of entries in the texture sampler cache\r\n                  (how many unique texture sampler can exist at the same time)\r\n            Not all of those limit values are used by all backends, but it is\r\n            good practice to provide them none-the-less.\r\n\r\n        (2) 3D-API \"context information\" (sometimes also called \"bindings\"):\r\n            sokol_gfx.h doesn't create or initialize 3D API objects which are\r\n            closely related to the presentation layer (this includes the \"rendering\r\n            device\", the swapchain, and any objects which depend on the\r\n            swapchain). These API objects (or callback functions to obtain\r\n            them, if those objects might change between frames), must\r\n            be provided in a nested sg_context_desc struct inside the\r\n            sg_desc struct. If sokol_gfx.h is used together with\r\n            sokol_app.h, have a look at the sokol_glue.h header which provides\r\n            a convenience function to get a sg_context_desc struct filled out\r\n            with context information provided by sokol_app.h\r\n\r\n    See the documention block of the sg_desc struct below for more information.\r\n\r\n    BACKEND-SPECIFIC TOPICS:\r\n    ========================\r\n    --- the GL backends need to know about the internal structure of uniform\r\n        blocks, and the texture sampler-name and -type:\r\n\r\n            typedef struct {\r\n                float mvp[16];      // model-view-projection matrix\r\n                float offset0[2];   // some 2D vectors\r\n                float offset1[2];\r\n                float offset2[2];\r\n            } params_t;\r\n\r\n            // uniform block structure and texture image definition in sg_shader_desc:\r\n            sg_shader_desc desc = {\r\n                // uniform block description (size and internal structure)\r\n                .vs.uniform_blocks[0] = {\r\n                    .size = sizeof(params_t),\r\n                    .uniforms = {\r\n                        [0] = { .name=\"mvp\", .type=SG_UNIFORMTYPE_MAT4 },\r\n                        [1] = { .name=\"offset0\", .type=SG_UNIFORMTYPE_VEC2 },\r\n                        ...\r\n                    }\r\n                },\r\n                // one texture on the fragment-shader-stage, GLES2/WebGL needs name and image type\r\n                .fs.images[0] = { .name=\"tex\", .type=SG_IMAGETYPE_ARRAY }\r\n                ...\r\n            };\r\n\r\n    --- the Metal and D3D11 backends only need to know the size of uniform blocks,\r\n        not their internal member structure, and they only need to know\r\n        the type of a texture sampler, not its name:\r\n\r\n            sg_shader_desc desc = {\r\n                .vs.uniform_blocks[0].size = sizeof(params_t),\r\n                .fs.images[0].type = SG_IMAGETYPE_ARRAY,\r\n                ...\r\n            };\r\n\r\n    --- when creating a shader object, GLES2/WebGL need to know the vertex\r\n        attribute names as used in the vertex shader:\r\n\r\n            sg_shader_desc desc = {\r\n                .attrs = {\r\n                    [0] = { .name=\"position\" },\r\n                    [1] = { .name=\"color1\" }\r\n                }\r\n            };\r\n\r\n        The vertex attribute names provided when creating a shader will be\r\n        used later in sg_create_pipeline() for matching the vertex layout\r\n        to vertex shader inputs.\r\n\r\n    --- on D3D11 you need to provide a semantic name and semantic index in the\r\n        shader description struct instead (see the D3D11 documentation on\r\n        D3D11_INPUT_ELEMENT_DESC for details):\r\n\r\n            sg_shader_desc desc = {\r\n                .attrs = {\r\n                    [0] = { .sem_name=\"POSITION\", .sem_index=0 }\r\n                    [1] = { .sem_name=\"COLOR\", .sem_index=1 }\r\n                }\r\n            };\r\n\r\n        The provided semantic information will be used later in sg_create_pipeline()\r\n        to match the vertex layout to vertex shader inputs.\r\n\r\n    --- on D3D11, and when passing HLSL source code (instead of byte code) to shader\r\n        creation, you can optionally define the shader model targets on the vertex\r\n        stage:\r\n\r\n            sg_shader_Desc desc = {\r\n                .vs = {\r\n                    ...\r\n                    .d3d11_target = \"vs_5_0\"\r\n                },\r\n                .fs = {\r\n                    ...\r\n                    .d3d11_target = \"ps_5_0\"\r\n                }\r\n            };\r\n\r\n        The default targets are \"ps_4_0\" and \"fs_4_0\". Note that those target names\r\n        are only used when compiling shaders from source. They are ignored when\r\n        creating a shader from bytecode.\r\n\r\n    --- on Metal, GL 3.3 or GLES3/WebGL2, you don't need to provide an attribute\r\n        name or semantic name, since vertex attributes can be bound by their slot index\r\n        (this is mandatory in Metal, and optional in GL):\r\n\r\n            sg_pipeline_desc desc = {\r\n                .layout = {\r\n                    .attrs = {\r\n                        [0] = { .format=SG_VERTEXFORMAT_FLOAT3 },\r\n                        [1] = { .format=SG_VERTEXFORMAT_FLOAT4 }\r\n                    }\r\n                }\r\n            };\r\n\r\n    WORKING WITH CONTEXTS\r\n    =====================\r\n    sokol-gfx allows to switch between different rendering contexts and\r\n    associate resource objects with contexts. This is useful to\r\n    create GL applications that render into multiple windows.\r\n\r\n    A rendering context keeps track of all resources created while\r\n    the context is active. When the context is destroyed, all resources\r\n    \"belonging to the context\" are destroyed as well.\r\n\r\n    A default context will be created and activated implicitly in\r\n    sg_setup(), and destroyed in sg_shutdown(). So for a typical application\r\n    which *doesn't* use multiple contexts, nothing changes, and calling\r\n    the context functions isn't necessary.\r\n\r\n    Three functions have been added to work with contexts:\r\n\r\n    --- sg_context sg_setup_context():\r\n        This must be called once after a GL context has been created and\r\n        made active.\r\n\r\n    --- void sg_activate_context(sg_context ctx)\r\n        This must be called after making a different GL context active.\r\n        Apart from 3D-API-specific actions, the call to sg_activate_context()\r\n        will internally call sg_reset_state_cache().\r\n\r\n    --- void sg_discard_context(sg_context ctx)\r\n        This must be called right before a GL context is destroyed and\r\n        will destroy all resources associated with the context (that\r\n        have been created while the context was active) The GL context must be\r\n        active at the time sg_discard_context(sg_context ctx) is called.\r\n\r\n    Also note that resources (buffers, images, shaders and pipelines) must\r\n    only be used or destroyed while the same GL context is active that\r\n    was also active while the resource was created (an exception is\r\n    resource sharing on GL, such resources can be used while\r\n    another context is active, but must still be destroyed under\r\n    the same context that was active during creation).\r\n\r\n    For more information, check out the multiwindow-glfw sample:\r\n\r\n    https://github.com/floooh/sokol-samples/blob/master/glfw/multiwindow-glfw.c\r\n\r\n    TRACE HOOKS:\r\n    ============\r\n    sokol_gfx.h optionally allows to install \"trace hook\" callbacks for\r\n    each public API functions. When a public API function is called, and\r\n    a trace hook callback has been installed for this function, the\r\n    callback will be invoked with the parameters and result of the function.\r\n    This is useful for things like debugging- and profiling-tools, or\r\n    keeping track of resource creation and destruction.\r\n\r\n    To use the trace hook feature:\r\n\r\n    --- Define SOKOL_TRACE_HOOKS before including the implementation.\r\n\r\n    --- Setup an sg_trace_hooks structure with your callback function\r\n        pointers (keep all function pointers you're not interested\r\n        in zero-initialized), optionally set the user_data member\r\n        in the sg_trace_hooks struct.\r\n\r\n    --- Install the trace hooks by calling sg_install_trace_hooks(),\r\n        the return value of this function is another sg_trace_hooks\r\n        struct which contains the previously set of trace hooks.\r\n        You should keep this struct around, and call those previous\r\n        functions pointers from your own trace callbacks for proper\r\n        chaining.\r\n\r\n    As an example of how trace hooks are used, have a look at the\r\n    imgui/sokol_gfx_imgui.h header which implements a realtime\r\n    debugging UI for sokol_gfx.h on top of Dear ImGui.\r\n\r\n    A NOTE ON PORTABLE PACKED VERTEX FORMATS:\r\n    =========================================\r\n    There are two things to consider when using packed\r\n    vertex formats like UBYTE4, SHORT2, etc which need to work\r\n    across all backends:\r\n\r\n    - D3D11 can only convert *normalized* vertex formats to\r\n      floating point during vertex fetch, normalized formats\r\n      have a trailing 'N', and are \"normalized\" to a range\r\n      -1.0..+1.0 (for the signed formats) or 0.0..1.0 (for the\r\n      unsigned formats):\r\n\r\n        - SG_VERTEXFORMAT_BYTE4N\r\n        - SG_VERTEXFORMAT_UBYTE4N\r\n        - SG_VERTEXFORMAT_SHORT2N\r\n        - SG_VERTEXFORMAT_USHORT2N\r\n        - SG_VERTEXFORMAT_SHORT4N\r\n        - SG_VERTEXFORMAT_USHORT4N\r\n\r\n      D3D11 will not convert *non-normalized* vertex formats to floating point\r\n      vertex shader inputs, those can only be uses with the *ivecn* vertex shader\r\n      input types when D3D11 is used as backend (GL and Metal can use both formats)\r\n\r\n        - SG_VERTEXFORMAT_BYTE4,\r\n        - SG_VERTEXFORMAT_UBYTE4\r\n        - SG_VERTEXFORMAT_SHORT2\r\n        - SG_VERTEXFORMAT_SHORT4\r\n\r\n    - WebGL/GLES2 cannot use integer vertex shader inputs (int or ivecn)\r\n\r\n    - SG_VERTEXFORMAT_UINT10_N2 is not supported on WebGL/GLES2\r\n\r\n    So for a vertex input layout which works on all platforms, only use the following\r\n    vertex formats, and if needed \"expand\" the normalized vertex shader\r\n    inputs in the vertex shader by multiplying with 127.0, 255.0, 32767.0 or\r\n    65535.0:\r\n\r\n        - SG_VERTEXFORMAT_FLOAT,\r\n        - SG_VERTEXFORMAT_FLOAT2,\r\n        - SG_VERTEXFORMAT_FLOAT3,\r\n        - SG_VERTEXFORMAT_FLOAT4,\r\n        - SG_VERTEXFORMAT_BYTE4N,\r\n        - SG_VERTEXFORMAT_UBYTE4N,\r\n        - SG_VERTEXFORMAT_SHORT2N,\r\n        - SG_VERTEXFORMAT_USHORT2N\r\n        - SG_VERTEXFORMAT_SHORT4N,\r\n        - SG_VERTEXFORMAT_USHORT4N\r\n\r\n    TODO:\r\n    ====\r\n    - talk about asynchronous resource creation\r\n\r\n    zlib/libpng license\r\n\r\n    Copyright (c) 2018 Andre Weissflog\r\n\r\n    This software is provided 'as-is', without any express or implied warranty.\r\n    In no event will the authors be held liable for any damages arising from the\r\n    use of this software.\r\n\r\n    Permission is granted to anyone to use this software for any purpose,\r\n    including commercial applications, and to alter it and redistribute it\r\n    freely, subject to the following restrictions:\r\n\r\n        1. The origin of this software must not be misrepresented; you must not\r\n        claim that you wrote the original software. If you use this software in a\r\n        product, an acknowledgment in the product documentation would be\r\n        appreciated but is not required.\r\n\r\n        2. Altered source versions must be plainly marked as such, and must not\r\n        be misrepresented as being the original software.\r\n\r\n        3. This notice may not be removed or altered from any source\r\n        distribution.\r\n*/\r\n#define SOKOL_GFX_INCLUDED (1)\r\n#include <stdint.h>\r\n#include <stdbool.h>\r\n\r\n#ifndef SOKOL_API_DECL\r\n#if defined(_WIN32) && defined(SOKOL_DLL) && defined(SOKOL_IMPL)\r\n#define SOKOL_API_DECL __declspec(dllexport)\r\n#elif defined(_WIN32) && defined(SOKOL_DLL)\r\n#define SOKOL_API_DECL __declspec(dllimport)\r\n#else\r\n#define SOKOL_API_DECL extern\r\n#endif\r\n#endif\r\n\r\n#ifdef __cplusplus\r\nextern \"C\" {\r\n#endif\r\n\r\n#ifdef _MSC_VER\r\n#pragma warning(push)\r\n#pragma warning(disable:4201)   /* nonstandard extension used: nameless struct/union */\r\n#endif\r\n\r\n/*\r\n    Resource id typedefs:\r\n\r\n    sg_buffer:      vertex- and index-buffers\r\n    sg_image:       textures and render targets\r\n    sg_shader:      vertex- and fragment-shaders, uniform blocks\r\n    sg_pipeline:    associated shader and vertex-layouts, and render states\r\n    sg_pass:        a bundle of render targets and actions on them\r\n    sg_context:     a 'context handle' for switching between 3D-API contexts\r\n\r\n    Instead of pointers, resource creation functions return a 32-bit\r\n    number which uniquely identifies the resource object.\r\n\r\n    The 32-bit resource id is split into a 16-bit pool index in the lower bits,\r\n    and a 16-bit 'unique counter' in the upper bits. The index allows fast\r\n    pool lookups, and combined with the unique-mask it allows to detect\r\n    'dangling accesses' (trying to use an object which no longer exists, and\r\n    its pool slot has been reused for a new object)\r\n\r\n    The resource ids are wrapped into a struct so that the compiler\r\n    can complain when the wrong resource type is used.\r\n*/\r\ntypedef struct sg_buffer   { uint32_t id; } sg_buffer;\r\ntypedef struct sg_image    { uint32_t id; } sg_image;\r\ntypedef struct sg_shader   { uint32_t id; } sg_shader;\r\ntypedef struct sg_pipeline { uint32_t id; } sg_pipeline;\r\ntypedef struct sg_pass     { uint32_t id; } sg_pass;\r\ntypedef struct sg_context  { uint32_t id; } sg_context;\r\n\r\n/*\r\n    various compile-time constants\r\n\r\n    FIXME: it may make sense to convert some of those into defines so\r\n    that the user code can override them.\r\n*/\r\nenum {\r\n    SG_INVALID_ID = 0,\r\n    SG_NUM_SHADER_STAGES = 2,\r\n    SG_NUM_INFLIGHT_FRAMES = 2,\r\n    SG_MAX_COLOR_ATTACHMENTS = 4,\r\n    SG_MAX_SHADERSTAGE_BUFFERS = 8,\r\n    SG_MAX_SHADERSTAGE_IMAGES = 12,\r\n    SG_MAX_SHADERSTAGE_UBS = 4,\r\n    SG_MAX_UB_MEMBERS = 16,\r\n    SG_MAX_VERTEX_ATTRIBUTES = 16,      /* NOTE: actual max vertex attrs can be less on GLES2, see sg_limits! */\r\n    SG_MAX_MIPMAPS = 16,\r\n    SG_MAX_TEXTUREARRAY_LAYERS = 128\r\n};\r\n\r\n/*\r\n    sg_backend\r\n\r\n    The active 3D-API backend, use the function sg_query_backend()\r\n    to get the currently active backend.\r\n\r\n    The returned value corresponds with the compile-time define to select\r\n    a backend, with the only exception of SOKOL_GLES3: this may\r\n    return SG_BACKEND_GLES2 if the backend has to fallback to GLES2 mode\r\n    because GLES3 isn't supported.\r\n*/\r\ntypedef enum sg_backend {\r\n    SG_BACKEND_GLCORE33,\r\n    SG_BACKEND_GLES2,\r\n    SG_BACKEND_GLES3,\r\n    SG_BACKEND_D3D11,\r\n    SG_BACKEND_METAL_IOS,\r\n    SG_BACKEND_METAL_MACOS,\r\n    SG_BACKEND_METAL_SIMULATOR,\r\n    SG_BACKEND_WGPU,\r\n    SG_BACKEND_DUMMY,\r\n} sg_backend;\r\n\r\n/*\r\n    sg_pixel_format\r\n\r\n    sokol_gfx.h basically uses the same pixel formats as WebGPU, since these\r\n    are supported on most newer GPUs. GLES2 and WebGL has a much smaller\r\n    subset of available pixel formats. Call sg_query_pixelformat() to check\r\n    at runtime if a pixel format supports the desired features.\r\n\r\n    A pixelformat name consist of three parts:\r\n\r\n        - components (R, RG, RGB or RGBA)\r\n        - bit width per component (8, 16 or 32)\r\n        - component data type:\r\n            - unsigned normalized (no postfix)\r\n            - signed normalized (SN postfix)\r\n            - unsigned integer (UI postfix)\r\n            - signed integer (SI postfix)\r\n            - float (F postfix)\r\n\r\n    Not all pixel formats can be used for everything, call sg_query_pixelformat()\r\n    to inspect the capabilities of a given pixelformat. The function returns\r\n    an sg_pixelformat_info struct with the following bool members:\r\n\r\n        - sample: the pixelformat can be sampled as texture at least with\r\n                  nearest filtering\r\n        - filter: the pixelformat can be samples as texture with linear\r\n                  filtering\r\n        - render: the pixelformat can be used for render targets\r\n        - blend:  blending is supported when using the pixelformat for\r\n                  render targets\r\n        - msaa:   multisample-antialiasing is supported when using the\r\n                  pixelformat for render targets\r\n        - depth:  the pixelformat can be used for depth-stencil attachments\r\n\r\n    When targeting GLES2/WebGL, the only safe formats to use\r\n    as texture are SG_PIXELFORMAT_R8 and SG_PIXELFORMAT_RGBA8. For rendering\r\n    in GLES2/WebGL, only SG_PIXELFORMAT_RGBA8 is safe. All other formats\r\n    must be checked via sg_query_pixelformats().\r\n\r\n    The default pixel format for texture images is SG_PIXELFORMAT_RGBA8.\r\n\r\n    The default pixel format for render target images is platform-dependent:\r\n        - for Metal and D3D11 it is SG_PIXELFORMAT_BGRA8\r\n        - for GL backends it is SG_PIXELFORMAT_RGBA8\r\n\r\n    This is mainly because of the default framebuffer which is setup outside\r\n    of sokol_gfx.h. On some backends, using BGRA for the default frame buffer\r\n    allows more efficient frame flips. For your own offscreen-render-targets,\r\n    use whatever renderable pixel format is convenient for you.\r\n*/\r\ntypedef enum sg_pixel_format {\r\n    _SG_PIXELFORMAT_DEFAULT,    /* value 0 reserved for default-init */\r\n    SG_PIXELFORMAT_NONE,\r\n\r\n    SG_PIXELFORMAT_R8,\r\n    SG_PIXELFORMAT_R8SN,\r\n    SG_PIXELFORMAT_R8UI,\r\n    SG_PIXELFORMAT_R8SI,\r\n\r\n    SG_PIXELFORMAT_R16,\r\n    SG_PIXELFORMAT_R16SN,\r\n    SG_PIXELFORMAT_R16UI,\r\n    SG_PIXELFORMAT_R16SI,\r\n    SG_PIXELFORMAT_R16F,\r\n    SG_PIXELFORMAT_RG8,\r\n    SG_PIXELFORMAT_RG8SN,\r\n    SG_PIXELFORMAT_RG8UI,\r\n    SG_PIXELFORMAT_RG8SI,\r\n\r\n    SG_PIXELFORMAT_R32UI,\r\n    SG_PIXELFORMAT_R32SI,\r\n    SG_PIXELFORMAT_R32F,\r\n    SG_PIXELFORMAT_RG16,\r\n    SG_PIXELFORMAT_RG16SN,\r\n    SG_PIXELFORMAT_RG16UI,\r\n    SG_PIXELFORMAT_RG16SI,\r\n    SG_PIXELFORMAT_RG16F,\r\n    SG_PIXELFORMAT_RGBA8,\r\n    SG_PIXELFORMAT_RGBA8SN,\r\n    SG_PIXELFORMAT_RGBA8UI,\r\n    SG_PIXELFORMAT_RGBA8SI,\r\n    SG_PIXELFORMAT_BGRA8,\r\n    SG_PIXELFORMAT_RGB10A2,\r\n    SG_PIXELFORMAT_RG11B10F,\r\n\r\n    SG_PIXELFORMAT_RG32UI,\r\n    SG_PIXELFORMAT_RG32SI,\r\n    SG_PIXELFORMAT_RG32F,\r\n    SG_PIXELFORMAT_RGBA16,\r\n    SG_PIXELFORMAT_RGBA16SN,\r\n    SG_PIXELFORMAT_RGBA16UI,\r\n    SG_PIXELFORMAT_RGBA16SI,\r\n    SG_PIXELFORMAT_RGBA16F,\r\n\r\n    SG_PIXELFORMAT_RGBA32UI,\r\n    SG_PIXELFORMAT_RGBA32SI,\r\n    SG_PIXELFORMAT_RGBA32F,\r\n\r\n    SG_PIXELFORMAT_DEPTH,\r\n    SG_PIXELFORMAT_DEPTH_STENCIL,\r\n\r\n    SG_PIXELFORMAT_BC1_RGBA,\r\n    SG_PIXELFORMAT_BC2_RGBA,\r\n    SG_PIXELFORMAT_BC3_RGBA,\r\n    SG_PIXELFORMAT_BC4_R,\r\n    SG_PIXELFORMAT_BC4_RSN,\r\n    SG_PIXELFORMAT_BC5_RG,\r\n    SG_PIXELFORMAT_BC5_RGSN,\r\n    SG_PIXELFORMAT_BC6H_RGBF,\r\n    SG_PIXELFORMAT_BC6H_RGBUF,\r\n    SG_PIXELFORMAT_BC7_RGBA,\r\n    SG_PIXELFORMAT_PVRTC_RGB_2BPP,\r\n    SG_PIXELFORMAT_PVRTC_RGB_4BPP,\r\n    SG_PIXELFORMAT_PVRTC_RGBA_2BPP,\r\n    SG_PIXELFORMAT_PVRTC_RGBA_4BPP,\r\n    SG_PIXELFORMAT_ETC2_RGB8,\r\n    SG_PIXELFORMAT_ETC2_RGB8A1,\r\n    SG_PIXELFORMAT_ETC2_RGBA8,\r\n    SG_PIXELFORMAT_ETC2_RG11,\r\n    SG_PIXELFORMAT_ETC2_RG11SN,\r\n\r\n    _SG_PIXELFORMAT_NUM,\r\n    _SG_PIXELFORMAT_FORCE_U32 = 0x7FFFFFFF\r\n} sg_pixel_format;\r\n\r\n/*\r\n    Runtime information about a pixel format, returned\r\n    by sg_query_pixelformat().\r\n*/\r\ntypedef struct sg_pixelformat_info {\r\n    bool sample;        /* pixel format can be sampled in shaders */\r\n    bool filter;        /* pixel format can be sampled with filtering */\r\n    bool render;        /* pixel format can be used as render target */\r\n    bool blend;         /* alpha-blending is supported */\r\n    bool msaa;          /* pixel format can be used as MSAA render target */\r\n    bool depth;         /* pixel format is a depth format */\r\n} sg_pixelformat_info;\r\n\r\n/*\r\n    Runtime information about available optional features,\r\n    returned by sg_query_features()\r\n*/\r\ntypedef struct sg_features {\r\n    bool instancing;                /* hardware instancing supported */\r\n    bool origin_top_left;           /* framebuffer and texture origin is in top left corner */\r\n    bool multiple_render_targets;   /* offscreen render passes can have multiple render targets attached */\r\n    bool msaa_render_targets;       /* offscreen render passes support MSAA antialiasing */\r\n    bool imagetype_3d;              /* creation of SG_IMAGETYPE_3D images is supported */\r\n    bool imagetype_array;           /* creation of SG_IMAGETYPE_ARRAY images is supported */\r\n    bool image_clamp_to_border;     /* border color and clamp-to-border UV-wrap mode is supported */\r\n} sg_features;\r\n\r\n/*\r\n    Runtime information about resource limits, returned by sg_query_limit()\r\n*/\r\ntypedef struct sg_limits {\r\n    uint32_t max_image_size_2d;         /* max width/height of SG_IMAGETYPE_2D images */\r\n    uint32_t max_image_size_cube;       /* max width/height of SG_IMAGETYPE_CUBE images */\r\n    uint32_t max_image_size_3d;         /* max width/height/depth of SG_IMAGETYPE_3D images */\r\n    uint32_t max_image_size_array;      /* max width/height pf SG_IMAGETYPE_ARRAY images */\r\n    uint32_t max_image_array_layers;    /* max number of layers in SG_IMAGETYPE_ARRAY images */\r\n    uint32_t max_vertex_attrs;          /* <= SG_MAX_VERTEX_ATTRIBUTES (only on some GLES2 impls) */\r\n} sg_limits;\r\n\r\n/*\r\n    sg_resource_state\r\n\r\n    The current state of a resource in its resource pool.\r\n    Resources start in the INITIAL state, which means the\r\n    pool slot is unoccupied and can be allocated. When a resource is\r\n    created, first an id is allocated, and the resource pool slot\r\n    is set to state ALLOC. After allocation, the resource is\r\n    initialized, which may result in the VALID or FAILED state. The\r\n    reason why allocation and initialization are separate is because\r\n    some resource types (e.g. buffers and images) might be asynchronously\r\n    initialized by the user application. If a resource which is not\r\n    in the VALID state is attempted to be used for rendering, rendering\r\n    operations will silently be dropped.\r\n\r\n    The special INVALID state is returned in sg_query_xxx_state() if no\r\n    resource object exists for the provided resource id.\r\n*/\r\ntypedef enum sg_resource_state {\r\n    SG_RESOURCESTATE_INITIAL,\r\n    SG_RESOURCESTATE_ALLOC,\r\n    SG_RESOURCESTATE_VALID,\r\n    SG_RESOURCESTATE_FAILED,\r\n    SG_RESOURCESTATE_INVALID,\r\n    _SG_RESOURCESTATE_FORCE_U32 = 0x7FFFFFFF\r\n} sg_resource_state;\r\n\r\n/*\r\n    sg_usage\r\n\r\n    A resource usage hint describing the update strategy of\r\n    buffers and images. This is used in the sg_buffer_desc.usage\r\n    and sg_image_desc.usage members when creating buffers\r\n    and images:\r\n\r\n    SG_USAGE_IMMUTABLE:     the resource will never be updated with\r\n                            new data, instead the content of the\r\n                            resource must be provided on creation\r\n    SG_USAGE_DYNAMIC:       the resource will be updated infrequently\r\n                            with new data (this could range from \"once\r\n                            after creation\", to \"quite often but not\r\n                            every frame\")\r\n    SG_USAGE_STREAM:        the resource will be updated each frame\r\n                            with new content\r\n\r\n    The rendering backends use this hint to prevent that the\r\n    CPU needs to wait for the GPU when attempting to update\r\n    a resource that might be currently accessed by the GPU.\r\n\r\n    Resource content is updated with the functions sg_update_buffer() or\r\n    sg_append_buffer() for buffer objects, and sg_update_image() for image\r\n    objects. For the sg_update_*() functions, only one update is allowed per\r\n    frame and resource object, while sg_append_buffer() can be called\r\n    multiple times per frame on the same buffer. The application must update\r\n    all data required for rendering (this means that the update data can be\r\n    smaller than the resource size, if only a part of the overall resource\r\n    size is used for rendering, you only need to make sure that the data that\r\n    *is* used is valid).\r\n\r\n    The default usage is SG_USAGE_IMMUTABLE.\r\n*/\r\ntypedef enum sg_usage {\r\n    _SG_USAGE_DEFAULT,      /* value 0 reserved for default-init */\r\n    SG_USAGE_IMMUTABLE,\r\n    SG_USAGE_DYNAMIC,\r\n    SG_USAGE_STREAM,\r\n    _SG_USAGE_NUM,\r\n    _SG_USAGE_FORCE_U32 = 0x7FFFFFFF\r\n} sg_usage;\r\n\r\n/*\r\n    sg_buffer_type\r\n\r\n    This indicates whether a buffer contains vertex- or index-data,\r\n    used in the sg_buffer_desc.type member when creating a buffer.\r\n\r\n    The default value is SG_BUFFERTYPE_VERTEXBUFFER.\r\n*/\r\ntypedef enum sg_buffer_type {\r\n    _SG_BUFFERTYPE_DEFAULT,         /* value 0 reserved for default-init */\r\n    SG_BUFFERTYPE_VERTEXBUFFER,\r\n    SG_BUFFERTYPE_INDEXBUFFER,\r\n    _SG_BUFFERTYPE_NUM,\r\n    _SG_BUFFERTYPE_FORCE_U32 = 0x7FFFFFFF\r\n} sg_buffer_type;\r\n\r\n/*\r\n    sg_index_type\r\n\r\n    Indicates whether indexed rendering (fetching vertex-indices from an\r\n    index buffer) is used, and if yes, the index data type (16- or 32-bits).\r\n    This is used in the sg_pipeline_desc.index_type member when creating a\r\n    pipeline object.\r\n\r\n    The default index type is SG_INDEXTYPE_NONE.\r\n*/\r\ntypedef enum sg_index_type {\r\n    _SG_INDEXTYPE_DEFAULT,   /* value 0 reserved for default-init */\r\n    SG_INDEXTYPE_NONE,\r\n    SG_INDEXTYPE_UINT16,\r\n    SG_INDEXTYPE_UINT32,\r\n    _SG_INDEXTYPE_NUM,\r\n    _SG_INDEXTYPE_FORCE_U32 = 0x7FFFFFFF\r\n} sg_index_type;\r\n\r\n/*\r\n    sg_image_type\r\n\r\n    Indicates the basic type of an image object (2D-texture, cubemap,\r\n    3D-texture or 2D-array-texture). 3D- and array-textures are not supported\r\n    on the GLES2/WebGL backend (use sg_query_features().imagetype_3d and\r\n    sg_query_features().imagetype_array to check for support). The image type\r\n    is used in the sg_image_desc.type member when creating an image, and\r\n    in sg_shader_image_desc when describing a shader's texture sampler binding.\r\n\r\n    The default image type when creating an image is SG_IMAGETYPE_2D.\r\n*/\r\ntypedef enum sg_image_type {\r\n    _SG_IMAGETYPE_DEFAULT,  /* value 0 reserved for default-init */\r\n    SG_IMAGETYPE_2D,\r\n    SG_IMAGETYPE_CUBE,\r\n    SG_IMAGETYPE_3D,\r\n    SG_IMAGETYPE_ARRAY,\r\n    _SG_IMAGETYPE_NUM,\r\n    _SG_IMAGETYPE_FORCE_U32 = 0x7FFFFFFF\r\n} sg_image_type;\r\n\r\n/*\r\n    sg_sampler_type\r\n\r\n    Indicates the basic data type of a shader's texture sampler which\r\n    can be float , unsigned integer or signed integer. The sampler\r\n    type is used in the sg_shader_image_desc to describe the\r\n    sampler type of a shader's texture sampler binding.\r\n\r\n    The default sampler type is SG_SAMPLERTYPE_FLOAT.\r\n*/\r\ntypedef enum sg_sampler_type {\r\n    _SG_SAMPLERTYPE_DEFAULT,  /* value 0 reserved for default-init */\r\n    SG_SAMPLERTYPE_FLOAT,\r\n    SG_SAMPLERTYPE_SINT,\r\n    SG_SAMPLERTYPE_UINT,\r\n} sg_sampler_type;\r\n\r\n/*\r\n    sg_cube_face\r\n\r\n    The cubemap faces. Use these as indices in the sg_image_desc.content\r\n    array.\r\n*/\r\ntypedef enum sg_cube_face {\r\n    SG_CUBEFACE_POS_X,\r\n    SG_CUBEFACE_NEG_X,\r\n    SG_CUBEFACE_POS_Y,\r\n    SG_CUBEFACE_NEG_Y,\r\n    SG_CUBEFACE_POS_Z,\r\n    SG_CUBEFACE_NEG_Z,\r\n    SG_CUBEFACE_NUM,\r\n    _SG_CUBEFACE_FORCE_U32 = 0x7FFFFFFF\r\n} sg_cube_face;\r\n\r\n/*\r\n    sg_shader_stage\r\n\r\n    There are 2 shader stages: vertex- and fragment-shader-stage.\r\n    Each shader stage consists of:\r\n\r\n    - one slot for a shader function (provided as source- or byte-code)\r\n    - SG_MAX_SHADERSTAGE_UBS slots for uniform blocks\r\n    - SG_MAX_SHADERSTAGE_IMAGES slots for images used as textures by\r\n      the shader function\r\n*/\r\ntypedef enum sg_shader_stage {\r\n    SG_SHADERSTAGE_VS,\r\n    SG_SHADERSTAGE_FS,\r\n    _SG_SHADERSTAGE_FORCE_U32 = 0x7FFFFFFF\r\n} sg_shader_stage;\r\n\r\n/*\r\n    sg_primitive_type\r\n\r\n    This is the common subset of 3D primitive types supported across all 3D\r\n    APIs. This is used in the sg_pipeline_desc.primitive_type member when\r\n    creating a pipeline object.\r\n\r\n    The default primitive type is SG_PRIMITIVETYPE_TRIANGLES.\r\n*/\r\ntypedef enum sg_primitive_type {\r\n    _SG_PRIMITIVETYPE_DEFAULT,  /* value 0 reserved for default-init */\r\n    SG_PRIMITIVETYPE_POINTS,\r\n    SG_PRIMITIVETYPE_LINES,\r\n    SG_PRIMITIVETYPE_LINE_STRIP,\r\n    SG_PRIMITIVETYPE_TRIANGLES,\r\n    SG_PRIMITIVETYPE_TRIANGLE_STRIP,\r\n    _SG_PRIMITIVETYPE_NUM,\r\n    _SG_PRIMITIVETYPE_FORCE_U32 = 0x7FFFFFFF\r\n} sg_primitive_type;\r\n\r\n/*\r\n    sg_filter\r\n\r\n    The filtering mode when sampling a texture image. This is\r\n    used in the sg_image_desc.min_filter and sg_image_desc.mag_filter\r\n    members when creating an image object.\r\n\r\n    The default filter mode is SG_FILTER_NEAREST.\r\n*/\r\ntypedef enum sg_filter {\r\n    _SG_FILTER_DEFAULT, /* value 0 reserved for default-init */\r\n    SG_FILTER_NEAREST,\r\n    SG_FILTER_LINEAR,\r\n    SG_FILTER_NEAREST_MIPMAP_NEAREST,\r\n    SG_FILTER_NEAREST_MIPMAP_LINEAR,\r\n    SG_FILTER_LINEAR_MIPMAP_NEAREST,\r\n    SG_FILTER_LINEAR_MIPMAP_LINEAR,\r\n    _SG_FILTER_NUM,\r\n    _SG_FILTER_FORCE_U32 = 0x7FFFFFFF\r\n} sg_filter;\r\n\r\n/*\r\n    sg_wrap\r\n\r\n    The texture coordinates wrapping mode when sampling a texture\r\n    image. This is used in the sg_image_desc.wrap_u, .wrap_v\r\n    and .wrap_w members when creating an image.\r\n\r\n    The default wrap mode is SG_WRAP_REPEAT.\r\n\r\n    NOTE: SG_WRAP_CLAMP_TO_BORDER is not supported on all backends\r\n    and platforms. To check for support, call sg_query_features()\r\n    and check the \"clamp_to_border\" boolean in the returned\r\n    sg_features struct.\r\n\r\n    Platforms which don't support SG_WRAP_CLAMP_TO_BORDER will silently fall back\r\n    to SG_WRAP_CLAMP_TO_EDGE without a validation error.\r\n\r\n    Platforms which support clamp-to-border are:\r\n\r\n        - all desktop GL platforms\r\n        - Metal on macOS\r\n        - D3D11\r\n\r\n    Platforms which do not support clamp-to-border:\r\n\r\n        - GLES2/3 and WebGL/WebGL2\r\n        - Metal on iOS\r\n*/\r\ntypedef enum sg_wrap {\r\n    _SG_WRAP_DEFAULT,   /* value 0 reserved for default-init */\r\n    SG_WRAP_REPEAT,\r\n    SG_WRAP_CLAMP_TO_EDGE,\r\n    SG_WRAP_CLAMP_TO_BORDER,\r\n    SG_WRAP_MIRRORED_REPEAT,\r\n    _SG_WRAP_NUM,\r\n    _SG_WRAP_FORCE_U32 = 0x7FFFFFFF\r\n} sg_wrap;\r\n\r\n/*\r\n    sg_border_color\r\n\r\n    The border color to use when sampling a texture, and the UV wrap\r\n    mode is SG_WRAP_CLAMP_TO_BORDER.\r\n\r\n    The default border color is SG_BORDERCOLOR_OPAQUE_BLACK\r\n*/\r\ntypedef enum sg_border_color {\r\n    _SG_BORDERCOLOR_DEFAULT,    /* value 0 reserved for default-init */\r\n    SG_BORDERCOLOR_TRANSPARENT_BLACK,\r\n    SG_BORDERCOLOR_OPAQUE_BLACK,\r\n    SG_BORDERCOLOR_OPAQUE_WHITE,\r\n    _SG_BORDERCOLOR_NUM,\r\n    _SG_BORDERCOLOR_FORCE_U32 = 0x7FFFFFFF\r\n} sg_border_color;\r\n\r\n/*\r\n    sg_vertex_format\r\n\r\n    The data type of a vertex component. This is used to describe\r\n    the layout of vertex data when creating a pipeline object.\r\n*/\r\ntypedef enum sg_vertex_format {\r\n    SG_VERTEXFORMAT_INVALID,\r\n    SG_VERTEXFORMAT_FLOAT,\r\n    SG_VERTEXFORMAT_FLOAT2,\r\n    SG_VERTEXFORMAT_FLOAT3,\r\n    SG_VERTEXFORMAT_FLOAT4,\r\n    SG_VERTEXFORMAT_BYTE4,\r\n    SG_VERTEXFORMAT_BYTE4N,\r\n    SG_VERTEXFORMAT_UBYTE4,\r\n    SG_VERTEXFORMAT_UBYTE4N,\r\n    SG_VERTEXFORMAT_SHORT2,\r\n    SG_VERTEXFORMAT_SHORT2N,\r\n    SG_VERTEXFORMAT_USHORT2N,\r\n    SG_VERTEXFORMAT_SHORT4,\r\n    SG_VERTEXFORMAT_SHORT4N,\r\n    SG_VERTEXFORMAT_USHORT4N,\r\n    SG_VERTEXFORMAT_UINT10_N2,\r\n    _SG_VERTEXFORMAT_NUM,\r\n    _SG_VERTEXFORMAT_FORCE_U32 = 0x7FFFFFFF\r\n} sg_vertex_format;\r\n\r\n/*\r\n    sg_vertex_step\r\n\r\n    Defines whether the input pointer of a vertex input stream is advanced\r\n    'per vertex' or 'per instance'. The default step-func is\r\n    SG_VERTEXSTEP_PER_VERTEX. SG_VERTEXSTEP_PER_INSTANCE is used with\r\n    instanced-rendering.\r\n\r\n    The vertex-step is part of the vertex-layout definition\r\n    when creating pipeline objects.\r\n*/\r\ntypedef enum sg_vertex_step {\r\n    _SG_VERTEXSTEP_DEFAULT,     /* value 0 reserved for default-init */\r\n    SG_VERTEXSTEP_PER_VERTEX,\r\n    SG_VERTEXSTEP_PER_INSTANCE,\r\n    _SG_VERTEXSTEP_NUM,\r\n    _SG_VERTEXSTEP_FORCE_U32 = 0x7FFFFFFF\r\n} sg_vertex_step;\r\n\r\n/*\r\n    sg_uniform_type\r\n\r\n    The data type of a uniform block member. This is used to\r\n    describe the internal layout of uniform blocks when creating\r\n    a shader object.\r\n*/\r\ntypedef enum sg_uniform_type {\r\n    SG_UNIFORMTYPE_INVALID,\r\n    SG_UNIFORMTYPE_FLOAT,\r\n    SG_UNIFORMTYPE_FLOAT2,\r\n    SG_UNIFORMTYPE_FLOAT3,\r\n    SG_UNIFORMTYPE_FLOAT4,\r\n    SG_UNIFORMTYPE_MAT4,\r\n    _SG_UNIFORMTYPE_NUM,\r\n    _SG_UNIFORMTYPE_FORCE_U32 = 0x7FFFFFFF\r\n} sg_uniform_type;\r\n\r\n/*\r\n    sg_cull_mode\r\n\r\n    The face-culling mode, this is used in the\r\n    sg_pipeline_desc.rasterizer.cull_mode member when creating a\r\n    pipeline object.\r\n\r\n    The default cull mode is SG_CULLMODE_NONE\r\n*/\r\ntypedef enum sg_cull_mode {\r\n    _SG_CULLMODE_DEFAULT,   /* value 0 reserved for default-init */\r\n    SG_CULLMODE_NONE,\r\n    SG_CULLMODE_FRONT,\r\n    SG_CULLMODE_BACK,\r\n    _SG_CULLMODE_NUM,\r\n    _SG_CULLMODE_FORCE_U32 = 0x7FFFFFFF\r\n} sg_cull_mode;\r\n\r\n/*\r\n    sg_face_winding\r\n\r\n    The vertex-winding rule that determines a front-facing primitive. This\r\n    is used in the member sg_pipeline_desc.rasterizer.face_winding\r\n    when creating a pipeline object.\r\n\r\n    The default winding is SG_FACEWINDING_CW (clockwise)\r\n*/\r\ntypedef enum sg_face_winding {\r\n    _SG_FACEWINDING_DEFAULT,    /* value 0 reserved for default-init */\r\n    SG_FACEWINDING_CCW,\r\n    SG_FACEWINDING_CW,\r\n    _SG_FACEWINDING_NUM,\r\n    _SG_FACEWINDING_FORCE_U32 = 0x7FFFFFFF\r\n} sg_face_winding;\r\n\r\n/*\r\n    sg_compare_func\r\n\r\n    The compare-function for depth- and stencil-ref tests.\r\n    This is used when creating pipeline objects in the members:\r\n\r\n    sg_pipeline_desc\r\n        .depth_stencil\r\n            .depth_compare_func\r\n            .stencil_front.compare_func\r\n            .stencil_back.compare_func\r\n\r\n    The default compare func for depth- and stencil-tests is\r\n    SG_COMPAREFUNC_ALWAYS.\r\n*/\r\ntypedef enum sg_compare_func {\r\n    _SG_COMPAREFUNC_DEFAULT,    /* value 0 reserved for default-init */\r\n    SG_COMPAREFUNC_NEVER,\r\n    SG_COMPAREFUNC_LESS,\r\n    SG_COMPAREFUNC_EQUAL,\r\n    SG_COMPAREFUNC_LESS_EQUAL,\r\n    SG_COMPAREFUNC_GREATER,\r\n    SG_COMPAREFUNC_NOT_EQUAL,\r\n    SG_COMPAREFUNC_GREATER_EQUAL,\r\n    SG_COMPAREFUNC_ALWAYS,\r\n    _SG_COMPAREFUNC_NUM,\r\n    _SG_COMPAREFUNC_FORCE_U32 = 0x7FFFFFFF\r\n} sg_compare_func;\r\n\r\n/*\r\n    sg_stencil_op\r\n\r\n    The operation performed on a currently stored stencil-value when a\r\n    comparison test passes or fails. This is used when creating a pipeline\r\n    object in the members:\r\n\r\n    sg_pipeline_desc\r\n        .depth_stencil\r\n            .stencil_front\r\n                .fail_op\r\n                .depth_fail_op\r\n                .pass_op\r\n            .stencil_back\r\n                .fail_op\r\n                .depth_fail_op\r\n                .pass_op\r\n\r\n    The default value is SG_STENCILOP_KEEP.\r\n*/\r\ntypedef enum sg_stencil_op {\r\n    _SG_STENCILOP_DEFAULT,      /* value 0 reserved for default-init */\r\n    SG_STENCILOP_KEEP,\r\n    SG_STENCILOP_ZERO,\r\n    SG_STENCILOP_REPLACE,\r\n    SG_STENCILOP_INCR_CLAMP,\r\n    SG_STENCILOP_DECR_CLAMP,\r\n    SG_STENCILOP_INVERT,\r\n    SG_STENCILOP_INCR_WRAP,\r\n    SG_STENCILOP_DECR_WRAP,\r\n    _SG_STENCILOP_NUM,\r\n    _SG_STENCILOP_FORCE_U32 = 0x7FFFFFFF\r\n} sg_stencil_op;\r\n\r\n/*\r\n    sg_blend_factor\r\n\r\n    The source and destination factors in blending operations.\r\n    This is used in the following members when creating a pipeline object:\r\n\r\n    sg_pipeline_desc\r\n        .blend\r\n            .src_factor_rgb\r\n            .dst_factor_rgb\r\n            .src_factor_alpha\r\n            .dst_factor_alpha\r\n\r\n    The default value is SG_BLENDFACTOR_ONE for source\r\n    factors, and SG_BLENDFACTOR_ZERO for destination factors.\r\n*/\r\ntypedef enum sg_blend_factor {\r\n    _SG_BLENDFACTOR_DEFAULT,    /* value 0 reserved for default-init */\r\n    SG_BLENDFACTOR_ZERO,\r\n    SG_BLENDFACTOR_ONE,\r\n    SG_BLENDFACTOR_SRC_COLOR,\r\n    SG_BLENDFACTOR_ONE_MINUS_SRC_COLOR,\r\n    SG_BLENDFACTOR_SRC_ALPHA,\r\n    SG_BLENDFACTOR_ONE_MINUS_SRC_ALPHA,\r\n    SG_BLENDFACTOR_DST_COLOR,\r\n    SG_BLENDFACTOR_ONE_MINUS_DST_COLOR,\r\n    SG_BLENDFACTOR_DST_ALPHA,\r\n    SG_BLENDFACTOR_ONE_MINUS_DST_ALPHA,\r\n    SG_BLENDFACTOR_SRC_ALPHA_SATURATED,\r\n    SG_BLENDFACTOR_BLEND_COLOR,\r\n    SG_BLENDFACTOR_ONE_MINUS_BLEND_COLOR,\r\n    SG_BLENDFACTOR_BLEND_ALPHA,\r\n    SG_BLENDFACTOR_ONE_MINUS_BLEND_ALPHA,\r\n    _SG_BLENDFACTOR_NUM,\r\n    _SG_BLENDFACTOR_FORCE_U32 = 0x7FFFFFFF\r\n} sg_blend_factor;\r\n\r\n/*\r\n    sg_blend_op\r\n\r\n    Describes how the source and destination values are combined in the\r\n    fragment blending operation. It is used in the following members when\r\n    creating a pipeline object:\r\n\r\n    sg_pipeline_desc\r\n        .blend\r\n            .op_rgb\r\n            .op_alpha\r\n\r\n    The default value is SG_BLENDOP_ADD.\r\n*/\r\ntypedef enum sg_blend_op {\r\n    _SG_BLENDOP_DEFAULT,    /* value 0 reserved for default-init */\r\n    SG_BLENDOP_ADD,\r\n    SG_BLENDOP_SUBTRACT,\r\n    SG_BLENDOP_REVERSE_SUBTRACT,\r\n    _SG_BLENDOP_NUM,\r\n    _SG_BLENDOP_FORCE_U32 = 0x7FFFFFFF\r\n} sg_blend_op;\r\n\r\n/*\r\n    sg_color_mask\r\n\r\n    Selects the color channels when writing a fragment color to the\r\n    framebuffer. This is used in the members\r\n    sg_pipeline_desc.blend.color_write_mask when creating a pipeline object.\r\n\r\n    The default colormask is SG_COLORMASK_RGBA (write all colors channels)\r\n\r\n    NOTE: since the color mask value 0 is reserved for the default value\r\n    (SG_COLORMASK_RGBA), use SG_COLORMASK_NONE if all color channels\r\n    should be disabled.\r\n*/\r\ntypedef enum sg_color_mask {\r\n    _SG_COLORMASK_DEFAULT = 0,      /* value 0 reserved for default-init */\r\n    SG_COLORMASK_NONE = (0x10),     /* special value for 'all channels disabled */\r\n    SG_COLORMASK_R = (1<<0),\r\n    SG_COLORMASK_G = (1<<1),\r\n    SG_COLORMASK_B = (1<<2),\r\n    SG_COLORMASK_A = (1<<3),\r\n    SG_COLORMASK_RGB = 0x7,\r\n    SG_COLORMASK_RGBA = 0xF,\r\n    _SG_COLORMASK_FORCE_U32 = 0x7FFFFFFF\r\n} sg_color_mask;\r\n\r\n/*\r\n    sg_action\r\n\r\n    Defines what action should be performed at the start of a render pass:\r\n\r\n    SG_ACTION_CLEAR:    clear the render target image\r\n    SG_ACTION_LOAD:     load the previous content of the render target image\r\n    SG_ACTION_DONTCARE: leave the render target image content undefined\r\n\r\n    This is used in the sg_pass_action structure.\r\n\r\n    The default action for all pass attachments is SG_ACTION_CLEAR, with the\r\n    clear color rgba = {0.5f, 0.5f, 0.5f, 1.0f], depth=1.0 and stencil=0.\r\n\r\n    If you want to override the default behaviour, it is important to not\r\n    only set the clear color, but the 'action' field as well (as long as this\r\n    is in its _SG_ACTION_DEFAULT, the value fields will be ignored).\r\n*/\r\ntypedef enum sg_action {\r\n    _SG_ACTION_DEFAULT,\r\n    SG_ACTION_CLEAR,\r\n    SG_ACTION_LOAD,\r\n    SG_ACTION_DONTCARE,\r\n    _SG_ACTION_NUM,\r\n    _SG_ACTION_FORCE_U32 = 0x7FFFFFFF\r\n} sg_action;\r\n\r\n/*\r\n    sg_pass_action\r\n\r\n    The sg_pass_action struct defines the actions to be performed\r\n    at the start of a rendering pass in the functions sg_begin_pass()\r\n    and sg_begin_default_pass().\r\n\r\n    A separate action and clear values can be defined for each\r\n    color attachment, and for the depth-stencil attachment.\r\n\r\n    The default clear values are defined by the macros:\r\n\r\n    - SG_DEFAULT_CLEAR_RED:     0.5f\r\n    - SG_DEFAULT_CLEAR_GREEN:   0.5f\r\n    - SG_DEFAULT_CLEAR_BLUE:    0.5f\r\n    - SG_DEFAULT_CLEAR_ALPHA:   1.0f\r\n    - SG_DEFAULT_CLEAR_DEPTH:   1.0f\r\n    - SG_DEFAULT_CLEAR_STENCIL: 0\r\n*/\r\ntypedef struct sg_color_attachment_action {\r\n    sg_action action;\r\n    float val[4];\r\n} sg_color_attachment_action;\r\n\r\ntypedef struct sg_depth_attachment_action {\r\n    sg_action action;\r\n    float val;\r\n} sg_depth_attachment_action;\r\n\r\ntypedef struct sg_stencil_attachment_action {\r\n    sg_action action;\r\n    uint8_t val;\r\n} sg_stencil_attachment_action;\r\n\r\ntypedef struct sg_pass_action {\r\n    uint32_t _start_canary;\r\n    sg_color_attachment_action colors[SG_MAX_COLOR_ATTACHMENTS];\r\n    sg_depth_attachment_action depth;\r\n    sg_stencil_attachment_action stencil;\r\n    uint32_t _end_canary;\r\n} sg_pass_action;\r\n\r\n/*\r\n    sg_bindings\r\n\r\n    The sg_bindings structure defines the resource binding slots\r\n    of the sokol_gfx render pipeline, used as argument to the\r\n    sg_apply_bindings() function.\r\n\r\n    A resource binding struct contains:\r\n\r\n    - 1..N vertex buffers\r\n    - 0..N vertex buffer offsets\r\n    - 0..1 index buffers\r\n    - 0..1 index buffer offsets\r\n    - 0..N vertex shader stage images\r\n    - 0..N fragment shader stage images\r\n\r\n    The max number of vertex buffer and shader stage images\r\n    are defined by the SG_MAX_SHADERSTAGE_BUFFERS and\r\n    SG_MAX_SHADERSTAGE_IMAGES configuration constants.\r\n\r\n    The optional buffer offsets can be used to put different unrelated\r\n    chunks of vertex- and/or index-data into the same buffer objects.\r\n*/\r\ntypedef struct sg_bindings {\r\n    uint32_t _start_canary;\r\n    sg_buffer vertex_buffers[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    int vertex_buffer_offsets[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    sg_buffer index_buffer;\r\n    int index_buffer_offset;\r\n    sg_image vs_images[SG_MAX_SHADERSTAGE_IMAGES];\r\n    sg_image fs_images[SG_MAX_SHADERSTAGE_IMAGES];\r\n    uint32_t _end_canary;\r\n} sg_bindings;\r\n\r\n/*\r\n    sg_buffer_desc\r\n\r\n    Creation parameters for sg_buffer objects, used in the\r\n    sg_make_buffer() call.\r\n\r\n    The default configuration is:\r\n\r\n    .size:      0       (this *must* be set to a valid size in bytes)\r\n    .type:      SG_BUFFERTYPE_VERTEXBUFFER\r\n    .usage:     SG_USAGE_IMMUTABLE\r\n    .content    0\r\n    .label      0       (optional string label for trace hooks)\r\n\r\n    The label will be ignored by sokol_gfx.h, it is only useful\r\n    when hooking into sg_make_buffer() or sg_init_buffer() via\r\n    the sg_install_trace_hooks() function.\r\n\r\n    ADVANCED TOPIC: Injecting native 3D-API buffers:\r\n\r\n    The following struct members allow to inject your own GL, Metal\r\n    or D3D11 buffers into sokol_gfx:\r\n\r\n    .gl_buffers[SG_NUM_INFLIGHT_FRAMES]\r\n    .mtl_buffers[SG_NUM_INFLIGHT_FRAMES]\r\n    .d3d11_buffer\r\n\r\n    You must still provide all other members except the .content member, and\r\n    these must match the creation parameters of the native buffers you\r\n    provide. For SG_USAGE_IMMUTABLE, only provide a single native 3D-API\r\n    buffer, otherwise you need to provide SG_NUM_INFLIGHT_FRAMES buffers\r\n    (only for GL and Metal, not D3D11). Providing multiple buffers for GL and\r\n    Metal is necessary because sokol_gfx will rotate through them when\r\n    calling sg_update_buffer() to prevent lock-stalls.\r\n\r\n    Note that it is expected that immutable injected buffer have already been\r\n    initialized with content, and the .content member must be 0!\r\n\r\n    Also you need to call sg_reset_state_cache() after calling native 3D-API\r\n    functions, and before calling any sokol_gfx function.\r\n*/\r\ntypedef struct sg_buffer_desc {\r\n    uint32_t _start_canary;\r\n    int size;\r\n    sg_buffer_type type;\r\n    sg_usage usage;\r\n    const void* content;\r\n    const char* label;\r\n    /* GL specific */\r\n    uint32_t gl_buffers[SG_NUM_INFLIGHT_FRAMES];\r\n    /* Metal specific */\r\n    const void* mtl_buffers[SG_NUM_INFLIGHT_FRAMES];\r\n    /* D3D11 specific */\r\n    const void* d3d11_buffer;\r\n    /* WebGPU specific */\r\n    const void* wgpu_buffer;\r\n    uint32_t _end_canary;\r\n} sg_buffer_desc;\r\n\r\n/*\r\n    sg_subimage_content\r\n\r\n    Pointer to and size of a subimage-surface data, this is\r\n    used to describe the initial content of immutable-usage images,\r\n    or for updating a dynamic- or stream-usage images.\r\n\r\n    For 3D- or array-textures, one sg_subimage_content item\r\n    describes an entire mipmap level consisting of all array- or\r\n    3D-slices of the mipmap level. It is only possible to update\r\n    an entire mipmap level, not parts of it.\r\n*/\r\ntypedef struct sg_subimage_content {\r\n    const void* ptr;    /* pointer to subimage data */\r\n    int size;           /* size in bytes of pointed-to subimage data */\r\n} sg_subimage_content;\r\n\r\n/*\r\n    sg_image_content\r\n\r\n    Defines the content of an image through a 2D array\r\n    of sg_subimage_content structs. The first array dimension\r\n    is the cubemap face, and the second array dimension the\r\n    mipmap level.\r\n*/\r\ntypedef struct sg_image_content {\r\n    sg_subimage_content subimage[SG_CUBEFACE_NUM][SG_MAX_MIPMAPS];\r\n} sg_image_content;\r\n\r\n/*\r\n    sg_image_desc\r\n\r\n    Creation parameters for sg_image objects, used in the\r\n    sg_make_image() call.\r\n\r\n    The default configuration is:\r\n\r\n    .type:              SG_IMAGETYPE_2D\r\n    .render_target:     false\r\n    .width              0 (must be set to >0)\r\n    .height             0 (must be set to >0)\r\n    .depth/.layers:     1\r\n    .num_mipmaps:       1\r\n    .usage:             SG_USAGE_IMMUTABLE\r\n    .pixel_format:      SG_PIXELFORMAT_RGBA8 for textures, or sg_desc.context.color_format for render targets\r\n    .sample_count:      1 for textures, or sg_desc.context.sample_count for render target\r\n    .min_filter:        SG_FILTER_NEAREST\r\n    .mag_filter:        SG_FILTER_NEAREST\r\n    .wrap_u:            SG_WRAP_REPEAT\r\n    .wrap_v:            SG_WRAP_REPEAT\r\n    .wrap_w:            SG_WRAP_REPEAT (only SG_IMAGETYPE_3D)\r\n    .border_color       SG_BORDERCOLOR_OPAQUE_BLACK\r\n    .max_anisotropy     1 (must be 1..16)\r\n    .min_lod            0.0f\r\n    .max_lod            FLT_MAX\r\n    .content            an sg_image_content struct to define the initial content\r\n    .label              0       (optional string label for trace hooks)\r\n\r\n    Q: Why is the default sample_count for render targets identical with the\r\n    \"default sample count\" from sg_desc.context.sample_count?\r\n\r\n    A: So that it matches the default sample count in pipeline objects. Even\r\n    though it is a bit strange/confusing that offscreen render targets by default\r\n    get the same sample count as the default framebuffer, but it's better that\r\n    an offscreen render target created with default parameters matches\r\n    a pipeline object created with default parameters.\r\n\r\n    NOTE:\r\n\r\n    SG_IMAGETYPE_ARRAY and SG_IMAGETYPE_3D are not supported on\r\n    WebGL/GLES2, use sg_query_features().imagetype_array and\r\n    sg_query_features().imagetype_3d at runtime to check\r\n    if array- and 3D-textures are supported.\r\n\r\n    Images with usage SG_USAGE_IMMUTABLE must be fully initialized by\r\n    providing a valid .content member which points to\r\n    initialization data.\r\n\r\n    ADVANCED TOPIC: Injecting native 3D-API textures:\r\n\r\n    The following struct members allow to inject your own GL, Metal\r\n    or D3D11 textures into sokol_gfx:\r\n\r\n    .gl_textures[SG_NUM_INFLIGHT_FRAMES]\r\n    .mtl_textures[SG_NUM_INFLIGHT_FRAMES]\r\n    .d3d11_texture\r\n\r\n    The same rules apply as for injecting native buffers\r\n    (see sg_buffer_desc documentation for more details).\r\n*/\r\ntypedef struct sg_image_desc {\r\n    uint32_t _start_canary;\r\n    sg_image_type type;\r\n    bool render_target;\r\n    int width;\r\n    int height;\r\n    union {\r\n        int depth;\r\n        int layers;\r\n    };\r\n    int num_mipmaps;\r\n    sg_usage usage;\r\n    sg_pixel_format pixel_format;\r\n    int sample_count;\r\n    sg_filter min_filter;\r\n    sg_filter mag_filter;\r\n    sg_wrap wrap_u;\r\n    sg_wrap wrap_v;\r\n    sg_wrap wrap_w;\r\n    sg_border_color border_color;\r\n    uint32_t max_anisotropy;\r\n    float min_lod;\r\n    float max_lod;\r\n    sg_image_content content;\r\n    const char* label;\r\n    /* GL specific */\r\n    uint32_t gl_textures[SG_NUM_INFLIGHT_FRAMES];\r\n    /* Metal specific */\r\n    const void* mtl_textures[SG_NUM_INFLIGHT_FRAMES];\r\n    /* D3D11 specific */\r\n    const void* d3d11_texture;\r\n    /* WebGPU specific */\r\n    const void* wgpu_texture;\r\n    uint32_t _end_canary;\r\n} sg_image_desc;\r\n\r\n/*\r\n    sg_shader_desc\r\n\r\n    The structure sg_shader_desc defines all creation parameters\r\n    for shader programs, used as input to the sg_make_shader() function:\r\n\r\n    - reflection information for vertex attributes (vertex shader inputs):\r\n        - vertex attribute name (required for GLES2, optional for GLES3 and GL)\r\n        - a semantic name and index (required for D3D11)\r\n    - for each shader-stage (vertex and fragment):\r\n        - the shader source or bytecode\r\n        - an optional entry function name\r\n        - an optional compile target (only for D3D11 when source is provided,\r\n          defaults are \"vs_4_0\" and \"ps_4_0\")\r\n        - reflection info for each uniform block used by the shader stage:\r\n            - the size of the uniform block in bytes\r\n            - reflection info for each uniform block member (only required for GL backends):\r\n                - member name\r\n                - member type (SG_UNIFORMTYPE_xxx)\r\n                - if the member is an array, the number of array items\r\n        - reflection info for the texture images used by the shader stage:\r\n            - the image type (SG_IMAGETYPE_xxx)\r\n            - the sampler type (SG_SAMPLERTYPE_xxx, default is SG_SAMPLERTYPE_FLOAT)\r\n            - the name of the texture sampler (required for GLES2, optional everywhere else)\r\n\r\n    For all GL backends, shader source-code must be provided. For D3D11 and Metal,\r\n    either shader source-code or byte-code can be provided.\r\n\r\n    For D3D11, if source code is provided, the d3dcompiler_47.dll will be loaded\r\n    on demand. If this fails, shader creation will fail. When compiling HLSL\r\n    source code, you can provide an optional target string via\r\n    sg_shader_stage_desc.d3d11_target, the default target is \"vs_4_0\" for the\r\n    vertex shader stage and \"ps_4_0\" for the pixel shader stage.\r\n*/\r\ntypedef struct sg_shader_attr_desc {\r\n    const char* name;           /* GLSL vertex attribute name (only required for GLES2) */\r\n    const char* sem_name;       /* HLSL semantic name */\r\n    int sem_index;              /* HLSL semantic index */\r\n} sg_shader_attr_desc;\r\n\r\ntypedef struct sg_shader_uniform_desc {\r\n    const char* name;\r\n    sg_uniform_type type;\r\n    int array_count;\r\n} sg_shader_uniform_desc;\r\n\r\ntypedef struct sg_shader_uniform_block_desc {\r\n    int size;\r\n    sg_shader_uniform_desc uniforms[SG_MAX_UB_MEMBERS];\r\n} sg_shader_uniform_block_desc;\r\n\r\ntypedef struct sg_shader_image_desc {\r\n    const char* name;\r\n    sg_image_type type;         /* FIXME: should this be renamed to 'image_type'? */\r\n    sg_sampler_type sampler_type;\r\n} sg_shader_image_desc;\r\n\r\ntypedef struct sg_shader_stage_desc {\r\n    const char* source;\r\n    const uint8_t* byte_code;\r\n    int byte_code_size;\r\n    const char* entry;\r\n    const char* d3d11_target;\r\n    sg_shader_uniform_block_desc uniform_blocks[SG_MAX_SHADERSTAGE_UBS];\r\n    sg_shader_image_desc images[SG_MAX_SHADERSTAGE_IMAGES];\r\n} sg_shader_stage_desc;\r\n\r\ntypedef struct sg_shader_desc {\r\n    uint32_t _start_canary;\r\n    sg_shader_attr_desc attrs[SG_MAX_VERTEX_ATTRIBUTES];\r\n    sg_shader_stage_desc vs;\r\n    sg_shader_stage_desc fs;\r\n    const char* label;\r\n    uint32_t _end_canary;\r\n} sg_shader_desc;\r\n\r\n/*\r\n    sg_pipeline_desc\r\n\r\n    The sg_pipeline_desc struct defines all creation parameters\r\n    for an sg_pipeline object, used as argument to the\r\n    sg_make_pipeline() function:\r\n\r\n    - the vertex layout for all input vertex buffers\r\n    - a shader object\r\n    - the 3D primitive type (points, lines, triangles, ...)\r\n    - the index type (none, 16- or 32-bit)\r\n    - depth-stencil state\r\n    - alpha-blending state\r\n    - rasterizer state\r\n\r\n    If the vertex data has no gaps between vertex components, you can omit\r\n    the .layout.buffers[].stride and layout.attrs[].offset items (leave them\r\n    default-initialized to 0), sokol-gfx will then compute the offsets and strides\r\n    from the vertex component formats (.layout.attrs[].format). Please note\r\n    that ALL vertex attribute offsets must be 0 in order for the\r\n    automatic offset computation to kick in.\r\n\r\n    The default configuration is as follows:\r\n\r\n    .layout:\r\n        .buffers[]:         vertex buffer layouts\r\n            .stride:        0 (if no stride is given it will be computed)\r\n            .step_func      SG_VERTEXSTEP_PER_VERTEX\r\n            .step_rate      1\r\n        .attrs[]:           vertex attribute declarations\r\n            .buffer_index   0 the vertex buffer bind slot\r\n            .offset         0 (offsets can be omitted if the vertex layout has no gaps)\r\n            .format         SG_VERTEXFORMAT_INVALID (must be initialized!)\r\n    .shader:            0 (must be initialized with a valid sg_shader id!)\r\n    .primitive_type:    SG_PRIMITIVETYPE_TRIANGLES\r\n    .index_type:        SG_INDEXTYPE_NONE\r\n    .depth_stencil:\r\n        .stencil_front, .stencil_back:\r\n            .fail_op:               SG_STENCILOP_KEEP\r\n            .depth_fail_op:         SG_STENCILOP_KEEP\r\n            .pass_op:               SG_STENCILOP_KEEP\r\n            .compare_func           SG_COMPAREFUNC_ALWAYS\r\n        .depth_compare_func:    SG_COMPAREFUNC_ALWAYS\r\n        .depth_write_enabled:   false\r\n        .stencil_enabled:       false\r\n        .stencil_read_mask:     0\r\n        .stencil_write_mask:    0\r\n        .stencil_ref:           0\r\n    .blend:\r\n        .enabled:               false\r\n        .src_factor_rgb:        SG_BLENDFACTOR_ONE\r\n        .dst_factor_rgb:        SG_BLENDFACTOR_ZERO\r\n        .op_rgb:                SG_BLENDOP_ADD\r\n        .src_factor_alpha:      SG_BLENDFACTOR_ONE\r\n        .dst_factor_alpha:      SG_BLENDFACTOR_ZERO\r\n        .op_alpha:              SG_BLENDOP_ADD\r\n        .color_write_mask:      SG_COLORMASK_RGBA\r\n        .color_attachment_count 1\r\n        .color_format           SG_PIXELFORMAT_RGBA8\r\n        .depth_format           SG_PIXELFORMAT_DEPTHSTENCIL\r\n        .blend_color:           { 0.0f, 0.0f, 0.0f, 0.0f }\r\n    .rasterizer:\r\n        .alpha_to_coverage_enabled:     false\r\n        .cull_mode:                     SG_CULLMODE_NONE\r\n        .face_winding:                  SG_FACEWINDING_CW\r\n        .sample_count:                  sg_desc.context.sample_count\r\n        .depth_bias:                    0.0f\r\n        .depth_bias_slope_scale:        0.0f\r\n        .depth_bias_clamp:              0.0f\r\n    .label  0       (optional string label for trace hooks)\r\n*/\r\ntypedef struct sg_buffer_layout_desc {\r\n    int stride;\r\n    sg_vertex_step step_func;\r\n    int step_rate;\r\n} sg_buffer_layout_desc;\r\n\r\ntypedef struct sg_vertex_attr_desc {\r\n    int buffer_index;\r\n    int offset;\r\n    sg_vertex_format format;\r\n} sg_vertex_attr_desc;\r\n\r\ntypedef struct sg_layout_desc {\r\n    sg_buffer_layout_desc buffers[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    sg_vertex_attr_desc attrs[SG_MAX_VERTEX_ATTRIBUTES];\r\n} sg_layout_desc;\r\n\r\ntypedef struct sg_stencil_state {\r\n    sg_stencil_op fail_op;\r\n    sg_stencil_op depth_fail_op;\r\n    sg_stencil_op pass_op;\r\n    sg_compare_func compare_func;\r\n} sg_stencil_state;\r\n\r\ntypedef struct sg_depth_stencil_state {\r\n    sg_stencil_state stencil_front;\r\n    sg_stencil_state stencil_back;\r\n    sg_compare_func depth_compare_func;\r\n    bool depth_write_enabled;\r\n    bool stencil_enabled;\r\n    uint8_t stencil_read_mask;\r\n    uint8_t stencil_write_mask;\r\n    uint8_t stencil_ref;\r\n} sg_depth_stencil_state;\r\n\r\ntypedef struct sg_blend_state {\r\n    bool enabled;\r\n    sg_blend_factor src_factor_rgb;\r\n    sg_blend_factor dst_factor_rgb;\r\n    sg_blend_op op_rgb;\r\n    sg_blend_factor src_factor_alpha;\r\n    sg_blend_factor dst_factor_alpha;\r\n    sg_blend_op op_alpha;\r\n    uint8_t color_write_mask;\r\n    int color_attachment_count;\r\n    sg_pixel_format color_format;\r\n    sg_pixel_format depth_format;\r\n    float blend_color[4];\r\n} sg_blend_state;\r\n\r\ntypedef struct sg_rasterizer_state {\r\n    bool alpha_to_coverage_enabled;\r\n    sg_cull_mode cull_mode;\r\n    sg_face_winding face_winding;\r\n    int sample_count;\r\n    float depth_bias;\r\n    float depth_bias_slope_scale;\r\n    float depth_bias_clamp;\r\n} sg_rasterizer_state;\r\n\r\ntypedef struct sg_pipeline_desc {\r\n    uint32_t _start_canary;\r\n    sg_layout_desc layout;\r\n    sg_shader shader;\r\n    sg_primitive_type primitive_type;\r\n    sg_index_type index_type;\r\n    sg_depth_stencil_state depth_stencil;\r\n    sg_blend_state blend;\r\n    sg_rasterizer_state rasterizer;\r\n    const char* label;\r\n    uint32_t _end_canary;\r\n} sg_pipeline_desc;\r\n\r\n/*\r\n    sg_pass_desc\r\n\r\n    Creation parameters for an sg_pass object, used as argument\r\n    to the sg_make_pass() function.\r\n\r\n    A pass object contains 1..4 color-attachments and none, or one,\r\n    depth-stencil-attachment. Each attachment consists of\r\n    an image, and two additional indices describing\r\n    which subimage the pass will render to: one mipmap index, and\r\n    if the image is a cubemap, array-texture or 3D-texture, the\r\n    face-index, array-layer or depth-slice.\r\n\r\n    Pass images must fulfill the following requirements:\r\n\r\n    All images must have:\r\n    - been created as render target (sg_image_desc.render_target = true)\r\n    - the same size\r\n    - the same sample count\r\n\r\n    In addition, all color-attachment images must have the same pixel format.\r\n*/\r\ntypedef struct sg_attachment_desc {\r\n    sg_image image;\r\n    int mip_level;\r\n    union {\r\n        int face;\r\n        int layer;\r\n        int slice;\r\n    };\r\n} sg_attachment_desc;\r\n\r\ntypedef struct sg_pass_desc {\r\n    uint32_t _start_canary;\r\n    sg_attachment_desc color_attachments[SG_MAX_COLOR_ATTACHMENTS];\r\n    sg_attachment_desc depth_stencil_attachment;\r\n    const char* label;\r\n    uint32_t _end_canary;\r\n} sg_pass_desc;\r\n\r\n/*\r\n    sg_trace_hooks\r\n\r\n    Installable callback functions to keep track of the sokol-gfx calls,\r\n    this is useful for debugging, or keeping track of resource creation\r\n    and destruction.\r\n\r\n    Trace hooks are installed with sg_install_trace_hooks(), this returns\r\n    another sg_trace_hooks struct with the previous set of\r\n    trace hook function pointers. These should be invoked by the\r\n    new trace hooks to form a proper call chain.\r\n*/\r\ntypedef struct sg_trace_hooks {\r\n    void* user_data;\r\n    void (*reset_state_cache)(void* user_data);\r\n    void (*make_buffer)(const sg_buffer_desc* desc, sg_buffer result, void* user_data);\r\n    void (*make_image)(const sg_image_desc* desc, sg_image result, void* user_data);\r\n    void (*make_shader)(const sg_shader_desc* desc, sg_shader result, void* user_data);\r\n    void (*make_pipeline)(const sg_pipeline_desc* desc, sg_pipeline result, void* user_data);\r\n    void (*make_pass)(const sg_pass_desc* desc, sg_pass result, void* user_data);\r\n    void (*destroy_buffer)(sg_buffer buf, void* user_data);\r\n    void (*destroy_image)(sg_image img, void* user_data);\r\n    void (*destroy_shader)(sg_shader shd, void* user_data);\r\n    void (*destroy_pipeline)(sg_pipeline pip, void* user_data);\r\n    void (*destroy_pass)(sg_pass pass, void* user_data);\r\n    void (*update_buffer)(sg_buffer buf, const void* data_ptr, int data_size, void* user_data);\r\n    void (*update_image)(sg_image img, const sg_image_content* data, void* user_data);\r\n    void (*append_buffer)(sg_buffer buf, const void* data_ptr, int data_size, int result, void* user_data);\r\n    void (*begin_default_pass)(const sg_pass_action* pass_action, int width, int height, void* user_data);\r\n    void (*begin_pass)(sg_pass pass, const sg_pass_action* pass_action, void* user_data);\r\n    void (*apply_viewport)(int x, int y, int width, int height, bool origin_top_left, void* user_data);\r\n    void (*apply_scissor_rect)(int x, int y, int width, int height, bool origin_top_left, void* user_data);\r\n    void (*apply_pipeline)(sg_pipeline pip, void* user_data);\r\n    void (*apply_bindings)(const sg_bindings* bindings, void* user_data);\r\n    void (*apply_uniforms)(sg_shader_stage stage, int ub_index, const void* data, int num_bytes, void* user_data);\r\n    void (*draw)(int base_element, int num_elements, int num_instances, void* user_data);\r\n    void (*end_pass)(void* user_data);\r\n    void (*commit)(void* user_data);\r\n    void (*alloc_buffer)(sg_buffer result, void* user_data);\r\n    void (*alloc_image)(sg_image result, void* user_data);\r\n    void (*alloc_shader)(sg_shader result, void* user_data);\r\n    void (*alloc_pipeline)(sg_pipeline result, void* user_data);\r\n    void (*alloc_pass)(sg_pass result, void* user_data);\r\n    void (*init_buffer)(sg_buffer buf_id, const sg_buffer_desc* desc, void* user_data);\r\n    void (*init_image)(sg_image img_id, const sg_image_desc* desc, void* user_data);\r\n    void (*init_shader)(sg_shader shd_id, const sg_shader_desc* desc, void* user_data);\r\n    void (*init_pipeline)(sg_pipeline pip_id, const sg_pipeline_desc* desc, void* user_data);\r\n    void (*init_pass)(sg_pass pass_id, const sg_pass_desc* desc, void* user_data);\r\n    void (*fail_buffer)(sg_buffer buf_id, void* user_data);\r\n    void (*fail_image)(sg_image img_id, void* user_data);\r\n    void (*fail_shader)(sg_shader shd_id, void* user_data);\r\n    void (*fail_pipeline)(sg_pipeline pip_id, void* user_data);\r\n    void (*fail_pass)(sg_pass pass_id, void* user_data);\r\n    void (*push_debug_group)(const char* name, void* user_data);\r\n    void (*pop_debug_group)(void* user_data);\r\n    void (*err_buffer_pool_exhausted)(void* user_data);\r\n    void (*err_image_pool_exhausted)(void* user_data);\r\n    void (*err_shader_pool_exhausted)(void* user_data);\r\n    void (*err_pipeline_pool_exhausted)(void* user_data);\r\n    void (*err_pass_pool_exhausted)(void* user_data);\r\n    void (*err_context_mismatch)(void* user_data);\r\n    void (*err_pass_invalid)(void* user_data);\r\n    void (*err_draw_invalid)(void* user_data);\r\n    void (*err_bindings_invalid)(void* user_data);\r\n} sg_trace_hooks;\r\n\r\n/*\r\n    sg_buffer_info\r\n    sg_image_info\r\n    sg_shader_info\r\n    sg_pipeline_info\r\n    sg_pass_info\r\n\r\n    These structs contain various internal resource attributes which\r\n    might be useful for debug-inspection. Please don't rely on the\r\n    actual content of those structs too much, as they are quite closely\r\n    tied to sokol_gfx.h internals and may change more frequently than\r\n    the other public API elements.\r\n\r\n    The *_info structs are used as the return values of the following functions:\r\n\r\n    sg_query_buffer_info()\r\n    sg_query_image_info()\r\n    sg_query_shader_info()\r\n    sg_query_pipeline_info()\r\n    sg_query_pass_info()\r\n*/\r\ntypedef struct sg_slot_info {\r\n    sg_resource_state state;    /* the current state of this resource slot */\r\n    uint32_t res_id;        /* type-neutral resource if (e.g. sg_buffer.id) */\r\n    uint32_t ctx_id;        /* the context this resource belongs to */\r\n} sg_slot_info;\r\n\r\ntypedef struct sg_buffer_info {\r\n    sg_slot_info slot;              /* resource pool slot info */\r\n    uint32_t update_frame_index;    /* frame index of last sg_update_buffer() */\r\n    uint32_t append_frame_index;    /* frame index of last sg_append_buffer() */\r\n    int append_pos;                 /* current position in buffer for sg_append_buffer() */\r\n    bool append_overflow;           /* is buffer in overflow state (due to sg_append_buffer) */\r\n    int num_slots;                  /* number of renaming-slots for dynamically updated buffers */\r\n    int active_slot;                /* currently active write-slot for dynamically updated buffers */\r\n} sg_buffer_info;\r\n\r\ntypedef struct sg_image_info {\r\n    sg_slot_info slot;              /* resource pool slot info */\r\n    uint32_t upd_frame_index;       /* frame index of last sg_update_image() */\r\n    int num_slots;                  /* number of renaming-slots for dynamically updated images */\r\n    int active_slot;                /* currently active write-slot for dynamically updated images */\r\n    int width;                      /* image width */\r\n    int height;                     /* image height */\r\n} sg_image_info;\r\n\r\ntypedef struct sg_shader_info {\r\n    sg_slot_info slot;              /* resoure pool slot info */\r\n} sg_shader_info;\r\n\r\ntypedef struct sg_pipeline_info {\r\n    sg_slot_info slot;              /* resource pool slot info */\r\n} sg_pipeline_info;\r\n\r\ntypedef struct sg_pass_info {\r\n    sg_slot_info slot;              /* resource pool slot info */\r\n} sg_pass_info;\r\n\r\n/*\r\n    sg_desc\r\n\r\n    The sg_desc struct contains configuration values for sokol_gfx,\r\n    it is used as parameter to the sg_setup() call.\r\n\r\n    NOTE that all callback function pointers come in two versions, one without\r\n    a userdata pointer, and one with a userdata pointer. You would\r\n    either initialize one or the other depending on whether you pass data\r\n    to your callbacks.\r\n\r\n    FIXME: explain the various configuration options\r\n\r\n    The default configuration is:\r\n\r\n    .buffer_pool_size       128\r\n    .image_pool_size        128\r\n    .shader_pool_size       32\r\n    .pipeline_pool_size     64\r\n    .pass_pool_size         16\r\n    .context_pool_size      16\r\n    .sampler_cache_size     64\r\n    .uniform_buffer_size    4 MB (4*1024*1024)\r\n    .staging_buffer_size    8 MB (8*1024*1024)\r\n\r\n    .context.color_format: default value depends on selected backend:\r\n        all GL backends:    SG_PIXELFORMAT_RGBA8\r\n        Metal and D3D11:    SG_PIXELFORMAT_BGRA8\r\n        WGPU:               *no default* (must be queried from WGPU swapchain)\r\n    .context.depth_format   SG_PIXELFORMAT_DEPTH_STENCIL\r\n    .context.sample_count   1\r\n\r\n    GL specific:\r\n        .context.gl.force_gles2\r\n            if this is true the GL backend will act in \"GLES2 fallback mode\" even\r\n            when compiled with SOKOL_GLES3, this is useful to fall back\r\n            to traditional WebGL if a browser doesn't support a WebGL2 context\r\n\r\n    Metal specific:\r\n        (NOTE: All Objective-C object references are transferred through\r\n        a bridged (const void*) to sokol_gfx, which will use a unretained\r\n        bridged cast (__bridged id<xxx>) to retrieve the Objective-C\r\n        references back. Since the bridge cast is unretained, the caller\r\n        must hold a strong reference to the Objective-C object for the\r\n        duration of the sokol_gfx call!\r\n\r\n        .context.metal.device\r\n            a pointer to the MTLDevice object\r\n        .context.metal.renderpass_descriptor_cb\r\n        .context.metal_renderpass_descriptor_userdata_cb\r\n            A C callback function to obtain the MTLRenderPassDescriptor for the\r\n            current frame when rendering to the default framebuffer, will be called\r\n            in sg_begin_default_pass().\r\n        .context.metal.drawable_cb\r\n        .context.metal.drawable_userdata_cb\r\n            a C callback function to obtain a MTLDrawable for the current\r\n            frame when rendering to the default framebuffer, will be called in\r\n            sg_end_pass() of the default pass\r\n        .context.metal.user_data\r\n            optional user data pointer passed to the userdata versions of\r\n            callback functions\r\n\r\n    D3D11 specific:\r\n        .context.d3d11.device\r\n            a pointer to the ID3D11Device object, this must have been created\r\n            before sg_setup() is called\r\n        .context.d3d11.device_context\r\n            a pointer to the ID3D11DeviceContext object\r\n        .context.d3d11.render_target_view_cb\r\n        .context.d3d11.render_target_view_userdata_cb\r\n            a C callback function to obtain a pointer to the current\r\n            ID3D11RenderTargetView object of the default framebuffer,\r\n            this function will be called in sg_begin_pass() when rendering\r\n            to the default framebuffer\r\n        .context.d3d11.depth_stencil_view_cb\r\n        .context.d3d11.depth_stencil_view_userdata_cb\r\n            a C callback function to obtain a pointer to the current\r\n            ID3D11DepthStencilView object of the default framebuffer,\r\n            this function will be called in sg_begin_pass() when rendering\r\n            to the default framebuffer\r\n        .context.metal.user_data\r\n            optional user data pointer passed to the userdata versions of\r\n            callback functions\r\n\r\n    WebGPU specific:\r\n        .context.wgpu.device\r\n            a WGPUDevice handle\r\n        .context.wgpu.render_format\r\n            WGPUTextureFormat of the swap chain surface\r\n        .context.wgpu.render_view_cb\r\n        .context.wgpu.render_view_userdata_cb\r\n            callback to get the current WGPUTextureView of the swapchain's\r\n            rendering attachment (may be an MSAA surface)\r\n        .context.wgpu.resolve_view_cb\r\n        .context.wgpu.resolve_view_userdata_cb\r\n            callback to get the current WGPUTextureView of the swapchain's\r\n            MSAA-resolve-target surface, must return 0 if not MSAA rendering\r\n        .context.wgpu.depth_stencil_view_cb\r\n        .context.wgpu.depth_stencil_view_userdata_cb\r\n            callback to get current default-pass depth-stencil-surface WGPUTextureView\r\n            the pixel format of the default WGPUTextureView must be WGPUTextureFormat_Depth24Plus8\r\n        .context.metal.user_data\r\n            optional user data pointer passed to the userdata versions of\r\n            callback functions\r\n\r\n    When using sokol_gfx.h and sokol_app.h together, consider using the\r\n    helper function sapp_sgcontext() in the sokol_glue.h header to\r\n    initialize the sg_desc.context nested struct. sapp_sgcontext() returns\r\n    a completely initialized sg_context_desc struct with information\r\n    provided by sokol_app.h.\r\n*/\r\ntypedef struct sg_gl_context_desc {\r\n    bool force_gles2;\r\n} sg_gl_context_desc;\r\n\r\ntypedef struct sg_mtl_context_desc {\r\n    const void* device;\r\n    const void* (*renderpass_descriptor_cb)(void);\r\n    const void* (*renderpass_descriptor_userdata_cb)(void*);\r\n    const void* (*drawable_cb)(void);\r\n    const void* (*drawable_userdata_cb)(void*);\r\n    void* user_data;\r\n} sg_metal_context_desc;\r\n\r\ntypedef struct sg_d3d11_context_desc {\r\n    const void* device;\r\n    const void* device_context;\r\n    const void* (*render_target_view_cb)(void);\r\n    const void* (*render_target_view_userdata_cb)(void*);\r\n    const void* (*depth_stencil_view_cb)(void);\r\n    const void* (*depth_stencil_view_userdata_cb)(void*);\r\n    void* user_data;\r\n} sg_d3d11_context_desc;\r\n\r\ntypedef struct sg_wgpu_context_desc {\r\n    const void* device;                    /* WGPUDevice */\r\n    const void* (*render_view_cb)(void);   /* returns WGPUTextureView */\r\n    const void* (*render_view_userdata_cb)(void*);\r\n    const void* (*resolve_view_cb)(void);  /* returns WGPUTextureView */\r\n    const void* (*resolve_view_userdata_cb)(void*);\r\n    const void* (*depth_stencil_view_cb)(void);    /* returns WGPUTextureView, must be WGPUTextureFormat_Depth24Plus8 */\r\n    const void* (*depth_stencil_view_userdata_cb)(void*);\r\n    void* user_data;\r\n} sg_wgpu_context_desc;\r\n\r\ntypedef struct sg_context_desc {\r\n    sg_pixel_format color_format;\r\n    sg_pixel_format depth_format;\r\n    int sample_count;\r\n    sg_gl_context_desc gl;\r\n    sg_metal_context_desc metal;\r\n    sg_d3d11_context_desc d3d11;\r\n    sg_wgpu_context_desc wgpu;\r\n} sg_context_desc;\r\n\r\ntypedef struct sg_desc {\r\n    uint32_t _start_canary;\r\n    int buffer_pool_size;\r\n    int image_pool_size;\r\n    int shader_pool_size;\r\n    int pipeline_pool_size;\r\n    int pass_pool_size;\r\n    int context_pool_size;\r\n    int uniform_buffer_size;\r\n    int staging_buffer_size;\r\n    int sampler_cache_size;\r\n    sg_context_desc context;\r\n    uint32_t _end_canary;\r\n} sg_desc;\r\n\r\n/* setup and misc functions */\r\nSOKOL_API_DECL void sg_setup(const sg_desc* desc);\r\nSOKOL_API_DECL void sg_shutdown(void);\r\nSOKOL_API_DECL bool sg_isvalid(void);\r\nSOKOL_API_DECL void sg_reset_state_cache(void);\r\nSOKOL_API_DECL sg_trace_hooks sg_install_trace_hooks(const sg_trace_hooks* trace_hooks);\r\nSOKOL_API_DECL void sg_push_debug_group(const char* name);\r\nSOKOL_API_DECL void sg_pop_debug_group(void);\r\n\r\n/* resource creation, destruction and updating */\r\nSOKOL_API_DECL sg_buffer sg_make_buffer(const sg_buffer_desc* desc);\r\nSOKOL_API_DECL sg_image sg_make_image(const sg_image_desc* desc);\r\nSOKOL_API_DECL sg_shader sg_make_shader(const sg_shader_desc* desc);\r\nSOKOL_API_DECL sg_pipeline sg_make_pipeline(const sg_pipeline_desc* desc);\r\nSOKOL_API_DECL sg_pass sg_make_pass(const sg_pass_desc* desc);\r\nSOKOL_API_DECL void sg_destroy_buffer(sg_buffer buf);\r\nSOKOL_API_DECL void sg_destroy_image(sg_image img);\r\nSOKOL_API_DECL void sg_destroy_shader(sg_shader shd);\r\nSOKOL_API_DECL void sg_destroy_pipeline(sg_pipeline pip);\r\nSOKOL_API_DECL void sg_destroy_pass(sg_pass pass);\r\nSOKOL_API_DECL void sg_update_buffer(sg_buffer buf, const void* data_ptr, int data_size);\r\nSOKOL_API_DECL void sg_update_image(sg_image img, const sg_image_content* data);\r\nSOKOL_API_DECL int sg_append_buffer(sg_buffer buf, const void* data_ptr, int data_size);\r\nSOKOL_API_DECL bool sg_query_buffer_overflow(sg_buffer buf);\r\n\r\n/* rendering functions */\r\nSOKOL_API_DECL void sg_begin_default_pass(const sg_pass_action* pass_action, int width, int height);\r\nSOKOL_API_DECL void sg_begin_pass(sg_pass pass, const sg_pass_action* pass_action);\r\nSOKOL_API_DECL void sg_apply_viewport(int x, int y, int width, int height, bool origin_top_left);\r\nSOKOL_API_DECL void sg_apply_scissor_rect(int x, int y, int width, int height, bool origin_top_left);\r\nSOKOL_API_DECL void sg_apply_pipeline(sg_pipeline pip);\r\nSOKOL_API_DECL void sg_apply_bindings(const sg_bindings* bindings);\r\nSOKOL_API_DECL void sg_apply_uniforms(sg_shader_stage stage, int ub_index, const void* data, int num_bytes);\r\nSOKOL_API_DECL void sg_draw(int base_element, int num_elements, int num_instances);\r\nSOKOL_API_DECL void sg_end_pass(void);\r\nSOKOL_API_DECL void sg_commit(void);\r\n\r\n/* getting information */\r\nSOKOL_API_DECL sg_desc sg_query_desc(void);\r\nSOKOL_API_DECL sg_backend sg_query_backend(void);\r\nSOKOL_API_DECL sg_features sg_query_features(void);\r\nSOKOL_API_DECL sg_limits sg_query_limits(void);\r\nSOKOL_API_DECL sg_pixelformat_info sg_query_pixelformat(sg_pixel_format fmt);\r\n/* get current state of a resource (INITIAL, ALLOC, VALID, FAILED, INVALID) */\r\nSOKOL_API_DECL sg_resource_state sg_query_buffer_state(sg_buffer buf);\r\nSOKOL_API_DECL sg_resource_state sg_query_image_state(sg_image img);\r\nSOKOL_API_DECL sg_resource_state sg_query_shader_state(sg_shader shd);\r\nSOKOL_API_DECL sg_resource_state sg_query_pipeline_state(sg_pipeline pip);\r\nSOKOL_API_DECL sg_resource_state sg_query_pass_state(sg_pass pass);\r\n/* get runtime information about a resource */\r\nSOKOL_API_DECL sg_buffer_info sg_query_buffer_info(sg_buffer buf);\r\nSOKOL_API_DECL sg_image_info sg_query_image_info(sg_image img);\r\nSOKOL_API_DECL sg_shader_info sg_query_shader_info(sg_shader shd);\r\nSOKOL_API_DECL sg_pipeline_info sg_query_pipeline_info(sg_pipeline pip);\r\nSOKOL_API_DECL sg_pass_info sg_query_pass_info(sg_pass pass);\r\n/* get resource creation desc struct with their default values replaced */\r\nSOKOL_API_DECL sg_buffer_desc sg_query_buffer_defaults(const sg_buffer_desc* desc);\r\nSOKOL_API_DECL sg_image_desc sg_query_image_defaults(const sg_image_desc* desc);\r\nSOKOL_API_DECL sg_shader_desc sg_query_shader_defaults(const sg_shader_desc* desc);\r\nSOKOL_API_DECL sg_pipeline_desc sg_query_pipeline_defaults(const sg_pipeline_desc* desc);\r\nSOKOL_API_DECL sg_pass_desc sg_query_pass_defaults(const sg_pass_desc* desc);\r\n\r\n/* separate resource allocation and initialization (for async setup) */\r\nSOKOL_API_DECL sg_buffer sg_alloc_buffer(void);\r\nSOKOL_API_DECL sg_image sg_alloc_image(void);\r\nSOKOL_API_DECL sg_shader sg_alloc_shader(void);\r\nSOKOL_API_DECL sg_pipeline sg_alloc_pipeline(void);\r\nSOKOL_API_DECL sg_pass sg_alloc_pass(void);\r\nSOKOL_API_DECL void sg_init_buffer(sg_buffer buf_id, const sg_buffer_desc* desc);\r\nSOKOL_API_DECL void sg_init_image(sg_image img_id, const sg_image_desc* desc);\r\nSOKOL_API_DECL void sg_init_shader(sg_shader shd_id, const sg_shader_desc* desc);\r\nSOKOL_API_DECL void sg_init_pipeline(sg_pipeline pip_id, const sg_pipeline_desc* desc);\r\nSOKOL_API_DECL void sg_init_pass(sg_pass pass_id, const sg_pass_desc* desc);\r\nSOKOL_API_DECL void sg_fail_buffer(sg_buffer buf_id);\r\nSOKOL_API_DECL void sg_fail_image(sg_image img_id);\r\nSOKOL_API_DECL void sg_fail_shader(sg_shader shd_id);\r\nSOKOL_API_DECL void sg_fail_pipeline(sg_pipeline pip_id);\r\nSOKOL_API_DECL void sg_fail_pass(sg_pass pass_id);\r\n\r\n/* rendering contexts (optional) */\r\nSOKOL_API_DECL sg_context sg_setup_context(void);\r\nSOKOL_API_DECL void sg_activate_context(sg_context ctx_id);\r\nSOKOL_API_DECL void sg_discard_context(sg_context ctx_id);\r\n\r\n/* Backend-specific helper functions, these may come in handy for mixing\r\n   sokol-gfx rendering with 'native backend' rendering functions.\r\n\r\n   This group of functions will be expanded as needed.\r\n*/\r\n\r\n/* Metal: return __bridge-casted MTLRenderCommandEncoder in current pass (or zero if outside pass) */\r\nSOKOL_API_DECL const void* sg_mtl_render_command_encoder(void);\r\n\r\n#ifdef _MSC_VER\r\n#pragma warning(pop)\r\n#endif\r\n#ifdef __cplusplus\r\n} /* extern \"C\" */\r\n\r\n/* reference-based equivalents for c++ */\r\ninline void sg_setup(const sg_desc& desc) { return sg_setup(&desc); }\r\n\r\ninline sg_buffer sg_make_buffer(const sg_buffer_desc& desc) { return sg_make_buffer(&desc); }\r\ninline sg_image sg_make_image(const sg_image_desc& desc) { return sg_make_image(&desc); }\r\ninline sg_shader sg_make_shader(const sg_shader_desc& desc) { return sg_make_shader(&desc); }\r\ninline sg_pipeline sg_make_pipeline(const sg_pipeline_desc& desc) { return sg_make_pipeline(&desc); }\r\ninline sg_pass sg_make_pass(const sg_pass_desc& desc) { return sg_make_pass(&desc); }\r\ninline void sg_update_image(sg_image img, const sg_image_content& data) { return sg_update_image(img, &data); }\r\n\r\ninline void sg_begin_default_pass(const sg_pass_action& pass_action, int width, int height) { return sg_begin_default_pass(&pass_action, width, height); }\r\ninline void sg_begin_pass(sg_pass pass, const sg_pass_action& pass_action) { return sg_begin_pass(pass, &pass_action); }\r\ninline void sg_apply_bindings(const sg_bindings& bindings) { return sg_apply_bindings(&bindings); }\r\n\r\ninline sg_buffer_desc sg_query_buffer_defaults(const sg_buffer_desc& desc) { return sg_query_buffer_defaults(&desc); }\r\ninline sg_image_desc sg_query_image_defaults(const sg_image_desc& desc) { return sg_query_image_defaults(&desc); }\r\ninline sg_shader_desc sg_query_shader_defaults(const sg_shader_desc& desc) { return sg_query_shader_defaults(&desc); }\r\ninline sg_pipeline_desc sg_query_pipeline_defaults(const sg_pipeline_desc& desc) { return sg_query_pipeline_defaults(&desc); }\r\ninline sg_pass_desc sg_query_pass_defaults(const sg_pass_desc& desc) { return sg_query_pass_defaults(&desc); }\r\n\r\ninline void sg_init_buffer(sg_buffer buf_id, const sg_buffer_desc& desc) { return sg_init_buffer(buf_id, &desc); }\r\ninline void sg_init_image(sg_image img_id, const sg_image_desc& desc) { return sg_init_image(img_id, &desc); }\r\ninline void sg_init_shader(sg_shader shd_id, const sg_shader_desc& desc) { return sg_init_shader(shd_id, &desc); }\r\ninline void sg_init_pipeline(sg_pipeline pip_id, const sg_pipeline_desc& desc) { return sg_init_pipeline(pip_id, &desc); }\r\ninline void sg_init_pass(sg_pass pass_id, const sg_pass_desc& desc) { return sg_init_pass(pass_id, &desc); }\r\n\r\n#endif\r\n#endif // SOKOL_GFX_INCLUDED\r\n\r\n/*--- IMPLEMENTATION ---------------------------------------------------------*/\r\n#ifdef SOKOL_IMPL\r\n#define SOKOL_GFX_IMPL_INCLUDED (1)\r\n\r\n#if !(defined(SOKOL_GLCORE33)||defined(SOKOL_GLES2)||defined(SOKOL_GLES3)||defined(SOKOL_D3D11)||defined(SOKOL_METAL)||defined(SOKOL_WGPU)||defined(SOKOL_DUMMY_BACKEND))\r\n#error \"Please select a backend with SOKOL_GLCORE33, SOKOL_GLES2, SOKOL_GLES3, SOKOL_D3D11, SOKOL_METAL, SOKOL_WGPU or SOKOL_DUMMY_BACKEND\"\r\n#endif\r\n#include <string.h> /* memset */\r\n#include <float.h> /* FLT_MAX */\r\n\r\n#ifndef SOKOL_API_IMPL\r\n    #define SOKOL_API_IMPL\r\n#endif\r\n#ifndef SOKOL_DEBUG\r\n    #ifndef NDEBUG\r\n        #define SOKOL_DEBUG (1)\r\n    #endif\r\n#endif\r\n#ifndef SOKOL_ASSERT\r\n    #include <assert.h>\r\n    #define SOKOL_ASSERT(c) assert(c)\r\n#endif\r\n#ifndef SOKOL_VALIDATE_BEGIN\r\n    #define SOKOL_VALIDATE_BEGIN() _sg_validate_begin()\r\n#endif\r\n#ifndef SOKOL_VALIDATE\r\n    #define SOKOL_VALIDATE(cond, err) _sg_validate((cond), err)\r\n#endif\r\n#ifndef SOKOL_VALIDATE_END\r\n    #define SOKOL_VALIDATE_END() _sg_validate_end()\r\n#endif\r\n#ifndef SOKOL_UNREACHABLE\r\n    #define SOKOL_UNREACHABLE SOKOL_ASSERT(false)\r\n#endif\r\n#ifndef SOKOL_MALLOC\r\n    #include <stdlib.h>\r\n    #define SOKOL_MALLOC(s) malloc(s)\r\n    #define SOKOL_FREE(p) free(p)\r\n#endif\r\n#ifndef SOKOL_LOG\r\n    #ifdef SOKOL_DEBUG\r\n        #include <stdio.h>\r\n        #define SOKOL_LOG(s) { SOKOL_ASSERT(s); puts(s); }\r\n    #else\r\n        #define SOKOL_LOG(s)\r\n    #endif\r\n#endif\r\n\r\n#ifndef _SOKOL_PRIVATE\r\n    #if defined(__GNUC__) || defined(__clang__)\r\n        #define _SOKOL_PRIVATE __attribute__((unused)) static\r\n    #else\r\n        #define _SOKOL_PRIVATE static\r\n    #endif\r\n#endif\r\n\r\n#ifndef _SOKOL_UNUSED\r\n    #define _SOKOL_UNUSED(x) (void)(x)\r\n#endif\r\n\r\n#if defined(SOKOL_TRACE_HOOKS)\r\n#define _SG_TRACE_ARGS(fn, ...) if (_sg.hooks.fn) { _sg.hooks.fn(__VA_ARGS__, _sg.hooks.user_data); }\r\n#define _SG_TRACE_NOARGS(fn) if (_sg.hooks.fn) { _sg.hooks.fn(_sg.hooks.user_data); }\r\n#else\r\n#define _SG_TRACE_ARGS(fn, ...)\r\n#define _SG_TRACE_NOARGS(fn)\r\n#endif\r\n\r\n/* default clear values */\r\n#ifndef SG_DEFAULT_CLEAR_RED\r\n#define SG_DEFAULT_CLEAR_RED (0.5f)\r\n#endif\r\n#ifndef SG_DEFAULT_CLEAR_GREEN\r\n#define SG_DEFAULT_CLEAR_GREEN (0.5f)\r\n#endif\r\n#ifndef SG_DEFAULT_CLEAR_BLUE\r\n#define SG_DEFAULT_CLEAR_BLUE (0.5f)\r\n#endif\r\n#ifndef SG_DEFAULT_CLEAR_ALPHA\r\n#define SG_DEFAULT_CLEAR_ALPHA (1.0f)\r\n#endif\r\n#ifndef SG_DEFAULT_CLEAR_DEPTH\r\n#define SG_DEFAULT_CLEAR_DEPTH (1.0f)\r\n#endif\r\n#ifndef SG_DEFAULT_CLEAR_STENCIL\r\n#define SG_DEFAULT_CLEAR_STENCIL (0)\r\n#endif\r\n\r\n#ifdef _MSC_VER\r\n#pragma warning(push)\r\n#pragma warning(disable:4201)   /* nonstandard extension used: nameless struct/union */\r\n#pragma warning(disable:4115)   /* named type definition in parentheses */\r\n#pragma warning(disable:4505)   /* unreferenced local function has been removed */\r\n#endif\r\n\r\n#if defined(SOKOL_GLCORE33) || defined(SOKOL_GLES2) || defined(SOKOL_GLES3)\r\n    #define _SOKOL_ANY_GL (1)\r\n\r\n    #ifndef GL_UNSIGNED_INT_2_10_10_10_REV\r\n    #define GL_UNSIGNED_INT_2_10_10_10_REV 0x8368\r\n    #endif\r\n    #ifndef GL_UNSIGNED_INT_24_8\r\n    #define GL_UNSIGNED_INT_24_8 0x84FA\r\n    #endif\r\n    #ifndef GL_TEXTURE_MAX_ANISOTROPY_EXT\r\n    #define GL_TEXTURE_MAX_ANISOTROPY_EXT 0x84FE\r\n    #endif\r\n    #ifndef GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT\r\n    #define GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT 0x84FF\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGBA_S3TC_DXT1_EXT\r\n    #define GL_COMPRESSED_RGBA_S3TC_DXT1_EXT 0x83F1\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGBA_S3TC_DXT3_EXT\r\n    #define GL_COMPRESSED_RGBA_S3TC_DXT3_EXT 0x83F2\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGBA_S3TC_DXT5_EXT\r\n    #define GL_COMPRESSED_RGBA_S3TC_DXT5_EXT 0x83F3\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RED_RGTC1\r\n    #define GL_COMPRESSED_RED_RGTC1 0x8DBB\r\n    #endif\r\n    #ifndef GL_COMPRESSED_SIGNED_RED_RGTC1\r\n    #define GL_COMPRESSED_SIGNED_RED_RGTC1 0x8DBC\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RED_GREEN_RGTC2\r\n    #define GL_COMPRESSED_RED_GREEN_RGTC2 0x8DBD\r\n    #endif\r\n    #ifndef GL_COMPRESSED_SIGNED_RED_GREEN_RGTC2\r\n    #define GL_COMPRESSED_SIGNED_RED_GREEN_RGTC2 0x8DBE\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGBA_BPTC_UNORM_ARB\r\n    #define GL_COMPRESSED_RGBA_BPTC_UNORM_ARB 0x8E8C\r\n    #endif\r\n    #ifndef GL_COMPRESSED_SRGB_ALPHA_BPTC_UNORM_ARB\r\n    #define GL_COMPRESSED_SRGB_ALPHA_BPTC_UNORM_ARB 0x8E8D\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGB_BPTC_SIGNED_FLOAT_ARB\r\n    #define GL_COMPRESSED_RGB_BPTC_SIGNED_FLOAT_ARB 0x8E8E\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_ARB\r\n    #define GL_COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_ARB 0x8E8F\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGB_PVRTC_2BPPV1_IMG\r\n    #define GL_COMPRESSED_RGB_PVRTC_2BPPV1_IMG 0x8C01\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGB_PVRTC_4BPPV1_IMG\r\n    #define GL_COMPRESSED_RGB_PVRTC_4BPPV1_IMG 0x8C00\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGBA_PVRTC_2BPPV1_IMG\r\n    #define GL_COMPRESSED_RGBA_PVRTC_2BPPV1_IMG 0x8C03\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGBA_PVRTC_4BPPV1_IMG\r\n    #define GL_COMPRESSED_RGBA_PVRTC_4BPPV1_IMG 0x8C02\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGB8_ETC2\r\n    #define GL_COMPRESSED_RGB8_ETC2 0x9274\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGBA8_ETC2_EAC\r\n    #define GL_COMPRESSED_RGBA8_ETC2_EAC 0x9278\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2\r\n    #define GL_COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2 0x9276\r\n    #endif\r\n    #ifndef GL_COMPRESSED_RG11_EAC\r\n    #define GL_COMPRESSED_RG11_EAC 0x9272\r\n    #endif\r\n    #ifndef GL_COMPRESSED_SIGNED_RG11_EAC\r\n    #define GL_COMPRESSED_SIGNED_RG11_EAC 0x9273\r\n    #endif\r\n    #ifndef GL_DEPTH24_STENCIL8\r\n    #define GL_DEPTH24_STENCIL8 0x88F0\r\n    #endif\r\n    #ifndef GL_HALF_FLOAT\r\n    #define GL_HALF_FLOAT 0x140B\r\n    #endif\r\n    #ifndef GL_DEPTH_STENCIL\r\n    #define GL_DEPTH_STENCIL 0x84F9\r\n    #endif\r\n    #ifndef GL_LUMINANCE\r\n    #define GL_LUMINANCE 0x1909\r\n    #endif\r\n\r\n    #ifdef SOKOL_GLES2\r\n    #   ifdef GL_ANGLE_instanced_arrays\r\n    #       define SOKOL_INSTANCING_ENABLED\r\n    #       define glDrawArraysInstanced(mode, first, count, instancecount)  glDrawArraysInstancedANGLE(mode, first, count, instancecount)\r\n    #       define glDrawElementsInstanced(mode, count, type, indices, instancecount) glDrawElementsInstancedANGLE(mode, count, type, indices, instancecount)\r\n    #       define glVertexAttribDivisor(index, divisor) glVertexAttribDivisorANGLE(index, divisor)\r\n    #   elif defined(GL_EXT_draw_instanced) && defined(GL_EXT_instanced_arrays)\r\n    #       define SOKOL_INSTANCING_ENABLED\r\n    #       define glDrawArraysInstanced(mode, first, count, instancecount)  glDrawArraysInstancedEXT(mode, first, count, instancecount)\r\n    #       define glDrawElementsInstanced(mode, count, type, indices, instancecount) glDrawElementsInstancedEXT(mode, count, type, indices, instancecount)\r\n    #       define glVertexAttribDivisor(index, divisor) glVertexAttribDivisorEXT(index, divisor)\r\n    #   else\r\n    #       define SOKOL_GLES2_INSTANCING_ERROR \"Select GL_ANGLE_instanced_arrays or (GL_EXT_draw_instanced & GL_EXT_instanced_arrays) to enable instancing in GLES2\"\r\n    #       define glDrawArraysInstanced(mode, first, count, instancecount) SOKOL_ASSERT(0 && SOKOL_GLES2_INSTANCING_ERROR)\r\n    #       define glDrawElementsInstanced(mode, count, type, indices, instancecount) SOKOL_ASSERT(0 && SOKOL_GLES2_INSTANCING_ERROR)\r\n    #       define glVertexAttribDivisor(index, divisor) SOKOL_ASSERT(0 && SOKOL_GLES2_INSTANCING_ERROR)\r\n    #   endif\r\n    #else\r\n    #   define SOKOL_INSTANCING_ENABLED\r\n    #endif\r\n    #define _SG_GL_CHECK_ERROR() { SOKOL_ASSERT(glGetError() == GL_NO_ERROR); }\r\n\r\n#elif defined(SOKOL_D3D11)\r\n    #ifndef D3D11_NO_HELPERS\r\n    #define D3D11_NO_HELPERS\r\n    #endif\r\n    #ifndef WIN32_LEAN_AND_MEAN\r\n    #define WIN32_LEAN_AND_MEAN\r\n    #endif\r\n    #ifndef NOMINMAX\r\n    #define NOMINMAX\r\n    #endif\r\n    #include <d3d11.h>\r\n    #include <d3dcompiler.h>\r\n    #ifdef _MSC_VER\r\n    #if (defined(WINAPI_FAMILY_PARTITION) && !WINAPI_FAMILY_PARTITION(WINAPI_PARTITION_DESKTOP))\r\n    #pragma comment (lib, \"WindowsApp.lib\")\r\n    #else\r\n    #pragma comment (lib, \"user32.lib\")\r\n    #pragma comment (lib, \"dxgi.lib\")\r\n    #pragma comment (lib, \"d3d11.lib\")\r\n    #pragma comment (lib, \"dxguid.lib\")\r\n    #endif\r\n    #endif\r\n#elif defined(SOKOL_METAL)\r\n    // see https://clang.llvm.org/docs/LanguageExtensions.html#automatic-reference-counting\r\n    #if !defined(__cplusplus)\r\n        #if __has_feature(objc_arc) && !__has_feature(objc_arc_fields)\r\n            #error \"sokol_app.h requires __has_feature(objc_arc_field) if ARC is enabled (use a more recent compiler version)\"\r\n        #endif\r\n    #endif\r\n    #include <TargetConditionals.h>\r\n    #import <Metal/Metal.h>\r\n    #if defined(TARGET_OS_IPHONE) && !TARGET_OS_IPHONE\r\n        #define _SG_TARGET_MACOS (1)\r\n    #else\r\n        #define _SG_TARGET_IOS (1)\r\n        #if defined(TARGET_IPHONE_SIMULATOR) && TARGET_IPHONE_SIMULATOR\r\n            #define _SG_TARGET_IOS_SIMULATOR (1)\r\n        #endif\r\n    #endif\r\n#elif defined(SOKOL_WGPU)\r\n    #if defined(__EMSCRIPTEN__)\r\n        #include <webgpu/webgpu.h>\r\n    #else\r\n        #include <dawn/webgpu.h>\r\n    #endif\r\n#endif\r\n\r\n/*=== COMMON BACKEND STUFF ===================================================*/\r\n\r\n/* resource pool slots */\r\ntypedef struct {\r\n    uint32_t id;\r\n    uint32_t ctx_id;\r\n    sg_resource_state state;\r\n} _sg_slot_t;\r\n\r\n/* constants */\r\nenum {\r\n    _SG_STRING_SIZE = 16,\r\n    _SG_SLOT_SHIFT = 16,\r\n    _SG_SLOT_MASK = (1<<_SG_SLOT_SHIFT)-1,\r\n    _SG_MAX_POOL_SIZE = (1<<_SG_SLOT_SHIFT),\r\n    _SG_DEFAULT_BUFFER_POOL_SIZE = 128,\r\n    _SG_DEFAULT_IMAGE_POOL_SIZE = 128,\r\n    _SG_DEFAULT_SHADER_POOL_SIZE = 32,\r\n    _SG_DEFAULT_PIPELINE_POOL_SIZE = 64,\r\n    _SG_DEFAULT_PASS_POOL_SIZE = 16,\r\n    _SG_DEFAULT_CONTEXT_POOL_SIZE = 16,\r\n    _SG_DEFAULT_SAMPLER_CACHE_CAPACITY = 64,\r\n    _SG_DEFAULT_UB_SIZE = 4 * 1024 * 1024,\r\n    _SG_DEFAULT_STAGING_SIZE = 8 * 1024 * 1024,\r\n};\r\n\r\n/* fixed-size string */\r\ntypedef struct {\r\n    char buf[_SG_STRING_SIZE];\r\n} _sg_str_t;\r\n\r\n/* helper macros */\r\n#define _sg_def(val, def) (((val) == 0) ? (def) : (val))\r\n#define _sg_def_flt(val, def) (((val) == 0.0f) ? (def) : (val))\r\n#define _sg_min(a,b) ((a<b)?a:b)\r\n#define _sg_max(a,b) ((a>b)?a:b)\r\n#define _sg_clamp(v,v0,v1) ((v<v0)?(v0):((v>v1)?(v1):(v)))\r\n#define _sg_fequal(val,cmp,delta) (((val-cmp)> -delta)&&((val-cmp)<delta))\r\n\r\ntypedef struct {\r\n    int size;\r\n    int append_pos;\r\n    bool append_overflow;\r\n    sg_buffer_type type;\r\n    sg_usage usage;\r\n    uint32_t update_frame_index;\r\n    uint32_t append_frame_index;\r\n    int num_slots;\r\n    int active_slot;\r\n} _sg_buffer_common_t;\r\n\r\n_SOKOL_PRIVATE void _sg_buffer_common_init(_sg_buffer_common_t* cmn, const sg_buffer_desc* desc) {\r\n    cmn->size = desc->size;\r\n    cmn->append_pos = 0;\r\n    cmn->append_overflow = false;\r\n    cmn->type = desc->type;\r\n    cmn->usage = desc->usage;\r\n    cmn->update_frame_index = 0;\r\n    cmn->append_frame_index = 0;\r\n    cmn->num_slots = (cmn->usage == SG_USAGE_IMMUTABLE) ? 1 : SG_NUM_INFLIGHT_FRAMES;\r\n    cmn->active_slot = 0;\r\n}\r\n\r\ntypedef struct {\r\n    sg_image_type type;\r\n    bool render_target;\r\n    int width;\r\n    int height;\r\n    int depth;\r\n    int num_mipmaps;\r\n    sg_usage usage;\r\n    sg_pixel_format pixel_format;\r\n    int sample_count;\r\n    sg_filter min_filter;\r\n    sg_filter mag_filter;\r\n    sg_wrap wrap_u;\r\n    sg_wrap wrap_v;\r\n    sg_wrap wrap_w;\r\n    sg_border_color border_color;\r\n    uint32_t max_anisotropy;\r\n    uint32_t upd_frame_index;\r\n    int num_slots;\r\n    int active_slot;\r\n} _sg_image_common_t;\r\n\r\n_SOKOL_PRIVATE void _sg_image_common_init(_sg_image_common_t* cmn, const sg_image_desc* desc) {\r\n    cmn->type = desc->type;\r\n    cmn->render_target = desc->render_target;\r\n    cmn->width = desc->width;\r\n    cmn->height = desc->height;\r\n    cmn->depth = desc->depth;\r\n    cmn->num_mipmaps = desc->num_mipmaps;\r\n    cmn->usage = desc->usage;\r\n    cmn->pixel_format = desc->pixel_format;\r\n    cmn->sample_count = desc->sample_count;\r\n    cmn->min_filter = desc->min_filter;\r\n    cmn->mag_filter = desc->mag_filter;\r\n    cmn->wrap_u = desc->wrap_u;\r\n    cmn->wrap_v = desc->wrap_v;\r\n    cmn->wrap_w = desc->wrap_w;\r\n    cmn->border_color = desc->border_color;\r\n    cmn->max_anisotropy = desc->max_anisotropy;\r\n    cmn->upd_frame_index = 0;\r\n    cmn->num_slots = (cmn->usage == SG_USAGE_IMMUTABLE) ? 1 : SG_NUM_INFLIGHT_FRAMES;\r\n    cmn->active_slot = 0;\r\n}\r\n\r\ntypedef struct {\r\n    int size;\r\n} _sg_uniform_block_t;\r\n\r\ntypedef struct {\r\n    sg_image_type type;\r\n    sg_sampler_type sampler_type;\r\n} _sg_shader_image_t;\r\n\r\ntypedef struct {\r\n    int num_uniform_blocks;\r\n    int num_images;\r\n    _sg_uniform_block_t uniform_blocks[SG_MAX_SHADERSTAGE_UBS];\r\n    _sg_shader_image_t images[SG_MAX_SHADERSTAGE_IMAGES];\r\n} _sg_shader_stage_t;\r\n\r\ntypedef struct {\r\n    _sg_shader_stage_t stage[SG_NUM_SHADER_STAGES];\r\n} _sg_shader_common_t;\r\n\r\n_SOKOL_PRIVATE void _sg_shader_common_init(_sg_shader_common_t* cmn, const sg_shader_desc* desc) {\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        const sg_shader_stage_desc* stage_desc = (stage_index == SG_SHADERSTAGE_VS) ? &desc->vs : &desc->fs;\r\n        _sg_shader_stage_t* stage = &cmn->stage[stage_index];\r\n        SOKOL_ASSERT(stage->num_uniform_blocks == 0);\r\n        for (int ub_index = 0; ub_index < SG_MAX_SHADERSTAGE_UBS; ub_index++) {\r\n            const sg_shader_uniform_block_desc* ub_desc = &stage_desc->uniform_blocks[ub_index];\r\n            if (0 == ub_desc->size) {\r\n                break;\r\n            }\r\n            stage->uniform_blocks[ub_index].size = ub_desc->size;\r\n            stage->num_uniform_blocks++;\r\n        }\r\n        SOKOL_ASSERT(stage->num_images == 0);\r\n        for (int img_index = 0; img_index < SG_MAX_SHADERSTAGE_IMAGES; img_index++) {\r\n            const sg_shader_image_desc* img_desc = &stage_desc->images[img_index];\r\n            if (img_desc->type == _SG_IMAGETYPE_DEFAULT) {\r\n                break;\r\n            }\r\n            stage->images[img_index].type = img_desc->type;\r\n            stage->images[img_index].sampler_type = img_desc->sampler_type;\r\n            stage->num_images++;\r\n        }\r\n    }\r\n}\r\n\r\ntypedef struct {\r\n    sg_shader shader_id;\r\n    sg_index_type index_type;\r\n    bool vertex_layout_valid[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    int color_attachment_count;\r\n    sg_pixel_format color_format;\r\n    sg_pixel_format depth_format;\r\n    int sample_count;\r\n    float depth_bias;\r\n    float depth_bias_slope_scale;\r\n    float depth_bias_clamp;\r\n    float blend_color[4];\r\n} _sg_pipeline_common_t;\r\n\r\n_SOKOL_PRIVATE void _sg_pipeline_common_init(_sg_pipeline_common_t* cmn, const sg_pipeline_desc* desc) {\r\n    cmn->shader_id = desc->shader;\r\n    cmn->index_type = desc->index_type;\r\n    for (int i = 0; i < SG_MAX_SHADERSTAGE_BUFFERS; i++) {\r\n        cmn->vertex_layout_valid[i] = false;\r\n    }\r\n    cmn->color_attachment_count = desc->blend.color_attachment_count;\r\n    cmn->color_format = desc->blend.color_format;\r\n    cmn->depth_format = desc->blend.depth_format;\r\n    cmn->sample_count = desc->rasterizer.sample_count;\r\n    cmn->depth_bias = desc->rasterizer.depth_bias;\r\n    cmn->depth_bias_slope_scale = desc->rasterizer.depth_bias_slope_scale;\r\n    cmn->depth_bias_clamp = desc->rasterizer.depth_bias_clamp;\r\n    for (int i = 0; i < 4; i++) {\r\n        cmn->blend_color[i] = desc->blend.blend_color[i];\r\n    }\r\n}\r\n\r\ntypedef struct {\r\n    sg_image image_id;\r\n    int mip_level;\r\n    int slice;\r\n} _sg_attachment_common_t;\r\n\r\ntypedef struct {\r\n    int num_color_atts;\r\n    _sg_attachment_common_t color_atts[SG_MAX_COLOR_ATTACHMENTS];\r\n    _sg_attachment_common_t ds_att;\r\n} _sg_pass_common_t;\r\n\r\n_SOKOL_PRIVATE void _sg_pass_common_init(_sg_pass_common_t* cmn, const sg_pass_desc* desc) {\r\n    const sg_attachment_desc* att_desc;\r\n    _sg_attachment_common_t* att;\r\n    for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n        att_desc = &desc->color_attachments[i];\r\n        if (att_desc->image.id != SG_INVALID_ID) {\r\n            cmn->num_color_atts++;\r\n            att = &cmn->color_atts[i];\r\n            att->image_id = att_desc->image;\r\n            att->mip_level = att_desc->mip_level;\r\n            att->slice = att_desc->slice;\r\n        }\r\n    }\r\n    att_desc = &desc->depth_stencil_attachment;\r\n    if (att_desc->image.id != SG_INVALID_ID) {\r\n        att = &cmn->ds_att;\r\n        att->image_id = att_desc->image;\r\n        att->mip_level = att_desc->mip_level;\r\n        att->slice = att_desc->slice;\r\n    }\r\n}\r\n\r\n/*=== GENERIC SAMPLER CACHE ==================================================*/\r\n\r\n/*\r\n    this is used by the Metal and WGPU backends to reduce the\r\n    number of sampler state objects created through the backend API\r\n*/\r\ntypedef struct {\r\n    sg_filter min_filter;\r\n    sg_filter mag_filter;\r\n    sg_wrap wrap_u;\r\n    sg_wrap wrap_v;\r\n    sg_wrap wrap_w;\r\n    sg_border_color border_color;\r\n    uint32_t max_anisotropy;\r\n    int min_lod;    /* orig min/max_lod is float, this is int(min/max_lod*1000.0) */\r\n    int max_lod;\r\n    uintptr_t sampler_handle;\r\n} _sg_sampler_cache_item_t;\r\n\r\ntypedef struct {\r\n    int capacity;\r\n    int num_items;\r\n    _sg_sampler_cache_item_t* items;\r\n} _sg_sampler_cache_t;\r\n\r\n_SOKOL_PRIVATE void _sg_smpcache_init(_sg_sampler_cache_t* cache, int capacity) {\r\n    SOKOL_ASSERT(cache && (capacity > 0));\r\n    memset(cache, 0, sizeof(_sg_sampler_cache_t));\r\n    cache->capacity = capacity;\r\n    const int size = cache->capacity * sizeof(_sg_sampler_cache_item_t);\r\n    cache->items = (_sg_sampler_cache_item_t*) SOKOL_MALLOC(size);\r\n    memset(cache->items, 0, size);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_smpcache_discard(_sg_sampler_cache_t* cache) {\r\n    SOKOL_ASSERT(cache && cache->items);\r\n    SOKOL_FREE(cache->items);\r\n    cache->items = 0;\r\n    cache->num_items = 0;\r\n    cache->capacity = 0;\r\n}\r\n\r\n_SOKOL_PRIVATE int _sg_smpcache_minlod_int(float min_lod) {\r\n    return (int) (min_lod * 1000.0f);\r\n}\r\n\r\n_SOKOL_PRIVATE int _sg_smpcache_maxlod_int(float max_lod) {\r\n    return (int) (_sg_clamp(max_lod, 0.0f, 1000.0f) * 1000.0f);\r\n}\r\n\r\n_SOKOL_PRIVATE int _sg_smpcache_find_item(const _sg_sampler_cache_t* cache, const sg_image_desc* img_desc) {\r\n    /* return matching sampler cache item index or -1 */\r\n    SOKOL_ASSERT(cache && cache->items);\r\n    SOKOL_ASSERT(img_desc);\r\n    const int min_lod = _sg_smpcache_minlod_int(img_desc->min_lod);\r\n    const int max_lod = _sg_smpcache_maxlod_int(img_desc->max_lod);\r\n    for (int i = 0; i < cache->num_items; i++) {\r\n        const _sg_sampler_cache_item_t* item = &cache->items[i];\r\n        if ((img_desc->min_filter == item->min_filter) &&\r\n            (img_desc->mag_filter == item->mag_filter) &&\r\n            (img_desc->wrap_u == item->wrap_u) &&\r\n            (img_desc->wrap_v == item->wrap_v) &&\r\n            (img_desc->wrap_w == item->wrap_w) &&\r\n            (img_desc->max_anisotropy == item->max_anisotropy) &&\r\n            (img_desc->border_color == item->border_color) &&\r\n            (min_lod == item->min_lod) &&\r\n            (max_lod == item->max_lod))\r\n        {\r\n            return i;\r\n        }\r\n    }\r\n    /* fallthrough: no matching cache item found */\r\n    return -1;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_smpcache_add_item(_sg_sampler_cache_t* cache, const sg_image_desc* img_desc, uintptr_t sampler_handle) {\r\n    SOKOL_ASSERT(cache && cache->items);\r\n    SOKOL_ASSERT(img_desc);\r\n    SOKOL_ASSERT(cache->num_items < cache->capacity);\r\n    const int item_index = cache->num_items++;\r\n    _sg_sampler_cache_item_t* item = &cache->items[item_index];\r\n    item->min_filter = img_desc->min_filter;\r\n    item->mag_filter = img_desc->mag_filter;\r\n    item->wrap_u = img_desc->wrap_u;\r\n    item->wrap_v = img_desc->wrap_v;\r\n    item->wrap_w = img_desc->wrap_w;\r\n    item->border_color = img_desc->border_color;\r\n    item->max_anisotropy = img_desc->max_anisotropy;\r\n    item->min_lod = _sg_smpcache_minlod_int(img_desc->min_lod);\r\n    item->max_lod = _sg_smpcache_maxlod_int(img_desc->max_lod);\r\n    item->sampler_handle = sampler_handle;\r\n}\r\n\r\n_SOKOL_PRIVATE uintptr_t _sg_smpcache_sampler(_sg_sampler_cache_t* cache, int item_index) {\r\n    SOKOL_ASSERT(cache && cache->items);\r\n    SOKOL_ASSERT((item_index >= 0) && (item_index < cache->num_items));\r\n    return cache->items[item_index].sampler_handle;\r\n}\r\n\r\n/*=== DUMMY BACKEND DECLARATIONS =============================================*/\r\n#if defined(SOKOL_DUMMY_BACKEND)\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_buffer_common_t cmn;\r\n} _sg_dummy_buffer_t;\r\ntypedef _sg_dummy_buffer_t _sg_buffer_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_image_common_t cmn;\r\n} _sg_dummy_image_t;\r\ntypedef _sg_dummy_image_t _sg_image_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_shader_common_t cmn;\r\n} _sg_dummy_shader_t;\r\ntypedef _sg_dummy_shader_t _sg_shader_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_shader_t* shader;\r\n    _sg_pipeline_common_t cmn;\r\n} _sg_dummy_pipeline_t;\r\ntypedef _sg_dummy_pipeline_t _sg_pipeline_t;\r\n\r\ntypedef struct {\r\n    _sg_image_t* image;\r\n} _sg_dummy_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_pass_common_t cmn;\r\n    struct {\r\n        _sg_dummy_attachment_t color_atts[SG_MAX_COLOR_ATTACHMENTS];\r\n        _sg_dummy_attachment_t ds_att;\r\n    } dmy;\r\n} _sg_dummy_pass_t;\r\ntypedef _sg_dummy_pass_t _sg_pass_t;\r\ntypedef _sg_attachment_common_t _sg_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n} _sg_dummy_context_t;\r\ntypedef _sg_dummy_context_t _sg_context_t;\r\n\r\n/*== GL BACKEND DECLARATIONS =================================================*/\r\n#elif defined(_SOKOL_ANY_GL)\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_buffer_common_t cmn;\r\n    struct {\r\n        GLuint buf[SG_NUM_INFLIGHT_FRAMES];\r\n        bool ext_buffers;   /* if true, external buffers were injected with sg_buffer_desc.gl_buffers */\r\n    } gl;\r\n} _sg_gl_buffer_t;\r\ntypedef _sg_gl_buffer_t _sg_buffer_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_image_common_t cmn;\r\n    struct {\r\n        GLenum target;\r\n        GLuint depth_render_buffer;\r\n        GLuint msaa_render_buffer;\r\n        GLuint tex[SG_NUM_INFLIGHT_FRAMES];\r\n        bool ext_textures;  /* if true, external textures were injected with sg_image_desc.gl_textures */\r\n    } gl;\r\n} _sg_gl_image_t;\r\ntypedef _sg_gl_image_t _sg_image_t;\r\n\r\ntypedef struct {\r\n    GLint gl_loc;\r\n    sg_uniform_type type;\r\n    uint8_t count;\r\n    uint16_t offset;\r\n} _sg_gl_uniform_t;\r\n\r\ntypedef struct {\r\n    int num_uniforms;\r\n    _sg_gl_uniform_t uniforms[SG_MAX_UB_MEMBERS];\r\n} _sg_gl_uniform_block_t;\r\n\r\ntypedef struct {\r\n    int gl_tex_slot;\r\n} _sg_gl_shader_image_t;\r\n\r\ntypedef struct {\r\n    _sg_str_t name;\r\n} _sg_gl_shader_attr_t;\r\n\r\ntypedef struct {\r\n    _sg_gl_uniform_block_t uniform_blocks[SG_MAX_SHADERSTAGE_UBS];\r\n    _sg_gl_shader_image_t images[SG_MAX_SHADERSTAGE_IMAGES];\r\n} _sg_gl_shader_stage_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_shader_common_t cmn;\r\n    struct {\r\n        GLuint prog;\r\n        _sg_gl_shader_attr_t attrs[SG_MAX_VERTEX_ATTRIBUTES];\r\n        _sg_gl_shader_stage_t stage[SG_NUM_SHADER_STAGES];\r\n    } gl;\r\n} _sg_gl_shader_t;\r\ntypedef _sg_gl_shader_t _sg_shader_t;\r\n\r\ntypedef struct {\r\n    int8_t vb_index;        /* -1 if attr is not enabled */\r\n    int8_t divisor;         /* -1 if not initialized */\r\n    uint8_t stride;\r\n    uint8_t size;\r\n    uint8_t normalized;\r\n    int offset;\r\n    GLenum type;\r\n} _sg_gl_attr_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_pipeline_common_t cmn;\r\n    _sg_shader_t* shader;\r\n    struct {\r\n        _sg_gl_attr_t attrs[SG_MAX_VERTEX_ATTRIBUTES];\r\n        sg_depth_stencil_state depth_stencil;\r\n        sg_primitive_type primitive_type;\r\n        sg_blend_state blend;\r\n        sg_rasterizer_state rast;\r\n    } gl;\r\n} _sg_gl_pipeline_t;\r\ntypedef _sg_gl_pipeline_t _sg_pipeline_t;\r\n\r\ntypedef struct {\r\n    _sg_image_t* image;\r\n    GLuint gl_msaa_resolve_buffer;\r\n} _sg_gl_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_pass_common_t cmn;\r\n    struct {\r\n        GLuint fb;\r\n        _sg_gl_attachment_t color_atts[SG_MAX_COLOR_ATTACHMENTS];\r\n        _sg_gl_attachment_t ds_att;\r\n    } gl;\r\n} _sg_gl_pass_t;\r\ntypedef _sg_gl_pass_t _sg_pass_t;\r\ntypedef _sg_attachment_common_t _sg_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    #if !defined(SOKOL_GLES2)\r\n    GLuint vao;\r\n    #endif\r\n    GLuint default_framebuffer;\r\n} _sg_gl_context_t;\r\ntypedef _sg_gl_context_t _sg_context_t;\r\n\r\ntypedef struct {\r\n    _sg_gl_attr_t gl_attr;\r\n    GLuint gl_vbuf;\r\n} _sg_gl_cache_attr_t;\r\n\r\ntypedef struct {\r\n    GLenum target;\r\n    GLuint texture;\r\n} _sg_gl_texture_bind_slot;\r\n\r\ntypedef struct {\r\n    sg_depth_stencil_state ds;\r\n    sg_blend_state blend;\r\n    sg_rasterizer_state rast;\r\n    bool polygon_offset_enabled;\r\n    _sg_gl_cache_attr_t attrs[SG_MAX_VERTEX_ATTRIBUTES];\r\n    GLuint vertex_buffer;\r\n    GLuint index_buffer;\r\n    GLuint stored_vertex_buffer;\r\n    GLuint stored_index_buffer;\r\n    GLuint prog;\r\n    _sg_gl_texture_bind_slot textures[SG_MAX_SHADERSTAGE_IMAGES];\r\n    _sg_gl_texture_bind_slot stored_texture;\r\n    int cur_ib_offset;\r\n    GLenum cur_primitive_type;\r\n    GLenum cur_index_type;\r\n    GLenum cur_active_texture;\r\n    _sg_pipeline_t* cur_pipeline;\r\n    sg_pipeline cur_pipeline_id;\r\n} _sg_gl_state_cache_t;\r\n\r\ntypedef struct {\r\n    bool valid;\r\n    bool gles2;\r\n    bool in_pass;\r\n    int cur_pass_width;\r\n    int cur_pass_height;\r\n    _sg_context_t* cur_context;\r\n    _sg_pass_t* cur_pass;\r\n    sg_pass cur_pass_id;\r\n    _sg_gl_state_cache_t cache;\r\n    bool ext_anisotropic;\r\n    GLint max_anisotropy;\r\n    GLint max_combined_texture_image_units;\r\n} _sg_gl_backend_t;\r\n\r\n/*== D3D11 BACKEND DECLARATIONS ==============================================*/\r\n#elif defined(SOKOL_D3D11)\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_buffer_common_t cmn;\r\n    struct {\r\n        ID3D11Buffer* buf;\r\n    } d3d11;\r\n} _sg_d3d11_buffer_t;\r\ntypedef _sg_d3d11_buffer_t _sg_buffer_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_image_common_t cmn;\r\n    struct {\r\n        DXGI_FORMAT format;\r\n        ID3D11Texture2D* tex2d;\r\n        ID3D11Texture3D* tex3d;\r\n        ID3D11Texture2D* texds;\r\n        ID3D11Texture2D* texmsaa;\r\n        ID3D11ShaderResourceView* srv;\r\n        ID3D11SamplerState* smp;\r\n    } d3d11;\r\n} _sg_d3d11_image_t;\r\ntypedef _sg_d3d11_image_t _sg_image_t;\r\n\r\ntypedef struct {\r\n    _sg_str_t sem_name;\r\n    int sem_index;\r\n} _sg_d3d11_shader_attr_t;\r\n\r\ntypedef struct {\r\n    ID3D11Buffer* cbufs[SG_MAX_SHADERSTAGE_UBS];\r\n} _sg_d3d11_shader_stage_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_shader_common_t cmn;\r\n    struct {\r\n        _sg_d3d11_shader_attr_t attrs[SG_MAX_VERTEX_ATTRIBUTES];\r\n        _sg_d3d11_shader_stage_t stage[SG_NUM_SHADER_STAGES];\r\n        ID3D11VertexShader* vs;\r\n        ID3D11PixelShader* fs;\r\n        void* vs_blob;\r\n        int vs_blob_length;\r\n    } d3d11;\r\n} _sg_d3d11_shader_t;\r\ntypedef _sg_d3d11_shader_t _sg_shader_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_pipeline_common_t cmn;\r\n    _sg_shader_t* shader;\r\n    struct {\r\n        UINT stencil_ref;\r\n        UINT vb_strides[SG_MAX_SHADERSTAGE_BUFFERS];\r\n        D3D_PRIMITIVE_TOPOLOGY topology;\r\n        DXGI_FORMAT index_format;\r\n        ID3D11InputLayout* il;\r\n        ID3D11RasterizerState* rs;\r\n        ID3D11DepthStencilState* dss;\r\n        ID3D11BlendState* bs;\r\n    } d3d11;\r\n} _sg_d3d11_pipeline_t;\r\ntypedef _sg_d3d11_pipeline_t _sg_pipeline_t;\r\n\r\ntypedef struct {\r\n    _sg_image_t* image;\r\n    ID3D11RenderTargetView* rtv;\r\n} _sg_d3d11_color_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_image_t* image;\r\n    ID3D11DepthStencilView* dsv;\r\n} _sg_d3d11_ds_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_pass_common_t cmn;\r\n    struct {\r\n        _sg_d3d11_color_attachment_t color_atts[SG_MAX_COLOR_ATTACHMENTS];\r\n        _sg_d3d11_ds_attachment_t ds_att;\r\n    } d3d11;\r\n} _sg_d3d11_pass_t;\r\ntypedef _sg_d3d11_pass_t _sg_pass_t;\r\ntypedef _sg_attachment_common_t _sg_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n} _sg_d3d11_context_t;\r\ntypedef _sg_d3d11_context_t _sg_context_t;\r\n\r\ntypedef struct {\r\n    bool valid;\r\n    ID3D11Device* dev;\r\n    ID3D11DeviceContext* ctx;\r\n    const void* (*rtv_cb)(void);\r\n    const void* (*rtv_userdata_cb)(void*);\r\n    const void* (*dsv_cb)(void);\r\n    const void* (*dsv_userdata_cb)(void*);\r\n    void* user_data;\r\n    bool in_pass;\r\n    bool use_indexed_draw;\r\n    int cur_width;\r\n    int cur_height;\r\n    int num_rtvs;\r\n    _sg_pass_t* cur_pass;\r\n    sg_pass cur_pass_id;\r\n    _sg_pipeline_t* cur_pipeline;\r\n    sg_pipeline cur_pipeline_id;\r\n    ID3D11RenderTargetView* cur_rtvs[SG_MAX_COLOR_ATTACHMENTS];\r\n    ID3D11DepthStencilView* cur_dsv;\r\n    /* on-demand loaded d3dcompiler_47.dll handles */\r\n    HINSTANCE d3dcompiler_dll;\r\n    bool d3dcompiler_dll_load_failed;\r\n    pD3DCompile D3DCompile_func;\r\n    /* the following arrays are used for unbinding resources, they will always contain zeroes */\r\n    ID3D11RenderTargetView* zero_rtvs[SG_MAX_COLOR_ATTACHMENTS];\r\n    ID3D11Buffer* zero_vbs[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    UINT zero_vb_offsets[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    UINT zero_vb_strides[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    ID3D11Buffer* zero_cbs[SG_MAX_SHADERSTAGE_UBS];\r\n    ID3D11ShaderResourceView* zero_srvs[SG_MAX_SHADERSTAGE_IMAGES];\r\n    ID3D11SamplerState* zero_smps[SG_MAX_SHADERSTAGE_IMAGES];\r\n    /* global subresourcedata array for texture updates */\r\n    D3D11_SUBRESOURCE_DATA subres_data[SG_MAX_MIPMAPS * SG_MAX_TEXTUREARRAY_LAYERS];\r\n} _sg_d3d11_backend_t;\r\n\r\n/*=== METAL BACKEND DECLARATIONS =============================================*/\r\n#elif defined(SOKOL_METAL)\r\n\r\n#if defined(_SG_TARGET_MACOS) || defined(_SG_TARGET_IOS_SIMULATOR)\r\n#define _SG_MTL_UB_ALIGN (256)\r\n#else\r\n#define _SG_MTL_UB_ALIGN (16)\r\n#endif\r\n#define _SG_MTL_INVALID_SLOT_INDEX (0)\r\n\r\ntypedef struct {\r\n    uint32_t frame_index;   /* frame index at which it is safe to release this resource */\r\n    uint32_t slot_index;\r\n} _sg_mtl_release_item_t;\r\n\r\ntypedef struct {\r\n    NSMutableArray* pool;\r\n    uint32_t num_slots;\r\n    uint32_t free_queue_top;\r\n    uint32_t* free_queue;\r\n    uint32_t release_queue_front;\r\n    uint32_t release_queue_back;\r\n    _sg_mtl_release_item_t* release_queue;\r\n} _sg_mtl_idpool_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_buffer_common_t cmn;\r\n    struct {\r\n        uint32_t buf[SG_NUM_INFLIGHT_FRAMES];  /* index into _sg_mtl_pool */\r\n    } mtl;\r\n} _sg_mtl_buffer_t;\r\ntypedef _sg_mtl_buffer_t _sg_buffer_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_image_common_t cmn;\r\n    struct {\r\n        uint32_t tex[SG_NUM_INFLIGHT_FRAMES];\r\n        uint32_t depth_tex;\r\n        uint32_t msaa_tex;\r\n        uint32_t sampler_state;\r\n    } mtl;\r\n} _sg_mtl_image_t;\r\ntypedef _sg_mtl_image_t _sg_image_t;\r\n\r\ntypedef struct {\r\n    uint32_t mtl_lib;\r\n    uint32_t mtl_func;\r\n} _sg_mtl_shader_stage_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_shader_common_t cmn;\r\n    struct {\r\n        _sg_mtl_shader_stage_t stage[SG_NUM_SHADER_STAGES];\r\n    } mtl;\r\n} _sg_mtl_shader_t;\r\ntypedef _sg_mtl_shader_t _sg_shader_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_pipeline_common_t cmn;\r\n    _sg_shader_t* shader;\r\n    struct {\r\n        MTLPrimitiveType prim_type;\r\n        NSUInteger index_size;\r\n        MTLIndexType index_type;\r\n        MTLCullMode cull_mode;\r\n        MTLWinding winding;\r\n        uint32_t stencil_ref;\r\n        uint32_t rps;\r\n        uint32_t dss;\r\n    } mtl;\r\n} _sg_mtl_pipeline_t;\r\ntypedef _sg_mtl_pipeline_t _sg_pipeline_t;\r\n\r\ntypedef struct {\r\n    _sg_image_t* image;\r\n} _sg_mtl_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_pass_common_t cmn;\r\n    struct {\r\n        _sg_mtl_attachment_t color_atts[SG_MAX_COLOR_ATTACHMENTS];\r\n        _sg_mtl_attachment_t ds_att;\r\n    } mtl;\r\n} _sg_mtl_pass_t;\r\ntypedef _sg_mtl_pass_t _sg_pass_t;\r\ntypedef _sg_attachment_common_t _sg_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n} _sg_mtl_context_t;\r\ntypedef _sg_mtl_context_t _sg_context_t;\r\n\r\n/* resouce binding state cache */\r\ntypedef struct {\r\n    const _sg_pipeline_t* cur_pipeline;\r\n    sg_pipeline cur_pipeline_id;\r\n    const _sg_buffer_t* cur_indexbuffer;\r\n    int cur_indexbuffer_offset;\r\n    sg_buffer cur_indexbuffer_id;\r\n    const _sg_buffer_t* cur_vertexbuffers[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    int cur_vertexbuffer_offsets[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    sg_buffer cur_vertexbuffer_ids[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    const _sg_image_t* cur_vs_images[SG_MAX_SHADERSTAGE_IMAGES];\r\n    sg_image cur_vs_image_ids[SG_MAX_SHADERSTAGE_IMAGES];\r\n    const _sg_image_t* cur_fs_images[SG_MAX_SHADERSTAGE_IMAGES];\r\n    sg_image cur_fs_image_ids[SG_MAX_SHADERSTAGE_IMAGES];\r\n} _sg_mtl_state_cache_t;\r\n\r\ntypedef struct {\r\n    bool valid;\r\n    const void*(*renderpass_descriptor_cb)(void);\r\n    const void*(*renderpass_descriptor_userdata_cb)(void*);\r\n    const void*(*drawable_cb)(void);\r\n    const void*(*drawable_userdata_cb)(void*);\r\n    void* user_data;\r\n    uint32_t frame_index;\r\n    uint32_t cur_frame_rotate_index;\r\n    uint32_t ub_size;\r\n    uint32_t cur_ub_offset;\r\n    uint8_t* cur_ub_base_ptr;\r\n    bool in_pass;\r\n    bool pass_valid;\r\n    int cur_width;\r\n    int cur_height;\r\n    _sg_mtl_state_cache_t state_cache;\r\n    _sg_sampler_cache_t sampler_cache;\r\n    _sg_mtl_idpool_t idpool;\r\n    dispatch_semaphore_t sem;\r\n    id<MTLDevice> device;\r\n    id<MTLCommandQueue> cmd_queue;\r\n    id<MTLCommandBuffer> cmd_buffer;\r\n    id<MTLRenderCommandEncoder> cmd_encoder;\r\n    id<MTLBuffer> uniform_buffers[SG_NUM_INFLIGHT_FRAMES];\r\n} _sg_mtl_backend_t;\r\n\r\n/*=== WGPU BACKEND DECLARATIONS ==============================================*/\r\n#elif defined(SOKOL_WGPU)\r\n\r\n#define _SG_WGPU_STAGING_ALIGN (256)\r\n#define _SG_WGPU_STAGING_PIPELINE_SIZE (8)\r\n#define _SG_WGPU_ROWPITCH_ALIGN (256)\r\n#define _SG_WGPU_MAX_SHADERSTAGE_IMAGES (8)\r\n#define _SG_WGPU_MAX_UNIFORM_UPDATE_SIZE (1<<16)\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_buffer_common_t cmn;\r\n    struct {\r\n        WGPUBuffer buf;\r\n    } wgpu;\r\n} _sg_wgpu_buffer_t;\r\ntypedef _sg_wgpu_buffer_t _sg_buffer_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_image_common_t cmn;\r\n    struct {\r\n        WGPUTexture tex;\r\n        WGPUTextureView tex_view;\r\n        WGPUTexture msaa_tex;\r\n        WGPUSampler sampler;\r\n    } wgpu;\r\n} _sg_wgpu_image_t;\r\ntypedef _sg_wgpu_image_t _sg_image_t;\r\n\r\ntypedef struct {\r\n    WGPUShaderModule module;\r\n    WGPUBindGroupLayout bind_group_layout;\r\n    _sg_str_t entry;\r\n} _sg_wgpu_shader_stage_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_shader_common_t cmn;\r\n    struct {\r\n        _sg_wgpu_shader_stage_t stage[SG_NUM_SHADER_STAGES];\r\n    } wgpu;\r\n} _sg_wgpu_shader_t;\r\ntypedef _sg_wgpu_shader_t _sg_shader_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_pipeline_common_t cmn;\r\n    _sg_shader_t* shader;\r\n    struct {\r\n        WGPURenderPipeline pip;\r\n        uint32_t stencil_ref;\r\n    } wgpu;\r\n} _sg_wgpu_pipeline_t;\r\ntypedef _sg_wgpu_pipeline_t _sg_pipeline_t;\r\n\r\ntypedef struct {\r\n    _sg_image_t* image;\r\n    WGPUTextureView render_tex_view;\r\n    WGPUTextureView resolve_tex_view;\r\n} _sg_wgpu_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n    _sg_pass_common_t cmn;\r\n    struct {\r\n        _sg_wgpu_attachment_t color_atts[SG_MAX_COLOR_ATTACHMENTS];\r\n        _sg_wgpu_attachment_t ds_att;\r\n    } wgpu;\r\n} _sg_wgpu_pass_t;\r\ntypedef _sg_wgpu_pass_t _sg_pass_t;\r\ntypedef _sg_attachment_common_t _sg_attachment_t;\r\n\r\ntypedef struct {\r\n    _sg_slot_t slot;\r\n} _sg_wgpu_context_t;\r\ntypedef _sg_wgpu_context_t _sg_context_t;\r\n\r\n/* a pool of per-frame uniform buffers */\r\ntypedef struct {\r\n    WGPUBindGroupLayout bindgroup_layout;\r\n    uint32_t num_bytes;\r\n    uint32_t offset;    /* current offset into current frame's mapped uniform buffer */\r\n    uint32_t bind_offsets[SG_NUM_SHADER_STAGES][SG_MAX_SHADERSTAGE_UBS];\r\n    WGPUBuffer buf;     /* the GPU-side uniform buffer */\r\n    WGPUBindGroup bindgroup;\r\n    struct {\r\n        int num;\r\n        int cur;\r\n        WGPUBuffer buf[_SG_WGPU_STAGING_PIPELINE_SIZE]; /* CPU-side staging buffers */\r\n        uint8_t* ptr[_SG_WGPU_STAGING_PIPELINE_SIZE];   /* if != 0, staging buffer currently mapped */\r\n    } stage;\r\n} _sg_wgpu_ubpool_t;\r\n\r\n/* ...a similar pool (like uniform buffer pool) of dynamic-resource staging buffers */\r\ntypedef struct {\r\n    uint32_t num_bytes;\r\n    uint32_t offset;    /* current offset into current frame's staging buffer */\r\n    int num;            /* number of staging buffers */\r\n    int cur;            /* this frame's staging buffer */\r\n    WGPUBuffer buf[_SG_WGPU_STAGING_PIPELINE_SIZE]; /* CPU-side staging buffers */\r\n    uint8_t* ptr[_SG_WGPU_STAGING_PIPELINE_SIZE];   /* if != 0, staging buffer currently mapped */\r\n} _sg_wgpu_stagingpool_t;\r\n\r\n/* the WGPU backend state */\r\ntypedef struct {\r\n    bool valid;\r\n    bool in_pass;\r\n    bool draw_indexed;\r\n    int cur_width;\r\n    int cur_height;\r\n    WGPUDevice dev;\r\n    WGPUTextureView (*render_view_cb)(void);\r\n    WGPUTextureView (*render_view_userdata_cb)(void*);\r\n    WGPUTextureView (*resolve_view_cb)(void);\r\n    WGPUTextureView (*resolve_view_userdata_cb)(void*);\r\n    WGPUTextureView (*depth_stencil_view_cb)(void);\r\n    WGPUTextureView (*depth_stencil_view_userdata_cb)(void*);\r\n    void* user_data;\r\n    WGPUQueue queue;\r\n    WGPUCommandEncoder render_cmd_enc;\r\n    WGPUCommandEncoder staging_cmd_enc;\r\n    WGPURenderPassEncoder pass_enc;\r\n    WGPUBindGroup empty_bind_group;\r\n    const _sg_pipeline_t* cur_pipeline;\r\n    sg_pipeline cur_pipeline_id;\r\n    _sg_sampler_cache_t sampler_cache;\r\n    _sg_wgpu_ubpool_t ub;\r\n    _sg_wgpu_stagingpool_t staging;\r\n} _sg_wgpu_backend_t;\r\n#endif\r\n\r\n/*=== RESOURCE POOL DECLARATIONS =============================================*/\r\n\r\n/* this *MUST* remain 0 */\r\n#define _SG_INVALID_SLOT_INDEX (0)\r\n\r\ntypedef struct {\r\n    int size;\r\n    int queue_top;\r\n    uint32_t* gen_ctrs;\r\n    int* free_queue;\r\n} _sg_pool_t;\r\n\r\ntypedef struct {\r\n    _sg_pool_t buffer_pool;\r\n    _sg_pool_t image_pool;\r\n    _sg_pool_t shader_pool;\r\n    _sg_pool_t pipeline_pool;\r\n    _sg_pool_t pass_pool;\r\n    _sg_pool_t context_pool;\r\n    _sg_buffer_t* buffers;\r\n    _sg_image_t* images;\r\n    _sg_shader_t* shaders;\r\n    _sg_pipeline_t* pipelines;\r\n    _sg_pass_t* passes;\r\n    _sg_context_t* contexts;\r\n} _sg_pools_t;\r\n\r\n/*=== VALIDATION LAYER DECLARATIONS ==========================================*/\r\ntypedef enum {\r\n    /* special case 'validation was successful' */\r\n    _SG_VALIDATE_SUCCESS,\r\n\r\n    /* buffer creation */\r\n    _SG_VALIDATE_BUFFERDESC_CANARY,\r\n    _SG_VALIDATE_BUFFERDESC_SIZE,\r\n    _SG_VALIDATE_BUFFERDESC_CONTENT,\r\n    _SG_VALIDATE_BUFFERDESC_NO_CONTENT,\r\n\r\n    /* image creation */\r\n    _SG_VALIDATE_IMAGEDESC_CANARY,\r\n    _SG_VALIDATE_IMAGEDESC_WIDTH,\r\n    _SG_VALIDATE_IMAGEDESC_HEIGHT,\r\n    _SG_VALIDATE_IMAGEDESC_RT_PIXELFORMAT,\r\n    _SG_VALIDATE_IMAGEDESC_NONRT_PIXELFORMAT,\r\n    _SG_VALIDATE_IMAGEDESC_MSAA_BUT_NO_RT,\r\n    _SG_VALIDATE_IMAGEDESC_NO_MSAA_RT_SUPPORT,\r\n    _SG_VALIDATE_IMAGEDESC_RT_IMMUTABLE,\r\n    _SG_VALIDATE_IMAGEDESC_RT_NO_CONTENT,\r\n    _SG_VALIDATE_IMAGEDESC_CONTENT,\r\n    _SG_VALIDATE_IMAGEDESC_NO_CONTENT,\r\n\r\n    /* shader creation */\r\n    _SG_VALIDATE_SHADERDESC_CANARY,\r\n    _SG_VALIDATE_SHADERDESC_SOURCE,\r\n    _SG_VALIDATE_SHADERDESC_BYTECODE,\r\n    _SG_VALIDATE_SHADERDESC_SOURCE_OR_BYTECODE,\r\n    _SG_VALIDATE_SHADERDESC_NO_BYTECODE_SIZE,\r\n    _SG_VALIDATE_SHADERDESC_NO_CONT_UBS,\r\n    _SG_VALIDATE_SHADERDESC_NO_CONT_IMGS,\r\n    _SG_VALIDATE_SHADERDESC_NO_CONT_UB_MEMBERS,\r\n    _SG_VALIDATE_SHADERDESC_NO_UB_MEMBERS,\r\n    _SG_VALIDATE_SHADERDESC_UB_MEMBER_NAME,\r\n    _SG_VALIDATE_SHADERDESC_UB_SIZE_MISMATCH,\r\n    _SG_VALIDATE_SHADERDESC_IMG_NAME,\r\n    _SG_VALIDATE_SHADERDESC_ATTR_NAMES,\r\n    _SG_VALIDATE_SHADERDESC_ATTR_SEMANTICS,\r\n    _SG_VALIDATE_SHADERDESC_ATTR_STRING_TOO_LONG,\r\n\r\n    /* pipeline creation */\r\n    _SG_VALIDATE_PIPELINEDESC_CANARY,\r\n    _SG_VALIDATE_PIPELINEDESC_SHADER,\r\n    _SG_VALIDATE_PIPELINEDESC_NO_ATTRS,\r\n    _SG_VALIDATE_PIPELINEDESC_LAYOUT_STRIDE4,\r\n    _SG_VALIDATE_PIPELINEDESC_ATTR_NAME,\r\n    _SG_VALIDATE_PIPELINEDESC_ATTR_SEMANTICS,\r\n\r\n    /* pass creation */\r\n    _SG_VALIDATE_PASSDESC_CANARY,\r\n    _SG_VALIDATE_PASSDESC_NO_COLOR_ATTS,\r\n    _SG_VALIDATE_PASSDESC_NO_CONT_COLOR_ATTS,\r\n    _SG_VALIDATE_PASSDESC_IMAGE,\r\n    _SG_VALIDATE_PASSDESC_MIPLEVEL,\r\n    _SG_VALIDATE_PASSDESC_FACE,\r\n    _SG_VALIDATE_PASSDESC_LAYER,\r\n    _SG_VALIDATE_PASSDESC_SLICE,\r\n    _SG_VALIDATE_PASSDESC_IMAGE_NO_RT,\r\n    _SG_VALIDATE_PASSDESC_COLOR_PIXELFORMATS,\r\n    _SG_VALIDATE_PASSDESC_COLOR_INV_PIXELFORMAT,\r\n    _SG_VALIDATE_PASSDESC_DEPTH_INV_PIXELFORMAT,\r\n    _SG_VALIDATE_PASSDESC_IMAGE_SIZES,\r\n    _SG_VALIDATE_PASSDESC_IMAGE_SAMPLE_COUNTS,\r\n\r\n    /* sg_begin_pass validation */\r\n    _SG_VALIDATE_BEGINPASS_PASS,\r\n    _SG_VALIDATE_BEGINPASS_IMAGE,\r\n\r\n    /* sg_apply_pipeline validation */\r\n    _SG_VALIDATE_APIP_PIPELINE_VALID_ID,\r\n    _SG_VALIDATE_APIP_PIPELINE_EXISTS,\r\n    _SG_VALIDATE_APIP_PIPELINE_VALID,\r\n    _SG_VALIDATE_APIP_SHADER_EXISTS,\r\n    _SG_VALIDATE_APIP_SHADER_VALID,\r\n    _SG_VALIDATE_APIP_ATT_COUNT,\r\n    _SG_VALIDATE_APIP_COLOR_FORMAT,\r\n    _SG_VALIDATE_APIP_DEPTH_FORMAT,\r\n    _SG_VALIDATE_APIP_SAMPLE_COUNT,\r\n\r\n    /* sg_apply_bindings validation */\r\n    _SG_VALIDATE_ABND_PIPELINE,\r\n    _SG_VALIDATE_ABND_PIPELINE_EXISTS,\r\n    _SG_VALIDATE_ABND_PIPELINE_VALID,\r\n    _SG_VALIDATE_ABND_VBS,\r\n    _SG_VALIDATE_ABND_VB_EXISTS,\r\n    _SG_VALIDATE_ABND_VB_TYPE,\r\n    _SG_VALIDATE_ABND_VB_OVERFLOW,\r\n    _SG_VALIDATE_ABND_NO_IB,\r\n    _SG_VALIDATE_ABND_IB,\r\n    _SG_VALIDATE_ABND_IB_EXISTS,\r\n    _SG_VALIDATE_ABND_IB_TYPE,\r\n    _SG_VALIDATE_ABND_IB_OVERFLOW,\r\n    _SG_VALIDATE_ABND_VS_IMGS,\r\n    _SG_VALIDATE_ABND_VS_IMG_EXISTS,\r\n    _SG_VALIDATE_ABND_VS_IMG_TYPES,\r\n    _SG_VALIDATE_ABND_FS_IMGS,\r\n    _SG_VALIDATE_ABND_FS_IMG_EXISTS,\r\n    _SG_VALIDATE_ABND_FS_IMG_TYPES,\r\n\r\n    /* sg_apply_uniforms validation */\r\n    _SG_VALIDATE_AUB_NO_PIPELINE,\r\n    _SG_VALIDATE_AUB_NO_UB_AT_SLOT,\r\n    _SG_VALIDATE_AUB_SIZE,\r\n\r\n    /* sg_update_buffer validation */\r\n    _SG_VALIDATE_UPDATEBUF_USAGE,\r\n    _SG_VALIDATE_UPDATEBUF_SIZE,\r\n    _SG_VALIDATE_UPDATEBUF_ONCE,\r\n    _SG_VALIDATE_UPDATEBUF_APPEND,\r\n\r\n    /* sg_append_buffer validation */\r\n    _SG_VALIDATE_APPENDBUF_USAGE,\r\n    _SG_VALIDATE_APPENDBUF_SIZE,\r\n    _SG_VALIDATE_APPENDBUF_UPDATE,\r\n\r\n    /* sg_update_image validation */\r\n    _SG_VALIDATE_UPDIMG_USAGE,\r\n    _SG_VALIDATE_UPDIMG_NOTENOUGHDATA,\r\n    _SG_VALIDATE_UPDIMG_SIZE,\r\n    _SG_VALIDATE_UPDIMG_COMPRESSED,\r\n    _SG_VALIDATE_UPDIMG_ONCE\r\n} _sg_validate_error_t;\r\n\r\n/*=== GENERIC BACKEND STATE ==================================================*/\r\n\r\ntypedef struct {\r\n    bool valid;\r\n    sg_desc desc;       /* original desc with default values patched in */\r\n    uint32_t frame_index;\r\n    sg_context active_context;\r\n    sg_pass cur_pass;\r\n    sg_pipeline cur_pipeline;\r\n    bool pass_valid;\r\n    bool bindings_valid;\r\n    bool next_draw_valid;\r\n    #if defined(SOKOL_DEBUG)\r\n    _sg_validate_error_t validate_error;\r\n    #endif\r\n    _sg_pools_t pools;\r\n    sg_backend backend;\r\n    sg_features features;\r\n    sg_limits limits;\r\n    sg_pixelformat_info formats[_SG_PIXELFORMAT_NUM];\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_backend_t gl;\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_backend_t mtl;\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_backend_t d3d11;\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_backend_t wgpu;\r\n    #endif\r\n    #if defined(SOKOL_TRACE_HOOKS)\r\n    sg_trace_hooks hooks;\r\n    #endif\r\n} _sg_state_t;\r\nstatic _sg_state_t _sg;\r\n\r\n/*-- helper functions --------------------------------------------------------*/\r\n\r\n_SOKOL_PRIVATE bool _sg_strempty(const _sg_str_t* str) {\r\n    return 0 == str->buf[0];\r\n}\r\n\r\n_SOKOL_PRIVATE const char* _sg_strptr(const _sg_str_t* str) {\r\n    return &str->buf[0];\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_strcpy(_sg_str_t* dst, const char* src) {\r\n    SOKOL_ASSERT(dst);\r\n    if (src) {\r\n        #if defined(_MSC_VER)\r\n        strncpy_s(dst->buf, _SG_STRING_SIZE, src, (_SG_STRING_SIZE-1));\r\n        #else\r\n        strncpy(dst->buf, src, _SG_STRING_SIZE);\r\n        #endif\r\n        dst->buf[_SG_STRING_SIZE-1] = 0;\r\n    }\r\n    else {\r\n        memset(dst->buf, 0, _SG_STRING_SIZE);\r\n    }\r\n}\r\n\r\n/* return byte size of a vertex format */\r\n_SOKOL_PRIVATE int _sg_vertexformat_bytesize(sg_vertex_format fmt) {\r\n    switch (fmt) {\r\n        case SG_VERTEXFORMAT_FLOAT:     return 4;\r\n        case SG_VERTEXFORMAT_FLOAT2:    return 8;\r\n        case SG_VERTEXFORMAT_FLOAT3:    return 12;\r\n        case SG_VERTEXFORMAT_FLOAT4:    return 16;\r\n        case SG_VERTEXFORMAT_BYTE4:     return 4;\r\n        case SG_VERTEXFORMAT_BYTE4N:    return 4;\r\n        case SG_VERTEXFORMAT_UBYTE4:    return 4;\r\n        case SG_VERTEXFORMAT_UBYTE4N:   return 4;\r\n        case SG_VERTEXFORMAT_SHORT2:    return 4;\r\n        case SG_VERTEXFORMAT_SHORT2N:   return 4;\r\n        case SG_VERTEXFORMAT_USHORT2N:  return 4;\r\n        case SG_VERTEXFORMAT_SHORT4:    return 8;\r\n        case SG_VERTEXFORMAT_SHORT4N:   return 8;\r\n        case SG_VERTEXFORMAT_USHORT4N:  return 8;\r\n        case SG_VERTEXFORMAT_UINT10_N2: return 4;\r\n        case SG_VERTEXFORMAT_INVALID:   return 0;\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return -1;\r\n    }\r\n}\r\n\r\n/* return the byte size of a shader uniform */\r\n_SOKOL_PRIVATE int _sg_uniform_size(sg_uniform_type type, int count) {\r\n    switch (type) {\r\n        case SG_UNIFORMTYPE_INVALID:    return 0;\r\n        case SG_UNIFORMTYPE_FLOAT:      return 4 * count;\r\n        case SG_UNIFORMTYPE_FLOAT2:     return 8 * count;\r\n        case SG_UNIFORMTYPE_FLOAT3:     return 12 * count; /* FIXME: std140??? */\r\n        case SG_UNIFORMTYPE_FLOAT4:     return 16 * count;\r\n        case SG_UNIFORMTYPE_MAT4:       return 64 * count;\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return -1;\r\n    }\r\n}\r\n\r\n/* return true if pixel format is a compressed format */\r\n_SOKOL_PRIVATE bool _sg_is_compressed_pixel_format(sg_pixel_format fmt) {\r\n    switch (fmt) {\r\n        case SG_PIXELFORMAT_BC1_RGBA:\r\n        case SG_PIXELFORMAT_BC2_RGBA:\r\n        case SG_PIXELFORMAT_BC3_RGBA:\r\n        case SG_PIXELFORMAT_BC4_R:\r\n        case SG_PIXELFORMAT_BC4_RSN:\r\n        case SG_PIXELFORMAT_BC5_RG:\r\n        case SG_PIXELFORMAT_BC5_RGSN:\r\n        case SG_PIXELFORMAT_BC6H_RGBF:\r\n        case SG_PIXELFORMAT_BC6H_RGBUF:\r\n        case SG_PIXELFORMAT_BC7_RGBA:\r\n        case SG_PIXELFORMAT_PVRTC_RGB_2BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGB_4BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_2BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_4BPP:\r\n        case SG_PIXELFORMAT_ETC2_RGB8:\r\n        case SG_PIXELFORMAT_ETC2_RGB8A1:\r\n        case SG_PIXELFORMAT_ETC2_RGBA8:\r\n        case SG_PIXELFORMAT_ETC2_RG11:\r\n        case SG_PIXELFORMAT_ETC2_RG11SN:\r\n            return true;\r\n        default:\r\n            return false;\r\n    }\r\n}\r\n\r\n/* return true if pixel format is a valid render target format */\r\n_SOKOL_PRIVATE bool _sg_is_valid_rendertarget_color_format(sg_pixel_format fmt) {\r\n    const int fmt_index = (int) fmt;\r\n    SOKOL_ASSERT((fmt_index >= 0) && (fmt_index < _SG_PIXELFORMAT_NUM));\r\n    return _sg.formats[fmt_index].render && !_sg.formats[fmt_index].depth;\r\n}\r\n\r\n/* return true if pixel format is a valid depth format */\r\n_SOKOL_PRIVATE bool _sg_is_valid_rendertarget_depth_format(sg_pixel_format fmt) {\r\n    const int fmt_index = (int) fmt;\r\n    SOKOL_ASSERT((fmt_index >= 0) && (fmt_index < _SG_PIXELFORMAT_NUM));\r\n    return _sg.formats[fmt_index].render && _sg.formats[fmt_index].depth;\r\n}\r\n\r\n/* return true if pixel format is a depth-stencil format */\r\n_SOKOL_PRIVATE bool _sg_is_depth_stencil_format(sg_pixel_format fmt) {\r\n    return (SG_PIXELFORMAT_DEPTH_STENCIL == fmt);\r\n}\r\n\r\n/* return the bytes-per-pixel for a pixel format */\r\n_SOKOL_PRIVATE int _sg_pixelformat_bytesize(sg_pixel_format fmt) {\r\n    switch (fmt) {\r\n        case SG_PIXELFORMAT_R8:\r\n        case SG_PIXELFORMAT_R8SN:\r\n        case SG_PIXELFORMAT_R8UI:\r\n        case SG_PIXELFORMAT_R8SI:\r\n            return 1;\r\n\r\n        case SG_PIXELFORMAT_R16:\r\n        case SG_PIXELFORMAT_R16SN:\r\n        case SG_PIXELFORMAT_R16UI:\r\n        case SG_PIXELFORMAT_R16SI:\r\n        case SG_PIXELFORMAT_R16F:\r\n        case SG_PIXELFORMAT_RG8:\r\n        case SG_PIXELFORMAT_RG8SN:\r\n        case SG_PIXELFORMAT_RG8UI:\r\n        case SG_PIXELFORMAT_RG8SI:\r\n            return 2;\r\n\r\n        case SG_PIXELFORMAT_R32UI:\r\n        case SG_PIXELFORMAT_R32SI:\r\n        case SG_PIXELFORMAT_R32F:\r\n        case SG_PIXELFORMAT_RG16:\r\n        case SG_PIXELFORMAT_RG16SN:\r\n        case SG_PIXELFORMAT_RG16UI:\r\n        case SG_PIXELFORMAT_RG16SI:\r\n        case SG_PIXELFORMAT_RG16F:\r\n        case SG_PIXELFORMAT_RGBA8:\r\n        case SG_PIXELFORMAT_RGBA8SN:\r\n        case SG_PIXELFORMAT_RGBA8UI:\r\n        case SG_PIXELFORMAT_RGBA8SI:\r\n        case SG_PIXELFORMAT_BGRA8:\r\n        case SG_PIXELFORMAT_RGB10A2:\r\n        case SG_PIXELFORMAT_RG11B10F:\r\n            return 4;\r\n\r\n        case SG_PIXELFORMAT_RG32UI:\r\n        case SG_PIXELFORMAT_RG32SI:\r\n        case SG_PIXELFORMAT_RG32F:\r\n        case SG_PIXELFORMAT_RGBA16:\r\n        case SG_PIXELFORMAT_RGBA16SN:\r\n        case SG_PIXELFORMAT_RGBA16UI:\r\n        case SG_PIXELFORMAT_RGBA16SI:\r\n        case SG_PIXELFORMAT_RGBA16F:\r\n            return 8;\r\n\r\n        case SG_PIXELFORMAT_RGBA32UI:\r\n        case SG_PIXELFORMAT_RGBA32SI:\r\n        case SG_PIXELFORMAT_RGBA32F:\r\n            return 16;\r\n\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return 0;\r\n    }\r\n}\r\n\r\n#define _sg_roundup(val, round_to) (((val)+((round_to)-1))&~((round_to)-1))\r\n\r\n/* return row pitch for an image\r\n    see ComputePitch in https://github.com/microsoft/DirectXTex/blob/master/DirectXTex/DirectXTexUtil.cpp\r\n*/\r\n_SOKOL_PRIVATE uint32_t _sg_row_pitch(sg_pixel_format fmt, uint32_t width, uint32_t row_align) {\r\n    uint32_t pitch;\r\n    switch (fmt) {\r\n        case SG_PIXELFORMAT_BC1_RGBA:\r\n        case SG_PIXELFORMAT_BC4_R:\r\n        case SG_PIXELFORMAT_BC4_RSN:\r\n        case SG_PIXELFORMAT_ETC2_RGB8:\r\n        case SG_PIXELFORMAT_ETC2_RGB8A1:\r\n            pitch = ((width + 3) / 4) * 8;\r\n            pitch = pitch < 8 ? 8 : pitch;\r\n            break;\r\n        case SG_PIXELFORMAT_BC2_RGBA:\r\n        case SG_PIXELFORMAT_BC3_RGBA:\r\n        case SG_PIXELFORMAT_BC5_RG:\r\n        case SG_PIXELFORMAT_BC5_RGSN:\r\n        case SG_PIXELFORMAT_BC6H_RGBF:\r\n        case SG_PIXELFORMAT_BC6H_RGBUF:\r\n        case SG_PIXELFORMAT_BC7_RGBA:\r\n        case SG_PIXELFORMAT_ETC2_RGBA8:\r\n        case SG_PIXELFORMAT_ETC2_RG11:\r\n        case SG_PIXELFORMAT_ETC2_RG11SN:\r\n            pitch = ((width + 3) / 4) * 16;\r\n            pitch = pitch < 16 ? 16 : pitch;\r\n            break;\r\n        case SG_PIXELFORMAT_PVRTC_RGB_4BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_4BPP:\r\n            {\r\n                const int block_size = 4*4;\r\n                const int bpp = 4;\r\n                int width_blocks = width / 4;\r\n                width_blocks = width_blocks < 2 ? 2 : width_blocks;\r\n                pitch = width_blocks * ((block_size * bpp) / 8);\r\n            }\r\n            break;\r\n        case SG_PIXELFORMAT_PVRTC_RGB_2BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_2BPP:\r\n            {\r\n                const int block_size = 8*4;\r\n                const int bpp = 2;\r\n                int width_blocks = width / 4;\r\n                width_blocks = width_blocks < 2 ? 2 : width_blocks;\r\n                pitch = width_blocks * ((block_size * bpp) / 8);\r\n            }\r\n            break;\r\n        default:\r\n            pitch = width * _sg_pixelformat_bytesize(fmt);\r\n            break;\r\n    }\r\n    pitch = _sg_roundup(pitch, row_align);\r\n    return pitch;\r\n}\r\n\r\n/* compute the number of rows in a surface depending on pixel format */\r\n_SOKOL_PRIVATE int _sg_num_rows(sg_pixel_format fmt, int height) {\r\n    int num_rows;\r\n    switch (fmt) {\r\n        case SG_PIXELFORMAT_BC1_RGBA:\r\n        case SG_PIXELFORMAT_BC4_R:\r\n        case SG_PIXELFORMAT_BC4_RSN:\r\n        case SG_PIXELFORMAT_ETC2_RGB8:\r\n        case SG_PIXELFORMAT_ETC2_RGB8A1:\r\n        case SG_PIXELFORMAT_ETC2_RGBA8:\r\n        case SG_PIXELFORMAT_ETC2_RG11:\r\n        case SG_PIXELFORMAT_ETC2_RG11SN:\r\n        case SG_PIXELFORMAT_BC2_RGBA:\r\n        case SG_PIXELFORMAT_BC3_RGBA:\r\n        case SG_PIXELFORMAT_BC5_RG:\r\n        case SG_PIXELFORMAT_BC5_RGSN:\r\n        case SG_PIXELFORMAT_BC6H_RGBF:\r\n        case SG_PIXELFORMAT_BC6H_RGBUF:\r\n        case SG_PIXELFORMAT_BC7_RGBA:\r\n        case SG_PIXELFORMAT_PVRTC_RGB_4BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_4BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGB_2BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_2BPP:\r\n            num_rows = ((height + 3) / 4);\r\n            break;\r\n        default:\r\n            num_rows = height;\r\n            break;\r\n    }\r\n    if (num_rows < 1) {\r\n        num_rows = 1;\r\n    }\r\n    return num_rows;\r\n}\r\n\r\n/* return pitch of a 2D subimage / texture slice\r\n    see ComputePitch in https://github.com/microsoft/DirectXTex/blob/master/DirectXTex/DirectXTexUtil.cpp\r\n*/\r\n_SOKOL_PRIVATE uint32_t _sg_surface_pitch(sg_pixel_format fmt, uint32_t width, uint32_t height, uint32_t row_align) {\r\n    int num_rows = _sg_num_rows(fmt, height);\r\n    return num_rows * _sg_row_pitch(fmt, width, row_align);\r\n}\r\n\r\n/* capability table pixel format helper functions */\r\n_SOKOL_PRIVATE void _sg_pixelformat_all(sg_pixelformat_info* pfi) {\r\n    pfi->sample = true;\r\n    pfi->filter = true;\r\n    pfi->blend = true;\r\n    pfi->render = true;\r\n    pfi->msaa = true;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_pixelformat_s(sg_pixelformat_info* pfi) {\r\n    pfi->sample = true;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_pixelformat_sf(sg_pixelformat_info* pfi) {\r\n    pfi->sample = true;\r\n    pfi->filter = true;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_pixelformat_sr(sg_pixelformat_info* pfi) {\r\n    pfi->sample = true;\r\n    pfi->render = true;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_pixelformat_srmd(sg_pixelformat_info* pfi) {\r\n    pfi->sample = true;\r\n    pfi->render = true;\r\n    pfi->msaa = true;\r\n    pfi->depth = true;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_pixelformat_srm(sg_pixelformat_info* pfi) {\r\n    pfi->sample = true;\r\n    pfi->render = true;\r\n    pfi->msaa = true;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_pixelformat_sfrm(sg_pixelformat_info* pfi) {\r\n    pfi->sample = true;\r\n    pfi->filter = true;\r\n    pfi->render = true;\r\n    pfi->msaa = true;\r\n}\r\n_SOKOL_PRIVATE void _sg_pixelformat_sbrm(sg_pixelformat_info* pfi) {\r\n    pfi->sample = true;\r\n    pfi->blend = true;\r\n    pfi->render = true;\r\n    pfi->msaa = true;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_pixelformat_sbr(sg_pixelformat_info* pfi) {\r\n    pfi->sample = true;\r\n    pfi->blend = true;\r\n    pfi->render = true;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_pixelformat_sfbr(sg_pixelformat_info* pfi) {\r\n    pfi->sample = true;\r\n    pfi->filter = true;\r\n    pfi->blend = true;\r\n    pfi->render = true;\r\n}\r\n\r\n/* resolve pass action defaults into a new pass action struct */\r\n_SOKOL_PRIVATE void _sg_resolve_default_pass_action(const sg_pass_action* from, sg_pass_action* to) {\r\n    SOKOL_ASSERT(from && to);\r\n    *to = *from;\r\n    for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n        if (to->colors[i].action  == _SG_ACTION_DEFAULT) {\r\n            to->colors[i].action = SG_ACTION_CLEAR;\r\n            to->colors[i].val[0] = SG_DEFAULT_CLEAR_RED;\r\n            to->colors[i].val[1] = SG_DEFAULT_CLEAR_GREEN;\r\n            to->colors[i].val[2] = SG_DEFAULT_CLEAR_BLUE;\r\n            to->colors[i].val[3] = SG_DEFAULT_CLEAR_ALPHA;\r\n        }\r\n    }\r\n    if (to->depth.action == _SG_ACTION_DEFAULT) {\r\n        to->depth.action = SG_ACTION_CLEAR;\r\n        to->depth.val = SG_DEFAULT_CLEAR_DEPTH;\r\n    }\r\n    if (to->stencil.action == _SG_ACTION_DEFAULT) {\r\n        to->stencil.action = SG_ACTION_CLEAR;\r\n        to->stencil.val = SG_DEFAULT_CLEAR_STENCIL;\r\n    }\r\n}\r\n\r\n/*== DUMMY BACKEND IMPL ======================================================*/\r\n#if defined(SOKOL_DUMMY_BACKEND)\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_setup_backend(const sg_desc* desc) {\r\n    SOKOL_ASSERT(desc);\r\n    _SOKOL_UNUSED(desc);\r\n    _sg.backend = SG_BACKEND_DUMMY;\r\n    for (int i = SG_PIXELFORMAT_R8; i < SG_PIXELFORMAT_BC1_RGBA; i++) {\r\n        _sg.formats[i].sample = true;\r\n        _sg.formats[i].filter = true;\r\n        _sg.formats[i].render = true;\r\n        _sg.formats[i].blend = true;\r\n        _sg.formats[i].msaa = true;\r\n    }\r\n    _sg.formats[SG_PIXELFORMAT_DEPTH].depth = true;\r\n    _sg.formats[SG_PIXELFORMAT_DEPTH_STENCIL].depth = true;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_discard_backend(void) {\r\n    /* empty */\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_reset_state_cache(void) {\r\n    /* empty*/\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    _SOKOL_UNUSED(ctx);\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_destroy_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    _SOKOL_UNUSED(ctx);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_activate_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    _SOKOL_UNUSED(ctx);\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {\r\n    SOKOL_ASSERT(buf && desc);\r\n    _sg_buffer_common_init(&buf->cmn, desc);\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_destroy_buffer(_sg_buffer_t* buf) {\r\n    SOKOL_ASSERT(buf);\r\n    _SOKOL_UNUSED(buf);\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_image(_sg_image_t* img, const sg_image_desc* desc) {\r\n    SOKOL_ASSERT(img && desc);\r\n    _sg_image_common_init(&img->cmn, desc);\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_destroy_image(_sg_image_t* img) {\r\n    SOKOL_ASSERT(img);\r\n    _SOKOL_UNUSED(img);\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {\r\n    SOKOL_ASSERT(shd && desc);\r\n    _sg_shader_common_init(&shd->cmn, desc);\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_destroy_shader(_sg_shader_t* shd) {\r\n    SOKOL_ASSERT(shd);\r\n    _SOKOL_UNUSED(shd);\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {\r\n    SOKOL_ASSERT(pip && desc);\r\n    pip->shader = shd;\r\n    _sg_pipeline_common_init(&pip->cmn, desc);\r\n    for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {\r\n        const sg_vertex_attr_desc* a_desc = &desc->layout.attrs[attr_index];\r\n        if (a_desc->format == SG_VERTEXFORMAT_INVALID) {\r\n            break;\r\n        }\r\n        SOKOL_ASSERT((a_desc->buffer_index >= 0) && (a_desc->buffer_index < SG_MAX_SHADERSTAGE_BUFFERS));\r\n        pip->cmn.vertex_layout_valid[a_desc->buffer_index] = true;\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_destroy_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    _SOKOL_UNUSED(pip);\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_pass(_sg_pass_t* pass, _sg_image_t** att_images, const sg_pass_desc* desc) {\r\n    SOKOL_ASSERT(pass && desc);\r\n    SOKOL_ASSERT(att_images && att_images[0]);\r\n\r\n    _sg_pass_common_init(&pass->cmn, desc);\r\n\r\n    const sg_attachment_desc* att_desc;\r\n    for (int i = 0; i < pass->cmn.num_color_atts; i++) {\r\n        att_desc = &desc->color_attachments[i];\r\n        SOKOL_ASSERT(att_desc->image.id != SG_INVALID_ID);\r\n        SOKOL_ASSERT(0 == pass->dmy.color_atts[i].image);\r\n        SOKOL_ASSERT(att_images[i] && (att_images[i]->slot.id == att_desc->image.id));\r\n        SOKOL_ASSERT(_sg_is_valid_rendertarget_color_format(att_images[i]->cmn.pixel_format));\r\n        pass->dmy.color_atts[i].image = att_images[i];\r\n    }\r\n\r\n    SOKOL_ASSERT(0 == pass->dmy.ds_att.image);\r\n    att_desc = &desc->depth_stencil_attachment;\r\n    if (att_desc->image.id != SG_INVALID_ID) {\r\n        const int ds_img_index = SG_MAX_COLOR_ATTACHMENTS;\r\n        SOKOL_ASSERT(att_images[ds_img_index] && (att_images[ds_img_index]->slot.id == att_desc->image.id));\r\n        SOKOL_ASSERT(_sg_is_valid_rendertarget_depth_format(att_images[ds_img_index]->cmn.pixel_format));\r\n        pass->dmy.ds_att.image = att_images[ds_img_index];\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_destroy_pass(_sg_pass_t* pass) {\r\n    SOKOL_ASSERT(pass);\r\n    _SOKOL_UNUSED(pass);\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_dummy_pass_color_image(const _sg_pass_t* pass, int index) {\r\n    SOKOL_ASSERT(pass && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));\r\n    /* NOTE: may return null */\r\n    return pass->dmy.color_atts[index].image;\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_dummy_pass_ds_image(const _sg_pass_t* pass) {\r\n    /* NOTE: may return null */\r\n    SOKOL_ASSERT(pass);\r\n    return pass->dmy.ds_att.image;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_begin_pass(_sg_pass_t* pass, const sg_pass_action* action, int w, int h) {\r\n    SOKOL_ASSERT(action);\r\n    _SOKOL_UNUSED(pass);\r\n    _SOKOL_UNUSED(action);\r\n    _SOKOL_UNUSED(w);\r\n    _SOKOL_UNUSED(h);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_end_pass(void) {\r\n    /* empty */\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_commit(void) {\r\n    /* empty */\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {\r\n    _SOKOL_UNUSED(x);\r\n    _SOKOL_UNUSED(y);\r\n    _SOKOL_UNUSED(w);\r\n    _SOKOL_UNUSED(h);\r\n    _SOKOL_UNUSED(origin_top_left);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {\r\n    _SOKOL_UNUSED(x);\r\n    _SOKOL_UNUSED(y);\r\n    _SOKOL_UNUSED(w);\r\n    _SOKOL_UNUSED(h);\r\n    _SOKOL_UNUSED(origin_top_left);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_apply_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    _SOKOL_UNUSED(pip);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_apply_bindings(\r\n    _sg_pipeline_t* pip,\r\n    _sg_buffer_t** vbs, const int* vb_offsets, int num_vbs,\r\n    _sg_buffer_t* ib, int ib_offset,\r\n    _sg_image_t** vs_imgs, int num_vs_imgs,\r\n    _sg_image_t** fs_imgs, int num_fs_imgs)\r\n{\r\n    SOKOL_ASSERT(pip);\r\n    SOKOL_ASSERT(vbs && vb_offsets);\r\n    SOKOL_ASSERT(vs_imgs);\r\n    SOKOL_ASSERT(fs_imgs);\r\n    _SOKOL_UNUSED(pip);\r\n    _SOKOL_UNUSED(vbs); _SOKOL_UNUSED(vb_offsets); _SOKOL_UNUSED(num_vbs);\r\n    _SOKOL_UNUSED(ib); _SOKOL_UNUSED(ib_offset);\r\n    _SOKOL_UNUSED(vs_imgs); _SOKOL_UNUSED(num_vs_imgs);\r\n    _SOKOL_UNUSED(fs_imgs); _SOKOL_UNUSED(num_fs_imgs);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_apply_uniforms(sg_shader_stage stage_index, int ub_index, const void* data, int num_bytes) {\r\n    SOKOL_ASSERT(data && (num_bytes > 0));\r\n    SOKOL_ASSERT((stage_index >= 0) && ((int)stage_index < SG_NUM_SHADER_STAGES));\r\n    SOKOL_ASSERT((ub_index >= 0) && (ub_index < SG_MAX_SHADERSTAGE_UBS));\r\n    _SOKOL_UNUSED(stage_index);\r\n    _SOKOL_UNUSED(ub_index);\r\n    _SOKOL_UNUSED(data);\r\n    _SOKOL_UNUSED(num_bytes);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_draw(int base_element, int num_elements, int num_instances) {\r\n    _SOKOL_UNUSED(base_element);\r\n    _SOKOL_UNUSED(num_elements);\r\n    _SOKOL_UNUSED(num_instances);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_update_buffer(_sg_buffer_t* buf, const void* data, uint32_t data_size) {\r\n    SOKOL_ASSERT(buf && data && (data_size > 0));\r\n    _SOKOL_UNUSED(data);\r\n    _SOKOL_UNUSED(data_size);\r\n    if (++buf->cmn.active_slot >= buf->cmn.num_slots) {\r\n        buf->cmn.active_slot = 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE uint32_t _sg_dummy_append_buffer(_sg_buffer_t* buf, const void* data, uint32_t data_size, bool new_frame) {\r\n    SOKOL_ASSERT(buf && data && (data_size > 0));\r\n    _SOKOL_UNUSED(data);\r\n    _SOKOL_UNUSED(data_size);\r\n    if (new_frame) {\r\n        if (++buf->cmn.active_slot >= buf->cmn.num_slots) {\r\n            buf->cmn.active_slot = 0;\r\n        }\r\n    }\r\n    /* NOTE: this is a requirement from WebGPU, but we want identical behaviour across all backend */\r\n    return _sg_roundup(data_size, 4);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_dummy_update_image(_sg_image_t* img, const sg_image_content* data) {\r\n    SOKOL_ASSERT(img && data);\r\n    _SOKOL_UNUSED(data);\r\n    if (++img->cmn.active_slot >= img->cmn.num_slots) {\r\n        img->cmn.active_slot = 0;\r\n    }\r\n}\r\n\r\n/*== GL BACKEND ==============================================================*/\r\n#elif defined(_SOKOL_ANY_GL)\r\n\r\n/*-- type translation --------------------------------------------------------*/\r\n_SOKOL_PRIVATE GLenum _sg_gl_buffer_target(sg_buffer_type t) {\r\n    switch (t) {\r\n        case SG_BUFFERTYPE_VERTEXBUFFER:    return GL_ARRAY_BUFFER;\r\n        case SG_BUFFERTYPE_INDEXBUFFER:     return GL_ELEMENT_ARRAY_BUFFER;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_texture_target(sg_image_type t) {\r\n    switch (t) {\r\n        case SG_IMAGETYPE_2D:   return GL_TEXTURE_2D;\r\n        case SG_IMAGETYPE_CUBE: return GL_TEXTURE_CUBE_MAP;\r\n        #if !defined(SOKOL_GLES2)\r\n        case SG_IMAGETYPE_3D:       return GL_TEXTURE_3D;\r\n        case SG_IMAGETYPE_ARRAY:    return GL_TEXTURE_2D_ARRAY;\r\n        #endif\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_usage(sg_usage u) {\r\n    switch (u) {\r\n        case SG_USAGE_IMMUTABLE:    return GL_STATIC_DRAW;\r\n        case SG_USAGE_DYNAMIC:      return GL_DYNAMIC_DRAW;\r\n        case SG_USAGE_STREAM:       return GL_STREAM_DRAW;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_shader_stage(sg_shader_stage stage) {\r\n    switch (stage) {\r\n        case SG_SHADERSTAGE_VS:     return GL_VERTEX_SHADER;\r\n        case SG_SHADERSTAGE_FS:     return GL_FRAGMENT_SHADER;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLint _sg_gl_vertexformat_size(sg_vertex_format fmt) {\r\n    switch (fmt) {\r\n        case SG_VERTEXFORMAT_FLOAT:     return 1;\r\n        case SG_VERTEXFORMAT_FLOAT2:    return 2;\r\n        case SG_VERTEXFORMAT_FLOAT3:    return 3;\r\n        case SG_VERTEXFORMAT_FLOAT4:    return 4;\r\n        case SG_VERTEXFORMAT_BYTE4:     return 4;\r\n        case SG_VERTEXFORMAT_BYTE4N:    return 4;\r\n        case SG_VERTEXFORMAT_UBYTE4:    return 4;\r\n        case SG_VERTEXFORMAT_UBYTE4N:   return 4;\r\n        case SG_VERTEXFORMAT_SHORT2:    return 2;\r\n        case SG_VERTEXFORMAT_SHORT2N:   return 2;\r\n        case SG_VERTEXFORMAT_USHORT2N:  return 2;\r\n        case SG_VERTEXFORMAT_SHORT4:    return 4;\r\n        case SG_VERTEXFORMAT_SHORT4N:   return 4;\r\n        case SG_VERTEXFORMAT_USHORT4N:  return 4;\r\n        case SG_VERTEXFORMAT_UINT10_N2: return 4;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_vertexformat_type(sg_vertex_format fmt) {\r\n    switch (fmt) {\r\n        case SG_VERTEXFORMAT_FLOAT:\r\n        case SG_VERTEXFORMAT_FLOAT2:\r\n        case SG_VERTEXFORMAT_FLOAT3:\r\n        case SG_VERTEXFORMAT_FLOAT4:\r\n            return GL_FLOAT;\r\n        case SG_VERTEXFORMAT_BYTE4:\r\n        case SG_VERTEXFORMAT_BYTE4N:\r\n            return GL_BYTE;\r\n        case SG_VERTEXFORMAT_UBYTE4:\r\n        case SG_VERTEXFORMAT_UBYTE4N:\r\n            return GL_UNSIGNED_BYTE;\r\n        case SG_VERTEXFORMAT_SHORT2:\r\n        case SG_VERTEXFORMAT_SHORT2N:\r\n        case SG_VERTEXFORMAT_SHORT4:\r\n        case SG_VERTEXFORMAT_SHORT4N:\r\n            return GL_SHORT;\r\n        case SG_VERTEXFORMAT_USHORT2N:\r\n        case SG_VERTEXFORMAT_USHORT4N:\r\n            return GL_UNSIGNED_SHORT;\r\n        case SG_VERTEXFORMAT_UINT10_N2:\r\n            return GL_UNSIGNED_INT_2_10_10_10_REV;\r\n        default:\r\n            SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLboolean _sg_gl_vertexformat_normalized(sg_vertex_format fmt) {\r\n    switch (fmt) {\r\n        case SG_VERTEXFORMAT_BYTE4N:\r\n        case SG_VERTEXFORMAT_UBYTE4N:\r\n        case SG_VERTEXFORMAT_SHORT2N:\r\n        case SG_VERTEXFORMAT_USHORT2N:\r\n        case SG_VERTEXFORMAT_SHORT4N:\r\n        case SG_VERTEXFORMAT_USHORT4N:\r\n        case SG_VERTEXFORMAT_UINT10_N2:\r\n            return GL_TRUE;\r\n        default:\r\n            return GL_FALSE;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_primitive_type(sg_primitive_type t) {\r\n    switch (t) {\r\n        case SG_PRIMITIVETYPE_POINTS:           return GL_POINTS;\r\n        case SG_PRIMITIVETYPE_LINES:            return GL_LINES;\r\n        case SG_PRIMITIVETYPE_LINE_STRIP:       return GL_LINE_STRIP;\r\n        case SG_PRIMITIVETYPE_TRIANGLES:        return GL_TRIANGLES;\r\n        case SG_PRIMITIVETYPE_TRIANGLE_STRIP:   return GL_TRIANGLE_STRIP;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_index_type(sg_index_type t) {\r\n    switch (t) {\r\n        case SG_INDEXTYPE_NONE:     return 0;\r\n        case SG_INDEXTYPE_UINT16:   return GL_UNSIGNED_SHORT;\r\n        case SG_INDEXTYPE_UINT32:   return GL_UNSIGNED_INT;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_compare_func(sg_compare_func cmp) {\r\n    switch (cmp) {\r\n        case SG_COMPAREFUNC_NEVER:          return GL_NEVER;\r\n        case SG_COMPAREFUNC_LESS:           return GL_LESS;\r\n        case SG_COMPAREFUNC_EQUAL:          return GL_EQUAL;\r\n        case SG_COMPAREFUNC_LESS_EQUAL:     return GL_LEQUAL;\r\n        case SG_COMPAREFUNC_GREATER:        return GL_GREATER;\r\n        case SG_COMPAREFUNC_NOT_EQUAL:      return GL_NOTEQUAL;\r\n        case SG_COMPAREFUNC_GREATER_EQUAL:  return GL_GEQUAL;\r\n        case SG_COMPAREFUNC_ALWAYS:         return GL_ALWAYS;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_stencil_op(sg_stencil_op op) {\r\n    switch (op) {\r\n        case SG_STENCILOP_KEEP:         return GL_KEEP;\r\n        case SG_STENCILOP_ZERO:         return GL_ZERO;\r\n        case SG_STENCILOP_REPLACE:      return GL_REPLACE;\r\n        case SG_STENCILOP_INCR_CLAMP:   return GL_INCR;\r\n        case SG_STENCILOP_DECR_CLAMP:   return GL_DECR;\r\n        case SG_STENCILOP_INVERT:       return GL_INVERT;\r\n        case SG_STENCILOP_INCR_WRAP:    return GL_INCR_WRAP;\r\n        case SG_STENCILOP_DECR_WRAP:    return GL_DECR_WRAP;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_blend_factor(sg_blend_factor f) {\r\n    switch (f) {\r\n        case SG_BLENDFACTOR_ZERO:                   return GL_ZERO;\r\n        case SG_BLENDFACTOR_ONE:                    return GL_ONE;\r\n        case SG_BLENDFACTOR_SRC_COLOR:              return GL_SRC_COLOR;\r\n        case SG_BLENDFACTOR_ONE_MINUS_SRC_COLOR:    return GL_ONE_MINUS_SRC_COLOR;\r\n        case SG_BLENDFACTOR_SRC_ALPHA:              return GL_SRC_ALPHA;\r\n        case SG_BLENDFACTOR_ONE_MINUS_SRC_ALPHA:    return GL_ONE_MINUS_SRC_ALPHA;\r\n        case SG_BLENDFACTOR_DST_COLOR:              return GL_DST_COLOR;\r\n        case SG_BLENDFACTOR_ONE_MINUS_DST_COLOR:    return GL_ONE_MINUS_DST_COLOR;\r\n        case SG_BLENDFACTOR_DST_ALPHA:              return GL_DST_ALPHA;\r\n        case SG_BLENDFACTOR_ONE_MINUS_DST_ALPHA:    return GL_ONE_MINUS_DST_ALPHA;\r\n        case SG_BLENDFACTOR_SRC_ALPHA_SATURATED:    return GL_SRC_ALPHA_SATURATE;\r\n        case SG_BLENDFACTOR_BLEND_COLOR:            return GL_CONSTANT_COLOR;\r\n        case SG_BLENDFACTOR_ONE_MINUS_BLEND_COLOR:  return GL_ONE_MINUS_CONSTANT_COLOR;\r\n        case SG_BLENDFACTOR_BLEND_ALPHA:            return GL_CONSTANT_ALPHA;\r\n        case SG_BLENDFACTOR_ONE_MINUS_BLEND_ALPHA:  return GL_ONE_MINUS_CONSTANT_ALPHA;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_blend_op(sg_blend_op op) {\r\n    switch (op) {\r\n        case SG_BLENDOP_ADD:                return GL_FUNC_ADD;\r\n        case SG_BLENDOP_SUBTRACT:           return GL_FUNC_SUBTRACT;\r\n        case SG_BLENDOP_REVERSE_SUBTRACT:   return GL_FUNC_REVERSE_SUBTRACT;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_filter(sg_filter f) {\r\n    switch (f) {\r\n        case SG_FILTER_NEAREST:                 return GL_NEAREST;\r\n        case SG_FILTER_LINEAR:                  return GL_LINEAR;\r\n        case SG_FILTER_NEAREST_MIPMAP_NEAREST:  return GL_NEAREST_MIPMAP_NEAREST;\r\n        case SG_FILTER_NEAREST_MIPMAP_LINEAR:   return GL_NEAREST_MIPMAP_LINEAR;\r\n        case SG_FILTER_LINEAR_MIPMAP_NEAREST:   return GL_LINEAR_MIPMAP_NEAREST;\r\n        case SG_FILTER_LINEAR_MIPMAP_LINEAR:    return GL_LINEAR_MIPMAP_LINEAR;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_wrap(sg_wrap w) {\r\n    switch (w) {\r\n        case SG_WRAP_CLAMP_TO_EDGE:     return GL_CLAMP_TO_EDGE;\r\n        #if defined(SOKOL_GLCORE33)\r\n        case SG_WRAP_CLAMP_TO_BORDER:   return GL_CLAMP_TO_BORDER;\r\n        #else\r\n        case SG_WRAP_CLAMP_TO_BORDER:   return GL_CLAMP_TO_EDGE;\r\n        #endif\r\n        case SG_WRAP_REPEAT:            return GL_REPEAT;\r\n        case SG_WRAP_MIRRORED_REPEAT:   return GL_MIRRORED_REPEAT;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_teximage_type(sg_pixel_format fmt) {\r\n    switch (fmt) {\r\n        case SG_PIXELFORMAT_R8:\r\n        case SG_PIXELFORMAT_R8UI:\r\n        case SG_PIXELFORMAT_RG8:\r\n        case SG_PIXELFORMAT_RG8UI:\r\n        case SG_PIXELFORMAT_RGBA8:\r\n        case SG_PIXELFORMAT_RGBA8UI:\r\n        case SG_PIXELFORMAT_BGRA8:\r\n            return GL_UNSIGNED_BYTE;\r\n        case SG_PIXELFORMAT_R8SN:\r\n        case SG_PIXELFORMAT_R8SI:\r\n        case SG_PIXELFORMAT_RG8SN:\r\n        case SG_PIXELFORMAT_RG8SI:\r\n        case SG_PIXELFORMAT_RGBA8SN:\r\n        case SG_PIXELFORMAT_RGBA8SI:\r\n            return GL_BYTE;\r\n        case SG_PIXELFORMAT_R16:\r\n        case SG_PIXELFORMAT_R16UI:\r\n        case SG_PIXELFORMAT_RG16:\r\n        case SG_PIXELFORMAT_RG16UI:\r\n        case SG_PIXELFORMAT_RGBA16:\r\n        case SG_PIXELFORMAT_RGBA16UI:\r\n            return GL_UNSIGNED_SHORT;\r\n        case SG_PIXELFORMAT_R16SN:\r\n        case SG_PIXELFORMAT_R16SI:\r\n        case SG_PIXELFORMAT_RG16SN:\r\n        case SG_PIXELFORMAT_RG16SI:\r\n        case SG_PIXELFORMAT_RGBA16SN:\r\n        case SG_PIXELFORMAT_RGBA16SI:\r\n            return GL_SHORT;\r\n        case SG_PIXELFORMAT_R16F:\r\n        case SG_PIXELFORMAT_RG16F:\r\n        case SG_PIXELFORMAT_RGBA16F:\r\n            return GL_HALF_FLOAT;\r\n        case SG_PIXELFORMAT_R32UI:\r\n        case SG_PIXELFORMAT_RG32UI:\r\n        case SG_PIXELFORMAT_RGBA32UI:\r\n            return GL_UNSIGNED_INT;\r\n        case SG_PIXELFORMAT_R32SI:\r\n        case SG_PIXELFORMAT_RG32SI:\r\n        case SG_PIXELFORMAT_RGBA32SI:\r\n            return GL_INT;\r\n        case SG_PIXELFORMAT_R32F:\r\n        case SG_PIXELFORMAT_RG32F:\r\n        case SG_PIXELFORMAT_RGBA32F:\r\n            return GL_FLOAT;\r\n        #if !defined(SOKOL_GLES2)\r\n        case SG_PIXELFORMAT_RGB10A2:\r\n            return GL_UNSIGNED_INT_2_10_10_10_REV;\r\n        case SG_PIXELFORMAT_RG11B10F:\r\n            return GL_UNSIGNED_INT_10F_11F_11F_REV;\r\n        #endif\r\n        case SG_PIXELFORMAT_DEPTH:\r\n            return GL_UNSIGNED_SHORT;\r\n        case SG_PIXELFORMAT_DEPTH_STENCIL:\r\n            return GL_UNSIGNED_INT_24_8;\r\n        default:\r\n            SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_teximage_format(sg_pixel_format fmt) {\r\n    switch (fmt) {\r\n        case SG_PIXELFORMAT_R8:\r\n        case SG_PIXELFORMAT_R8SN:\r\n        case SG_PIXELFORMAT_R16:\r\n        case SG_PIXELFORMAT_R16SN:\r\n        case SG_PIXELFORMAT_R16F:\r\n        case SG_PIXELFORMAT_R32F:\r\n            #if defined(SOKOL_GLES2)\r\n                return GL_LUMINANCE;\r\n            #else\r\n            if (_sg.gl.gles2) {\r\n                return GL_LUMINANCE;\r\n            }\r\n            else {\r\n                return GL_RED;\r\n            }\r\n            #endif\r\n        #if !defined(SOKOL_GLES2)\r\n            case SG_PIXELFORMAT_R8UI:\r\n            case SG_PIXELFORMAT_R8SI:\r\n            case SG_PIXELFORMAT_R16UI:\r\n            case SG_PIXELFORMAT_R16SI:\r\n            case SG_PIXELFORMAT_R32UI:\r\n            case SG_PIXELFORMAT_R32SI:\r\n                return GL_RED_INTEGER;\r\n            case SG_PIXELFORMAT_RG8:\r\n            case SG_PIXELFORMAT_RG8SN:\r\n            case SG_PIXELFORMAT_RG16:\r\n            case SG_PIXELFORMAT_RG16SN:\r\n            case SG_PIXELFORMAT_RG16F:\r\n            case SG_PIXELFORMAT_RG32F:\r\n                return GL_RG;\r\n            case SG_PIXELFORMAT_RG8UI:\r\n            case SG_PIXELFORMAT_RG8SI:\r\n            case SG_PIXELFORMAT_RG16UI:\r\n            case SG_PIXELFORMAT_RG16SI:\r\n            case SG_PIXELFORMAT_RG32UI:\r\n            case SG_PIXELFORMAT_RG32SI:\r\n                return GL_RG_INTEGER;\r\n        #endif\r\n        case SG_PIXELFORMAT_RGBA8:\r\n        case SG_PIXELFORMAT_RGBA8SN:\r\n        case SG_PIXELFORMAT_RGBA16:\r\n        case SG_PIXELFORMAT_RGBA16SN:\r\n        case SG_PIXELFORMAT_RGBA16F:\r\n        case SG_PIXELFORMAT_RGBA32F:\r\n        case SG_PIXELFORMAT_RGB10A2:\r\n            return GL_RGBA;\r\n        #if !defined(SOKOL_GLES2)\r\n            case SG_PIXELFORMAT_RGBA8UI:\r\n            case SG_PIXELFORMAT_RGBA8SI:\r\n            case SG_PIXELFORMAT_RGBA16UI:\r\n            case SG_PIXELFORMAT_RGBA16SI:\r\n            case SG_PIXELFORMAT_RGBA32UI:\r\n            case SG_PIXELFORMAT_RGBA32SI:\r\n                return GL_RGBA_INTEGER;\r\n        #endif\r\n        case SG_PIXELFORMAT_RG11B10F:\r\n            return GL_RGB;\r\n        case SG_PIXELFORMAT_DEPTH:\r\n            return GL_DEPTH_COMPONENT;\r\n        case SG_PIXELFORMAT_DEPTH_STENCIL:\r\n            return GL_DEPTH_STENCIL;\r\n        case SG_PIXELFORMAT_BC1_RGBA:\r\n            return GL_COMPRESSED_RGBA_S3TC_DXT1_EXT;\r\n        case SG_PIXELFORMAT_BC2_RGBA:\r\n            return GL_COMPRESSED_RGBA_S3TC_DXT3_EXT;\r\n        case SG_PIXELFORMAT_BC3_RGBA:\r\n            return GL_COMPRESSED_RGBA_S3TC_DXT5_EXT;\r\n        case SG_PIXELFORMAT_BC4_R:\r\n            return GL_COMPRESSED_RED_RGTC1;\r\n        case SG_PIXELFORMAT_BC4_RSN:\r\n            return GL_COMPRESSED_SIGNED_RED_RGTC1;\r\n        case SG_PIXELFORMAT_BC5_RG:\r\n            return GL_COMPRESSED_RED_GREEN_RGTC2;\r\n        case SG_PIXELFORMAT_BC5_RGSN:\r\n            return GL_COMPRESSED_SIGNED_RED_GREEN_RGTC2;\r\n        case SG_PIXELFORMAT_BC6H_RGBF:\r\n            return GL_COMPRESSED_RGB_BPTC_SIGNED_FLOAT_ARB;\r\n        case SG_PIXELFORMAT_BC6H_RGBUF:\r\n            return GL_COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_ARB;\r\n        case SG_PIXELFORMAT_BC7_RGBA:\r\n            return GL_COMPRESSED_RGBA_BPTC_UNORM_ARB;\r\n        case SG_PIXELFORMAT_PVRTC_RGB_2BPP:\r\n            return GL_COMPRESSED_RGB_PVRTC_2BPPV1_IMG;\r\n        case SG_PIXELFORMAT_PVRTC_RGB_4BPP:\r\n            return GL_COMPRESSED_RGB_PVRTC_4BPPV1_IMG;\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_2BPP:\r\n            return GL_COMPRESSED_RGBA_PVRTC_2BPPV1_IMG;\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_4BPP:\r\n            return GL_COMPRESSED_RGBA_PVRTC_4BPPV1_IMG;\r\n        case SG_PIXELFORMAT_ETC2_RGB8:\r\n            return GL_COMPRESSED_RGB8_ETC2;\r\n        case SG_PIXELFORMAT_ETC2_RGB8A1:\r\n            return GL_COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2;\r\n        case SG_PIXELFORMAT_ETC2_RGBA8:\r\n            return GL_COMPRESSED_RGBA8_ETC2_EAC;\r\n        case SG_PIXELFORMAT_ETC2_RG11:\r\n            return GL_COMPRESSED_RG11_EAC;\r\n        case SG_PIXELFORMAT_ETC2_RG11SN:\r\n            return GL_COMPRESSED_SIGNED_RG11_EAC;\r\n        default:\r\n            SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_teximage_internal_format(sg_pixel_format fmt) {\r\n    #if defined(SOKOL_GLES2)\r\n    return _sg_gl_teximage_format(fmt);\r\n    #else\r\n    if (_sg.gl.gles2) {\r\n        return _sg_gl_teximage_format(fmt);\r\n    }\r\n    else {\r\n        switch (fmt) {\r\n            case SG_PIXELFORMAT_R8:         return GL_R8;\r\n            case SG_PIXELFORMAT_R8SN:       return GL_R8_SNORM;\r\n            case SG_PIXELFORMAT_R8UI:       return GL_R8UI;\r\n            case SG_PIXELFORMAT_R8SI:       return GL_R8I;\r\n            #if !defined(SOKOL_GLES3)\r\n                case SG_PIXELFORMAT_R16:        return GL_R16;\r\n                case SG_PIXELFORMAT_R16SN:      return GL_R16_SNORM;\r\n            #endif\r\n            case SG_PIXELFORMAT_R16UI:      return GL_R16UI;\r\n            case SG_PIXELFORMAT_R16SI:      return GL_R16I;\r\n            case SG_PIXELFORMAT_R16F:       return GL_R16F;\r\n            case SG_PIXELFORMAT_RG8:        return GL_RG8;\r\n            case SG_PIXELFORMAT_RG8SN:      return GL_RG8_SNORM;\r\n            case SG_PIXELFORMAT_RG8UI:      return GL_RG8UI;\r\n            case SG_PIXELFORMAT_RG8SI:      return GL_RG8I;\r\n            case SG_PIXELFORMAT_R32UI:      return GL_R32UI;\r\n            case SG_PIXELFORMAT_R32SI:      return GL_R32I;\r\n            case SG_PIXELFORMAT_R32F:       return GL_R32F;\r\n            #if !defined(SOKOL_GLES3)\r\n                case SG_PIXELFORMAT_RG16:       return GL_RG16;\r\n                case SG_PIXELFORMAT_RG16SN:     return GL_RG16_SNORM;\r\n            #endif\r\n            case SG_PIXELFORMAT_RG16UI:     return GL_RG16UI;\r\n            case SG_PIXELFORMAT_RG16SI:     return GL_RG16I;\r\n            case SG_PIXELFORMAT_RG16F:      return GL_RG16F;\r\n            case SG_PIXELFORMAT_RGBA8:      return GL_RGBA8;\r\n            case SG_PIXELFORMAT_RGBA8SN:    return GL_RGBA8_SNORM;\r\n            case SG_PIXELFORMAT_RGBA8UI:    return GL_RGBA8UI;\r\n            case SG_PIXELFORMAT_RGBA8SI:    return GL_RGBA8I;\r\n            case SG_PIXELFORMAT_RGB10A2:    return GL_RGB10_A2;\r\n            case SG_PIXELFORMAT_RG11B10F:   return GL_R11F_G11F_B10F;\r\n            case SG_PIXELFORMAT_RG32UI:     return GL_RG32UI;\r\n            case SG_PIXELFORMAT_RG32SI:     return GL_RG32I;\r\n            case SG_PIXELFORMAT_RG32F:      return GL_RG32F;\r\n            #if !defined(SOKOL_GLES3)\r\n                case SG_PIXELFORMAT_RGBA16:     return GL_RGBA16;\r\n                case SG_PIXELFORMAT_RGBA16SN:   return GL_RGBA16_SNORM;\r\n            #endif\r\n            case SG_PIXELFORMAT_RGBA16UI:   return GL_RGBA16UI;\r\n            case SG_PIXELFORMAT_RGBA16SI:   return GL_RGBA16I;\r\n            case SG_PIXELFORMAT_RGBA16F:    return GL_RGBA16F;\r\n            case SG_PIXELFORMAT_RGBA32UI:   return GL_RGBA32UI;\r\n            case SG_PIXELFORMAT_RGBA32SI:   return GL_RGBA32I;\r\n            case SG_PIXELFORMAT_RGBA32F:    return GL_RGBA32F;\r\n            case SG_PIXELFORMAT_DEPTH:      return GL_DEPTH_COMPONENT16;\r\n            case SG_PIXELFORMAT_DEPTH_STENCIL:      return GL_DEPTH24_STENCIL8;\r\n            case SG_PIXELFORMAT_BC1_RGBA:           return GL_COMPRESSED_RGBA_S3TC_DXT1_EXT;\r\n            case SG_PIXELFORMAT_BC2_RGBA:           return GL_COMPRESSED_RGBA_S3TC_DXT3_EXT;\r\n            case SG_PIXELFORMAT_BC3_RGBA:           return GL_COMPRESSED_RGBA_S3TC_DXT5_EXT;\r\n            case SG_PIXELFORMAT_BC4_R:              return GL_COMPRESSED_RED_RGTC1;\r\n            case SG_PIXELFORMAT_BC4_RSN:            return GL_COMPRESSED_SIGNED_RED_RGTC1;\r\n            case SG_PIXELFORMAT_BC5_RG:             return GL_COMPRESSED_RED_GREEN_RGTC2;\r\n            case SG_PIXELFORMAT_BC5_RGSN:           return GL_COMPRESSED_SIGNED_RED_GREEN_RGTC2;\r\n            case SG_PIXELFORMAT_BC6H_RGBF:          return GL_COMPRESSED_RGB_BPTC_SIGNED_FLOAT_ARB;\r\n            case SG_PIXELFORMAT_BC6H_RGBUF:         return GL_COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_ARB;\r\n            case SG_PIXELFORMAT_BC7_RGBA:           return GL_COMPRESSED_RGBA_BPTC_UNORM_ARB;\r\n            case SG_PIXELFORMAT_PVRTC_RGB_2BPP:     return GL_COMPRESSED_RGB_PVRTC_2BPPV1_IMG;\r\n            case SG_PIXELFORMAT_PVRTC_RGB_4BPP:     return GL_COMPRESSED_RGB_PVRTC_4BPPV1_IMG;\r\n            case SG_PIXELFORMAT_PVRTC_RGBA_2BPP:    return GL_COMPRESSED_RGBA_PVRTC_2BPPV1_IMG;\r\n            case SG_PIXELFORMAT_PVRTC_RGBA_4BPP:    return GL_COMPRESSED_RGBA_PVRTC_4BPPV1_IMG;\r\n            case SG_PIXELFORMAT_ETC2_RGB8:          return GL_COMPRESSED_RGB8_ETC2;\r\n            case SG_PIXELFORMAT_ETC2_RGB8A1:        return GL_COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2;\r\n            case SG_PIXELFORMAT_ETC2_RGBA8:         return GL_COMPRESSED_RGBA8_ETC2_EAC;\r\n            case SG_PIXELFORMAT_ETC2_RG11:          return GL_COMPRESSED_RG11_EAC;\r\n            case SG_PIXELFORMAT_ETC2_RG11SN:        return GL_COMPRESSED_SIGNED_RG11_EAC;\r\n            default: SOKOL_UNREACHABLE; return 0;\r\n        }\r\n    }\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_cubeface_target(int face_index) {\r\n    switch (face_index) {\r\n        case 0: return GL_TEXTURE_CUBE_MAP_POSITIVE_X;\r\n        case 1: return GL_TEXTURE_CUBE_MAP_NEGATIVE_X;\r\n        case 2: return GL_TEXTURE_CUBE_MAP_POSITIVE_Y;\r\n        case 3: return GL_TEXTURE_CUBE_MAP_NEGATIVE_Y;\r\n        case 4: return GL_TEXTURE_CUBE_MAP_POSITIVE_Z;\r\n        case 5: return GL_TEXTURE_CUBE_MAP_NEGATIVE_Z;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE GLenum _sg_gl_depth_attachment_format(sg_pixel_format fmt) {\r\n    switch (fmt) {\r\n        case SG_PIXELFORMAT_DEPTH:          return GL_DEPTH_COMPONENT16;\r\n        case SG_PIXELFORMAT_DEPTH_STENCIL:  return GL_DEPTH24_STENCIL8;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_attr(_sg_gl_attr_t* attr) {\r\n    attr->vb_index = -1;\r\n    attr->divisor = -1;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_stencil_state(sg_stencil_state* s) {\r\n    SOKOL_ASSERT(s);\r\n    s->fail_op = SG_STENCILOP_KEEP;\r\n    s->depth_fail_op = SG_STENCILOP_KEEP;\r\n    s->pass_op = SG_STENCILOP_KEEP;\r\n    s->compare_func = SG_COMPAREFUNC_ALWAYS;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_depth_stencil_state(sg_depth_stencil_state* s) {\r\n    SOKOL_ASSERT(s);\r\n    _sg_gl_init_stencil_state(&s->stencil_front);\r\n    _sg_gl_init_stencil_state(&s->stencil_back);\r\n    s->depth_compare_func = SG_COMPAREFUNC_ALWAYS;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_blend_state(sg_blend_state* s) {\r\n    SOKOL_ASSERT(s);\r\n    s->src_factor_rgb = SG_BLENDFACTOR_ONE;\r\n    s->dst_factor_rgb = SG_BLENDFACTOR_ZERO;\r\n    s->op_rgb = SG_BLENDOP_ADD;\r\n    s->src_factor_alpha = SG_BLENDFACTOR_ONE;\r\n    s->dst_factor_alpha = SG_BLENDFACTOR_ZERO;\r\n    s->op_alpha = SG_BLENDOP_ADD;\r\n    s->color_write_mask = SG_COLORMASK_RGBA;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_rasterizer_state(sg_rasterizer_state* s) {\r\n    SOKOL_ASSERT(s);\r\n    s->cull_mode = SG_CULLMODE_NONE;\r\n    s->face_winding = SG_FACEWINDING_CW;\r\n    s->sample_count = 1;\r\n}\r\n\r\n/* see: https://www.khronos.org/registry/OpenGL-Refpages/es3.0/html/glTexImage2D.xhtml */\r\n_SOKOL_PRIVATE void _sg_gl_init_pixelformats(bool has_bgra) {\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2) {\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R8]);\r\n    }\r\n    else {\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R8]);\r\n    }\r\n    #else\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R8]);\r\n    #endif\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2) {\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R8SN]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R8UI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R8SI]);\r\n        #if !defined(SOKOL_GLES3)\r\n            _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16]);\r\n            _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16SN]);\r\n        #endif\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R16UI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R16SI]);\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG8]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG8SN]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG8UI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG8SI]);\r\n        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32UI]);\r\n        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32SI]);\r\n        #if !defined(SOKOL_GLES3)\r\n            _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16]);\r\n            _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16SN]);\r\n        #endif\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG16UI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG16SI]);\r\n    }\r\n    #endif\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA8]);\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2) {\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGBA8SN]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA8UI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA8SI]);\r\n    }\r\n    #endif\r\n    if (has_bgra) {\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_BGRA8]);\r\n    }\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2) {\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGB10A2]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG11B10F]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG32UI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG32SI]);\r\n        #if !defined(SOKOL_GLES3)\r\n            _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16]);\r\n            _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16SN]);\r\n        #endif\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA16UI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA16SI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);\r\n    }\r\n    #endif\r\n    // FIXME: WEBGL_depth_texture extension?\r\n    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH]);\r\n    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH_STENCIL]);\r\n}\r\n\r\n/* FIXME: OES_half_float_blend */\r\n_SOKOL_PRIVATE void _sg_gl_init_pixelformats_half_float(bool has_colorbuffer_half_float, bool has_texture_half_float_linear) {\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2) {\r\n        if (has_texture_half_float_linear) {\r\n            if (has_colorbuffer_half_float) {\r\n                _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16F]);\r\n                _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16F]);\r\n                _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);\r\n            }\r\n            else {\r\n                _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R16F]);\r\n                _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG16F]);\r\n                _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);\r\n            }\r\n        }\r\n        else {\r\n            if (has_colorbuffer_half_float) {\r\n                _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_R16F]);\r\n                _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_RG16F]);\r\n                _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);\r\n            }\r\n            else {\r\n                _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_R16F]);\r\n                _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_RG16F]);\r\n                _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);\r\n            }\r\n        }\r\n    }\r\n    else {\r\n    #endif\r\n        /* GLES2 can only render to RGBA, and there's no RG format */\r\n        if (has_texture_half_float_linear) {\r\n            if (has_colorbuffer_half_float) {\r\n                _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);\r\n            }\r\n            else {\r\n                _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);\r\n            }\r\n            _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R16F]);\r\n        }\r\n        else {\r\n            if (has_colorbuffer_half_float) {\r\n                _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);\r\n            }\r\n            else {\r\n                _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);\r\n            }\r\n            _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_R16F]);\r\n        }\r\n    #if !defined(SOKOL_GLES2)\r\n    }\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_pixelformats_float(bool has_colorbuffer_float, bool has_texture_float_linear, bool has_float_blend) {\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2) {\r\n        if (has_texture_float_linear) {\r\n            if (has_colorbuffer_float) {\r\n                if (has_float_blend) {\r\n                    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R32F]);\r\n                    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG32F]);\r\n                    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n                }\r\n                else {\r\n                    _sg_pixelformat_sfrm(&_sg.formats[SG_PIXELFORMAT_R32F]);\r\n                    _sg_pixelformat_sfrm(&_sg.formats[SG_PIXELFORMAT_RG32F]);\r\n                    _sg_pixelformat_sfrm(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n                }\r\n            }\r\n            else {\r\n                _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R32F]);\r\n                _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG32F]);\r\n                _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n            }\r\n        }\r\n        else {\r\n            if (has_colorbuffer_float) {\r\n                _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_R32F]);\r\n                _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_RG32F]);\r\n                _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n            }\r\n            else {\r\n                _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_R32F]);\r\n                _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_RG32F]);\r\n                _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n            }\r\n        }\r\n    }\r\n    else {\r\n    #endif\r\n        /* GLES2 can only render to RGBA, and there's no RG format */\r\n        if (has_texture_float_linear) {\r\n            if (has_colorbuffer_float) {\r\n                if (has_float_blend) {\r\n                    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n                }\r\n                else {\r\n                    _sg_pixelformat_sfrm(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n                }\r\n            }\r\n            else {\r\n                _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n            }\r\n            _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R32F]);\r\n        }\r\n        else {\r\n            if (has_colorbuffer_float) {\r\n                _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n            }\r\n            else {\r\n                _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n            }\r\n            _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_R32F]);\r\n        }\r\n    #if !defined(SOKOL_GLES2)\r\n    }\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_pixelformats_s3tc(void) {\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC1_RGBA]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC2_RGBA]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC3_RGBA]);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_pixelformats_rgtc(void) {\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_R]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_RSN]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RG]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RGSN]);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_pixelformats_bptc(void) {\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBF]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBUF]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC7_RGBA]);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_pixelformats_pvrtc(void) {\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_PVRTC_RGB_2BPP]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_PVRTC_RGB_4BPP]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_PVRTC_RGBA_2BPP]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_PVRTC_RGBA_4BPP]);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_pixelformats_etc2(void) {\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGB8]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGB8A1]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGBA8]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RG11]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RG11SN]);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_init_limits(void) {\r\n    _SG_GL_CHECK_ERROR();\r\n    GLint gl_int;\r\n    glGetIntegerv(GL_MAX_TEXTURE_SIZE, &gl_int);\r\n    _SG_GL_CHECK_ERROR();\r\n    _sg.limits.max_image_size_2d = gl_int;\r\n    _sg.limits.max_image_size_array = gl_int;\r\n    glGetIntegerv(GL_MAX_CUBE_MAP_TEXTURE_SIZE, &gl_int);\r\n    _SG_GL_CHECK_ERROR();\r\n    _sg.limits.max_image_size_cube = gl_int;\r\n    glGetIntegerv(GL_MAX_VERTEX_ATTRIBS, &gl_int);\r\n    _SG_GL_CHECK_ERROR();\r\n    if (gl_int > SG_MAX_VERTEX_ATTRIBUTES) {\r\n        gl_int = SG_MAX_VERTEX_ATTRIBUTES;\r\n    }\r\n    _sg.limits.max_vertex_attrs = gl_int;\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2) {\r\n        glGetIntegerv(GL_MAX_3D_TEXTURE_SIZE, &gl_int);\r\n        _SG_GL_CHECK_ERROR();\r\n        _sg.limits.max_image_size_3d = gl_int;\r\n        glGetIntegerv(GL_MAX_ARRAY_TEXTURE_LAYERS, &gl_int);\r\n        _SG_GL_CHECK_ERROR();\r\n        _sg.limits.max_image_array_layers = gl_int;\r\n    }\r\n    #endif\r\n    if (_sg.gl.ext_anisotropic) {\r\n        glGetIntegerv(GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT, &gl_int);\r\n        _SG_GL_CHECK_ERROR();\r\n        _sg.gl.max_anisotropy = gl_int;\r\n    }\r\n    else {\r\n        _sg.gl.max_anisotropy = 1;\r\n    }\r\n    glGetIntegerv(GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS, &gl_int);\r\n    _SG_GL_CHECK_ERROR();\r\n    _sg.gl.max_combined_texture_image_units = gl_int;\r\n}\r\n\r\n#if defined(SOKOL_GLCORE33)\r\n_SOKOL_PRIVATE void _sg_gl_init_caps_glcore33(void) {\r\n    _sg.backend = SG_BACKEND_GLCORE33;\r\n\r\n    _sg.features.origin_top_left = false;\r\n    _sg.features.instancing = true;\r\n    _sg.features.multiple_render_targets = true;\r\n    _sg.features.msaa_render_targets = true;\r\n    _sg.features.imagetype_3d = true;\r\n    _sg.features.imagetype_array = true;\r\n    _sg.features.image_clamp_to_border = true;\r\n\r\n    /* scan extensions */\r\n    bool has_s3tc = false;  /* BC1..BC3 */\r\n    bool has_rgtc = false;  /* BC4 and BC5 */\r\n    bool has_bptc = false;  /* BC6H and BC7 */\r\n    bool has_pvrtc = false;\r\n    bool has_etc2 = false;\r\n    GLint num_ext = 0;\r\n    glGetIntegerv(GL_NUM_EXTENSIONS, &num_ext);\r\n    for (int i = 0; i < num_ext; i++) {\r\n        const char* ext = (const char*) glGetStringi(GL_EXTENSIONS, i);\r\n        if (ext) {\r\n            if (strstr(ext, \"_texture_compression_s3tc\")) {\r\n                has_s3tc = true;\r\n            }\r\n            else if (strstr(ext, \"_texture_compression_rgtc\")) {\r\n                has_rgtc = true;\r\n            }\r\n            else if (strstr(ext, \"_texture_compression_bptc\")) {\r\n                has_bptc = true;\r\n            }\r\n            else if (strstr(ext, \"_texture_compression_pvrtc\")) {\r\n                has_pvrtc = true;\r\n            }\r\n            else if (strstr(ext, \"_ES3_compatibility\")) {\r\n                has_etc2 = true;\r\n            }\r\n            else if (strstr(ext, \"_texture_filter_anisotropic\")) {\r\n                _sg.gl.ext_anisotropic = true;\r\n            }\r\n        }\r\n    }\r\n\r\n    /* limits */\r\n    _sg_gl_init_limits();\r\n\r\n    /* pixel formats */\r\n    const bool has_bgra = false;    /* not a bug */\r\n    const bool has_colorbuffer_float = true;\r\n    const bool has_colorbuffer_half_float = true;\r\n    const bool has_texture_float_linear = true; /* FIXME??? */\r\n    const bool has_texture_half_float_linear = true;\r\n    const bool has_float_blend = true;\r\n    _sg_gl_init_pixelformats(has_bgra);\r\n    _sg_gl_init_pixelformats_float(has_colorbuffer_float, has_texture_float_linear, has_float_blend);\r\n    _sg_gl_init_pixelformats_half_float(has_colorbuffer_half_float, has_texture_half_float_linear);\r\n    if (has_s3tc) {\r\n        _sg_gl_init_pixelformats_s3tc();\r\n    }\r\n    if (has_rgtc) {\r\n        _sg_gl_init_pixelformats_rgtc();\r\n    }\r\n    if (has_bptc) {\r\n        _sg_gl_init_pixelformats_bptc();\r\n    }\r\n    if (has_pvrtc) {\r\n        _sg_gl_init_pixelformats_pvrtc();\r\n    }\r\n    if (has_etc2) {\r\n        _sg_gl_init_pixelformats_etc2();\r\n    }\r\n}\r\n#endif\r\n\r\n#if defined(SOKOL_GLES3)\r\n_SOKOL_PRIVATE void _sg_gl_init_caps_gles3(void) {\r\n    _sg.backend = SG_BACKEND_GLES3;\r\n\r\n    _sg.features.origin_top_left = false;\r\n    _sg.features.instancing = true;\r\n    _sg.features.multiple_render_targets = true;\r\n    _sg.features.msaa_render_targets = true;\r\n    _sg.features.imagetype_3d = true;\r\n    _sg.features.imagetype_array = true;\r\n    _sg.features.image_clamp_to_border = false;\r\n\r\n    bool has_s3tc = false;  /* BC1..BC3 */\r\n    bool has_rgtc = false;  /* BC4 and BC5 */\r\n    bool has_bptc = false;  /* BC6H and BC7 */\r\n    bool has_pvrtc = false;\r\n    #if defined(__EMSCRIPTEN__)\r\n        bool has_etc2 = false;\r\n    #else\r\n        bool has_etc2 = true;\r\n    #endif\r\n    bool has_colorbuffer_float = false;\r\n    bool has_colorbuffer_half_float = false;\r\n    bool has_texture_float_linear = false;\r\n    bool has_float_blend = false;\r\n    GLint num_ext = 0;\r\n    glGetIntegerv(GL_NUM_EXTENSIONS, &num_ext);\r\n    for (int i = 0; i < num_ext; i++) {\r\n        const char* ext = (const char*) glGetStringi(GL_EXTENSIONS, i);\r\n        if (ext) {\r\n            if (strstr(ext, \"_texture_compression_s3tc\")) {\r\n                has_s3tc = true;\r\n            }\r\n            else if (strstr(ext, \"_compressed_texture_s3tc\")) {\r\n                has_s3tc = true;\r\n            }\r\n            else if (strstr(ext, \"_texture_compression_rgtc\")) {\r\n                has_rgtc = true;\r\n            }\r\n            else if (strstr(ext, \"_texture_compression_bptc\")) {\r\n                has_bptc = true;\r\n            }\r\n            else if (strstr(ext, \"_texture_compression_pvrtc\")) {\r\n                has_pvrtc = true;\r\n            }\r\n            else if (strstr(ext, \"_compressed_texture_pvrtc\")) {\r\n                has_pvrtc = true;\r\n            }\r\n            else if (strstr(ext, \"_compressed_texture_etc\")) {\r\n                has_etc2 = true;\r\n            }\r\n            else if (strstr(ext, \"_color_buffer_float\")) {\r\n                has_colorbuffer_float = true;\r\n            }\r\n            else if (strstr(ext, \"_color_buffer_half_float\")) {\r\n                has_colorbuffer_half_float = true;\r\n            }\r\n            else if (strstr(ext, \"_texture_float_linear\")) {\r\n                has_texture_float_linear = true;\r\n            }\r\n            else if (strstr(ext, \"_float_blend\")) {\r\n                has_float_blend = true;\r\n            }\r\n            else if (strstr(ext, \"_texture_filter_anisotropic\")) {\r\n                _sg.gl.ext_anisotropic = true;\r\n            }\r\n        }\r\n    }\r\n\r\n    /* limits */\r\n    _sg_gl_init_limits();\r\n\r\n    /* pixel formats */\r\n    const bool has_texture_half_float_linear = true;\r\n    const bool has_bgra = false;    /* not a bug */\r\n    _sg_gl_init_pixelformats(has_bgra);\r\n    _sg_gl_init_pixelformats_float(has_colorbuffer_float, has_texture_float_linear, has_float_blend);\r\n    _sg_gl_init_pixelformats_half_float(has_colorbuffer_half_float, has_texture_half_float_linear);\r\n    if (has_s3tc) {\r\n        _sg_gl_init_pixelformats_s3tc();\r\n    }\r\n    if (has_rgtc) {\r\n        _sg_gl_init_pixelformats_rgtc();\r\n    }\r\n    if (has_bptc) {\r\n        _sg_gl_init_pixelformats_bptc();\r\n    }\r\n    if (has_pvrtc) {\r\n        _sg_gl_init_pixelformats_pvrtc();\r\n    }\r\n    if (has_etc2) {\r\n        _sg_gl_init_pixelformats_etc2();\r\n    }\r\n}\r\n#endif\r\n\r\n#if defined(SOKOL_GLES3) || defined(SOKOL_GLES2)\r\n_SOKOL_PRIVATE void _sg_gl_init_caps_gles2(void) {\r\n    _sg.backend = SG_BACKEND_GLES2;\r\n\r\n    bool has_s3tc = false;  /* BC1..BC3 */\r\n    bool has_rgtc = false;  /* BC4 and BC5 */\r\n    bool has_bptc = false;  /* BC6H and BC7 */\r\n    bool has_pvrtc = false;\r\n    bool has_etc2 = false;\r\n    bool has_texture_float = false;\r\n    bool has_texture_float_linear = false;\r\n    bool has_colorbuffer_float = false;\r\n    bool has_float_blend = false;\r\n    bool has_instancing = false;\r\n    const char* ext = (const char*) glGetString(GL_EXTENSIONS);\r\n    if (ext) {\r\n        has_s3tc = strstr(ext, \"_texture_compression_s3tc\") || strstr(ext, \"_compressed_texture_s3tc\");\r\n        has_rgtc = strstr(ext, \"_texture_compression_rgtc\");\r\n        has_bptc = strstr(ext, \"_texture_compression_bptc\");\r\n        has_pvrtc = strstr(ext, \"_texture_compression_pvrtc\") || strstr(ext, \"_compressed_texture_pvrtc\");\r\n        has_etc2 = strstr(ext, \"_compressed_texture_etc\");\r\n        has_texture_float = strstr(ext, \"_texture_float\");\r\n        has_texture_float_linear = strstr(ext, \"_texture_float_linear\");\r\n        has_colorbuffer_float = strstr(ext, \"_color_buffer_float\");\r\n        has_float_blend = strstr(ext, \"_float_blend\");\r\n        /* don't bother with half_float support on WebGL1\r\n            has_texture_half_float = strstr(ext, \"_texture_half_float\");\r\n            has_texture_half_float_linear = strstr(ext, \"_texture_half_float_linear\");\r\n            has_colorbuffer_half_float = strstr(ext, \"_color_buffer_half_float\");\r\n        */\r\n        has_instancing = strstr(ext, \"_instanced_arrays\");\r\n        _sg.gl.ext_anisotropic = strstr(ext, \"ext_anisotropic\");\r\n    }\r\n\r\n    _sg.features.origin_top_left = false;\r\n    #if defined(SOKOL_INSTANCING_ENABLED)\r\n        _sg.features.instancing = has_instancing;\r\n    #endif\r\n    _sg.features.multiple_render_targets = false;\r\n    _sg.features.msaa_render_targets = false;\r\n    _sg.features.imagetype_3d = false;\r\n    _sg.features.imagetype_array = false;\r\n    _sg.features.image_clamp_to_border = false;\r\n\r\n    /* limits */\r\n    _sg_gl_init_limits();\r\n\r\n    /* pixel formats */\r\n    const bool has_bgra = false;    /* not a bug */\r\n    const bool has_texture_half_float = false;\r\n    const bool has_texture_half_float_linear = false;\r\n    const bool has_colorbuffer_half_float = false;\r\n    _sg_gl_init_pixelformats(has_bgra);\r\n    if (has_texture_float) {\r\n        _sg_gl_init_pixelformats_float(has_colorbuffer_float, has_texture_float_linear, has_float_blend);\r\n    }\r\n    if (has_texture_half_float) {\r\n        _sg_gl_init_pixelformats_half_float(has_colorbuffer_half_float, has_texture_half_float_linear);\r\n    }\r\n    if (has_s3tc) {\r\n        _sg_gl_init_pixelformats_s3tc();\r\n    }\r\n    if (has_rgtc) {\r\n        _sg_gl_init_pixelformats_rgtc();\r\n    }\r\n    if (has_bptc) {\r\n        _sg_gl_init_pixelformats_bptc();\r\n    }\r\n    if (has_pvrtc) {\r\n        _sg_gl_init_pixelformats_pvrtc();\r\n    }\r\n    if (has_etc2) {\r\n        _sg_gl_init_pixelformats_etc2();\r\n    }\r\n    /* GLES2 doesn't allow multi-sampled render targets at all */\r\n    for (int i = 0; i < _SG_PIXELFORMAT_NUM; i++) {\r\n        _sg.formats[i].msaa = false;\r\n    }\r\n}\r\n#endif\r\n\r\n/*-- state cache implementation ----------------------------------------------*/\r\n_SOKOL_PRIVATE void _sg_gl_cache_clear_buffer_bindings(bool force) {\r\n    if (force || (_sg.gl.cache.vertex_buffer != 0)) {\r\n        glBindBuffer(GL_ARRAY_BUFFER, 0);\r\n        _sg.gl.cache.vertex_buffer = 0;\r\n    }\r\n    if (force || (_sg.gl.cache.index_buffer != 0)) {\r\n        glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0);\r\n        _sg.gl.cache.index_buffer = 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_cache_bind_buffer(GLenum target, GLuint buffer) {\r\n    SOKOL_ASSERT((GL_ARRAY_BUFFER == target) || (GL_ELEMENT_ARRAY_BUFFER == target));\r\n    if (target == GL_ARRAY_BUFFER) {\r\n        if (_sg.gl.cache.vertex_buffer != buffer) {\r\n            _sg.gl.cache.vertex_buffer = buffer;\r\n            glBindBuffer(target, buffer);\r\n        }\r\n    }\r\n    else {\r\n        if (_sg.gl.cache.index_buffer != buffer) {\r\n            _sg.gl.cache.index_buffer = buffer;\r\n            glBindBuffer(target, buffer);\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_cache_store_buffer_binding(GLenum target) {\r\n    if (target == GL_ARRAY_BUFFER) {\r\n        _sg.gl.cache.stored_vertex_buffer = _sg.gl.cache.vertex_buffer;\r\n    }\r\n    else {\r\n        _sg.gl.cache.stored_index_buffer = _sg.gl.cache.index_buffer;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_cache_restore_buffer_binding(GLenum target) {\r\n    if (target == GL_ARRAY_BUFFER) {\r\n        if (_sg.gl.cache.stored_vertex_buffer != 0) {\r\n            /* we only care restoring valid ids */\r\n            _sg_gl_cache_bind_buffer(target, _sg.gl.cache.stored_vertex_buffer);\r\n            _sg.gl.cache.stored_vertex_buffer = 0;\r\n        }\r\n    }\r\n    else {\r\n        if (_sg.gl.cache.stored_index_buffer != 0) {\r\n            /* we only care restoring valid ids */\r\n            _sg_gl_cache_bind_buffer(target, _sg.gl.cache.stored_index_buffer);\r\n            _sg.gl.cache.stored_index_buffer = 0;\r\n        }\r\n    }\r\n}\r\n\r\n/* called when from _sg_gl_destroy_buffer() */\r\n_SOKOL_PRIVATE void _sg_gl_cache_invalidate_buffer(GLuint buf) {\r\n    if (buf == _sg.gl.cache.vertex_buffer) {\r\n        _sg.gl.cache.vertex_buffer = 0;\r\n        glBindBuffer(GL_ARRAY_BUFFER, 0);\r\n    }\r\n    if (buf == _sg.gl.cache.index_buffer) {\r\n        _sg.gl.cache.index_buffer = 0;\r\n        glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0);\r\n    }\r\n    if (buf == _sg.gl.cache.stored_vertex_buffer) {\r\n        _sg.gl.cache.stored_vertex_buffer = 0;\r\n    }\r\n    if (buf == _sg.gl.cache.stored_index_buffer) {\r\n        _sg.gl.cache.stored_index_buffer = 0;\r\n    }\r\n    for (int i = 0; i < SG_MAX_VERTEX_ATTRIBUTES; i++) {\r\n        if (buf == _sg.gl.cache.attrs[i].gl_vbuf) {\r\n            _sg.gl.cache.attrs[i].gl_vbuf = 0;\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_cache_active_texture(GLenum texture) {\r\n    if (_sg.gl.cache.cur_active_texture != texture) {\r\n        _sg.gl.cache.cur_active_texture = texture;\r\n        glActiveTexture(texture);\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_cache_clear_texture_bindings(bool force) {\r\n    for (int i = 0; (i < SG_MAX_SHADERSTAGE_IMAGES) && (i < _sg.gl.max_combined_texture_image_units); i++) {\r\n        if (force || (_sg.gl.cache.textures[i].texture != 0)) {\r\n            GLenum gl_texture_slot = GL_TEXTURE0 + i;\r\n            glActiveTexture(gl_texture_slot);\r\n            glBindTexture(GL_TEXTURE_2D, 0);\r\n            glBindTexture(GL_TEXTURE_CUBE_MAP, 0);\r\n            #if !defined(SOKOL_GLES2)\r\n            if (!_sg.gl.gles2) {\r\n                glBindTexture(GL_TEXTURE_3D, 0);\r\n                glBindTexture(GL_TEXTURE_2D_ARRAY, 0);\r\n            }\r\n            #endif\r\n            _sg.gl.cache.textures[i].target = 0;\r\n            _sg.gl.cache.textures[i].texture = 0;\r\n            _sg.gl.cache.cur_active_texture = gl_texture_slot;\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_cache_bind_texture(int slot_index, GLenum target, GLuint texture) {\r\n    /* it's valid to call this function with target=0 and/or texture=0\r\n       target=0 will unbind the previous binding, texture=0 will clear\r\n       the new binding\r\n    */\r\n    SOKOL_ASSERT(slot_index < SG_MAX_SHADERSTAGE_IMAGES);\r\n    if (slot_index >= _sg.gl.max_combined_texture_image_units) {\r\n        return;\r\n    }\r\n    _sg_gl_texture_bind_slot* slot = &_sg.gl.cache.textures[slot_index];\r\n    if ((slot->target != target) || (slot->texture != texture)) {\r\n        _sg_gl_cache_active_texture(GL_TEXTURE0 + slot_index);\r\n        /* if the target has changed, clear the previous binding on that target */\r\n        if ((target != slot->target) && (slot->target != 0)) {\r\n            glBindTexture(slot->target, 0);\r\n        }\r\n        /* apply new binding (texture can be 0 to unbind) */\r\n        if (target != 0) {\r\n            glBindTexture(target, texture);\r\n        }\r\n        slot->target = target;\r\n        slot->texture = texture;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_cache_store_texture_binding(int slot_index) {\r\n    SOKOL_ASSERT(slot_index < SG_MAX_SHADERSTAGE_IMAGES);\r\n    _sg.gl.cache.stored_texture = _sg.gl.cache.textures[slot_index];\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_cache_restore_texture_binding(int slot_index) {\r\n    SOKOL_ASSERT(slot_index < SG_MAX_SHADERSTAGE_IMAGES);\r\n    _sg_gl_texture_bind_slot* slot = &_sg.gl.cache.stored_texture;\r\n    if (slot->texture != 0) {\r\n        /* we only care restoring valid ids */\r\n        SOKOL_ASSERT(slot->target != 0);\r\n        _sg_gl_cache_bind_texture(slot_index, slot->target, slot->texture);\r\n        slot->target = 0;\r\n        slot->texture = 0;\r\n    }\r\n}\r\n\r\n/* called from _sg_gl_destroy_texture() */\r\n_SOKOL_PRIVATE void _sg_gl_cache_invalidate_texture(GLuint tex) {\r\n    for (int i = 0; i < SG_MAX_SHADERSTAGE_IMAGES; i++) {\r\n        _sg_gl_texture_bind_slot* slot = &_sg.gl.cache.textures[i];\r\n        if (tex == slot->texture) {\r\n            _sg_gl_cache_active_texture(GL_TEXTURE0 + i);\r\n            glBindTexture(slot->target, 0);\r\n            slot->target = 0;\r\n            slot->texture = 0;\r\n        }\r\n    }\r\n    if (tex == _sg.gl.cache.stored_texture.texture) {\r\n        _sg.gl.cache.stored_texture.target = 0;\r\n        _sg.gl.cache.stored_texture.texture = 0;\r\n    }\r\n}\r\n\r\n/* called from _sg_gl_destroy_shader() */\r\n_SOKOL_PRIVATE void _sg_gl_cache_invalidate_program(GLuint prog) {\r\n    if (prog == _sg.gl.cache.prog) {\r\n        _sg.gl.cache.prog = 0;\r\n        glUseProgram(0);\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_reset_state_cache(void) {\r\n    if (_sg.gl.cur_context) {\r\n        _SG_GL_CHECK_ERROR();\r\n        #if !defined(SOKOL_GLES2)\r\n        if (!_sg.gl.gles2) {\r\n            glBindVertexArray(_sg.gl.cur_context->vao);\r\n            _SG_GL_CHECK_ERROR();\r\n        }\r\n        #endif\r\n        memset(&_sg.gl.cache, 0, sizeof(_sg.gl.cache));\r\n        _sg_gl_cache_clear_buffer_bindings(true);\r\n        _SG_GL_CHECK_ERROR();\r\n        _sg_gl_cache_clear_texture_bindings(true);\r\n        _SG_GL_CHECK_ERROR();\r\n        for (uint32_t i = 0; i < _sg.limits.max_vertex_attrs; i++) {\r\n            _sg_gl_init_attr(&_sg.gl.cache.attrs[i].gl_attr);\r\n            glDisableVertexAttribArray(i);\r\n            _SG_GL_CHECK_ERROR();\r\n        }\r\n        _sg.gl.cache.cur_primitive_type = GL_TRIANGLES;\r\n\r\n        /* shader program */\r\n        glGetIntegerv(GL_CURRENT_PROGRAM, (GLint*)&_sg.gl.cache.prog);\r\n        _SG_GL_CHECK_ERROR();\r\n\r\n        /* depth-stencil state */\r\n        _sg_gl_init_depth_stencil_state(&_sg.gl.cache.ds);\r\n        glEnable(GL_DEPTH_TEST);\r\n        glDepthFunc(GL_ALWAYS);\r\n        glDepthMask(GL_FALSE);\r\n        glDisable(GL_STENCIL_TEST);\r\n        glStencilFunc(GL_ALWAYS, 0, 0);\r\n        glStencilOp(GL_KEEP, GL_KEEP, GL_KEEP);\r\n        glStencilMask(0);\r\n\r\n        /* blend state */\r\n        _sg_gl_init_blend_state(&_sg.gl.cache.blend);\r\n        glDisable(GL_BLEND);\r\n        glBlendFuncSeparate(GL_ONE, GL_ZERO, GL_ONE, GL_ZERO);\r\n        glBlendEquationSeparate(GL_FUNC_ADD, GL_FUNC_ADD);\r\n        glColorMask(GL_TRUE, GL_TRUE, GL_TRUE, GL_TRUE);\r\n        glBlendColor(0.0f, 0.0f, 0.0f, 0.0f);\r\n\r\n        /* rasterizer state */\r\n        _sg_gl_init_rasterizer_state(&_sg.gl.cache.rast);\r\n        glPolygonOffset(0.0f, 0.0f);\r\n        glDisable(GL_POLYGON_OFFSET_FILL);\r\n        glDisable(GL_CULL_FACE);\r\n        glFrontFace(GL_CW);\r\n        glCullFace(GL_BACK);\r\n        glEnable(GL_SCISSOR_TEST);\r\n        glDisable(GL_SAMPLE_ALPHA_TO_COVERAGE);\r\n        glEnable(GL_DITHER);\r\n        glDisable(GL_POLYGON_OFFSET_FILL);\r\n        #if defined(SOKOL_GLCORE33)\r\n            glEnable(GL_MULTISAMPLE);\r\n            glEnable(GL_PROGRAM_POINT_SIZE);\r\n        #endif\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_setup_backend(const sg_desc* desc) {\r\n    /* assumes that _sg.gl is already zero-initialized */\r\n    _sg.gl.valid = true;\r\n    #if defined(SOKOL_GLES2) || defined(SOKOL_GLES3)\r\n    _sg.gl.gles2 = desc->context.gl.force_gles2;\r\n    #else\r\n    _SOKOL_UNUSED(desc);\r\n    _sg.gl.gles2 = false;\r\n    #endif\r\n\r\n    /* clear initial GL error state */\r\n    #if defined(SOKOL_DEBUG)\r\n        while (glGetError() != GL_NO_ERROR);\r\n    #endif\r\n    #if defined(SOKOL_GLCORE33)\r\n        _sg_gl_init_caps_glcore33();\r\n    #elif defined(SOKOL_GLES3)\r\n        if (_sg.gl.gles2) {\r\n            _sg_gl_init_caps_gles2();\r\n        }\r\n        else {\r\n            _sg_gl_init_caps_gles3();\r\n        }\r\n    #else\r\n        _sg_gl_init_caps_gles2();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_discard_backend(void) {\r\n    SOKOL_ASSERT(_sg.gl.valid);\r\n    _sg.gl.valid = false;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_activate_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(_sg.gl.valid);\r\n    /* NOTE: ctx can be 0 to unset the current context */\r\n    _sg.gl.cur_context = ctx;\r\n    _sg_gl_reset_state_cache();\r\n}\r\n\r\n/*-- GL backend resource creation and destruction ----------------------------*/\r\n_SOKOL_PRIVATE sg_resource_state _sg_gl_create_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    SOKOL_ASSERT(0 == ctx->default_framebuffer);\r\n    _SG_GL_CHECK_ERROR();\r\n    glGetIntegerv(GL_FRAMEBUFFER_BINDING, (GLint*)&ctx->default_framebuffer);\r\n    _SG_GL_CHECK_ERROR();\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2) {\r\n        SOKOL_ASSERT(0 == ctx->vao);\r\n        glGenVertexArrays(1, &ctx->vao);\r\n        glBindVertexArray(ctx->vao);\r\n        _SG_GL_CHECK_ERROR();\r\n    }\r\n    #endif\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_destroy_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2) {\r\n        if (ctx->vao) {\r\n            glDeleteVertexArrays(1, &ctx->vao);\r\n        }\r\n        _SG_GL_CHECK_ERROR();\r\n    }\r\n    #else\r\n    _SOKOL_UNUSED(ctx);\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_gl_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {\r\n    SOKOL_ASSERT(buf && desc);\r\n    _SG_GL_CHECK_ERROR();\r\n    _sg_buffer_common_init(&buf->cmn, desc);\r\n    buf->gl.ext_buffers = (0 != desc->gl_buffers[0]);\r\n    GLenum gl_target = _sg_gl_buffer_target(buf->cmn.type);\r\n    GLenum gl_usage  = _sg_gl_usage(buf->cmn.usage);\r\n    for (int slot = 0; slot < buf->cmn.num_slots; slot++) {\r\n        GLuint gl_buf = 0;\r\n        if (buf->gl.ext_buffers) {\r\n            SOKOL_ASSERT(desc->gl_buffers[slot]);\r\n            gl_buf = desc->gl_buffers[slot];\r\n        }\r\n        else {\r\n            glGenBuffers(1, &gl_buf);\r\n            _sg_gl_cache_store_buffer_binding(gl_target);\r\n            _sg_gl_cache_bind_buffer(gl_target, gl_buf);\r\n            glBufferData(gl_target, buf->cmn.size, 0, gl_usage);\r\n            if (buf->cmn.usage == SG_USAGE_IMMUTABLE) {\r\n                SOKOL_ASSERT(desc->content);\r\n                glBufferSubData(gl_target, 0, buf->cmn.size, desc->content);\r\n            }\r\n            _sg_gl_cache_restore_buffer_binding(gl_target);\r\n        }\r\n        buf->gl.buf[slot] = gl_buf;\r\n    }\r\n    _SG_GL_CHECK_ERROR();\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_destroy_buffer(_sg_buffer_t* buf) {\r\n    SOKOL_ASSERT(buf);\r\n    _SG_GL_CHECK_ERROR();\r\n    for (int slot = 0; slot < buf->cmn.num_slots; slot++) {\r\n        if (buf->gl.buf[slot]) {\r\n            _sg_gl_cache_invalidate_buffer(buf->gl.buf[slot]);\r\n            if (!buf->gl.ext_buffers) {\r\n                glDeleteBuffers(1, &buf->gl.buf[slot]);\r\n            }\r\n        }\r\n    }\r\n    _SG_GL_CHECK_ERROR();\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_gl_supported_texture_format(sg_pixel_format fmt) {\r\n    const int fmt_index = (int) fmt;\r\n    SOKOL_ASSERT((fmt_index > SG_PIXELFORMAT_NONE) && (fmt_index < _SG_PIXELFORMAT_NUM));\r\n    return _sg.formats[fmt_index].sample;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_gl_create_image(_sg_image_t* img, const sg_image_desc* desc) {\r\n    SOKOL_ASSERT(img && desc);\r\n    _SG_GL_CHECK_ERROR();\r\n    _sg_image_common_init(&img->cmn, desc);\r\n    img->gl.ext_textures = (0 != desc->gl_textures[0]);\r\n\r\n    /* check if texture format is support */\r\n    if (!_sg_gl_supported_texture_format(img->cmn.pixel_format)) {\r\n        SOKOL_LOG(\"texture format not supported by GL context\\n\");\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n    /* check for optional texture types */\r\n    if ((img->cmn.type == SG_IMAGETYPE_3D) && !_sg.features.imagetype_3d) {\r\n        SOKOL_LOG(\"3D textures not supported by GL context\\n\");\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n    if ((img->cmn.type == SG_IMAGETYPE_ARRAY) && !_sg.features.imagetype_array) {\r\n        SOKOL_LOG(\"array textures not supported by GL context\\n\");\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n\r\n    #if !defined(SOKOL_GLES2)\r\n    bool msaa = false;\r\n    if (!_sg.gl.gles2) {\r\n        msaa = (img->cmn.sample_count > 1) && (_sg.features.msaa_render_targets);\r\n    }\r\n    #endif\r\n\r\n    if (_sg_is_valid_rendertarget_depth_format(img->cmn.pixel_format)) {\r\n        /* special case depth-stencil-buffer? */\r\n        SOKOL_ASSERT((img->cmn.usage == SG_USAGE_IMMUTABLE) && (img->cmn.num_slots == 1));\r\n        SOKOL_ASSERT(!img->gl.ext_textures);   /* cannot provide external texture for depth images */\r\n        glGenRenderbuffers(1, &img->gl.depth_render_buffer);\r\n        glBindRenderbuffer(GL_RENDERBUFFER, img->gl.depth_render_buffer);\r\n        GLenum gl_depth_format = _sg_gl_depth_attachment_format(img->cmn.pixel_format);\r\n        #if !defined(SOKOL_GLES2)\r\n        if (!_sg.gl.gles2 && msaa) {\r\n            glRenderbufferStorageMultisample(GL_RENDERBUFFER, img->cmn.sample_count, gl_depth_format, img->cmn.width, img->cmn.height);\r\n        }\r\n        else\r\n        #endif\r\n        {\r\n            glRenderbufferStorage(GL_RENDERBUFFER, gl_depth_format, img->cmn.width, img->cmn.height);\r\n        }\r\n    }\r\n    else {\r\n        /* regular color texture */\r\n        img->gl.target = _sg_gl_texture_target(img->cmn.type);\r\n        const GLenum gl_internal_format = _sg_gl_teximage_internal_format(img->cmn.pixel_format);\r\n\r\n        /* if this is a MSAA render target, need to create a separate render buffer */\r\n        #if !defined(SOKOL_GLES2)\r\n        if (!_sg.gl.gles2 && img->cmn.render_target && msaa) {\r\n            glGenRenderbuffers(1, &img->gl.msaa_render_buffer);\r\n            glBindRenderbuffer(GL_RENDERBUFFER, img->gl.msaa_render_buffer);\r\n            glRenderbufferStorageMultisample(GL_RENDERBUFFER, img->cmn.sample_count, gl_internal_format, img->cmn.width, img->cmn.height);\r\n        }\r\n        #endif\r\n\r\n        if (img->gl.ext_textures) {\r\n            /* inject externally GL textures */\r\n            for (int slot = 0; slot < img->cmn.num_slots; slot++) {\r\n                SOKOL_ASSERT(desc->gl_textures[slot]);\r\n                img->gl.tex[slot] = desc->gl_textures[slot];\r\n            }\r\n        }\r\n        else {\r\n            /* create our own GL texture(s) */\r\n            const GLenum gl_format = _sg_gl_teximage_format(img->cmn.pixel_format);\r\n            const bool is_compressed = _sg_is_compressed_pixel_format(img->cmn.pixel_format);\r\n            for (int slot = 0; slot < img->cmn.num_slots; slot++) {\r\n                glGenTextures(1, &img->gl.tex[slot]);\r\n                _sg_gl_cache_store_texture_binding(0);\r\n                _sg_gl_cache_bind_texture(0, img->gl.target, img->gl.tex[slot]);\r\n                GLenum gl_min_filter = _sg_gl_filter(img->cmn.min_filter);\r\n                GLenum gl_mag_filter = _sg_gl_filter(img->cmn.mag_filter);\r\n                glTexParameteri(img->gl.target, GL_TEXTURE_MIN_FILTER, gl_min_filter);\r\n                glTexParameteri(img->gl.target, GL_TEXTURE_MAG_FILTER, gl_mag_filter);\r\n                if (_sg.gl.ext_anisotropic && (img->cmn.max_anisotropy > 1)) {\r\n                    GLint max_aniso = (GLint) img->cmn.max_anisotropy;\r\n                    if (max_aniso > _sg.gl.max_anisotropy) {\r\n                        max_aniso = _sg.gl.max_anisotropy;\r\n                    }\r\n                    glTexParameteri(img->gl.target, GL_TEXTURE_MAX_ANISOTROPY_EXT, max_aniso);\r\n                }\r\n                if (img->cmn.type == SG_IMAGETYPE_CUBE) {\r\n                    glTexParameteri(img->gl.target, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);\r\n                    glTexParameteri(img->gl.target, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);\r\n                }\r\n                else {\r\n                    glTexParameteri(img->gl.target, GL_TEXTURE_WRAP_S, _sg_gl_wrap(img->cmn.wrap_u));\r\n                    glTexParameteri(img->gl.target, GL_TEXTURE_WRAP_T, _sg_gl_wrap(img->cmn.wrap_v));\r\n                    #if !defined(SOKOL_GLES2)\r\n                    if (!_sg.gl.gles2 && (img->cmn.type == SG_IMAGETYPE_3D)) {\r\n                        glTexParameteri(img->gl.target, GL_TEXTURE_WRAP_R, _sg_gl_wrap(img->cmn.wrap_w));\r\n                    }\r\n                    #endif\r\n                    #if defined(SOKOL_GLCORE33)\r\n                    float border[4];\r\n                    switch (img->cmn.border_color) {\r\n                        case SG_BORDERCOLOR_TRANSPARENT_BLACK:\r\n                            border[0] = 0.0f; border[1] = 0.0f; border[2] = 0.0f; border[3] = 0.0f;\r\n                            break;\r\n                        case SG_BORDERCOLOR_OPAQUE_WHITE:\r\n                            border[0] = 1.0f; border[1] = 1.0f; border[2] = 1.0f; border[3] = 1.0f;\r\n                            break;\r\n                        default:\r\n                            border[0] = 0.0f; border[1] = 0.0f; border[2] = 0.0f; border[3] = 1.0f;\r\n                            break;\r\n                    }\r\n                    glTexParameterfv(img->gl.target, GL_TEXTURE_BORDER_COLOR, border);\r\n                    #endif\r\n                }\r\n                #if !defined(SOKOL_GLES2)\r\n                if (!_sg.gl.gles2) {\r\n                    /* GL spec has strange defaults for mipmap min/max lod: -1000 to +1000 */\r\n                    const float min_lod = _sg_clamp(desc->min_lod, 0.0f, 1000.0f);\r\n                    const float max_lod = _sg_clamp(desc->max_lod, 0.0f, 1000.0f);\r\n                    glTexParameterf(img->gl.target, GL_TEXTURE_MIN_LOD, min_lod);\r\n                    glTexParameterf(img->gl.target, GL_TEXTURE_MAX_LOD, max_lod);\r\n                }\r\n                #endif\r\n                const int num_faces = img->cmn.type == SG_IMAGETYPE_CUBE ? 6 : 1;\r\n                int data_index = 0;\r\n                for (int face_index = 0; face_index < num_faces; face_index++) {\r\n                    for (int mip_index = 0; mip_index < img->cmn.num_mipmaps; mip_index++, data_index++) {\r\n                        GLenum gl_img_target = img->gl.target;\r\n                        if (SG_IMAGETYPE_CUBE == img->cmn.type) {\r\n                            gl_img_target = _sg_gl_cubeface_target(face_index);\r\n                        }\r\n                        const GLvoid* data_ptr = desc->content.subimage[face_index][mip_index].ptr;\r\n                        const int data_size = desc->content.subimage[face_index][mip_index].size;\r\n                        int mip_width = img->cmn.width >> mip_index;\r\n                        if (mip_width == 0) {\r\n                            mip_width = 1;\r\n                        }\r\n                        int mip_height = img->cmn.height >> mip_index;\r\n                        if (mip_height == 0) {\r\n                            mip_height = 1;\r\n                        }\r\n                        if ((SG_IMAGETYPE_2D == img->cmn.type) || (SG_IMAGETYPE_CUBE == img->cmn.type)) {\r\n                            if (is_compressed) {\r\n                                glCompressedTexImage2D(gl_img_target, mip_index, gl_internal_format,\r\n                                    mip_width, mip_height, 0, data_size, data_ptr);\r\n                            }\r\n                            else {\r\n                                const GLenum gl_type = _sg_gl_teximage_type(img->cmn.pixel_format);\r\n                                glTexImage2D(gl_img_target, mip_index, gl_internal_format,\r\n                                    mip_width, mip_height, 0, gl_format, gl_type, data_ptr);\r\n                            }\r\n                        }\r\n                        #if !defined(SOKOL_GLES2)\r\n                        else if (!_sg.gl.gles2 && ((SG_IMAGETYPE_3D == img->cmn.type) || (SG_IMAGETYPE_ARRAY == img->cmn.type))) {\r\n                            int mip_depth = img->cmn.depth;\r\n                            if (SG_IMAGETYPE_3D == img->cmn.type) {\r\n                                mip_depth >>= mip_index;\r\n                            }\r\n                            if (mip_depth == 0) {\r\n                                mip_depth = 1;\r\n                            }\r\n                            if (is_compressed) {\r\n                                glCompressedTexImage3D(gl_img_target, mip_index, gl_internal_format,\r\n                                    mip_width, mip_height, mip_depth, 0, data_size, data_ptr);\r\n                            }\r\n                            else {\r\n                                const GLenum gl_type = _sg_gl_teximage_type(img->cmn.pixel_format);\r\n                                glTexImage3D(gl_img_target, mip_index, gl_internal_format,\r\n                                    mip_width, mip_height, mip_depth, 0, gl_format, gl_type, data_ptr);\r\n                            }\r\n                        }\r\n                        #endif\r\n                    }\r\n                }\r\n                _sg_gl_cache_restore_texture_binding(0);\r\n            }\r\n        }\r\n    }\r\n    _SG_GL_CHECK_ERROR();\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_destroy_image(_sg_image_t* img) {\r\n    SOKOL_ASSERT(img);\r\n    _SG_GL_CHECK_ERROR();\r\n    for (int slot = 0; slot < img->cmn.num_slots; slot++) {\r\n        if (img->gl.tex[slot]) {\r\n            _sg_gl_cache_invalidate_texture(img->gl.tex[slot]);\r\n            if (!img->gl.ext_textures) {\r\n                glDeleteTextures(1, &img->gl.tex[slot]);\r\n            }\r\n        }\r\n    }\r\n    if (img->gl.depth_render_buffer) {\r\n        glDeleteRenderbuffers(1, &img->gl.depth_render_buffer);\r\n    }\r\n    if (img->gl.msaa_render_buffer) {\r\n        glDeleteRenderbuffers(1, &img->gl.msaa_render_buffer);\r\n    }\r\n    _SG_GL_CHECK_ERROR();\r\n}\r\n\r\n_SOKOL_PRIVATE GLuint _sg_gl_compile_shader(sg_shader_stage stage, const char* src) {\r\n    SOKOL_ASSERT(src);\r\n    _SG_GL_CHECK_ERROR();\r\n    GLuint gl_shd = glCreateShader(_sg_gl_shader_stage(stage));\r\n    glShaderSource(gl_shd, 1, &src, 0);\r\n    glCompileShader(gl_shd);\r\n    GLint compile_status = 0;\r\n    glGetShaderiv(gl_shd, GL_COMPILE_STATUS, &compile_status);\r\n    if (!compile_status) {\r\n        /* compilation failed, log error and delete shader */\r\n        GLint log_len = 0;\r\n        glGetShaderiv(gl_shd, GL_INFO_LOG_LENGTH, &log_len);\r\n        if (log_len > 0) {\r\n            GLchar* log_buf = (GLchar*) SOKOL_MALLOC(log_len);\r\n            glGetShaderInfoLog(gl_shd, log_len, &log_len, log_buf);\r\n            SOKOL_LOG(log_buf);\r\n            SOKOL_FREE(log_buf);\r\n        }\r\n        glDeleteShader(gl_shd);\r\n        gl_shd = 0;\r\n    }\r\n    _SG_GL_CHECK_ERROR();\r\n    return gl_shd;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_gl_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {\r\n    SOKOL_ASSERT(shd && desc);\r\n    SOKOL_ASSERT(!shd->gl.prog);\r\n    _SG_GL_CHECK_ERROR();\r\n\r\n    _sg_shader_common_init(&shd->cmn, desc);\r\n\r\n    /* copy vertex attribute names over, these are required for GLES2, and optional for GLES3 and GL3.x */\r\n    for (int i = 0; i < SG_MAX_VERTEX_ATTRIBUTES; i++) {\r\n        _sg_strcpy(&shd->gl.attrs[i].name, desc->attrs[i].name);\r\n    }\r\n\r\n    GLuint gl_vs = _sg_gl_compile_shader(SG_SHADERSTAGE_VS, desc->vs.source);\r\n    GLuint gl_fs = _sg_gl_compile_shader(SG_SHADERSTAGE_FS, desc->fs.source);\r\n    if (!(gl_vs && gl_fs)) {\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n    GLuint gl_prog = glCreateProgram();\r\n    glAttachShader(gl_prog, gl_vs);\r\n    glAttachShader(gl_prog, gl_fs);\r\n    glLinkProgram(gl_prog);\r\n    glDeleteShader(gl_vs);\r\n    glDeleteShader(gl_fs);\r\n    _SG_GL_CHECK_ERROR();\r\n\r\n    GLint link_status;\r\n    glGetProgramiv(gl_prog, GL_LINK_STATUS, &link_status);\r\n    if (!link_status) {\r\n        GLint log_len = 0;\r\n        glGetProgramiv(gl_prog, GL_INFO_LOG_LENGTH, &log_len);\r\n        if (log_len > 0) {\r\n            GLchar* log_buf = (GLchar*) SOKOL_MALLOC(log_len);\r\n            glGetProgramInfoLog(gl_prog, log_len, &log_len, log_buf);\r\n            SOKOL_LOG(log_buf);\r\n            SOKOL_FREE(log_buf);\r\n        }\r\n        glDeleteProgram(gl_prog);\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n    shd->gl.prog = gl_prog;\r\n\r\n    /* resolve uniforms */\r\n    _SG_GL_CHECK_ERROR();\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        const sg_shader_stage_desc* stage_desc = (stage_index == SG_SHADERSTAGE_VS)? &desc->vs : &desc->fs;\r\n        _sg_gl_shader_stage_t* gl_stage = &shd->gl.stage[stage_index];\r\n        for (int ub_index = 0; ub_index < shd->cmn.stage[stage_index].num_uniform_blocks; ub_index++) {\r\n            const sg_shader_uniform_block_desc* ub_desc = &stage_desc->uniform_blocks[ub_index];\r\n            SOKOL_ASSERT(ub_desc->size > 0);\r\n            _sg_gl_uniform_block_t* ub = &gl_stage->uniform_blocks[ub_index];\r\n            SOKOL_ASSERT(ub->num_uniforms == 0);\r\n            int cur_uniform_offset = 0;\r\n            for (int u_index = 0; u_index < SG_MAX_UB_MEMBERS; u_index++) {\r\n                const sg_shader_uniform_desc* u_desc = &ub_desc->uniforms[u_index];\r\n                if (u_desc->type == SG_UNIFORMTYPE_INVALID) {\r\n                    break;\r\n                }\r\n                _sg_gl_uniform_t* u = &ub->uniforms[u_index];\r\n                u->type = u_desc->type;\r\n                u->count = (uint8_t) u_desc->array_count;\r\n                u->offset = (uint16_t) cur_uniform_offset;\r\n                cur_uniform_offset += _sg_uniform_size(u->type, u->count);\r\n                if (u_desc->name) {\r\n                    u->gl_loc = glGetUniformLocation(gl_prog, u_desc->name);\r\n                }\r\n                else {\r\n                    u->gl_loc = u_index;\r\n                }\r\n                ub->num_uniforms++;\r\n            }\r\n            SOKOL_ASSERT(ub_desc->size == cur_uniform_offset);\r\n        }\r\n    }\r\n\r\n    /* resolve image locations */\r\n    _SG_GL_CHECK_ERROR();\r\n    GLuint cur_prog = 0;\r\n    glGetIntegerv(GL_CURRENT_PROGRAM, (GLint*)&cur_prog);\r\n    glUseProgram(gl_prog);\r\n    int gl_tex_slot = 0;\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        const sg_shader_stage_desc* stage_desc = (stage_index == SG_SHADERSTAGE_VS)? &desc->vs : &desc->fs;\r\n        _sg_gl_shader_stage_t* gl_stage = &shd->gl.stage[stage_index];\r\n        for (int img_index = 0; img_index < shd->cmn.stage[stage_index].num_images; img_index++) {\r\n            const sg_shader_image_desc* img_desc = &stage_desc->images[img_index];\r\n            SOKOL_ASSERT(img_desc->type != _SG_IMAGETYPE_DEFAULT);\r\n            _sg_gl_shader_image_t* gl_img = &gl_stage->images[img_index];\r\n            GLint gl_loc = img_index;\r\n            if (img_desc->name) {\r\n                gl_loc = glGetUniformLocation(gl_prog, img_desc->name);\r\n            }\r\n            if (gl_loc != -1) {\r\n                gl_img->gl_tex_slot = gl_tex_slot++;\r\n                glUniform1i(gl_loc, gl_img->gl_tex_slot);\r\n            }\r\n            else {\r\n                gl_img->gl_tex_slot = -1;\r\n            }\r\n        }\r\n    }\r\n    /* it's legal to call glUseProgram with 0 */\r\n    glUseProgram(cur_prog);\r\n    _SG_GL_CHECK_ERROR();\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_destroy_shader(_sg_shader_t* shd) {\r\n    SOKOL_ASSERT(shd);\r\n    _SG_GL_CHECK_ERROR();\r\n    if (shd->gl.prog) {\r\n        _sg_gl_cache_invalidate_program(shd->gl.prog);\r\n        glDeleteProgram(shd->gl.prog);\r\n    }\r\n    _SG_GL_CHECK_ERROR();\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_gl_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {\r\n    SOKOL_ASSERT(pip && shd && desc);\r\n    SOKOL_ASSERT(!pip->shader && pip->cmn.shader_id.id == SG_INVALID_ID);\r\n    SOKOL_ASSERT(desc->shader.id == shd->slot.id);\r\n    SOKOL_ASSERT(shd->gl.prog);\r\n    pip->shader = shd;\r\n    _sg_pipeline_common_init(&pip->cmn, desc);\r\n    pip->gl.primitive_type = desc->primitive_type;\r\n    pip->gl.depth_stencil = desc->depth_stencil;\r\n    pip->gl.blend = desc->blend;\r\n    pip->gl.rast = desc->rasterizer;\r\n\r\n    /* resolve vertex attributes */\r\n    for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {\r\n        pip->gl.attrs[attr_index].vb_index = -1;\r\n    }\r\n    for (uint32_t attr_index = 0; attr_index < _sg.limits.max_vertex_attrs; attr_index++) {\r\n        const sg_vertex_attr_desc* a_desc = &desc->layout.attrs[attr_index];\r\n        if (a_desc->format == SG_VERTEXFORMAT_INVALID) {\r\n            break;\r\n        }\r\n        SOKOL_ASSERT((a_desc->buffer_index >= 0) && (a_desc->buffer_index < SG_MAX_SHADERSTAGE_BUFFERS));\r\n        const sg_buffer_layout_desc* l_desc = &desc->layout.buffers[a_desc->buffer_index];\r\n        const sg_vertex_step step_func = l_desc->step_func;\r\n        const int step_rate = l_desc->step_rate;\r\n        GLint attr_loc = attr_index;\r\n        if (!_sg_strempty(&shd->gl.attrs[attr_index].name)) {\r\n            attr_loc = glGetAttribLocation(pip->shader->gl.prog, _sg_strptr(&shd->gl.attrs[attr_index].name));\r\n        }\r\n        SOKOL_ASSERT(attr_loc < (GLint)_sg.limits.max_vertex_attrs);\r\n        if (attr_loc != -1) {\r\n            _sg_gl_attr_t* gl_attr = &pip->gl.attrs[attr_loc];\r\n            SOKOL_ASSERT(gl_attr->vb_index == -1);\r\n            gl_attr->vb_index = (int8_t) a_desc->buffer_index;\r\n            if (step_func == SG_VERTEXSTEP_PER_VERTEX) {\r\n                gl_attr->divisor = 0;\r\n            }\r\n            else {\r\n                gl_attr->divisor = (int8_t) step_rate;\r\n            }\r\n            SOKOL_ASSERT(l_desc->stride > 0);\r\n            gl_attr->stride = (uint8_t) l_desc->stride;\r\n            gl_attr->offset = a_desc->offset;\r\n            gl_attr->size = (uint8_t) _sg_gl_vertexformat_size(a_desc->format);\r\n            gl_attr->type = _sg_gl_vertexformat_type(a_desc->format);\r\n            gl_attr->normalized = _sg_gl_vertexformat_normalized(a_desc->format);\r\n            pip->cmn.vertex_layout_valid[a_desc->buffer_index] = true;\r\n        }\r\n        else {\r\n            SOKOL_LOG(\"Vertex attribute not found in shader: \");\r\n            SOKOL_LOG(_sg_strptr(&shd->gl.attrs[attr_index].name));\r\n        }\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_destroy_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    _SOKOL_UNUSED(pip);\r\n    /* empty */\r\n}\r\n\r\n/*\r\n    _sg_create_pass\r\n\r\n    att_imgs must point to a _sg_image* att_imgs[SG_MAX_COLOR_ATTACHMENTS+1] array,\r\n    first entries are the color attachment images (or nullptr), last entry\r\n    is the depth-stencil image (or nullptr).\r\n*/\r\n_SOKOL_PRIVATE sg_resource_state _sg_gl_create_pass(_sg_pass_t* pass, _sg_image_t** att_images, const sg_pass_desc* desc) {\r\n    SOKOL_ASSERT(pass && att_images && desc);\r\n    SOKOL_ASSERT(att_images && att_images[0]);\r\n    _SG_GL_CHECK_ERROR();\r\n\r\n    _sg_pass_common_init(&pass->cmn, desc);\r\n\r\n    /* copy image pointers */\r\n    const sg_attachment_desc* att_desc;\r\n    for (int i = 0; i < pass->cmn.num_color_atts; i++) {\r\n        att_desc = &desc->color_attachments[i];\r\n        SOKOL_ASSERT(att_desc->image.id != SG_INVALID_ID);\r\n        SOKOL_ASSERT(0 == pass->gl.color_atts[i].image);\r\n        SOKOL_ASSERT(att_images[i] && (att_images[i]->slot.id == att_desc->image.id));\r\n        SOKOL_ASSERT(_sg_is_valid_rendertarget_color_format(att_images[i]->cmn.pixel_format));\r\n        pass->gl.color_atts[i].image = att_images[i];\r\n    }\r\n    SOKOL_ASSERT(0 == pass->gl.ds_att.image);\r\n    att_desc = &desc->depth_stencil_attachment;\r\n    if (att_desc->image.id != SG_INVALID_ID) {\r\n        const int ds_img_index = SG_MAX_COLOR_ATTACHMENTS;\r\n        SOKOL_ASSERT(att_images[ds_img_index] && (att_images[ds_img_index]->slot.id == att_desc->image.id));\r\n        SOKOL_ASSERT(_sg_is_valid_rendertarget_depth_format(att_images[ds_img_index]->cmn.pixel_format));\r\n        pass->gl.ds_att.image = att_images[ds_img_index];\r\n    }\r\n\r\n    /* store current framebuffer binding (restored at end of function) */\r\n    GLuint gl_orig_fb;\r\n    glGetIntegerv(GL_FRAMEBUFFER_BINDING, (GLint*)&gl_orig_fb);\r\n\r\n    /* create a framebuffer object */\r\n    glGenFramebuffers(1, &pass->gl.fb);\r\n    glBindFramebuffer(GL_FRAMEBUFFER, pass->gl.fb);\r\n\r\n    /* attach msaa render buffer or textures */\r\n    const bool is_msaa = (0 != att_images[0]->gl.msaa_render_buffer);\r\n    if (is_msaa) {\r\n        for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n            const _sg_image_t* att_img = pass->gl.color_atts[i].image;\r\n            if (att_img) {\r\n                const GLuint gl_render_buffer = att_img->gl.msaa_render_buffer;\r\n                SOKOL_ASSERT(gl_render_buffer);\r\n                glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0+i, GL_RENDERBUFFER, gl_render_buffer);\r\n            }\r\n        }\r\n    }\r\n    else {\r\n        for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n            const _sg_image_t* att_img = pass->gl.color_atts[i].image;\r\n            const int mip_level = pass->cmn.color_atts[i].mip_level;\r\n            const int slice = pass->cmn.color_atts[i].slice;\r\n            if (att_img) {\r\n                const GLuint gl_tex = att_img->gl.tex[0];\r\n                SOKOL_ASSERT(gl_tex);\r\n                const GLenum gl_att = GL_COLOR_ATTACHMENT0 + i;\r\n                switch (att_img->cmn.type) {\r\n                    case SG_IMAGETYPE_2D:\r\n                        glFramebufferTexture2D(GL_FRAMEBUFFER, gl_att, GL_TEXTURE_2D, gl_tex, mip_level);\r\n                        break;\r\n                    case SG_IMAGETYPE_CUBE:\r\n                        glFramebufferTexture2D(GL_FRAMEBUFFER, gl_att, _sg_gl_cubeface_target(slice), gl_tex, mip_level);\r\n                        break;\r\n                    default:\r\n                        /* 3D- or array-texture */\r\n                        #if !defined(SOKOL_GLES2)\r\n                        if (!_sg.gl.gles2) {\r\n                            glFramebufferTextureLayer(GL_FRAMEBUFFER, gl_att, gl_tex, mip_level, slice);\r\n                        }\r\n                        #endif\r\n                        break;\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    /* attach depth-stencil buffer to framebuffer */\r\n    if (pass->gl.ds_att.image) {\r\n        const GLuint gl_render_buffer = pass->gl.ds_att.image->gl.depth_render_buffer;\r\n        SOKOL_ASSERT(gl_render_buffer);\r\n        glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, gl_render_buffer);\r\n        if (_sg_is_depth_stencil_format(pass->gl.ds_att.image->cmn.pixel_format)) {\r\n            glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_STENCIL_ATTACHMENT, GL_RENDERBUFFER, gl_render_buffer);\r\n        }\r\n    }\r\n\r\n    /* check if framebuffer is complete */\r\n    if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) {\r\n        SOKOL_LOG(\"Framebuffer completeness check failed!\\n\");\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n\r\n    /* setup color attachments for the framebuffer */\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2) {\r\n        GLenum att[SG_MAX_COLOR_ATTACHMENTS] = {\r\n            GL_COLOR_ATTACHMENT0,\r\n            GL_COLOR_ATTACHMENT1,\r\n            GL_COLOR_ATTACHMENT2,\r\n            GL_COLOR_ATTACHMENT3\r\n        };\r\n        glDrawBuffers(pass->cmn.num_color_atts, att);\r\n    }\r\n    #endif\r\n\r\n    /* create MSAA resolve framebuffers if necessary */\r\n    if (is_msaa) {\r\n        for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n            _sg_gl_attachment_t* gl_att = &pass->gl.color_atts[i];\r\n            _sg_attachment_t* cmn_att = &pass->cmn.color_atts[i];\r\n            if (gl_att->image) {\r\n                SOKOL_ASSERT(0 == gl_att->gl_msaa_resolve_buffer);\r\n                glGenFramebuffers(1, &gl_att->gl_msaa_resolve_buffer);\r\n                glBindFramebuffer(GL_FRAMEBUFFER, gl_att->gl_msaa_resolve_buffer);\r\n                const GLuint gl_tex = gl_att->image->gl.tex[0];\r\n                SOKOL_ASSERT(gl_tex);\r\n                switch (gl_att->image->cmn.type) {\r\n                    case SG_IMAGETYPE_2D:\r\n                        glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,\r\n                            GL_TEXTURE_2D, gl_tex, cmn_att->mip_level);\r\n                        break;\r\n                    case SG_IMAGETYPE_CUBE:\r\n                        glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,\r\n                            _sg_gl_cubeface_target(cmn_att->slice), gl_tex, cmn_att->mip_level);\r\n                        break;\r\n                    default:\r\n                        #if !defined(SOKOL_GLES2)\r\n                        if (!_sg.gl.gles2) {\r\n                            glFramebufferTextureLayer(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, gl_tex, cmn_att->mip_level, cmn_att->slice);\r\n                        }\r\n                        #endif\r\n                        break;\r\n                }\r\n                /* check if framebuffer is complete */\r\n                if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) {\r\n                    SOKOL_LOG(\"Framebuffer completeness check failed (msaa resolve buffer)!\\n\");\r\n                    return SG_RESOURCESTATE_FAILED;\r\n                }\r\n                /* setup color attachments for the framebuffer */\r\n                #if !defined(SOKOL_GLES2)\r\n                if (!_sg.gl.gles2) {\r\n                    const GLenum gl_draw_bufs = GL_COLOR_ATTACHMENT0;\r\n                    glDrawBuffers(1, &gl_draw_bufs);\r\n                }\r\n                #endif\r\n            }\r\n        }\r\n    }\r\n\r\n    /* restore original framebuffer binding */\r\n    glBindFramebuffer(GL_FRAMEBUFFER, gl_orig_fb);\r\n    _SG_GL_CHECK_ERROR();\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_destroy_pass(_sg_pass_t* pass) {\r\n    SOKOL_ASSERT(pass);\r\n    _SG_GL_CHECK_ERROR();\r\n    if (0 != pass->gl.fb) {\r\n        glDeleteFramebuffers(1, &pass->gl.fb);\r\n    }\r\n    for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n        if (pass->gl.color_atts[i].gl_msaa_resolve_buffer) {\r\n            glDeleteFramebuffers(1, &pass->gl.color_atts[i].gl_msaa_resolve_buffer);\r\n        }\r\n    }\r\n    if (pass->gl.ds_att.gl_msaa_resolve_buffer) {\r\n        glDeleteFramebuffers(1, &pass->gl.ds_att.gl_msaa_resolve_buffer);\r\n    }\r\n    _SG_GL_CHECK_ERROR();\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_gl_pass_color_image(const _sg_pass_t* pass, int index) {\r\n    SOKOL_ASSERT(pass && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));\r\n    /* NOTE: may return null */\r\n    return pass->gl.color_atts[index].image;\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_gl_pass_ds_image(const _sg_pass_t* pass) {\r\n    /* NOTE: may return null */\r\n    SOKOL_ASSERT(pass);\r\n    return pass->gl.ds_att.image;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_begin_pass(_sg_pass_t* pass, const sg_pass_action* action, int w, int h) {\r\n    /* FIXME: what if a texture used as render target is still bound, should we\r\n       unbind all currently bound textures in begin pass? */\r\n    SOKOL_ASSERT(action);\r\n    SOKOL_ASSERT(!_sg.gl.in_pass);\r\n    _SG_GL_CHECK_ERROR();\r\n    _sg.gl.in_pass = true;\r\n    _sg.gl.cur_pass = pass; /* can be 0 */\r\n    if (pass) {\r\n        _sg.gl.cur_pass_id.id = pass->slot.id;\r\n    }\r\n    else {\r\n        _sg.gl.cur_pass_id.id = SG_INVALID_ID;\r\n    }\r\n    _sg.gl.cur_pass_width = w;\r\n    _sg.gl.cur_pass_height = h;\r\n\r\n    /* number of color attachments */\r\n    const int num_color_atts = pass ? pass->cmn.num_color_atts : 1;\r\n\r\n    /* bind the render pass framebuffer */\r\n    if (pass) {\r\n        /* offscreen pass */\r\n        SOKOL_ASSERT(pass->gl.fb);\r\n        glBindFramebuffer(GL_FRAMEBUFFER, pass->gl.fb);\r\n    }\r\n    else {\r\n        /* default pass */\r\n        SOKOL_ASSERT(_sg.gl.cur_context);\r\n        glBindFramebuffer(GL_FRAMEBUFFER, _sg.gl.cur_context->default_framebuffer);\r\n    }\r\n    glViewport(0, 0, w, h);\r\n    glScissor(0, 0, w, h);\r\n\r\n    /* clear color and depth-stencil attachments if needed */\r\n    bool clear_color = false;\r\n    for (int i = 0; i < num_color_atts; i++) {\r\n        if (SG_ACTION_CLEAR == action->colors[i].action) {\r\n            clear_color = true;\r\n            break;\r\n        }\r\n    }\r\n    const bool clear_depth = (action->depth.action == SG_ACTION_CLEAR);\r\n    const bool clear_stencil = (action->stencil.action == SG_ACTION_CLEAR);\r\n\r\n    bool need_pip_cache_flush = false;\r\n    if (clear_color) {\r\n        if (_sg.gl.cache.blend.color_write_mask != SG_COLORMASK_RGBA) {\r\n            need_pip_cache_flush = true;\r\n            _sg.gl.cache.blend.color_write_mask = SG_COLORMASK_RGBA;\r\n            glColorMask(GL_TRUE, GL_TRUE, GL_TRUE, GL_TRUE);\r\n        }\r\n    }\r\n    if (clear_depth) {\r\n        if (!_sg.gl.cache.ds.depth_write_enabled) {\r\n            need_pip_cache_flush = true;\r\n            _sg.gl.cache.ds.depth_write_enabled = true;\r\n            glDepthMask(GL_TRUE);\r\n        }\r\n        if (_sg.gl.cache.ds.depth_compare_func != SG_COMPAREFUNC_ALWAYS) {\r\n            need_pip_cache_flush = true;\r\n            _sg.gl.cache.ds.depth_compare_func = SG_COMPAREFUNC_ALWAYS;\r\n            glDepthFunc(GL_ALWAYS);\r\n        }\r\n    }\r\n    if (clear_stencil) {\r\n        if (_sg.gl.cache.ds.stencil_write_mask != 0xFF) {\r\n            need_pip_cache_flush = true;\r\n            _sg.gl.cache.ds.stencil_write_mask = 0xFF;\r\n            glStencilMask(0xFF);\r\n        }\r\n    }\r\n    if (need_pip_cache_flush) {\r\n        /* we messed with the state cache directly, need to clear cached\r\n           pipeline to force re-evaluation in next sg_apply_pipeline() */\r\n        _sg.gl.cache.cur_pipeline = 0;\r\n        _sg.gl.cache.cur_pipeline_id.id = SG_INVALID_ID;\r\n    }\r\n    bool use_mrt_clear = (0 != pass);\r\n    #if defined(SOKOL_GLES2)\r\n    use_mrt_clear = false;\r\n    #else\r\n    if (_sg.gl.gles2) {\r\n        use_mrt_clear = false;\r\n    }\r\n    #endif\r\n    if (!use_mrt_clear) {\r\n        GLbitfield clear_mask = 0;\r\n        if (clear_color) {\r\n            clear_mask |= GL_COLOR_BUFFER_BIT;\r\n            const float* c = action->colors[0].val;\r\n            glClearColor(c[0], c[1], c[2], c[3]);\r\n        }\r\n        if (clear_depth) {\r\n            clear_mask |= GL_DEPTH_BUFFER_BIT;\r\n            #ifdef SOKOL_GLCORE33\r\n            glClearDepth(action->depth.val);\r\n            #else\r\n            glClearDepthf(action->depth.val);\r\n            #endif\r\n        }\r\n        if (clear_stencil) {\r\n            clear_mask |= GL_STENCIL_BUFFER_BIT;\r\n            glClearStencil(action->stencil.val);\r\n        }\r\n        if (0 != clear_mask) {\r\n            glClear(clear_mask);\r\n        }\r\n    }\r\n    #if !defined SOKOL_GLES2\r\n    else {\r\n        SOKOL_ASSERT(pass);\r\n        for (int i = 0; i < num_color_atts; i++) {\r\n            if (action->colors[i].action == SG_ACTION_CLEAR) {\r\n                glClearBufferfv(GL_COLOR, i, action->colors[i].val);\r\n            }\r\n        }\r\n        if (pass->gl.ds_att.image) {\r\n            if (clear_depth && clear_stencil) {\r\n                glClearBufferfi(GL_DEPTH_STENCIL, 0, action->depth.val, action->stencil.val);\r\n            }\r\n            else if (clear_depth) {\r\n                glClearBufferfv(GL_DEPTH, 0, &action->depth.val);\r\n            }\r\n            else if (clear_stencil) {\r\n                GLint val = (GLint) action->stencil.val;\r\n                glClearBufferiv(GL_STENCIL, 0, &val);\r\n            }\r\n        }\r\n    }\r\n    #endif\r\n    _SG_GL_CHECK_ERROR();\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_end_pass(void) {\r\n    SOKOL_ASSERT(_sg.gl.in_pass);\r\n    _SG_GL_CHECK_ERROR();\r\n\r\n    /* if this was an offscreen pass, and MSAA rendering was used, need\r\n       to resolve into the pass images */\r\n    #if !defined(SOKOL_GLES2)\r\n    if (!_sg.gl.gles2 && _sg.gl.cur_pass) {\r\n        /* check if the pass object is still valid */\r\n        const _sg_pass_t* pass = _sg.gl.cur_pass;\r\n        SOKOL_ASSERT(pass->slot.id == _sg.gl.cur_pass_id.id);\r\n        bool is_msaa = (0 != _sg.gl.cur_pass->gl.color_atts[0].gl_msaa_resolve_buffer);\r\n        if (is_msaa) {\r\n            SOKOL_ASSERT(pass->gl.fb);\r\n            glBindFramebuffer(GL_READ_FRAMEBUFFER, pass->gl.fb);\r\n            SOKOL_ASSERT(pass->gl.color_atts[0].image);\r\n            const int w = pass->gl.color_atts[0].image->cmn.width;\r\n            const int h = pass->gl.color_atts[0].image->cmn.height;\r\n            for (int att_index = 0; att_index < SG_MAX_COLOR_ATTACHMENTS; att_index++) {\r\n                const _sg_gl_attachment_t* gl_att = &pass->gl.color_atts[att_index];\r\n                if (gl_att->image) {\r\n                    SOKOL_ASSERT(gl_att->gl_msaa_resolve_buffer);\r\n                    glBindFramebuffer(GL_DRAW_FRAMEBUFFER, gl_att->gl_msaa_resolve_buffer);\r\n                    glReadBuffer(GL_COLOR_ATTACHMENT0 + att_index);\r\n                    glBlitFramebuffer(0, 0, w, h, 0, 0, w, h, GL_COLOR_BUFFER_BIT, GL_NEAREST);\r\n                }\r\n                else {\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    #endif\r\n    _sg.gl.cur_pass = 0;\r\n    _sg.gl.cur_pass_id.id = SG_INVALID_ID;\r\n    _sg.gl.cur_pass_width = 0;\r\n    _sg.gl.cur_pass_height = 0;\r\n\r\n    SOKOL_ASSERT(_sg.gl.cur_context);\r\n    glBindFramebuffer(GL_FRAMEBUFFER, _sg.gl.cur_context->default_framebuffer);\r\n    _sg.gl.in_pass = false;\r\n    _SG_GL_CHECK_ERROR();\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {\r\n    SOKOL_ASSERT(_sg.gl.in_pass);\r\n    y = origin_top_left ? (_sg.gl.cur_pass_height - (y+h)) : y;\r\n    glViewport(x, y, w, h);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {\r\n    SOKOL_ASSERT(_sg.gl.in_pass);\r\n    y = origin_top_left ? (_sg.gl.cur_pass_height - (y+h)) : y;\r\n    glScissor(x, y, w, h);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_apply_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    SOKOL_ASSERT(pip->shader && (pip->cmn.shader_id.id == pip->shader->slot.id));\r\n    _SG_GL_CHECK_ERROR();\r\n    if ((_sg.gl.cache.cur_pipeline != pip) || (_sg.gl.cache.cur_pipeline_id.id != pip->slot.id)) {\r\n        _sg.gl.cache.cur_pipeline = pip;\r\n        _sg.gl.cache.cur_pipeline_id.id = pip->slot.id;\r\n        _sg.gl.cache.cur_primitive_type = _sg_gl_primitive_type(pip->gl.primitive_type);\r\n        _sg.gl.cache.cur_index_type = _sg_gl_index_type(pip->cmn.index_type);\r\n\r\n        /* update depth-stencil state */\r\n        const sg_depth_stencil_state* new_ds = &pip->gl.depth_stencil;\r\n        sg_depth_stencil_state* cache_ds = &_sg.gl.cache.ds;\r\n        if (new_ds->depth_compare_func != cache_ds->depth_compare_func) {\r\n            cache_ds->depth_compare_func = new_ds->depth_compare_func;\r\n            glDepthFunc(_sg_gl_compare_func(new_ds->depth_compare_func));\r\n        }\r\n        if (new_ds->depth_write_enabled != cache_ds->depth_write_enabled) {\r\n            cache_ds->depth_write_enabled = new_ds->depth_write_enabled;\r\n            glDepthMask(new_ds->depth_write_enabled);\r\n        }\r\n        if (new_ds->stencil_enabled != cache_ds->stencil_enabled) {\r\n            cache_ds->stencil_enabled = new_ds->stencil_enabled;\r\n            if (new_ds->stencil_enabled) glEnable(GL_STENCIL_TEST);\r\n            else glDisable(GL_STENCIL_TEST);\r\n        }\r\n        if (new_ds->stencil_write_mask != cache_ds->stencil_write_mask) {\r\n            cache_ds->stencil_write_mask = new_ds->stencil_write_mask;\r\n            glStencilMask(new_ds->stencil_write_mask);\r\n        }\r\n        for (int i = 0; i < 2; i++) {\r\n            const sg_stencil_state* new_ss = (i==0)? &new_ds->stencil_front : &new_ds->stencil_back;\r\n            sg_stencil_state* cache_ss = (i==0)? &cache_ds->stencil_front : &cache_ds->stencil_back;\r\n            GLenum gl_face = (i==0)? GL_FRONT : GL_BACK;\r\n            if ((new_ss->compare_func != cache_ss->compare_func) ||\r\n                (new_ds->stencil_read_mask != cache_ds->stencil_read_mask) ||\r\n                (new_ds->stencil_ref != cache_ds->stencil_ref))\r\n            {\r\n                cache_ss->compare_func = new_ss->compare_func;\r\n                glStencilFuncSeparate(gl_face,\r\n                    _sg_gl_compare_func(new_ss->compare_func),\r\n                    new_ds->stencil_ref,\r\n                    new_ds->stencil_read_mask);\r\n            }\r\n            if ((new_ss->fail_op != cache_ss->fail_op) ||\r\n                (new_ss->depth_fail_op != cache_ss->depth_fail_op) ||\r\n                (new_ss->pass_op != cache_ss->pass_op))\r\n            {\r\n                cache_ss->fail_op = new_ss->fail_op;\r\n                cache_ss->depth_fail_op = new_ss->depth_fail_op;\r\n                cache_ss->pass_op = new_ss->pass_op;\r\n                glStencilOpSeparate(gl_face,\r\n                    _sg_gl_stencil_op(new_ss->fail_op),\r\n                    _sg_gl_stencil_op(new_ss->depth_fail_op),\r\n                    _sg_gl_stencil_op(new_ss->pass_op));\r\n            }\r\n        }\r\n        cache_ds->stencil_read_mask = new_ds->stencil_read_mask;\r\n        cache_ds->stencil_ref = new_ds->stencil_ref;\r\n\r\n        /* update blend state */\r\n        const sg_blend_state* new_b = &pip->gl.blend;\r\n        sg_blend_state* cache_b = &_sg.gl.cache.blend;\r\n        if (new_b->enabled != cache_b->enabled) {\r\n            cache_b->enabled = new_b->enabled;\r\n            if (new_b->enabled) glEnable(GL_BLEND);\r\n            else glDisable(GL_BLEND);\r\n        }\r\n        if ((new_b->src_factor_rgb != cache_b->src_factor_rgb) ||\r\n            (new_b->dst_factor_rgb != cache_b->dst_factor_rgb) ||\r\n            (new_b->src_factor_alpha != cache_b->src_factor_alpha) ||\r\n            (new_b->dst_factor_alpha != cache_b->dst_factor_alpha))\r\n        {\r\n            cache_b->src_factor_rgb = new_b->src_factor_rgb;\r\n            cache_b->dst_factor_rgb = new_b->dst_factor_rgb;\r\n            cache_b->src_factor_alpha = new_b->src_factor_alpha;\r\n            cache_b->dst_factor_alpha = new_b->dst_factor_alpha;\r\n            glBlendFuncSeparate(_sg_gl_blend_factor(new_b->src_factor_rgb),\r\n                _sg_gl_blend_factor(new_b->dst_factor_rgb),\r\n                _sg_gl_blend_factor(new_b->src_factor_alpha),\r\n                _sg_gl_blend_factor(new_b->dst_factor_alpha));\r\n        }\r\n        if ((new_b->op_rgb != cache_b->op_rgb) || (new_b->op_alpha != cache_b->op_alpha)) {\r\n            cache_b->op_rgb = new_b->op_rgb;\r\n            cache_b->op_alpha = new_b->op_alpha;\r\n            glBlendEquationSeparate(_sg_gl_blend_op(new_b->op_rgb), _sg_gl_blend_op(new_b->op_alpha));\r\n        }\r\n        if (new_b->color_write_mask != cache_b->color_write_mask) {\r\n            cache_b->color_write_mask = new_b->color_write_mask;\r\n            glColorMask((new_b->color_write_mask & SG_COLORMASK_R) != 0,\r\n                        (new_b->color_write_mask & SG_COLORMASK_G) != 0,\r\n                        (new_b->color_write_mask & SG_COLORMASK_B) != 0,\r\n                        (new_b->color_write_mask & SG_COLORMASK_A) != 0);\r\n        }\r\n        if (!_sg_fequal(new_b->blend_color[0], cache_b->blend_color[0], 0.0001f) ||\r\n            !_sg_fequal(new_b->blend_color[1], cache_b->blend_color[1], 0.0001f) ||\r\n            !_sg_fequal(new_b->blend_color[2], cache_b->blend_color[2], 0.0001f) ||\r\n            !_sg_fequal(new_b->blend_color[3], cache_b->blend_color[3], 0.0001f))\r\n        {\r\n            const float* bc = new_b->blend_color;\r\n            for (int i=0; i<4; i++) {\r\n                cache_b->blend_color[i] = bc[i];\r\n            }\r\n            glBlendColor(bc[0], bc[1], bc[2], bc[3]);\r\n        }\r\n\r\n        /* update rasterizer state */\r\n        const sg_rasterizer_state* new_r = &pip->gl.rast;\r\n        sg_rasterizer_state* cache_r = &_sg.gl.cache.rast;\r\n        if (new_r->cull_mode != cache_r->cull_mode) {\r\n            cache_r->cull_mode = new_r->cull_mode;\r\n            if (SG_CULLMODE_NONE == new_r->cull_mode) {\r\n                glDisable(GL_CULL_FACE);\r\n            }\r\n            else {\r\n                glEnable(GL_CULL_FACE);\r\n                GLenum gl_mode = (SG_CULLMODE_FRONT == new_r->cull_mode) ? GL_FRONT : GL_BACK;\r\n                glCullFace(gl_mode);\r\n            }\r\n        }\r\n        if (new_r->face_winding != cache_r->face_winding) {\r\n            cache_r->face_winding = new_r->face_winding;\r\n            GLenum gl_winding = (SG_FACEWINDING_CW == new_r->face_winding) ? GL_CW : GL_CCW;\r\n            glFrontFace(gl_winding);\r\n        }\r\n        if (new_r->alpha_to_coverage_enabled != cache_r->alpha_to_coverage_enabled) {\r\n            cache_r->alpha_to_coverage_enabled = new_r->alpha_to_coverage_enabled;\r\n            if (new_r->alpha_to_coverage_enabled) glEnable(GL_SAMPLE_ALPHA_TO_COVERAGE);\r\n            else glDisable(GL_SAMPLE_ALPHA_TO_COVERAGE);\r\n        }\r\n        #ifdef SOKOL_GLCORE33\r\n        if (new_r->sample_count != cache_r->sample_count) {\r\n            cache_r->sample_count = new_r->sample_count;\r\n            if (new_r->sample_count > 1) glEnable(GL_MULTISAMPLE);\r\n            else glDisable(GL_MULTISAMPLE);\r\n        }\r\n        #endif\r\n        if (!_sg_fequal(new_r->depth_bias, cache_r->depth_bias, 0.000001f) ||\r\n            !_sg_fequal(new_r->depth_bias_slope_scale, cache_r->depth_bias_slope_scale, 0.000001f))\r\n        {\r\n            /* according to ANGLE's D3D11 backend:\r\n                D3D11 SlopeScaledDepthBias ==> GL polygonOffsetFactor\r\n                D3D11 DepthBias ==> GL polygonOffsetUnits\r\n                DepthBiasClamp has no meaning on GL\r\n            */\r\n            cache_r->depth_bias = new_r->depth_bias;\r\n            cache_r->depth_bias_slope_scale = new_r->depth_bias_slope_scale;\r\n            glPolygonOffset(new_r->depth_bias_slope_scale, new_r->depth_bias);\r\n            bool po_enabled = true;\r\n            if (_sg_fequal(new_r->depth_bias, 0.0f, 0.000001f) &&\r\n                _sg_fequal(new_r->depth_bias_slope_scale, 0.0f, 0.000001f))\r\n            {\r\n                po_enabled = false;\r\n            }\r\n            if (po_enabled != _sg.gl.cache.polygon_offset_enabled) {\r\n                _sg.gl.cache.polygon_offset_enabled = po_enabled;\r\n                if (po_enabled) glEnable(GL_POLYGON_OFFSET_FILL);\r\n                else glDisable(GL_POLYGON_OFFSET_FILL);\r\n            }\r\n        }\r\n\r\n        /* bind shader program */\r\n        if (pip->shader->gl.prog != _sg.gl.cache.prog) {\r\n            _sg.gl.cache.prog = pip->shader->gl.prog;\r\n            glUseProgram(pip->shader->gl.prog);\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_apply_bindings(\r\n    _sg_pipeline_t* pip,\r\n    _sg_buffer_t** vbs, const int* vb_offsets, int num_vbs,\r\n    _sg_buffer_t* ib, int ib_offset,\r\n    _sg_image_t** vs_imgs, int num_vs_imgs,\r\n    _sg_image_t** fs_imgs, int num_fs_imgs)\r\n{\r\n    SOKOL_ASSERT(pip);\r\n    _SOKOL_UNUSED(num_fs_imgs);\r\n    _SOKOL_UNUSED(num_vs_imgs);\r\n    _SOKOL_UNUSED(num_vbs);\r\n    _SG_GL_CHECK_ERROR();\r\n\r\n    /* bind textures */\r\n    _SG_GL_CHECK_ERROR();\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        const _sg_shader_stage_t* stage = &pip->shader->cmn.stage[stage_index];\r\n        const _sg_gl_shader_stage_t* gl_stage = &pip->shader->gl.stage[stage_index];\r\n        _sg_image_t** imgs = (stage_index == SG_SHADERSTAGE_VS)? vs_imgs : fs_imgs;\r\n        SOKOL_ASSERT(((stage_index == SG_SHADERSTAGE_VS)? num_vs_imgs : num_fs_imgs) == stage->num_images);\r\n        for (int img_index = 0; img_index < stage->num_images; img_index++) {\r\n            const _sg_gl_shader_image_t* gl_shd_img = &gl_stage->images[img_index];\r\n            if (gl_shd_img->gl_tex_slot != -1) {\r\n                _sg_image_t* img = imgs[img_index];\r\n                const GLuint gl_tex = img->gl.tex[img->cmn.active_slot];\r\n                SOKOL_ASSERT(img && img->gl.target);\r\n                SOKOL_ASSERT((gl_shd_img->gl_tex_slot != -1) && gl_tex);\r\n                _sg_gl_cache_bind_texture(gl_shd_img->gl_tex_slot, img->gl.target, gl_tex);\r\n            }\r\n        }\r\n    }\r\n    _SG_GL_CHECK_ERROR();\r\n\r\n    /* index buffer (can be 0) */\r\n    const GLuint gl_ib = ib ? ib->gl.buf[ib->cmn.active_slot] : 0;\r\n    _sg_gl_cache_bind_buffer(GL_ELEMENT_ARRAY_BUFFER, gl_ib);\r\n    _sg.gl.cache.cur_ib_offset = ib_offset;\r\n\r\n    /* vertex attributes */\r\n    for (uint32_t attr_index = 0; attr_index < _sg.limits.max_vertex_attrs; attr_index++) {\r\n        _sg_gl_attr_t* attr = &pip->gl.attrs[attr_index];\r\n        _sg_gl_cache_attr_t* cache_attr = &_sg.gl.cache.attrs[attr_index];\r\n        bool cache_attr_dirty = false;\r\n        int vb_offset = 0;\r\n        GLuint gl_vb = 0;\r\n        if (attr->vb_index >= 0) {\r\n            /* attribute is enabled */\r\n            SOKOL_ASSERT(attr->vb_index < num_vbs);\r\n            _sg_buffer_t* vb = vbs[attr->vb_index];\r\n            SOKOL_ASSERT(vb);\r\n            gl_vb = vb->gl.buf[vb->cmn.active_slot];\r\n            vb_offset = vb_offsets[attr->vb_index] + attr->offset;\r\n            if ((gl_vb != cache_attr->gl_vbuf) ||\r\n                (attr->size != cache_attr->gl_attr.size) ||\r\n                (attr->type != cache_attr->gl_attr.type) ||\r\n                (attr->normalized != cache_attr->gl_attr.normalized) ||\r\n                (attr->stride != cache_attr->gl_attr.stride) ||\r\n                (vb_offset != cache_attr->gl_attr.offset) ||\r\n                (cache_attr->gl_attr.divisor != attr->divisor))\r\n            {\r\n                _sg_gl_cache_bind_buffer(GL_ARRAY_BUFFER, gl_vb);\r\n                glVertexAttribPointer(attr_index, attr->size, attr->type,\r\n                    attr->normalized, attr->stride,\r\n                    (const GLvoid*)(GLintptr)vb_offset);\r\n                #ifdef SOKOL_INSTANCING_ENABLED\r\n                    if (_sg.features.instancing) {\r\n                        glVertexAttribDivisor(attr_index, attr->divisor);\r\n                    }\r\n                #endif\r\n                cache_attr_dirty = true;\r\n            }\r\n            if (cache_attr->gl_attr.vb_index == -1) {\r\n                glEnableVertexAttribArray(attr_index);\r\n                cache_attr_dirty = true;\r\n            }\r\n        }\r\n        else {\r\n            /* attribute is disabled */\r\n            if (cache_attr->gl_attr.vb_index != -1) {\r\n                glDisableVertexAttribArray(attr_index);\r\n                cache_attr_dirty = true;\r\n            }\r\n        }\r\n        if (cache_attr_dirty) {\r\n            cache_attr->gl_attr = *attr;\r\n            cache_attr->gl_attr.offset = vb_offset;\r\n            cache_attr->gl_vbuf = gl_vb;\r\n        }\r\n    }\r\n    _SG_GL_CHECK_ERROR();\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_apply_uniforms(sg_shader_stage stage_index, int ub_index, const void* data, int num_bytes) {\r\n    _SOKOL_UNUSED(num_bytes);\r\n    SOKOL_ASSERT(data && (num_bytes > 0));\r\n    SOKOL_ASSERT((stage_index >= 0) && ((int)stage_index < SG_NUM_SHADER_STAGES));\r\n    SOKOL_ASSERT(_sg.gl.cache.cur_pipeline);\r\n    SOKOL_ASSERT(_sg.gl.cache.cur_pipeline->slot.id == _sg.gl.cache.cur_pipeline_id.id);\r\n    SOKOL_ASSERT(_sg.gl.cache.cur_pipeline->shader->slot.id == _sg.gl.cache.cur_pipeline->cmn.shader_id.id);\r\n    SOKOL_ASSERT(_sg.gl.cache.cur_pipeline->shader->cmn.stage[stage_index].num_uniform_blocks > ub_index);\r\n    SOKOL_ASSERT(_sg.gl.cache.cur_pipeline->shader->cmn.stage[stage_index].uniform_blocks[ub_index].size == num_bytes);\r\n    const _sg_gl_shader_stage_t* gl_stage = &_sg.gl.cache.cur_pipeline->shader->gl.stage[stage_index];\r\n    const _sg_gl_uniform_block_t* gl_ub = &gl_stage->uniform_blocks[ub_index];\r\n    for (int u_index = 0; u_index < gl_ub->num_uniforms; u_index++) {\r\n        const _sg_gl_uniform_t* u = &gl_ub->uniforms[u_index];\r\n        SOKOL_ASSERT(u->type != SG_UNIFORMTYPE_INVALID);\r\n        if (u->gl_loc == -1) {\r\n            continue;\r\n        }\r\n        GLfloat* ptr = (GLfloat*) (((uint8_t*)data) + u->offset);\r\n        switch (u->type) {\r\n            case SG_UNIFORMTYPE_INVALID:\r\n                break;\r\n            case SG_UNIFORMTYPE_FLOAT:\r\n                glUniform1fv(u->gl_loc, u->count, ptr);\r\n                break;\r\n            case SG_UNIFORMTYPE_FLOAT2:\r\n                glUniform2fv(u->gl_loc, u->count, ptr);\r\n                break;\r\n            case SG_UNIFORMTYPE_FLOAT3:\r\n                glUniform3fv(u->gl_loc, u->count, ptr);\r\n                break;\r\n            case SG_UNIFORMTYPE_FLOAT4:\r\n                glUniform4fv(u->gl_loc, u->count, ptr);\r\n                break;\r\n            case SG_UNIFORMTYPE_MAT4:\r\n                glUniformMatrix4fv(u->gl_loc, u->count, GL_FALSE, ptr);\r\n                break;\r\n            default:\r\n                SOKOL_UNREACHABLE;\r\n                break;\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_draw(int base_element, int num_elements, int num_instances) {\r\n    const GLenum i_type = _sg.gl.cache.cur_index_type;\r\n    const GLenum p_type = _sg.gl.cache.cur_primitive_type;\r\n    if (0 != i_type) {\r\n        /* indexed rendering */\r\n        const int i_size = (i_type == GL_UNSIGNED_SHORT) ? 2 : 4;\r\n        const int ib_offset = _sg.gl.cache.cur_ib_offset;\r\n        const GLvoid* indices = (const GLvoid*)(GLintptr)(base_element*i_size+ib_offset);\r\n        if (num_instances == 1) {\r\n            glDrawElements(p_type, num_elements, i_type, indices);\r\n        }\r\n        else {\r\n            if (_sg.features.instancing) {\r\n                glDrawElementsInstanced(p_type, num_elements, i_type, indices, num_instances);\r\n            }\r\n        }\r\n    }\r\n    else {\r\n        /* non-indexed rendering */\r\n        if (num_instances == 1) {\r\n            glDrawArrays(p_type, base_element, num_elements);\r\n        }\r\n        else {\r\n            if (_sg.features.instancing) {\r\n                glDrawArraysInstanced(p_type, base_element, num_elements, num_instances);\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_commit(void) {\r\n    SOKOL_ASSERT(!_sg.gl.in_pass);\r\n    /* \"soft\" clear bindings (only those that are actually bound) */\r\n    _sg_gl_cache_clear_buffer_bindings(false);\r\n    _sg_gl_cache_clear_texture_bindings(false);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_update_buffer(_sg_buffer_t* buf, const void* data_ptr, uint32_t data_size) {\r\n    SOKOL_ASSERT(buf && data_ptr && (data_size > 0));\r\n    /* only one update per buffer per frame allowed */\r\n    if (++buf->cmn.active_slot >= buf->cmn.num_slots) {\r\n        buf->cmn.active_slot = 0;\r\n    }\r\n    GLenum gl_tgt = _sg_gl_buffer_target(buf->cmn.type);\r\n    SOKOL_ASSERT(buf->cmn.active_slot < SG_NUM_INFLIGHT_FRAMES);\r\n    GLuint gl_buf = buf->gl.buf[buf->cmn.active_slot];\r\n    SOKOL_ASSERT(gl_buf);\r\n    _SG_GL_CHECK_ERROR();\r\n    _sg_gl_cache_store_buffer_binding(gl_tgt);\r\n    _sg_gl_cache_bind_buffer(gl_tgt, gl_buf);\r\n    glBufferSubData(gl_tgt, 0, data_size, data_ptr);\r\n    _sg_gl_cache_restore_buffer_binding(gl_tgt);\r\n    _SG_GL_CHECK_ERROR();\r\n}\r\n\r\n_SOKOL_PRIVATE uint32_t _sg_gl_append_buffer(_sg_buffer_t* buf, const void* data_ptr, uint32_t data_size, bool new_frame) {\r\n    SOKOL_ASSERT(buf && data_ptr && (data_size > 0));\r\n    if (new_frame) {\r\n        if (++buf->cmn.active_slot >= buf->cmn.num_slots) {\r\n            buf->cmn.active_slot = 0;\r\n        }\r\n    }\r\n    GLenum gl_tgt = _sg_gl_buffer_target(buf->cmn.type);\r\n    SOKOL_ASSERT(buf->cmn.active_slot < SG_NUM_INFLIGHT_FRAMES);\r\n    GLuint gl_buf = buf->gl.buf[buf->cmn.active_slot];\r\n    SOKOL_ASSERT(gl_buf);\r\n    _SG_GL_CHECK_ERROR();\r\n    _sg_gl_cache_store_buffer_binding(gl_tgt);\r\n    _sg_gl_cache_bind_buffer(gl_tgt, gl_buf);\r\n    glBufferSubData(gl_tgt, buf->cmn.append_pos, data_size, data_ptr);\r\n    _sg_gl_cache_restore_buffer_binding(gl_tgt);\r\n    _SG_GL_CHECK_ERROR();\r\n    /* NOTE: this is a requirement from WebGPU, but we want identical behaviour across all backend */\r\n    return _sg_roundup(data_size, 4);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_gl_update_image(_sg_image_t* img, const sg_image_content* data) {\r\n    SOKOL_ASSERT(img && data);\r\n    /* only one update per image per frame allowed */\r\n    if (++img->cmn.active_slot >= img->cmn.num_slots) {\r\n        img->cmn.active_slot = 0;\r\n    }\r\n    SOKOL_ASSERT(img->cmn.active_slot < SG_NUM_INFLIGHT_FRAMES);\r\n    SOKOL_ASSERT(0 != img->gl.tex[img->cmn.active_slot]);\r\n    _sg_gl_cache_store_texture_binding(0);\r\n    _sg_gl_cache_bind_texture(0, img->gl.target, img->gl.tex[img->cmn.active_slot]);\r\n    const GLenum gl_img_format = _sg_gl_teximage_format(img->cmn.pixel_format);\r\n    const GLenum gl_img_type = _sg_gl_teximage_type(img->cmn.pixel_format);\r\n    const int num_faces = img->cmn.type == SG_IMAGETYPE_CUBE ? 6 : 1;\r\n    const int num_mips = img->cmn.num_mipmaps;\r\n    for (int face_index = 0; face_index < num_faces; face_index++) {\r\n        for (int mip_index = 0; mip_index < num_mips; mip_index++) {\r\n            GLenum gl_img_target = img->gl.target;\r\n            if (SG_IMAGETYPE_CUBE == img->cmn.type) {\r\n                gl_img_target = _sg_gl_cubeface_target(face_index);\r\n            }\r\n            const GLvoid* data_ptr = data->subimage[face_index][mip_index].ptr;\r\n            int mip_width = img->cmn.width >> mip_index;\r\n            if (mip_width == 0) {\r\n                mip_width = 1;\r\n            }\r\n            int mip_height = img->cmn.height >> mip_index;\r\n            if (mip_height == 0) {\r\n                mip_height = 1;\r\n            }\r\n            if ((SG_IMAGETYPE_2D == img->cmn.type) || (SG_IMAGETYPE_CUBE == img->cmn.type)) {\r\n                glTexSubImage2D(gl_img_target, mip_index,\r\n                    0, 0,\r\n                    mip_width, mip_height,\r\n                    gl_img_format, gl_img_type,\r\n                    data_ptr);\r\n            }\r\n            #if !defined(SOKOL_GLES2)\r\n            else if (!_sg.gl.gles2 && ((SG_IMAGETYPE_3D == img->cmn.type) || (SG_IMAGETYPE_ARRAY == img->cmn.type))) {\r\n                int mip_depth = img->cmn.depth >> mip_index;\r\n                if (mip_depth == 0) {\r\n                    mip_depth = 1;\r\n                }\r\n                glTexSubImage3D(gl_img_target, mip_index,\r\n                    0, 0, 0,\r\n                    mip_width, mip_height, mip_depth,\r\n                    gl_img_format, gl_img_type,\r\n                    data_ptr);\r\n\r\n            }\r\n            #endif\r\n        }\r\n    }\r\n    _sg_gl_cache_restore_texture_binding(0);\r\n}\r\n\r\n/*== D3D11 BACKEND IMPLEMENTATION ============================================*/\r\n#elif defined(SOKOL_D3D11)\r\n\r\n#if defined(__cplusplus)\r\n#define _sg_d3d11_AddRef(self) (self)->AddRef()\r\n#else\r\n#define _sg_d3d11_AddRef(self) (self)->lpVtbl->AddRef(self)\r\n#endif\r\n\r\n#if defined(__cplusplus)\r\n#define _sg_d3d11_Release(self) (self)->Release()\r\n#else\r\n#define _sg_d3d11_Release(self) (self)->lpVtbl->Release(self)\r\n#endif\r\n\r\n/*-- D3D11 C/C++ wrappers ----------------------------------------------------*/\r\nstatic inline HRESULT _sg_d3d11_CheckFormatSupport(ID3D11Device* self, DXGI_FORMAT Format, UINT* pFormatSupport) {\r\n    #if defined(__cplusplus)\r\n        return self->CheckFormatSupport(Format, pFormatSupport);\r\n    #else\r\n        return self->lpVtbl->CheckFormatSupport(self, Format, pFormatSupport);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_OMSetRenderTargets(ID3D11DeviceContext* self, UINT NumViews, ID3D11RenderTargetView* const* ppRenderTargetViews, ID3D11DepthStencilView *pDepthStencilView) {\r\n    #if defined(__cplusplus)\r\n        self->OMSetRenderTargets(NumViews, ppRenderTargetViews, pDepthStencilView);\r\n    #else\r\n        self->lpVtbl->OMSetRenderTargets(self, NumViews, ppRenderTargetViews, pDepthStencilView);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_RSSetState(ID3D11DeviceContext* self, ID3D11RasterizerState* pRasterizerState) {\r\n    #if defined(__cplusplus)\r\n        self->RSSetState(pRasterizerState);\r\n    #else\r\n        self->lpVtbl->RSSetState(self, pRasterizerState);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_OMSetDepthStencilState(ID3D11DeviceContext* self, ID3D11DepthStencilState* pDepthStencilState, UINT StencilRef) {\r\n    #if defined(__cplusplus)\r\n        self->OMSetDepthStencilState(pDepthStencilState, StencilRef);\r\n    #else\r\n        self->lpVtbl->OMSetDepthStencilState(self, pDepthStencilState, StencilRef);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_OMSetBlendState(ID3D11DeviceContext* self, ID3D11BlendState* pBlendState, const FLOAT BlendFactor[4], UINT SampleMask) {\r\n    #if defined(__cplusplus)\r\n        self->OMSetBlendState(pBlendState, BlendFactor, SampleMask);\r\n    #else\r\n        self->lpVtbl->OMSetBlendState(self, pBlendState, BlendFactor, SampleMask);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_IASetVertexBuffers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumBuffers, ID3D11Buffer* const* ppVertexBuffers, const UINT* pStrides, const UINT* pOffsets) {\r\n    #if defined(__cplusplus)\r\n        self->IASetVertexBuffers(StartSlot, NumBuffers, ppVertexBuffers, pStrides, pOffsets);\r\n    #else\r\n        self->lpVtbl->IASetVertexBuffers(self, StartSlot, NumBuffers, ppVertexBuffers, pStrides, pOffsets);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_IASetIndexBuffer(ID3D11DeviceContext* self, ID3D11Buffer* pIndexBuffer, DXGI_FORMAT Format, UINT Offset) {\r\n    #if defined(__cplusplus)\r\n        self->IASetIndexBuffer(pIndexBuffer, Format, Offset);\r\n    #else\r\n        self->lpVtbl->IASetIndexBuffer(self, pIndexBuffer, Format, Offset);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_IASetInputLayout(ID3D11DeviceContext* self, ID3D11InputLayout* pInputLayout) {\r\n    #if defined(__cplusplus)\r\n        self->IASetInputLayout(pInputLayout);\r\n    #else\r\n        self->lpVtbl->IASetInputLayout(self, pInputLayout);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_VSSetShader(ID3D11DeviceContext* self, ID3D11VertexShader* pVertexShader, ID3D11ClassInstance* const* ppClassInstances, UINT NumClassInstances) {\r\n    #if defined(__cplusplus)\r\n        self->VSSetShader(pVertexShader, ppClassInstances, NumClassInstances);\r\n    #else\r\n        self->lpVtbl->VSSetShader(self, pVertexShader, ppClassInstances, NumClassInstances);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_PSSetShader(ID3D11DeviceContext* self, ID3D11PixelShader* pPixelShader, ID3D11ClassInstance* const* ppClassInstances, UINT NumClassInstances) {\r\n    #if defined(__cplusplus)\r\n        self->PSSetShader(pPixelShader, ppClassInstances, NumClassInstances);\r\n    #else\r\n        self->lpVtbl->PSSetShader(self, pPixelShader, ppClassInstances, NumClassInstances);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_VSSetConstantBuffers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumBuffers, ID3D11Buffer* const* ppConstantBuffers) {\r\n    #if defined(__cplusplus)\r\n        self->VSSetConstantBuffers(StartSlot, NumBuffers, ppConstantBuffers);\r\n    #else\r\n        self->lpVtbl->VSSetConstantBuffers(self, StartSlot, NumBuffers, ppConstantBuffers);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_PSSetConstantBuffers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumBuffers, ID3D11Buffer* const* ppConstantBuffers) {\r\n    #if defined(__cplusplus)\r\n        self->PSSetConstantBuffers(StartSlot, NumBuffers, ppConstantBuffers);\r\n    #else\r\n        self->lpVtbl->PSSetConstantBuffers(self, StartSlot, NumBuffers, ppConstantBuffers);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_VSSetShaderResources(ID3D11DeviceContext* self, UINT StartSlot, UINT NumViews, ID3D11ShaderResourceView* const* ppShaderResourceViews) {\r\n    #if defined(__cplusplus)\r\n        self->VSSetShaderResources(StartSlot, NumViews, ppShaderResourceViews);\r\n    #else\r\n        self->lpVtbl->VSSetShaderResources(self, StartSlot, NumViews, ppShaderResourceViews);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_PSSetShaderResources(ID3D11DeviceContext* self, UINT StartSlot, UINT NumViews, ID3D11ShaderResourceView* const* ppShaderResourceViews) {\r\n    #if defined(__cplusplus)\r\n        self->PSSetShaderResources(StartSlot, NumViews, ppShaderResourceViews);\r\n    #else\r\n        self->lpVtbl->PSSetShaderResources(self, StartSlot, NumViews, ppShaderResourceViews);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_VSSetSamplers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumSamplers, ID3D11SamplerState* const* ppSamplers) {\r\n    #if defined(__cplusplus)\r\n        self->VSSetSamplers(StartSlot, NumSamplers, ppSamplers);\r\n    #else\r\n        self->lpVtbl->VSSetSamplers(self, StartSlot, NumSamplers, ppSamplers);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_PSSetSamplers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumSamplers, ID3D11SamplerState* const* ppSamplers) {\r\n    #if defined(__cplusplus)\r\n        self->PSSetSamplers(StartSlot, NumSamplers, ppSamplers);\r\n    #else\r\n        self->lpVtbl->PSSetSamplers(self, StartSlot, NumSamplers, ppSamplers);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateBuffer(ID3D11Device* self, const D3D11_BUFFER_DESC* pDesc, const D3D11_SUBRESOURCE_DATA* pInitialData, ID3D11Buffer** ppBuffer) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateBuffer(pDesc, pInitialData, ppBuffer);\r\n    #else\r\n        return self->lpVtbl->CreateBuffer(self, pDesc, pInitialData, ppBuffer);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateTexture2D(ID3D11Device* self, const D3D11_TEXTURE2D_DESC* pDesc, const D3D11_SUBRESOURCE_DATA* pInitialData, ID3D11Texture2D** ppTexture2D) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateTexture2D(pDesc, pInitialData, ppTexture2D);\r\n    #else\r\n        return self->lpVtbl->CreateTexture2D(self, pDesc, pInitialData, ppTexture2D);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateShaderResourceView(ID3D11Device* self, ID3D11Resource* pResource, const D3D11_SHADER_RESOURCE_VIEW_DESC* pDesc, ID3D11ShaderResourceView** ppSRView) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateShaderResourceView(pResource, pDesc, ppSRView);\r\n    #else\r\n        return self->lpVtbl->CreateShaderResourceView(self, pResource, pDesc, ppSRView);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateTexture3D(ID3D11Device* self, const D3D11_TEXTURE3D_DESC* pDesc, const D3D11_SUBRESOURCE_DATA* pInitialData, ID3D11Texture3D** ppTexture3D) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateTexture3D(pDesc, pInitialData, ppTexture3D);\r\n    #else\r\n        return self->lpVtbl->CreateTexture3D(self, pDesc, pInitialData, ppTexture3D);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateSamplerState(ID3D11Device* self, const D3D11_SAMPLER_DESC* pSamplerDesc, ID3D11SamplerState** ppSamplerState) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateSamplerState(pSamplerDesc, ppSamplerState);\r\n    #else\r\n        return self->lpVtbl->CreateSamplerState(self, pSamplerDesc, ppSamplerState);\r\n    #endif\r\n}\r\n\r\nstatic inline LPVOID _sg_d3d11_GetBufferPointer(ID3D10Blob* self) {\r\n    #if defined(__cplusplus)\r\n        return self->GetBufferPointer();\r\n    #else\r\n        return self->lpVtbl->GetBufferPointer(self);\r\n    #endif\r\n}\r\n\r\nstatic inline SIZE_T _sg_d3d11_GetBufferSize(ID3D10Blob* self) {\r\n    #if defined(__cplusplus)\r\n        return self->GetBufferSize();\r\n    #else\r\n        return self->lpVtbl->GetBufferSize(self);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateVertexShader(ID3D11Device* self, const void* pShaderBytecode, SIZE_T BytecodeLength, ID3D11ClassLinkage* pClassLinkage, ID3D11VertexShader** ppVertexShader) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateVertexShader(pShaderBytecode, BytecodeLength, pClassLinkage, ppVertexShader);\r\n    #else\r\n        return self->lpVtbl->CreateVertexShader(self, pShaderBytecode, BytecodeLength, pClassLinkage, ppVertexShader);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreatePixelShader(ID3D11Device* self, const void* pShaderBytecode, SIZE_T BytecodeLength, ID3D11ClassLinkage* pClassLinkage, ID3D11PixelShader** ppPixelShader) {\r\n    #if defined(__cplusplus)\r\n        return self->CreatePixelShader(pShaderBytecode, BytecodeLength, pClassLinkage, ppPixelShader);\r\n    #else\r\n        return self->lpVtbl->CreatePixelShader(self, pShaderBytecode, BytecodeLength, pClassLinkage, ppPixelShader);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateInputLayout(ID3D11Device* self, const D3D11_INPUT_ELEMENT_DESC* pInputElementDescs, UINT NumElements, const void* pShaderBytecodeWithInputSignature, SIZE_T BytecodeLength, ID3D11InputLayout **ppInputLayout) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateInputLayout(pInputElementDescs, NumElements, pShaderBytecodeWithInputSignature, BytecodeLength, ppInputLayout);\r\n    #else\r\n        return self->lpVtbl->CreateInputLayout(self, pInputElementDescs, NumElements, pShaderBytecodeWithInputSignature, BytecodeLength, ppInputLayout);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateRasterizerState(ID3D11Device* self, const D3D11_RASTERIZER_DESC* pRasterizerDesc, ID3D11RasterizerState** ppRasterizerState) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateRasterizerState(pRasterizerDesc, ppRasterizerState);\r\n    #else\r\n        return self->lpVtbl->CreateRasterizerState(self, pRasterizerDesc, ppRasterizerState);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateDepthStencilState(ID3D11Device* self, const D3D11_DEPTH_STENCIL_DESC* pDepthStencilDesc, ID3D11DepthStencilState** ppDepthStencilState) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateDepthStencilState(pDepthStencilDesc, ppDepthStencilState);\r\n    #else\r\n        return self->lpVtbl->CreateDepthStencilState(self, pDepthStencilDesc, ppDepthStencilState);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateBlendState(ID3D11Device* self, const D3D11_BLEND_DESC* pBlendStateDesc, ID3D11BlendState** ppBlendState) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateBlendState(pBlendStateDesc, ppBlendState);\r\n    #else\r\n        return self->lpVtbl->CreateBlendState(self, pBlendStateDesc, ppBlendState);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateRenderTargetView(ID3D11Device* self, ID3D11Resource *pResource, const D3D11_RENDER_TARGET_VIEW_DESC* pDesc, ID3D11RenderTargetView** ppRTView) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateRenderTargetView(pResource, pDesc, ppRTView);\r\n    #else\r\n        return self->lpVtbl->CreateRenderTargetView(self, pResource, pDesc, ppRTView);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_CreateDepthStencilView(ID3D11Device* self, ID3D11Resource* pResource, const D3D11_DEPTH_STENCIL_VIEW_DESC* pDesc, ID3D11DepthStencilView** ppDepthStencilView) {\r\n    #if defined(__cplusplus)\r\n        return self->CreateDepthStencilView(pResource, pDesc, ppDepthStencilView);\r\n    #else\r\n        return self->lpVtbl->CreateDepthStencilView(self, pResource, pDesc, ppDepthStencilView);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_RSSetViewports(ID3D11DeviceContext* self, UINT NumViewports, const D3D11_VIEWPORT* pViewports) {\r\n    #if defined(__cplusplus)\r\n        self->RSSetViewports(NumViewports, pViewports);\r\n    #else\r\n        self->lpVtbl->RSSetViewports(self, NumViewports, pViewports);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_RSSetScissorRects(ID3D11DeviceContext* self, UINT NumRects, const D3D11_RECT* pRects) {\r\n    #if defined(__cplusplus)\r\n        self->RSSetScissorRects(NumRects, pRects);\r\n    #else\r\n        self->lpVtbl->RSSetScissorRects(self, NumRects, pRects);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_ClearRenderTargetView(ID3D11DeviceContext* self, ID3D11RenderTargetView* pRenderTargetView, const FLOAT ColorRGBA[4]) {\r\n    #if defined(__cplusplus)\r\n        self->ClearRenderTargetView(pRenderTargetView, ColorRGBA);\r\n    #else\r\n        self->lpVtbl->ClearRenderTargetView(self, pRenderTargetView, ColorRGBA);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_ClearDepthStencilView(ID3D11DeviceContext* self, ID3D11DepthStencilView* pDepthStencilView, UINT ClearFlags, FLOAT Depth, UINT8 Stencil) {\r\n    #if defined(__cplusplus)\r\n        self->ClearDepthStencilView(pDepthStencilView, ClearFlags, Depth, Stencil);\r\n    #else\r\n        self->lpVtbl->ClearDepthStencilView(self, pDepthStencilView, ClearFlags, Depth, Stencil);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_ResolveSubresource(ID3D11DeviceContext* self, ID3D11Resource* pDstResource, UINT DstSubresource, ID3D11Resource* pSrcResource, UINT SrcSubresource, DXGI_FORMAT Format) {\r\n    #if defined(__cplusplus)\r\n        self->ResolveSubresource(pDstResource, DstSubresource, pSrcResource, SrcSubresource, Format);\r\n    #else\r\n        self->lpVtbl->ResolveSubresource(self, pDstResource, DstSubresource, pSrcResource, SrcSubresource, Format);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_IASetPrimitiveTopology(ID3D11DeviceContext* self, D3D11_PRIMITIVE_TOPOLOGY Topology) {\r\n    #if defined(__cplusplus)\r\n        self->IASetPrimitiveTopology(Topology);\r\n    #else\r\n        self->lpVtbl->IASetPrimitiveTopology(self, Topology);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_UpdateSubresource(ID3D11DeviceContext* self, ID3D11Resource* pDstResource, UINT DstSubresource, const D3D11_BOX* pDstBox, const void* pSrcData, UINT SrcRowPitch, UINT SrcDepthPitch) {\r\n    #if defined(__cplusplus)\r\n        self->UpdateSubresource(pDstResource, DstSubresource, pDstBox, pSrcData, SrcRowPitch, SrcDepthPitch);\r\n    #else\r\n        self->lpVtbl->UpdateSubresource(self, pDstResource, DstSubresource, pDstBox, pSrcData, SrcRowPitch, SrcDepthPitch);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_DrawIndexed(ID3D11DeviceContext* self, UINT IndexCount, UINT StartIndexLocation, INT  BaseVertexLocation) {\r\n    #if defined(__cplusplus)\r\n        self->DrawIndexed(IndexCount, StartIndexLocation, BaseVertexLocation);\r\n    #else\r\n        self->lpVtbl->DrawIndexed(self, IndexCount, StartIndexLocation, BaseVertexLocation);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_DrawIndexedInstanced(ID3D11DeviceContext* self, UINT IndexCountPerInstance, UINT InstanceCount, UINT StartIndexLocation, INT BaseVertexLocation, UINT StartInstanceLocation) {\r\n    #if defined(__cplusplus)\r\n        self->DrawIndexedInstanced(IndexCountPerInstance, InstanceCount, StartIndexLocation, BaseVertexLocation, StartInstanceLocation);\r\n    #else\r\n        self->lpVtbl->DrawIndexedInstanced(self, IndexCountPerInstance, InstanceCount, StartIndexLocation, BaseVertexLocation, StartInstanceLocation);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_Draw(ID3D11DeviceContext* self, UINT VertexCount, UINT StartVertexLocation) {\r\n    #if defined(__cplusplus)\r\n        self->Draw(VertexCount, StartVertexLocation);\r\n    #else\r\n        self->lpVtbl->Draw(self, VertexCount, StartVertexLocation);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_DrawInstanced(ID3D11DeviceContext* self, UINT VertexCountPerInstance, UINT InstanceCount, UINT StartVertexLocation, UINT StartInstanceLocation) {\r\n    #if defined(__cplusplus)\r\n        self->DrawInstanced(VertexCountPerInstance, InstanceCount, StartVertexLocation, StartInstanceLocation);\r\n    #else\r\n        self->lpVtbl->DrawInstanced(self, VertexCountPerInstance, InstanceCount, StartVertexLocation, StartInstanceLocation);\r\n    #endif\r\n}\r\n\r\nstatic inline HRESULT _sg_d3d11_Map(ID3D11DeviceContext* self, ID3D11Resource* pResource, UINT Subresource, D3D11_MAP MapType, UINT MapFlags, D3D11_MAPPED_SUBRESOURCE* pMappedResource) {\r\n    #if defined(__cplusplus)\r\n        return self->Map(pResource, Subresource, MapType, MapFlags, pMappedResource);\r\n    #else\r\n        return self->lpVtbl->Map(self, pResource, Subresource, MapType, MapFlags, pMappedResource);\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_d3d11_Unmap(ID3D11DeviceContext* self, ID3D11Resource* pResource, UINT Subresource) {\r\n    #if defined(__cplusplus)\r\n        self->Unmap(pResource, Subresource);\r\n    #else\r\n        self->lpVtbl->Unmap(self, pResource, Subresource);\r\n    #endif\r\n}\r\n\r\n/*-- enum translation functions ----------------------------------------------*/\r\n_SOKOL_PRIVATE D3D11_USAGE _sg_d3d11_usage(sg_usage usg) {\r\n    switch (usg) {\r\n        case SG_USAGE_IMMUTABLE:\r\n            return D3D11_USAGE_IMMUTABLE;\r\n        case SG_USAGE_DYNAMIC:\r\n        case SG_USAGE_STREAM:\r\n            return D3D11_USAGE_DYNAMIC;\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return (D3D11_USAGE) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE UINT _sg_d3d11_cpu_access_flags(sg_usage usg) {\r\n    switch (usg) {\r\n        case SG_USAGE_IMMUTABLE:\r\n            return 0;\r\n        case SG_USAGE_DYNAMIC:\r\n        case SG_USAGE_STREAM:\r\n            return D3D11_CPU_ACCESS_WRITE;\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE DXGI_FORMAT _sg_d3d11_pixel_format(sg_pixel_format fmt) {\r\n    switch (fmt) {\r\n        case SG_PIXELFORMAT_R8:             return DXGI_FORMAT_R8_UNORM;\r\n        case SG_PIXELFORMAT_R8SN:           return DXGI_FORMAT_R8_SNORM;\r\n        case SG_PIXELFORMAT_R8UI:           return DXGI_FORMAT_R8_UINT;\r\n        case SG_PIXELFORMAT_R8SI:           return DXGI_FORMAT_R8_SINT;\r\n        case SG_PIXELFORMAT_R16:            return DXGI_FORMAT_R16_UNORM;\r\n        case SG_PIXELFORMAT_R16SN:          return DXGI_FORMAT_R16_SNORM;\r\n        case SG_PIXELFORMAT_R16UI:          return DXGI_FORMAT_R16_UINT;\r\n        case SG_PIXELFORMAT_R16SI:          return DXGI_FORMAT_R16_SINT;\r\n        case SG_PIXELFORMAT_R16F:           return DXGI_FORMAT_R16_FLOAT;\r\n        case SG_PIXELFORMAT_RG8:            return DXGI_FORMAT_R8G8_UNORM;\r\n        case SG_PIXELFORMAT_RG8SN:          return DXGI_FORMAT_R8G8_SNORM;\r\n        case SG_PIXELFORMAT_RG8UI:          return DXGI_FORMAT_R8G8_UINT;\r\n        case SG_PIXELFORMAT_RG8SI:          return DXGI_FORMAT_R8G8_SINT;\r\n        case SG_PIXELFORMAT_R32UI:          return DXGI_FORMAT_R32_UINT;\r\n        case SG_PIXELFORMAT_R32SI:          return DXGI_FORMAT_R32_SINT;\r\n        case SG_PIXELFORMAT_R32F:           return DXGI_FORMAT_R32_FLOAT;\r\n        case SG_PIXELFORMAT_RG16:           return DXGI_FORMAT_R16G16_UNORM;\r\n        case SG_PIXELFORMAT_RG16SN:         return DXGI_FORMAT_R16G16_SNORM;\r\n        case SG_PIXELFORMAT_RG16UI:         return DXGI_FORMAT_R16G16_UINT;\r\n        case SG_PIXELFORMAT_RG16SI:         return DXGI_FORMAT_R16G16_SINT;\r\n        case SG_PIXELFORMAT_RG16F:          return DXGI_FORMAT_R16G16_FLOAT;\r\n        case SG_PIXELFORMAT_RGBA8:          return DXGI_FORMAT_R8G8B8A8_UNORM;\r\n        case SG_PIXELFORMAT_RGBA8SN:        return DXGI_FORMAT_R8G8B8A8_SNORM;\r\n        case SG_PIXELFORMAT_RGBA8UI:        return DXGI_FORMAT_R8G8B8A8_UINT;\r\n        case SG_PIXELFORMAT_RGBA8SI:        return DXGI_FORMAT_R8G8B8A8_SINT;\r\n        case SG_PIXELFORMAT_BGRA8:          return DXGI_FORMAT_B8G8R8A8_UNORM;\r\n        case SG_PIXELFORMAT_RGB10A2:        return DXGI_FORMAT_R10G10B10A2_UNORM;\r\n        case SG_PIXELFORMAT_RG11B10F:       return DXGI_FORMAT_R11G11B10_FLOAT;\r\n        case SG_PIXELFORMAT_RG32UI:         return DXGI_FORMAT_R32G32_UINT;\r\n        case SG_PIXELFORMAT_RG32SI:         return DXGI_FORMAT_R32G32_SINT;\r\n        case SG_PIXELFORMAT_RG32F:          return DXGI_FORMAT_R32G32_FLOAT;\r\n        case SG_PIXELFORMAT_RGBA16:         return DXGI_FORMAT_R16G16B16A16_UNORM;\r\n        case SG_PIXELFORMAT_RGBA16SN:       return DXGI_FORMAT_R16G16B16A16_SNORM;\r\n        case SG_PIXELFORMAT_RGBA16UI:       return DXGI_FORMAT_R16G16B16A16_UINT;\r\n        case SG_PIXELFORMAT_RGBA16SI:       return DXGI_FORMAT_R16G16B16A16_SINT;\r\n        case SG_PIXELFORMAT_RGBA16F:        return DXGI_FORMAT_R16G16B16A16_FLOAT;\r\n        case SG_PIXELFORMAT_RGBA32UI:       return DXGI_FORMAT_R32G32B32A32_UINT;\r\n        case SG_PIXELFORMAT_RGBA32SI:       return DXGI_FORMAT_R32G32B32A32_SINT;\r\n        case SG_PIXELFORMAT_RGBA32F:        return DXGI_FORMAT_R32G32B32A32_FLOAT;\r\n        case SG_PIXELFORMAT_DEPTH:          return DXGI_FORMAT_D32_FLOAT;\r\n        case SG_PIXELFORMAT_DEPTH_STENCIL:  return DXGI_FORMAT_D24_UNORM_S8_UINT;\r\n        case SG_PIXELFORMAT_BC1_RGBA:       return DXGI_FORMAT_BC1_UNORM;\r\n        case SG_PIXELFORMAT_BC2_RGBA:       return DXGI_FORMAT_BC2_UNORM;\r\n        case SG_PIXELFORMAT_BC3_RGBA:       return DXGI_FORMAT_BC3_UNORM;\r\n        case SG_PIXELFORMAT_BC4_R:          return DXGI_FORMAT_BC4_UNORM;\r\n        case SG_PIXELFORMAT_BC4_RSN:        return DXGI_FORMAT_BC4_SNORM;\r\n        case SG_PIXELFORMAT_BC5_RG:         return DXGI_FORMAT_BC5_UNORM;\r\n        case SG_PIXELFORMAT_BC5_RGSN:       return DXGI_FORMAT_BC5_SNORM;\r\n        case SG_PIXELFORMAT_BC6H_RGBF:      return DXGI_FORMAT_BC6H_SF16;\r\n        case SG_PIXELFORMAT_BC6H_RGBUF:     return DXGI_FORMAT_BC6H_UF16;\r\n        case SG_PIXELFORMAT_BC7_RGBA:       return DXGI_FORMAT_BC7_UNORM;\r\n        default:                            return DXGI_FORMAT_UNKNOWN;\r\n    };\r\n}\r\n\r\n_SOKOL_PRIVATE D3D11_PRIMITIVE_TOPOLOGY _sg_d3d11_primitive_topology(sg_primitive_type prim_type) {\r\n    switch (prim_type) {\r\n        case SG_PRIMITIVETYPE_POINTS:           return D3D11_PRIMITIVE_TOPOLOGY_POINTLIST;\r\n        case SG_PRIMITIVETYPE_LINES:            return D3D11_PRIMITIVE_TOPOLOGY_LINELIST;\r\n        case SG_PRIMITIVETYPE_LINE_STRIP:       return D3D11_PRIMITIVE_TOPOLOGY_LINESTRIP;\r\n        case SG_PRIMITIVETYPE_TRIANGLES:        return D3D11_PRIMITIVE_TOPOLOGY_TRIANGLELIST;\r\n        case SG_PRIMITIVETYPE_TRIANGLE_STRIP:   return D3D11_PRIMITIVE_TOPOLOGY_TRIANGLESTRIP;\r\n        default: SOKOL_UNREACHABLE; return (D3D11_PRIMITIVE_TOPOLOGY) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE DXGI_FORMAT _sg_d3d11_index_format(sg_index_type index_type) {\r\n    switch (index_type) {\r\n        case SG_INDEXTYPE_NONE:     return DXGI_FORMAT_UNKNOWN;\r\n        case SG_INDEXTYPE_UINT16:   return DXGI_FORMAT_R16_UINT;\r\n        case SG_INDEXTYPE_UINT32:   return DXGI_FORMAT_R32_UINT;\r\n        default: SOKOL_UNREACHABLE; return (DXGI_FORMAT) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE D3D11_FILTER _sg_d3d11_filter(sg_filter min_f, sg_filter mag_f, uint32_t max_anisotropy) {\r\n    if (max_anisotropy > 1) {\r\n        return D3D11_FILTER_ANISOTROPIC;\r\n    }\r\n    else if (mag_f == SG_FILTER_NEAREST) {\r\n        switch (min_f) {\r\n            case SG_FILTER_NEAREST:\r\n            case SG_FILTER_NEAREST_MIPMAP_NEAREST:\r\n                return D3D11_FILTER_MIN_MAG_MIP_POINT;\r\n            case SG_FILTER_LINEAR:\r\n            case SG_FILTER_LINEAR_MIPMAP_NEAREST:\r\n                return D3D11_FILTER_MIN_LINEAR_MAG_MIP_POINT;\r\n            case SG_FILTER_NEAREST_MIPMAP_LINEAR:\r\n                return D3D11_FILTER_MIN_MAG_POINT_MIP_LINEAR;\r\n            case SG_FILTER_LINEAR_MIPMAP_LINEAR:\r\n                return D3D11_FILTER_MIN_LINEAR_MAG_POINT_MIP_LINEAR;\r\n            default:\r\n                SOKOL_UNREACHABLE; break;\r\n        }\r\n    }\r\n    else if (mag_f == SG_FILTER_LINEAR) {\r\n        switch (min_f) {\r\n            case SG_FILTER_NEAREST:\r\n            case SG_FILTER_NEAREST_MIPMAP_NEAREST:\r\n                return D3D11_FILTER_MIN_POINT_MAG_LINEAR_MIP_POINT;\r\n            case SG_FILTER_LINEAR:\r\n            case SG_FILTER_LINEAR_MIPMAP_NEAREST:\r\n                return D3D11_FILTER_MIN_MAG_LINEAR_MIP_POINT;\r\n            case SG_FILTER_NEAREST_MIPMAP_LINEAR:\r\n                return D3D11_FILTER_MIN_POINT_MAG_MIP_LINEAR;\r\n            case SG_FILTER_LINEAR_MIPMAP_LINEAR:\r\n                return D3D11_FILTER_MIN_MAG_MIP_LINEAR;\r\n            default:\r\n                SOKOL_UNREACHABLE; break;\r\n        }\r\n    }\r\n    /* invalid value for mag filter */\r\n    SOKOL_UNREACHABLE;\r\n    return D3D11_FILTER_MIN_MAG_MIP_POINT;\r\n}\r\n\r\n_SOKOL_PRIVATE D3D11_TEXTURE_ADDRESS_MODE _sg_d3d11_address_mode(sg_wrap m) {\r\n    switch (m) {\r\n        case SG_WRAP_REPEAT:            return D3D11_TEXTURE_ADDRESS_WRAP;\r\n        case SG_WRAP_CLAMP_TO_EDGE:     return D3D11_TEXTURE_ADDRESS_CLAMP;\r\n        case SG_WRAP_CLAMP_TO_BORDER:   return D3D11_TEXTURE_ADDRESS_BORDER;\r\n        case SG_WRAP_MIRRORED_REPEAT:   return D3D11_TEXTURE_ADDRESS_MIRROR;\r\n        default: SOKOL_UNREACHABLE; return (D3D11_TEXTURE_ADDRESS_MODE) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE DXGI_FORMAT _sg_d3d11_vertex_format(sg_vertex_format fmt) {\r\n    switch (fmt) {\r\n        case SG_VERTEXFORMAT_FLOAT:     return DXGI_FORMAT_R32_FLOAT;\r\n        case SG_VERTEXFORMAT_FLOAT2:    return DXGI_FORMAT_R32G32_FLOAT;\r\n        case SG_VERTEXFORMAT_FLOAT3:    return DXGI_FORMAT_R32G32B32_FLOAT;\r\n        case SG_VERTEXFORMAT_FLOAT4:    return DXGI_FORMAT_R32G32B32A32_FLOAT;\r\n        case SG_VERTEXFORMAT_BYTE4:     return DXGI_FORMAT_R8G8B8A8_SINT;\r\n        case SG_VERTEXFORMAT_BYTE4N:    return DXGI_FORMAT_R8G8B8A8_SNORM;\r\n        case SG_VERTEXFORMAT_UBYTE4:    return DXGI_FORMAT_R8G8B8A8_UINT;\r\n        case SG_VERTEXFORMAT_UBYTE4N:   return DXGI_FORMAT_R8G8B8A8_UNORM;\r\n        case SG_VERTEXFORMAT_SHORT2:    return DXGI_FORMAT_R16G16_SINT;\r\n        case SG_VERTEXFORMAT_SHORT2N:   return DXGI_FORMAT_R16G16_SNORM;\r\n        case SG_VERTEXFORMAT_USHORT2N:  return DXGI_FORMAT_R16G16_UNORM;\r\n        case SG_VERTEXFORMAT_SHORT4:    return DXGI_FORMAT_R16G16B16A16_SINT;\r\n        case SG_VERTEXFORMAT_SHORT4N:   return DXGI_FORMAT_R16G16B16A16_SNORM;\r\n        case SG_VERTEXFORMAT_USHORT4N:  return DXGI_FORMAT_R16G16B16A16_UNORM;\r\n        case SG_VERTEXFORMAT_UINT10_N2: return DXGI_FORMAT_R10G10B10A2_UNORM;\r\n        default: SOKOL_UNREACHABLE; return (DXGI_FORMAT) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE D3D11_INPUT_CLASSIFICATION _sg_d3d11_input_classification(sg_vertex_step step) {\r\n    switch (step) {\r\n        case SG_VERTEXSTEP_PER_VERTEX:      return D3D11_INPUT_PER_VERTEX_DATA;\r\n        case SG_VERTEXSTEP_PER_INSTANCE:    return D3D11_INPUT_PER_INSTANCE_DATA;\r\n        default: SOKOL_UNREACHABLE; return (D3D11_INPUT_CLASSIFICATION) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE D3D11_CULL_MODE _sg_d3d11_cull_mode(sg_cull_mode m) {\r\n    switch (m) {\r\n        case SG_CULLMODE_NONE:      return D3D11_CULL_NONE;\r\n        case SG_CULLMODE_FRONT:     return D3D11_CULL_FRONT;\r\n        case SG_CULLMODE_BACK:      return D3D11_CULL_BACK;\r\n        default: SOKOL_UNREACHABLE; return (D3D11_CULL_MODE) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE D3D11_COMPARISON_FUNC _sg_d3d11_compare_func(sg_compare_func f) {\r\n    switch (f) {\r\n        case SG_COMPAREFUNC_NEVER:          return D3D11_COMPARISON_NEVER;\r\n        case SG_COMPAREFUNC_LESS:           return D3D11_COMPARISON_LESS;\r\n        case SG_COMPAREFUNC_EQUAL:          return D3D11_COMPARISON_EQUAL;\r\n        case SG_COMPAREFUNC_LESS_EQUAL:     return D3D11_COMPARISON_LESS_EQUAL;\r\n        case SG_COMPAREFUNC_GREATER:        return D3D11_COMPARISON_GREATER;\r\n        case SG_COMPAREFUNC_NOT_EQUAL:      return D3D11_COMPARISON_NOT_EQUAL;\r\n        case SG_COMPAREFUNC_GREATER_EQUAL:  return D3D11_COMPARISON_GREATER_EQUAL;\r\n        case SG_COMPAREFUNC_ALWAYS:         return D3D11_COMPARISON_ALWAYS;\r\n        default: SOKOL_UNREACHABLE; return (D3D11_COMPARISON_FUNC) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE D3D11_STENCIL_OP _sg_d3d11_stencil_op(sg_stencil_op op) {\r\n    switch (op) {\r\n        case SG_STENCILOP_KEEP:         return D3D11_STENCIL_OP_KEEP;\r\n        case SG_STENCILOP_ZERO:         return D3D11_STENCIL_OP_ZERO;\r\n        case SG_STENCILOP_REPLACE:      return D3D11_STENCIL_OP_REPLACE;\r\n        case SG_STENCILOP_INCR_CLAMP:   return D3D11_STENCIL_OP_INCR_SAT;\r\n        case SG_STENCILOP_DECR_CLAMP:   return D3D11_STENCIL_OP_DECR_SAT;\r\n        case SG_STENCILOP_INVERT:       return D3D11_STENCIL_OP_INVERT;\r\n        case SG_STENCILOP_INCR_WRAP:    return D3D11_STENCIL_OP_INCR;\r\n        case SG_STENCILOP_DECR_WRAP:    return D3D11_STENCIL_OP_DECR;\r\n        default: SOKOL_UNREACHABLE; return (D3D11_STENCIL_OP) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE D3D11_BLEND _sg_d3d11_blend_factor(sg_blend_factor f) {\r\n    switch (f) {\r\n        case SG_BLENDFACTOR_ZERO:                   return D3D11_BLEND_ZERO;\r\n        case SG_BLENDFACTOR_ONE:                    return D3D11_BLEND_ONE;\r\n        case SG_BLENDFACTOR_SRC_COLOR:              return D3D11_BLEND_SRC_COLOR;\r\n        case SG_BLENDFACTOR_ONE_MINUS_SRC_COLOR:    return D3D11_BLEND_INV_SRC_COLOR;\r\n        case SG_BLENDFACTOR_SRC_ALPHA:              return D3D11_BLEND_SRC_ALPHA;\r\n        case SG_BLENDFACTOR_ONE_MINUS_SRC_ALPHA:    return D3D11_BLEND_INV_SRC_ALPHA;\r\n        case SG_BLENDFACTOR_DST_COLOR:              return D3D11_BLEND_DEST_COLOR;\r\n        case SG_BLENDFACTOR_ONE_MINUS_DST_COLOR:    return D3D11_BLEND_INV_DEST_COLOR;\r\n        case SG_BLENDFACTOR_DST_ALPHA:              return D3D11_BLEND_DEST_ALPHA;\r\n        case SG_BLENDFACTOR_ONE_MINUS_DST_ALPHA:    return D3D11_BLEND_INV_DEST_ALPHA;\r\n        case SG_BLENDFACTOR_SRC_ALPHA_SATURATED:    return D3D11_BLEND_SRC_ALPHA_SAT;\r\n        case SG_BLENDFACTOR_BLEND_COLOR:            return D3D11_BLEND_BLEND_FACTOR;\r\n        case SG_BLENDFACTOR_ONE_MINUS_BLEND_COLOR:  return D3D11_BLEND_INV_BLEND_FACTOR;\r\n        case SG_BLENDFACTOR_BLEND_ALPHA:            return D3D11_BLEND_BLEND_FACTOR;\r\n        case SG_BLENDFACTOR_ONE_MINUS_BLEND_ALPHA:  return D3D11_BLEND_INV_BLEND_FACTOR;\r\n        default: SOKOL_UNREACHABLE; return (D3D11_BLEND) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE D3D11_BLEND_OP _sg_d3d11_blend_op(sg_blend_op op) {\r\n    switch (op) {\r\n        case SG_BLENDOP_ADD:                return D3D11_BLEND_OP_ADD;\r\n        case SG_BLENDOP_SUBTRACT:           return D3D11_BLEND_OP_SUBTRACT;\r\n        case SG_BLENDOP_REVERSE_SUBTRACT:   return D3D11_BLEND_OP_REV_SUBTRACT;\r\n        default: SOKOL_UNREACHABLE; return (D3D11_BLEND_OP) 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE UINT8 _sg_d3d11_color_write_mask(sg_color_mask m) {\r\n    UINT8 res = 0;\r\n    if (m & SG_COLORMASK_R) {\r\n        res |= D3D11_COLOR_WRITE_ENABLE_RED;\r\n    }\r\n    if (m & SG_COLORMASK_G) {\r\n        res |= D3D11_COLOR_WRITE_ENABLE_GREEN;\r\n    }\r\n    if (m & SG_COLORMASK_B) {\r\n        res |= D3D11_COLOR_WRITE_ENABLE_BLUE;\r\n    }\r\n    if (m & SG_COLORMASK_A) {\r\n        res |= D3D11_COLOR_WRITE_ENABLE_ALPHA;\r\n    }\r\n    return res;\r\n}\r\n\r\n/* see: https://docs.microsoft.com/en-us/windows/win32/direct3d11/overviews-direct3d-11-resources-limits#resource-limits-for-feature-level-11-hardware */\r\n_SOKOL_PRIVATE void _sg_d3d11_init_caps(void) {\r\n    _sg.backend = SG_BACKEND_D3D11;\r\n\r\n    _sg.features.instancing = true;\r\n    _sg.features.origin_top_left = true;\r\n    _sg.features.multiple_render_targets = true;\r\n    _sg.features.msaa_render_targets = true;\r\n    _sg.features.imagetype_3d = true;\r\n    _sg.features.imagetype_array = true;\r\n    _sg.features.image_clamp_to_border = true;\r\n\r\n    _sg.limits.max_image_size_2d = 16 * 1024;\r\n    _sg.limits.max_image_size_cube = 16 * 1024;\r\n    _sg.limits.max_image_size_3d = 2 * 1024;\r\n    _sg.limits.max_image_size_array = 16 * 1024;\r\n    _sg.limits.max_image_array_layers = 2 * 1024;\r\n    _sg.limits.max_vertex_attrs = SG_MAX_VERTEX_ATTRIBUTES;\r\n\r\n    /* see: https://docs.microsoft.com/en-us/windows/win32/api/d3d11/ne-d3d11-d3d11_format_support */\r\n    for (int fmt = (SG_PIXELFORMAT_NONE+1); fmt < _SG_PIXELFORMAT_NUM; fmt++) {\r\n        UINT dxgi_fmt_caps = 0;\r\n        const DXGI_FORMAT dxgi_fmt = _sg_d3d11_pixel_format((sg_pixel_format)fmt);\r\n        if (dxgi_fmt != DXGI_FORMAT_UNKNOWN) {\r\n            HRESULT hr = _sg_d3d11_CheckFormatSupport(_sg.d3d11.dev, dxgi_fmt, &dxgi_fmt_caps);\r\n            SOKOL_ASSERT(SUCCEEDED(hr) || (E_FAIL == hr));\r\n            if (!SUCCEEDED(hr)) {\r\n                dxgi_fmt_caps = 0;\r\n            }\r\n        }\r\n        sg_pixelformat_info* info = &_sg.formats[fmt];\r\n        info->sample = 0 != (dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_TEXTURE2D);\r\n        info->filter = 0 != (dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_SHADER_SAMPLE);\r\n        info->render = 0 != (dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_RENDER_TARGET);\r\n        info->blend  = 0 != (dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_BLENDABLE);\r\n        info->msaa   = 0 != (dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_MULTISAMPLE_RENDERTARGET);\r\n        info->depth  = 0 != (dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_DEPTH_STENCIL);\r\n        if (info->depth) {\r\n            info->render = true;\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_setup_backend(const sg_desc* desc) {\r\n    /* assume _sg.d3d11 already is zero-initialized */\r\n    SOKOL_ASSERT(desc);\r\n    SOKOL_ASSERT(desc->context.d3d11.device);\r\n    SOKOL_ASSERT(desc->context.d3d11.device_context);\r\n    SOKOL_ASSERT(desc->context.d3d11.render_target_view_cb || desc->context.d3d11.render_target_view_userdata_cb);\r\n    SOKOL_ASSERT(desc->context.d3d11.depth_stencil_view_cb || desc->context.d3d11.depth_stencil_view_userdata_cb);\r\n    _sg.d3d11.valid = true;\r\n    _sg.d3d11.dev = (ID3D11Device*) desc->context.d3d11.device;\r\n    _sg.d3d11.ctx = (ID3D11DeviceContext*) desc->context.d3d11.device_context;\r\n    _sg.d3d11.rtv_cb = desc->context.d3d11.render_target_view_cb;\r\n    _sg.d3d11.rtv_userdata_cb = desc->context.d3d11.render_target_view_userdata_cb;\r\n    _sg.d3d11.dsv_cb = desc->context.d3d11.depth_stencil_view_cb;\r\n    _sg.d3d11.dsv_userdata_cb = desc->context.d3d11.depth_stencil_view_userdata_cb;\r\n    _sg.d3d11.user_data = desc->context.d3d11.user_data;\r\n    _sg_d3d11_init_caps();\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_discard_backend(void) {\r\n    SOKOL_ASSERT(_sg.d3d11.valid);\r\n    _sg.d3d11.valid = false;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_clear_state(void) {\r\n    /* clear all the device context state, so that resource refs don't keep stuck in the d3d device context */\r\n    _sg_d3d11_OMSetRenderTargets(_sg.d3d11.ctx, SG_MAX_COLOR_ATTACHMENTS, _sg.d3d11.zero_rtvs, NULL);\r\n    _sg_d3d11_RSSetState(_sg.d3d11.ctx, NULL);\r\n    _sg_d3d11_OMSetDepthStencilState(_sg.d3d11.ctx, NULL, 0);\r\n    _sg_d3d11_OMSetBlendState(_sg.d3d11.ctx, NULL, NULL, 0xFFFFFFFF);\r\n    _sg_d3d11_IASetVertexBuffers(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_BUFFERS, _sg.d3d11.zero_vbs, _sg.d3d11.zero_vb_strides, _sg.d3d11.zero_vb_offsets);\r\n    _sg_d3d11_IASetIndexBuffer(_sg.d3d11.ctx, NULL, DXGI_FORMAT_UNKNOWN, 0);\r\n    _sg_d3d11_IASetInputLayout(_sg.d3d11.ctx, NULL);\r\n    _sg_d3d11_VSSetShader(_sg.d3d11.ctx, NULL, NULL, 0);\r\n    _sg_d3d11_PSSetShader(_sg.d3d11.ctx, NULL, NULL, 0);\r\n    _sg_d3d11_VSSetConstantBuffers(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_UBS, _sg.d3d11.zero_cbs);\r\n    _sg_d3d11_PSSetConstantBuffers(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_UBS, _sg.d3d11.zero_cbs);\r\n    _sg_d3d11_VSSetShaderResources(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_IMAGES, _sg.d3d11.zero_srvs);\r\n    _sg_d3d11_PSSetShaderResources(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_IMAGES, _sg.d3d11.zero_srvs);\r\n    _sg_d3d11_VSSetSamplers(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_IMAGES, _sg.d3d11.zero_smps);\r\n    _sg_d3d11_PSSetSamplers(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_IMAGES, _sg.d3d11.zero_smps);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_reset_state_cache(void) {\r\n    /* just clear the d3d11 device context state */\r\n    _sg_d3d11_clear_state();\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_activate_context(_sg_context_t* ctx) {\r\n    _SOKOL_UNUSED(ctx);\r\n    _sg_d3d11_clear_state();\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    _SOKOL_UNUSED(ctx);\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_destroy_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    _SOKOL_UNUSED(ctx);\r\n    /* empty */\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {\r\n    SOKOL_ASSERT(buf && desc);\r\n    SOKOL_ASSERT(!buf->d3d11.buf);\r\n    _sg_buffer_common_init(&buf->cmn, desc);\r\n    const bool injected = (0 != desc->d3d11_buffer);\r\n    if (injected) {\r\n        buf->d3d11.buf = (ID3D11Buffer*) desc->d3d11_buffer;\r\n        _sg_d3d11_AddRef(buf->d3d11.buf);\r\n    }\r\n    else {\r\n        D3D11_BUFFER_DESC d3d11_desc;\r\n        memset(&d3d11_desc, 0, sizeof(d3d11_desc));\r\n        d3d11_desc.ByteWidth = buf->cmn.size;\r\n        d3d11_desc.Usage = _sg_d3d11_usage(buf->cmn.usage);\r\n        d3d11_desc.BindFlags = buf->cmn.type == SG_BUFFERTYPE_VERTEXBUFFER ? D3D11_BIND_VERTEX_BUFFER : D3D11_BIND_INDEX_BUFFER;\r\n        d3d11_desc.CPUAccessFlags = _sg_d3d11_cpu_access_flags(buf->cmn.usage);\r\n        D3D11_SUBRESOURCE_DATA* init_data_ptr = 0;\r\n        D3D11_SUBRESOURCE_DATA init_data;\r\n        memset(&init_data, 0, sizeof(init_data));\r\n        if (buf->cmn.usage == SG_USAGE_IMMUTABLE) {\r\n            SOKOL_ASSERT(desc->content);\r\n            init_data.pSysMem = desc->content;\r\n            init_data_ptr = &init_data;\r\n        }\r\n        HRESULT hr = _sg_d3d11_CreateBuffer(_sg.d3d11.dev, &d3d11_desc, init_data_ptr, &buf->d3d11.buf);\r\n        _SOKOL_UNUSED(hr);\r\n        SOKOL_ASSERT(SUCCEEDED(hr) && buf->d3d11.buf);\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_destroy_buffer(_sg_buffer_t* buf) {\r\n    SOKOL_ASSERT(buf);\r\n    if (buf->d3d11.buf) {\r\n        _sg_d3d11_Release(buf->d3d11.buf);\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_fill_subres_data(const _sg_image_t* img, const sg_image_content* content) {\r\n    const int num_faces = (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6:1;\r\n    const int num_slices = (img->cmn.type == SG_IMAGETYPE_ARRAY) ? img->cmn.depth:1;\r\n    int subres_index = 0;\r\n    for (int face_index = 0; face_index < num_faces; face_index++) {\r\n        for (int slice_index = 0; slice_index < num_slices; slice_index++) {\r\n            for (int mip_index = 0; mip_index < img->cmn.num_mipmaps; mip_index++, subres_index++) {\r\n                SOKOL_ASSERT(subres_index < (SG_MAX_MIPMAPS * SG_MAX_TEXTUREARRAY_LAYERS));\r\n                D3D11_SUBRESOURCE_DATA* subres_data = &_sg.d3d11.subres_data[subres_index];\r\n                const int mip_width = ((img->cmn.width>>mip_index)>0) ? img->cmn.width>>mip_index : 1;\r\n                const int mip_height = ((img->cmn.height>>mip_index)>0) ? img->cmn.height>>mip_index : 1;\r\n                const sg_subimage_content* subimg_content = &(content->subimage[face_index][mip_index]);\r\n                const int slice_size = subimg_content->size / num_slices;\r\n                const int slice_offset = slice_size * slice_index;\r\n                const uint8_t* ptr = (const uint8_t*) subimg_content->ptr;\r\n                subres_data->pSysMem = ptr + slice_offset;\r\n                subres_data->SysMemPitch = _sg_row_pitch(img->cmn.pixel_format, mip_width, 1);\r\n                if (img->cmn.type == SG_IMAGETYPE_3D) {\r\n                    /* FIXME? const int mip_depth = ((img->depth>>mip_index)>0) ? img->depth>>mip_index : 1; */\r\n                    subres_data->SysMemSlicePitch = _sg_surface_pitch(img->cmn.pixel_format, mip_width, mip_height, 1);\r\n                }\r\n                else {\r\n                    subres_data->SysMemSlicePitch = 0;\r\n                }\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_image(_sg_image_t* img, const sg_image_desc* desc) {\r\n    SOKOL_ASSERT(img && desc);\r\n    SOKOL_ASSERT(!img->d3d11.tex2d && !img->d3d11.tex3d && !img->d3d11.texds && !img->d3d11.texmsaa);\r\n    SOKOL_ASSERT(!img->d3d11.srv && !img->d3d11.smp);\r\n    HRESULT hr;\r\n    _SOKOL_UNUSED(hr);\r\n\r\n    _sg_image_common_init(&img->cmn, desc);\r\n    const bool injected = (0 != desc->d3d11_texture);\r\n    const bool msaa = (img->cmn.sample_count > 1);\r\n\r\n    /* special case depth-stencil buffer? */\r\n    if (_sg_is_valid_rendertarget_depth_format(img->cmn.pixel_format)) {\r\n        /* create only a depth-texture */\r\n        SOKOL_ASSERT(!injected);\r\n        img->d3d11.format = _sg_d3d11_pixel_format(img->cmn.pixel_format);\r\n        if (img->d3d11.format == DXGI_FORMAT_UNKNOWN) {\r\n            SOKOL_LOG(\"trying to create a D3D11 depth-texture with unsupported pixel format\\n\");\r\n            return SG_RESOURCESTATE_FAILED;\r\n        }\r\n        D3D11_TEXTURE2D_DESC d3d11_desc;\r\n        memset(&d3d11_desc, 0, sizeof(d3d11_desc));\r\n        d3d11_desc.Width = img->cmn.width;\r\n        d3d11_desc.Height = img->cmn.height;\r\n        d3d11_desc.MipLevels = 1;\r\n        d3d11_desc.ArraySize = 1;\r\n        d3d11_desc.Format = img->d3d11.format;\r\n        d3d11_desc.Usage = D3D11_USAGE_DEFAULT;\r\n        d3d11_desc.BindFlags = D3D11_BIND_DEPTH_STENCIL;\r\n        d3d11_desc.SampleDesc.Count = img->cmn.sample_count;\r\n        d3d11_desc.SampleDesc.Quality = msaa ? D3D11_STANDARD_MULTISAMPLE_PATTERN : 0;\r\n        hr = _sg_d3d11_CreateTexture2D(_sg.d3d11.dev, &d3d11_desc, NULL, &img->d3d11.texds);\r\n        SOKOL_ASSERT(SUCCEEDED(hr) && img->d3d11.texds);\r\n    }\r\n    else {\r\n        /* create (or inject) color texture */\r\n\r\n        /* prepare initial content pointers */\r\n        D3D11_SUBRESOURCE_DATA* init_data = 0;\r\n        if (!injected && (img->cmn.usage == SG_USAGE_IMMUTABLE) && !img->cmn.render_target) {\r\n            _sg_d3d11_fill_subres_data(img, &desc->content);\r\n            init_data = _sg.d3d11.subres_data;\r\n        }\r\n        if (img->cmn.type != SG_IMAGETYPE_3D) {\r\n            /* 2D-, cube- or array-texture */\r\n            /* if this is an MSAA render target, the following texture will be the 'resolve-texture' */\r\n            D3D11_TEXTURE2D_DESC d3d11_tex_desc;\r\n            memset(&d3d11_tex_desc, 0, sizeof(d3d11_tex_desc));\r\n            d3d11_tex_desc.Width = img->cmn.width;\r\n            d3d11_tex_desc.Height = img->cmn.height;\r\n            d3d11_tex_desc.MipLevels = img->cmn.num_mipmaps;\r\n            switch (img->cmn.type) {\r\n                case SG_IMAGETYPE_ARRAY:    d3d11_tex_desc.ArraySize = img->cmn.depth; break;\r\n                case SG_IMAGETYPE_CUBE:     d3d11_tex_desc.ArraySize = 6; break;\r\n                default:                    d3d11_tex_desc.ArraySize = 1; break;\r\n            }\r\n            d3d11_tex_desc.BindFlags = D3D11_BIND_SHADER_RESOURCE;\r\n            if (img->cmn.render_target) {\r\n                img->d3d11.format = _sg_d3d11_pixel_format(img->cmn.pixel_format);\r\n                d3d11_tex_desc.Format = img->d3d11.format;\r\n                d3d11_tex_desc.Usage = D3D11_USAGE_DEFAULT;\r\n                if (!msaa) {\r\n                    d3d11_tex_desc.BindFlags |= D3D11_BIND_RENDER_TARGET;\r\n                }\r\n                d3d11_tex_desc.CPUAccessFlags = 0;\r\n            }\r\n            else {\r\n                img->d3d11.format = _sg_d3d11_pixel_format(img->cmn.pixel_format);\r\n                d3d11_tex_desc.Format = img->d3d11.format;\r\n                d3d11_tex_desc.Usage = _sg_d3d11_usage(img->cmn.usage);\r\n                d3d11_tex_desc.CPUAccessFlags = _sg_d3d11_cpu_access_flags(img->cmn.usage);\r\n            }\r\n            if (img->d3d11.format == DXGI_FORMAT_UNKNOWN) {\r\n                /* trying to create a texture format that's not supported by D3D */\r\n                SOKOL_LOG(\"trying to create a D3D11 texture with unsupported pixel format\\n\");\r\n                return SG_RESOURCESTATE_FAILED;\r\n            }\r\n            d3d11_tex_desc.SampleDesc.Count = 1;\r\n            d3d11_tex_desc.SampleDesc.Quality = 0;\r\n            d3d11_tex_desc.MiscFlags = (img->cmn.type == SG_IMAGETYPE_CUBE) ? D3D11_RESOURCE_MISC_TEXTURECUBE : 0;\r\n            if (injected) {\r\n                img->d3d11.tex2d = (ID3D11Texture2D*) desc->d3d11_texture;\r\n                _sg_d3d11_AddRef(img->d3d11.tex2d);\r\n            }\r\n            else {\r\n                hr = _sg_d3d11_CreateTexture2D(_sg.d3d11.dev, &d3d11_tex_desc, init_data, &img->d3d11.tex2d);\r\n                SOKOL_ASSERT(SUCCEEDED(hr) && img->d3d11.tex2d);\r\n            }\r\n\r\n            /* shader-resource-view */\r\n            D3D11_SHADER_RESOURCE_VIEW_DESC d3d11_srv_desc;\r\n            memset(&d3d11_srv_desc, 0, sizeof(d3d11_srv_desc));\r\n            d3d11_srv_desc.Format = d3d11_tex_desc.Format;\r\n            switch (img->cmn.type) {\r\n                case SG_IMAGETYPE_2D:\r\n                    d3d11_srv_desc.ViewDimension = D3D11_SRV_DIMENSION_TEXTURE2D;\r\n                    d3d11_srv_desc.Texture2D.MipLevels = img->cmn.num_mipmaps;\r\n                    break;\r\n                case SG_IMAGETYPE_CUBE:\r\n                    d3d11_srv_desc.ViewDimension = D3D11_SRV_DIMENSION_TEXTURECUBE;\r\n                    d3d11_srv_desc.TextureCube.MipLevels = img->cmn.num_mipmaps;\r\n                    break;\r\n                case SG_IMAGETYPE_ARRAY:\r\n                    d3d11_srv_desc.ViewDimension = D3D11_SRV_DIMENSION_TEXTURE2DARRAY;\r\n                    d3d11_srv_desc.Texture2DArray.MipLevels = img->cmn.num_mipmaps;\r\n                    d3d11_srv_desc.Texture2DArray.ArraySize = img->cmn.depth;\r\n                    break;\r\n                default:\r\n                    SOKOL_UNREACHABLE; break;\r\n            }\r\n            hr = _sg_d3d11_CreateShaderResourceView(_sg.d3d11.dev, (ID3D11Resource*)img->d3d11.tex2d, &d3d11_srv_desc, &img->d3d11.srv);\r\n            SOKOL_ASSERT(SUCCEEDED(hr) && img->d3d11.srv);\r\n        }\r\n        else {\r\n            /* 3D texture */\r\n            D3D11_TEXTURE3D_DESC d3d11_tex_desc;\r\n            memset(&d3d11_tex_desc, 0, sizeof(d3d11_tex_desc));\r\n            d3d11_tex_desc.Width = img->cmn.width;\r\n            d3d11_tex_desc.Height = img->cmn.height;\r\n            d3d11_tex_desc.Depth = img->cmn.depth;\r\n            d3d11_tex_desc.MipLevels = img->cmn.num_mipmaps;\r\n            d3d11_tex_desc.BindFlags = D3D11_BIND_SHADER_RESOURCE;\r\n            if (img->cmn.render_target) {\r\n                img->d3d11.format = _sg_d3d11_pixel_format(img->cmn.pixel_format);\r\n                d3d11_tex_desc.Format = img->d3d11.format;\r\n                d3d11_tex_desc.Usage = D3D11_USAGE_DEFAULT;\r\n                if (!msaa) {\r\n                    d3d11_tex_desc.BindFlags |= D3D11_BIND_RENDER_TARGET;\r\n                }\r\n                d3d11_tex_desc.CPUAccessFlags = 0;\r\n            }\r\n            else {\r\n                img->d3d11.format = _sg_d3d11_pixel_format(img->cmn.pixel_format);\r\n                d3d11_tex_desc.Format = img->d3d11.format;\r\n                d3d11_tex_desc.Usage = _sg_d3d11_usage(img->cmn.usage);\r\n                d3d11_tex_desc.CPUAccessFlags = _sg_d3d11_cpu_access_flags(img->cmn.usage);\r\n            }\r\n            if (img->d3d11.format == DXGI_FORMAT_UNKNOWN) {\r\n                /* trying to create a texture format that's not supported by D3D */\r\n                SOKOL_LOG(\"trying to create a D3D11 texture with unsupported pixel format\\n\");\r\n                return SG_RESOURCESTATE_FAILED;\r\n            }\r\n            if (injected) {\r\n                img->d3d11.tex3d = (ID3D11Texture3D*) desc->d3d11_texture;\r\n                _sg_d3d11_AddRef(img->d3d11.tex3d);\r\n            }\r\n            else {\r\n                hr = _sg_d3d11_CreateTexture3D(_sg.d3d11.dev, &d3d11_tex_desc, init_data, &img->d3d11.tex3d);\r\n                SOKOL_ASSERT(SUCCEEDED(hr) && img->d3d11.tex3d);\r\n            }\r\n\r\n            /* shader resource view for 3d texture */\r\n            D3D11_SHADER_RESOURCE_VIEW_DESC d3d11_srv_desc;\r\n            memset(&d3d11_srv_desc, 0, sizeof(d3d11_srv_desc));\r\n            d3d11_srv_desc.Format = d3d11_tex_desc.Format;\r\n            d3d11_srv_desc.ViewDimension = D3D11_SRV_DIMENSION_TEXTURE3D;\r\n            d3d11_srv_desc.Texture3D.MipLevels = img->cmn.num_mipmaps;\r\n            hr = _sg_d3d11_CreateShaderResourceView(_sg.d3d11.dev, (ID3D11Resource*)img->d3d11.tex3d, &d3d11_srv_desc, &img->d3d11.srv);\r\n            SOKOL_ASSERT(SUCCEEDED(hr) && img->d3d11.srv);\r\n        }\r\n\r\n        /* also need to create a separate MSAA render target texture? */\r\n        if (msaa) {\r\n            D3D11_TEXTURE2D_DESC d3d11_tex_desc;\r\n            memset(&d3d11_tex_desc, 0, sizeof(d3d11_tex_desc));\r\n            d3d11_tex_desc.Width = img->cmn.width;\r\n            d3d11_tex_desc.Height = img->cmn.height;\r\n            d3d11_tex_desc.MipLevels = 1;\r\n            d3d11_tex_desc.ArraySize = 1;\r\n            d3d11_tex_desc.Format = img->d3d11.format;\r\n            d3d11_tex_desc.Usage = D3D11_USAGE_DEFAULT;\r\n            d3d11_tex_desc.BindFlags = D3D11_BIND_RENDER_TARGET;\r\n            d3d11_tex_desc.CPUAccessFlags = 0;\r\n            d3d11_tex_desc.SampleDesc.Count = img->cmn.sample_count;\r\n            d3d11_tex_desc.SampleDesc.Quality = (UINT)D3D11_STANDARD_MULTISAMPLE_PATTERN;\r\n            hr = _sg_d3d11_CreateTexture2D(_sg.d3d11.dev, &d3d11_tex_desc, NULL, &img->d3d11.texmsaa);\r\n            SOKOL_ASSERT(SUCCEEDED(hr) && img->d3d11.texmsaa);\r\n        }\r\n\r\n        /* sampler state object, note D3D11 implements an internal shared-pool for sampler objects */\r\n        D3D11_SAMPLER_DESC d3d11_smp_desc;\r\n        memset(&d3d11_smp_desc, 0, sizeof(d3d11_smp_desc));\r\n        d3d11_smp_desc.Filter = _sg_d3d11_filter(img->cmn.min_filter, img->cmn.mag_filter, img->cmn.max_anisotropy);\r\n        d3d11_smp_desc.AddressU = _sg_d3d11_address_mode(img->cmn.wrap_u);\r\n        d3d11_smp_desc.AddressV = _sg_d3d11_address_mode(img->cmn.wrap_v);\r\n        d3d11_smp_desc.AddressW = _sg_d3d11_address_mode(img->cmn.wrap_w);\r\n        switch (img->cmn.border_color) {\r\n            case SG_BORDERCOLOR_TRANSPARENT_BLACK:\r\n                /* all 0.0f */\r\n                break;\r\n            case SG_BORDERCOLOR_OPAQUE_WHITE:\r\n                for (int i = 0; i < 4; i++) {\r\n                    d3d11_smp_desc.BorderColor[i] = 1.0f;\r\n                }\r\n                break;\r\n            default:\r\n                /* opaque black */\r\n                d3d11_smp_desc.BorderColor[3] = 1.0f;\r\n                break;\r\n        }\r\n        d3d11_smp_desc.MaxAnisotropy = img->cmn.max_anisotropy;\r\n        d3d11_smp_desc.ComparisonFunc = D3D11_COMPARISON_NEVER;\r\n        d3d11_smp_desc.MinLOD = desc->min_lod;\r\n        d3d11_smp_desc.MaxLOD = desc->max_lod;\r\n        hr = _sg_d3d11_CreateSamplerState(_sg.d3d11.dev, &d3d11_smp_desc, &img->d3d11.smp);\r\n        SOKOL_ASSERT(SUCCEEDED(hr) && img->d3d11.smp);\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_destroy_image(_sg_image_t* img) {\r\n    SOKOL_ASSERT(img);\r\n    if (img->d3d11.tex2d) {\r\n        _sg_d3d11_Release(img->d3d11.tex2d);\r\n    }\r\n    if (img->d3d11.tex3d) {\r\n        _sg_d3d11_Release(img->d3d11.tex3d);\r\n    }\r\n    if (img->d3d11.texds) {\r\n        _sg_d3d11_Release(img->d3d11.texds);\r\n    }\r\n    if (img->d3d11.texmsaa) {\r\n        _sg_d3d11_Release(img->d3d11.texmsaa);\r\n    }\r\n    if (img->d3d11.srv) {\r\n        _sg_d3d11_Release(img->d3d11.srv);\r\n    }\r\n    if (img->d3d11.smp) {\r\n        _sg_d3d11_Release(img->d3d11.smp);\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_d3d11_load_d3dcompiler_dll(void) {\r\n    /* on UWP, don't do anything (not tested) */\r\n    #if (defined(WINAPI_FAMILY_PARTITION) && !WINAPI_FAMILY_PARTITION(WINAPI_PARTITION_DESKTOP))\r\n        return true;\r\n    #else\r\n        /* load DLL on demand */\r\n        if ((0 == _sg.d3d11.d3dcompiler_dll) && !_sg.d3d11.d3dcompiler_dll_load_failed) {\r\n            _sg.d3d11.d3dcompiler_dll = LoadLibraryA(\"d3dcompiler_47.dll\");\r\n            if (0 == _sg.d3d11.d3dcompiler_dll) {\r\n                /* don't attempt to load missing DLL in the future */\r\n                SOKOL_LOG(\"failed to load d3dcompiler_47.dll!\\n\");\r\n                _sg.d3d11.d3dcompiler_dll_load_failed = true;\r\n                return false;\r\n            }\r\n            /* look up function pointers */\r\n            _sg.d3d11.D3DCompile_func = (pD3DCompile) GetProcAddress(_sg.d3d11.d3dcompiler_dll, \"D3DCompile\");\r\n            SOKOL_ASSERT(_sg.d3d11.D3DCompile_func);\r\n        }\r\n        return 0 != _sg.d3d11.d3dcompiler_dll;\r\n    #endif\r\n}\r\n\r\n#if (defined(WINAPI_FAMILY_PARTITION) && !WINAPI_FAMILY_PARTITION(WINAPI_PARTITION_DESKTOP))\r\n#define _sg_d3d11_D3DCompile D3DCompile\r\n#else\r\n#define _sg_d3d11_D3DCompile _sg.d3d11.D3DCompile_func\r\n#endif\r\n\r\n_SOKOL_PRIVATE ID3DBlob* _sg_d3d11_compile_shader(const sg_shader_stage_desc* stage_desc) {\r\n    if (!_sg_d3d11_load_d3dcompiler_dll()) {\r\n        return NULL;\r\n    }\r\n    SOKOL_ASSERT(stage_desc->d3d11_target);\r\n    ID3DBlob* output = NULL;\r\n    ID3DBlob* errors_or_warnings = NULL;\r\n    HRESULT hr = _sg_d3d11_D3DCompile(\r\n        stage_desc->source,             /* pSrcData */\r\n        strlen(stage_desc->source),     /* SrcDataSize */\r\n        NULL,                           /* pSourceName */\r\n        NULL,                           /* pDefines */\r\n        NULL,                           /* pInclude */\r\n        stage_desc->entry ? stage_desc->entry : \"main\",     /* pEntryPoint */\r\n        stage_desc->d3d11_target,       /* pTarget (vs_5_0 or ps_5_0) */\r\n        D3DCOMPILE_PACK_MATRIX_COLUMN_MAJOR | D3DCOMPILE_OPTIMIZATION_LEVEL3,   /* Flags1 */\r\n        0,          /* Flags2 */\r\n        &output,    /* ppCode */\r\n        &errors_or_warnings);   /* ppErrorMsgs */\r\n    if (errors_or_warnings) {\r\n        SOKOL_LOG((LPCSTR)_sg_d3d11_GetBufferPointer(errors_or_warnings));\r\n        _sg_d3d11_Release(errors_or_warnings); errors_or_warnings = NULL;\r\n    }\r\n    if (FAILED(hr)) {\r\n        /* just in case, usually output is NULL here */\r\n        if (output) {\r\n            _sg_d3d11_Release(output);\r\n            output = NULL;\r\n        }\r\n    }\r\n    return output;\r\n}\r\n\r\n#define _sg_d3d11_roundup(val, round_to) (((val)+((round_to)-1))&~((round_to)-1))\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {\r\n    SOKOL_ASSERT(shd && desc);\r\n    SOKOL_ASSERT(!shd->d3d11.vs && !shd->d3d11.fs && !shd->d3d11.vs_blob);\r\n    HRESULT hr;\r\n    _SOKOL_UNUSED(hr);\r\n\r\n    _sg_shader_common_init(&shd->cmn, desc);\r\n\r\n    /* copy vertex attribute semantic names and indices */\r\n    for (int i = 0; i < SG_MAX_VERTEX_ATTRIBUTES; i++) {\r\n        _sg_strcpy(&shd->d3d11.attrs[i].sem_name, desc->attrs[i].sem_name);\r\n        shd->d3d11.attrs[i].sem_index = desc->attrs[i].sem_index;\r\n    }\r\n\r\n    /* shader stage uniform blocks and image slots */\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        _sg_shader_stage_t* cmn_stage = &shd->cmn.stage[stage_index];\r\n        _sg_d3d11_shader_stage_t* d3d11_stage = &shd->d3d11.stage[stage_index];\r\n        for (int ub_index = 0; ub_index < cmn_stage->num_uniform_blocks; ub_index++) {\r\n            const _sg_uniform_block_t* ub = &cmn_stage->uniform_blocks[ub_index];\r\n\r\n            /* create a D3D constant buffer for each uniform block */\r\n            SOKOL_ASSERT(0 == d3d11_stage->cbufs[ub_index]);\r\n            D3D11_BUFFER_DESC cb_desc;\r\n            memset(&cb_desc, 0, sizeof(cb_desc));\r\n            cb_desc.ByteWidth = _sg_d3d11_roundup(ub->size, 16);\r\n            cb_desc.Usage = D3D11_USAGE_DEFAULT;\r\n            cb_desc.BindFlags = D3D11_BIND_CONSTANT_BUFFER;\r\n            hr = _sg_d3d11_CreateBuffer(_sg.d3d11.dev, &cb_desc, NULL, &d3d11_stage->cbufs[ub_index]);\r\n            SOKOL_ASSERT(SUCCEEDED(hr) && d3d11_stage->cbufs[ub_index]);\r\n        }\r\n    }\r\n\r\n    const void* vs_ptr = 0, *fs_ptr = 0;\r\n    SIZE_T vs_length = 0, fs_length = 0;\r\n    ID3DBlob* vs_blob = 0, *fs_blob = 0;\r\n    if (desc->vs.byte_code && desc->fs.byte_code) {\r\n        /* create from shader byte code */\r\n        vs_ptr = desc->vs.byte_code;\r\n        fs_ptr = desc->fs.byte_code;\r\n        vs_length = desc->vs.byte_code_size;\r\n        fs_length = desc->fs.byte_code_size;\r\n    }\r\n    else {\r\n        /* compile from shader source code */\r\n        vs_blob = _sg_d3d11_compile_shader(&desc->vs);\r\n        fs_blob = _sg_d3d11_compile_shader(&desc->fs);\r\n        if (vs_blob && fs_blob) {\r\n            vs_ptr = _sg_d3d11_GetBufferPointer(vs_blob);\r\n            vs_length = _sg_d3d11_GetBufferSize(vs_blob);\r\n            fs_ptr = _sg_d3d11_GetBufferPointer(fs_blob);\r\n            fs_length = _sg_d3d11_GetBufferSize(fs_blob);\r\n        }\r\n    }\r\n    sg_resource_state result = SG_RESOURCESTATE_FAILED;\r\n    if (vs_ptr && fs_ptr && (vs_length > 0) && (fs_length > 0)) {\r\n        /* create the D3D vertex- and pixel-shader objects */\r\n        hr = _sg_d3d11_CreateVertexShader(_sg.d3d11.dev, vs_ptr, vs_length, NULL, &shd->d3d11.vs);\r\n        bool vs_succeeded = SUCCEEDED(hr) && shd->d3d11.vs;\r\n        hr = _sg_d3d11_CreatePixelShader(_sg.d3d11.dev, fs_ptr, fs_length, NULL, &shd->d3d11.fs);\r\n        bool fs_succeeded = SUCCEEDED(hr) && shd->d3d11.fs;\r\n\r\n        /* need to store the vertex shader byte code, this is needed later in sg_create_pipeline */\r\n        if (vs_succeeded && fs_succeeded) {\r\n            shd->d3d11.vs_blob_length = (int)vs_length;\r\n            shd->d3d11.vs_blob = SOKOL_MALLOC((int)vs_length);\r\n            SOKOL_ASSERT(shd->d3d11.vs_blob);\r\n            memcpy(shd->d3d11.vs_blob, vs_ptr, vs_length);\r\n            result = SG_RESOURCESTATE_VALID;\r\n        }\r\n    }\r\n    if (vs_blob) {\r\n        _sg_d3d11_Release(vs_blob); vs_blob = 0;\r\n    }\r\n    if (fs_blob) {\r\n        _sg_d3d11_Release(fs_blob); fs_blob = 0;\r\n    }\r\n    return result;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_destroy_shader(_sg_shader_t* shd) {\r\n    SOKOL_ASSERT(shd);\r\n    if (shd->d3d11.vs) {\r\n        _sg_d3d11_Release(shd->d3d11.vs);\r\n    }\r\n    if (shd->d3d11.fs) {\r\n        _sg_d3d11_Release(shd->d3d11.fs);\r\n    }\r\n    if (shd->d3d11.vs_blob) {\r\n        SOKOL_FREE(shd->d3d11.vs_blob);\r\n    }\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        _sg_shader_stage_t* cmn_stage = &shd->cmn.stage[stage_index];\r\n        _sg_d3d11_shader_stage_t* d3d11_stage = &shd->d3d11.stage[stage_index];\r\n        for (int ub_index = 0; ub_index < cmn_stage->num_uniform_blocks; ub_index++) {\r\n            if (d3d11_stage->cbufs[ub_index]) {\r\n                _sg_d3d11_Release(d3d11_stage->cbufs[ub_index]);\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {\r\n    SOKOL_ASSERT(pip && shd && desc);\r\n    SOKOL_ASSERT(desc->shader.id == shd->slot.id);\r\n    SOKOL_ASSERT(shd->slot.state == SG_RESOURCESTATE_VALID);\r\n    SOKOL_ASSERT(shd->d3d11.vs_blob && shd->d3d11.vs_blob_length > 0);\r\n    SOKOL_ASSERT(!pip->d3d11.il && !pip->d3d11.rs && !pip->d3d11.dss && !pip->d3d11.bs);\r\n\r\n    pip->shader = shd;\r\n    _sg_pipeline_common_init(&pip->cmn, desc);\r\n    pip->d3d11.index_format = _sg_d3d11_index_format(pip->cmn.index_type);\r\n    pip->d3d11.topology = _sg_d3d11_primitive_topology(desc->primitive_type);\r\n    pip->d3d11.stencil_ref = desc->depth_stencil.stencil_ref;\r\n\r\n    /* create input layout object */\r\n    HRESULT hr;\r\n    _SOKOL_UNUSED(hr);\r\n    D3D11_INPUT_ELEMENT_DESC d3d11_comps[SG_MAX_VERTEX_ATTRIBUTES];\r\n    memset(d3d11_comps, 0, sizeof(d3d11_comps));\r\n    int attr_index = 0;\r\n    for (; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {\r\n        const sg_vertex_attr_desc* a_desc = &desc->layout.attrs[attr_index];\r\n        if (a_desc->format == SG_VERTEXFORMAT_INVALID) {\r\n            break;\r\n        }\r\n        SOKOL_ASSERT((a_desc->buffer_index >= 0) && (a_desc->buffer_index < SG_MAX_SHADERSTAGE_BUFFERS));\r\n        const sg_buffer_layout_desc* l_desc = &desc->layout.buffers[a_desc->buffer_index];\r\n        const sg_vertex_step step_func = l_desc->step_func;\r\n        const int step_rate = l_desc->step_rate;\r\n        D3D11_INPUT_ELEMENT_DESC* d3d11_comp = &d3d11_comps[attr_index];\r\n        d3d11_comp->SemanticName = _sg_strptr(&shd->d3d11.attrs[attr_index].sem_name);\r\n        d3d11_comp->SemanticIndex = shd->d3d11.attrs[attr_index].sem_index;\r\n        d3d11_comp->Format = _sg_d3d11_vertex_format(a_desc->format);\r\n        d3d11_comp->InputSlot = a_desc->buffer_index;\r\n        d3d11_comp->AlignedByteOffset = a_desc->offset;\r\n        d3d11_comp->InputSlotClass = _sg_d3d11_input_classification(step_func);\r\n        if (SG_VERTEXSTEP_PER_INSTANCE == step_func) {\r\n            d3d11_comp->InstanceDataStepRate = step_rate;\r\n        }\r\n        pip->cmn.vertex_layout_valid[a_desc->buffer_index] = true;\r\n    }\r\n    for (int layout_index = 0; layout_index < SG_MAX_SHADERSTAGE_BUFFERS; layout_index++) {\r\n        if (pip->cmn.vertex_layout_valid[layout_index]) {\r\n            const sg_buffer_layout_desc* l_desc = &desc->layout.buffers[layout_index];\r\n            SOKOL_ASSERT(l_desc->stride > 0);\r\n            pip->d3d11.vb_strides[layout_index] = l_desc->stride;\r\n        }\r\n        else {\r\n            pip->d3d11.vb_strides[layout_index] = 0;\r\n        }\r\n    }\r\n    hr = _sg_d3d11_CreateInputLayout(_sg.d3d11.dev,\r\n        d3d11_comps,                /* pInputElementDesc */\r\n        attr_index,                 /* NumElements */\r\n        shd->d3d11.vs_blob,         /* pShaderByteCodeWithInputSignature */\r\n        shd->d3d11.vs_blob_length,  /* BytecodeLength */\r\n        &pip->d3d11.il);\r\n    SOKOL_ASSERT(SUCCEEDED(hr) && pip->d3d11.il);\r\n\r\n    /* create rasterizer state */\r\n    D3D11_RASTERIZER_DESC rs_desc;\r\n    memset(&rs_desc, 0, sizeof(rs_desc));\r\n    rs_desc.FillMode = D3D11_FILL_SOLID;\r\n    rs_desc.CullMode = _sg_d3d11_cull_mode(desc->rasterizer.cull_mode);\r\n    rs_desc.FrontCounterClockwise = desc->rasterizer.face_winding == SG_FACEWINDING_CCW;\r\n    rs_desc.DepthBias = (INT) pip->cmn.depth_bias;\r\n    rs_desc.DepthBiasClamp = pip->cmn.depth_bias_clamp;\r\n    rs_desc.SlopeScaledDepthBias = pip->cmn.depth_bias_slope_scale;\r\n    rs_desc.DepthClipEnable = TRUE;\r\n    rs_desc.ScissorEnable = TRUE;\r\n    rs_desc.MultisampleEnable = desc->rasterizer.sample_count > 1;\r\n    rs_desc.AntialiasedLineEnable = FALSE;\r\n    hr = _sg_d3d11_CreateRasterizerState(_sg.d3d11.dev, &rs_desc, &pip->d3d11.rs);\r\n    SOKOL_ASSERT(SUCCEEDED(hr) && pip->d3d11.rs);\r\n\r\n    /* create depth-stencil state */\r\n    D3D11_DEPTH_STENCIL_DESC dss_desc;\r\n    memset(&dss_desc, 0, sizeof(dss_desc));\r\n    dss_desc.DepthEnable = TRUE;\r\n    dss_desc.DepthWriteMask = desc->depth_stencil.depth_write_enabled ? D3D11_DEPTH_WRITE_MASK_ALL : D3D11_DEPTH_WRITE_MASK_ZERO;\r\n    dss_desc.DepthFunc = _sg_d3d11_compare_func(desc->depth_stencil.depth_compare_func);\r\n    dss_desc.StencilEnable = desc->depth_stencil.stencil_enabled;\r\n    dss_desc.StencilReadMask = desc->depth_stencil.stencil_read_mask;\r\n    dss_desc.StencilWriteMask = desc->depth_stencil.stencil_write_mask;\r\n    const sg_stencil_state* sf = &desc->depth_stencil.stencil_front;\r\n    dss_desc.FrontFace.StencilFailOp = _sg_d3d11_stencil_op(sf->fail_op);\r\n    dss_desc.FrontFace.StencilDepthFailOp = _sg_d3d11_stencil_op(sf->depth_fail_op);\r\n    dss_desc.FrontFace.StencilPassOp = _sg_d3d11_stencil_op(sf->pass_op);\r\n    dss_desc.FrontFace.StencilFunc = _sg_d3d11_compare_func(sf->compare_func);\r\n    const sg_stencil_state* sb = &desc->depth_stencil.stencil_back;\r\n    dss_desc.BackFace.StencilFailOp = _sg_d3d11_stencil_op(sb->fail_op);\r\n    dss_desc.BackFace.StencilDepthFailOp = _sg_d3d11_stencil_op(sb->depth_fail_op);\r\n    dss_desc.BackFace.StencilPassOp = _sg_d3d11_stencil_op(sb->pass_op);\r\n    dss_desc.BackFace.StencilFunc = _sg_d3d11_compare_func(sb->compare_func);\r\n    hr = _sg_d3d11_CreateDepthStencilState(_sg.d3d11.dev, &dss_desc, &pip->d3d11.dss);\r\n    SOKOL_ASSERT(SUCCEEDED(hr) && pip->d3d11.dss);\r\n\r\n    /* create blend state */\r\n    D3D11_BLEND_DESC bs_desc;\r\n    memset(&bs_desc, 0, sizeof(bs_desc));\r\n    bs_desc.AlphaToCoverageEnable = desc->rasterizer.alpha_to_coverage_enabled;\r\n    bs_desc.IndependentBlendEnable = FALSE;\r\n    bs_desc.RenderTarget[0].BlendEnable = desc->blend.enabled;\r\n    bs_desc.RenderTarget[0].SrcBlend = _sg_d3d11_blend_factor(desc->blend.src_factor_rgb);\r\n    bs_desc.RenderTarget[0].DestBlend = _sg_d3d11_blend_factor(desc->blend.dst_factor_rgb);\r\n    bs_desc.RenderTarget[0].BlendOp = _sg_d3d11_blend_op(desc->blend.op_rgb);\r\n    bs_desc.RenderTarget[0].SrcBlendAlpha = _sg_d3d11_blend_factor(desc->blend.src_factor_alpha);\r\n    bs_desc.RenderTarget[0].DestBlendAlpha = _sg_d3d11_blend_factor(desc->blend.dst_factor_alpha);\r\n    bs_desc.RenderTarget[0].BlendOpAlpha = _sg_d3d11_blend_op(desc->blend.op_alpha);\r\n    bs_desc.RenderTarget[0].RenderTargetWriteMask = _sg_d3d11_color_write_mask((sg_color_mask)desc->blend.color_write_mask);\r\n    hr = _sg_d3d11_CreateBlendState(_sg.d3d11.dev, &bs_desc, &pip->d3d11.bs);\r\n    SOKOL_ASSERT(SUCCEEDED(hr) && pip->d3d11.bs);\r\n\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_destroy_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    if (pip->d3d11.il) {\r\n        _sg_d3d11_Release(pip->d3d11.il);\r\n    }\r\n    if (pip->d3d11.rs) {\r\n        _sg_d3d11_Release(pip->d3d11.rs);\r\n    }\r\n    if (pip->d3d11.dss) {\r\n        _sg_d3d11_Release(pip->d3d11.dss);\r\n    }\r\n    if (pip->d3d11.bs) {\r\n        _sg_d3d11_Release(pip->d3d11.bs);\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_pass(_sg_pass_t* pass, _sg_image_t** att_images, const sg_pass_desc* desc) {\r\n    SOKOL_ASSERT(pass && desc);\r\n    SOKOL_ASSERT(att_images && att_images[0]);\r\n    SOKOL_ASSERT(_sg.d3d11.dev);\r\n\r\n    _sg_pass_common_init(&pass->cmn, desc);\r\n\r\n    for (int i = 0; i < pass->cmn.num_color_atts; i++) {\r\n        const sg_attachment_desc* att_desc = &desc->color_attachments[i];\r\n        _SOKOL_UNUSED(att_desc);\r\n        SOKOL_ASSERT(att_desc->image.id != SG_INVALID_ID);\r\n        _sg_image_t* att_img = att_images[i];\r\n        SOKOL_ASSERT(att_img && (att_img->slot.id == att_desc->image.id));\r\n        SOKOL_ASSERT(_sg_is_valid_rendertarget_color_format(att_img->cmn.pixel_format));\r\n        SOKOL_ASSERT(0 == pass->d3d11.color_atts[i].image);\r\n        pass->d3d11.color_atts[i].image = att_img;\r\n\r\n        /* create D3D11 render-target-view */\r\n        const _sg_attachment_t* cmn_att = &pass->cmn.color_atts[i];\r\n        SOKOL_ASSERT(0 == pass->d3d11.color_atts[i].rtv);\r\n        ID3D11Resource* d3d11_res = 0;\r\n        const bool is_msaa = att_img->cmn.sample_count > 1;\r\n        D3D11_RENDER_TARGET_VIEW_DESC d3d11_rtv_desc;\r\n        memset(&d3d11_rtv_desc, 0, sizeof(d3d11_rtv_desc));\r\n        d3d11_rtv_desc.Format = att_img->d3d11.format;\r\n        if ((att_img->cmn.type == SG_IMAGETYPE_2D) || is_msaa) {\r\n            if (is_msaa) {\r\n                d3d11_res = (ID3D11Resource*) att_img->d3d11.texmsaa;\r\n                d3d11_rtv_desc.ViewDimension = D3D11_RTV_DIMENSION_TEXTURE2DMS;\r\n            }\r\n            else {\r\n                d3d11_res = (ID3D11Resource*) att_img->d3d11.tex2d;\r\n                d3d11_rtv_desc.ViewDimension = D3D11_RTV_DIMENSION_TEXTURE2D;\r\n                d3d11_rtv_desc.Texture2D.MipSlice = cmn_att->mip_level;\r\n            }\r\n        }\r\n        else if ((att_img->cmn.type == SG_IMAGETYPE_CUBE) || (att_img->cmn.type == SG_IMAGETYPE_ARRAY)) {\r\n            d3d11_res = (ID3D11Resource*) att_img->d3d11.tex2d;\r\n            d3d11_rtv_desc.ViewDimension = D3D11_RTV_DIMENSION_TEXTURE2DARRAY;\r\n            d3d11_rtv_desc.Texture2DArray.MipSlice = cmn_att->mip_level;\r\n            d3d11_rtv_desc.Texture2DArray.FirstArraySlice = cmn_att->slice;\r\n            d3d11_rtv_desc.Texture2DArray.ArraySize = 1;\r\n        }\r\n        else {\r\n            SOKOL_ASSERT(att_img->cmn.type == SG_IMAGETYPE_3D);\r\n            d3d11_res = (ID3D11Resource*) att_img->d3d11.tex3d;\r\n            d3d11_rtv_desc.ViewDimension = D3D11_RTV_DIMENSION_TEXTURE3D;\r\n            d3d11_rtv_desc.Texture3D.MipSlice = cmn_att->mip_level;\r\n            d3d11_rtv_desc.Texture3D.FirstWSlice = cmn_att->slice;\r\n            d3d11_rtv_desc.Texture3D.WSize = 1;\r\n        }\r\n        SOKOL_ASSERT(d3d11_res);\r\n        HRESULT hr = _sg_d3d11_CreateRenderTargetView(_sg.d3d11.dev, d3d11_res, &d3d11_rtv_desc, &pass->d3d11.color_atts[i].rtv);\r\n        _SOKOL_UNUSED(hr);\r\n        SOKOL_ASSERT(SUCCEEDED(hr) && pass->d3d11.color_atts[i].rtv);\r\n    }\r\n\r\n    /* optional depth-stencil image */\r\n    SOKOL_ASSERT(0 == pass->d3d11.ds_att.image);\r\n    SOKOL_ASSERT(0 == pass->d3d11.ds_att.dsv);\r\n    if (desc->depth_stencil_attachment.image.id != SG_INVALID_ID) {\r\n        const int ds_img_index = SG_MAX_COLOR_ATTACHMENTS;\r\n        const sg_attachment_desc* att_desc = &desc->depth_stencil_attachment;\r\n        _SOKOL_UNUSED(att_desc);\r\n        _sg_image_t* att_img = att_images[ds_img_index];\r\n        SOKOL_ASSERT(att_img && (att_img->slot.id == att_desc->image.id));\r\n        SOKOL_ASSERT(_sg_is_valid_rendertarget_depth_format(att_img->cmn.pixel_format));\r\n        SOKOL_ASSERT(0 == pass->d3d11.ds_att.image);\r\n        pass->d3d11.ds_att.image = att_img;\r\n\r\n        /* create D3D11 depth-stencil-view */\r\n        D3D11_DEPTH_STENCIL_VIEW_DESC d3d11_dsv_desc;\r\n        memset(&d3d11_dsv_desc, 0, sizeof(d3d11_dsv_desc));\r\n        d3d11_dsv_desc.Format = att_img->d3d11.format;\r\n        const bool is_msaa = att_img->cmn.sample_count > 1;\r\n        if (is_msaa) {\r\n            d3d11_dsv_desc.ViewDimension = D3D11_DSV_DIMENSION_TEXTURE2DMS;\r\n        }\r\n        else {\r\n            d3d11_dsv_desc.ViewDimension = D3D11_DSV_DIMENSION_TEXTURE2D;\r\n        }\r\n        ID3D11Resource* d3d11_res = (ID3D11Resource*) att_img->d3d11.texds;\r\n        SOKOL_ASSERT(d3d11_res);\r\n        HRESULT hr = _sg_d3d11_CreateDepthStencilView(_sg.d3d11.dev, d3d11_res, &d3d11_dsv_desc, &pass->d3d11.ds_att.dsv);\r\n        _SOKOL_UNUSED(hr);\r\n        SOKOL_ASSERT(SUCCEEDED(hr) && pass->d3d11.ds_att.dsv);\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_destroy_pass(_sg_pass_t* pass) {\r\n    SOKOL_ASSERT(pass);\r\n    for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n        if (pass->d3d11.color_atts[i].rtv) {\r\n            _sg_d3d11_Release(pass->d3d11.color_atts[i].rtv);\r\n        }\r\n    }\r\n    if (pass->d3d11.ds_att.dsv) {\r\n        _sg_d3d11_Release(pass->d3d11.ds_att.dsv);\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_d3d11_pass_color_image(const _sg_pass_t* pass, int index) {\r\n    SOKOL_ASSERT(pass && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));\r\n    /* NOTE: may return null */\r\n    return pass->d3d11.color_atts[index].image;\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_d3d11_pass_ds_image(const _sg_pass_t* pass) {\r\n    /* NOTE: may return null */\r\n    SOKOL_ASSERT(pass);\r\n    return pass->d3d11.ds_att.image;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_begin_pass(_sg_pass_t* pass, const sg_pass_action* action, int w, int h) {\r\n    SOKOL_ASSERT(action);\r\n    SOKOL_ASSERT(!_sg.d3d11.in_pass);\r\n    SOKOL_ASSERT(_sg.d3d11.rtv_cb || _sg.d3d11.rtv_userdata_cb);\r\n    SOKOL_ASSERT(_sg.d3d11.dsv_cb || _sg.d3d11.dsv_userdata_cb);\r\n    _sg.d3d11.in_pass = true;\r\n    _sg.d3d11.cur_width = w;\r\n    _sg.d3d11.cur_height = h;\r\n    if (pass) {\r\n        _sg.d3d11.cur_pass = pass;\r\n        _sg.d3d11.cur_pass_id.id = pass->slot.id;\r\n        _sg.d3d11.num_rtvs = 0;\r\n        for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n            _sg.d3d11.cur_rtvs[i] = pass->d3d11.color_atts[i].rtv;\r\n            if (_sg.d3d11.cur_rtvs[i]) {\r\n                _sg.d3d11.num_rtvs++;\r\n            }\r\n        }\r\n        _sg.d3d11.cur_dsv = pass->d3d11.ds_att.dsv;\r\n    }\r\n    else {\r\n        /* render to default frame buffer */\r\n        _sg.d3d11.cur_pass = 0;\r\n        _sg.d3d11.cur_pass_id.id = SG_INVALID_ID;\r\n        _sg.d3d11.num_rtvs = 1;\r\n        if (_sg.d3d11.rtv_cb) {\r\n            _sg.d3d11.cur_rtvs[0] = (ID3D11RenderTargetView*) _sg.d3d11.rtv_cb();\r\n        }\r\n        else {\r\n            _sg.d3d11.cur_rtvs[0] = (ID3D11RenderTargetView*) _sg.d3d11.rtv_userdata_cb(_sg.d3d11.user_data);\r\n        }\r\n        for (int i = 1; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n            _sg.d3d11.cur_rtvs[i] = 0;\r\n        }\r\n        if (_sg.d3d11.dsv_cb) {\r\n            _sg.d3d11.cur_dsv = (ID3D11DepthStencilView*) _sg.d3d11.dsv_cb();\r\n        }\r\n        else {\r\n            _sg.d3d11.cur_dsv = (ID3D11DepthStencilView*) _sg.d3d11.dsv_userdata_cb(_sg.d3d11.user_data);\r\n        }\r\n        SOKOL_ASSERT(_sg.d3d11.cur_rtvs[0] && _sg.d3d11.cur_dsv);\r\n    }\r\n    /* apply the render-target- and depth-stencil-views */\r\n    _sg_d3d11_OMSetRenderTargets(_sg.d3d11.ctx, SG_MAX_COLOR_ATTACHMENTS, _sg.d3d11.cur_rtvs, _sg.d3d11.cur_dsv);\r\n\r\n    /* set viewport and scissor rect to cover whole screen */\r\n    D3D11_VIEWPORT vp;\r\n    memset(&vp, 0, sizeof(vp));\r\n    vp.Width = (FLOAT) w;\r\n    vp.Height = (FLOAT) h;\r\n    vp.MaxDepth = 1.0f;\r\n    _sg_d3d11_RSSetViewports(_sg.d3d11.ctx, 1, &vp);\r\n    D3D11_RECT rect;\r\n    rect.left = 0;\r\n    rect.top = 0;\r\n    rect.right = w;\r\n    rect.bottom = h;\r\n    _sg_d3d11_RSSetScissorRects(_sg.d3d11.ctx, 1, &rect);\r\n\r\n    /* perform clear action */\r\n    for (int i = 0; i < _sg.d3d11.num_rtvs; i++) {\r\n        if (action->colors[i].action == SG_ACTION_CLEAR) {\r\n            _sg_d3d11_ClearRenderTargetView(_sg.d3d11.ctx, _sg.d3d11.cur_rtvs[i], action->colors[i].val);\r\n        }\r\n    }\r\n    UINT ds_flags = 0;\r\n    if (action->depth.action == SG_ACTION_CLEAR) {\r\n        ds_flags |= D3D11_CLEAR_DEPTH;\r\n    }\r\n    if (action->stencil.action == SG_ACTION_CLEAR) {\r\n        ds_flags |= D3D11_CLEAR_STENCIL;\r\n    }\r\n    if ((0 != ds_flags) && _sg.d3d11.cur_dsv) {\r\n        _sg_d3d11_ClearDepthStencilView(_sg.d3d11.ctx, _sg.d3d11.cur_dsv, ds_flags, action->depth.val, action->stencil.val);\r\n    }\r\n}\r\n\r\n/* D3D11CalcSubresource only exists for C++ */\r\n_SOKOL_PRIVATE UINT _sg_d3d11_calcsubresource(UINT mip_slice, UINT array_slice, UINT mip_levels) {\r\n    return mip_slice + array_slice * mip_levels;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_end_pass(void) {\r\n    SOKOL_ASSERT(_sg.d3d11.in_pass && _sg.d3d11.ctx);\r\n    _sg.d3d11.in_pass = false;\r\n\r\n    /* need to resolve MSAA render target into texture? */\r\n    if (_sg.d3d11.cur_pass) {\r\n        SOKOL_ASSERT(_sg.d3d11.cur_pass->slot.id == _sg.d3d11.cur_pass_id.id);\r\n        for (int i = 0; i < _sg.d3d11.num_rtvs; i++) {\r\n            _sg_attachment_t* cmn_att = &_sg.d3d11.cur_pass->cmn.color_atts[i];\r\n            _sg_image_t* att_img = _sg.d3d11.cur_pass->d3d11.color_atts[i].image;\r\n            SOKOL_ASSERT(att_img && (att_img->slot.id == cmn_att->image_id.id));\r\n            if (att_img->cmn.sample_count > 1) {\r\n                /* FIXME: support MSAA resolve into 3D texture */\r\n                SOKOL_ASSERT(att_img->d3d11.tex2d && att_img->d3d11.texmsaa && !att_img->d3d11.tex3d);\r\n                SOKOL_ASSERT(DXGI_FORMAT_UNKNOWN != att_img->d3d11.format);\r\n                UINT dst_subres = _sg_d3d11_calcsubresource(cmn_att->mip_level, cmn_att->slice, att_img->cmn.num_mipmaps);\r\n                _sg_d3d11_ResolveSubresource(_sg.d3d11.ctx,\r\n                    (ID3D11Resource*) att_img->d3d11.tex2d,     /* pDstResource */\r\n                    dst_subres,                                 /* DstSubresource */\r\n                    (ID3D11Resource*) att_img->d3d11.texmsaa,   /* pSrcResource */\r\n                    0,                                          /* SrcSubresource */\r\n                    att_img->d3d11.format);\r\n            }\r\n        }\r\n    }\r\n    _sg.d3d11.cur_pass = 0;\r\n    _sg.d3d11.cur_pass_id.id = SG_INVALID_ID;\r\n    _sg.d3d11.cur_pipeline = 0;\r\n    _sg.d3d11.cur_pipeline_id.id = SG_INVALID_ID;\r\n    for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n        _sg.d3d11.cur_rtvs[i] = 0;\r\n    }\r\n    _sg.d3d11.cur_dsv = 0;\r\n    _sg_d3d11_clear_state();\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {\r\n    SOKOL_ASSERT(_sg.d3d11.ctx);\r\n    SOKOL_ASSERT(_sg.d3d11.in_pass);\r\n    D3D11_VIEWPORT vp;\r\n    vp.TopLeftX = (FLOAT) x;\r\n    vp.TopLeftY = (FLOAT) (origin_top_left ? y : (_sg.d3d11.cur_height - (y + h)));\r\n    vp.Width = (FLOAT) w;\r\n    vp.Height = (FLOAT) h;\r\n    vp.MinDepth = 0.0f;\r\n    vp.MaxDepth = 1.0f;\r\n    _sg_d3d11_RSSetViewports(_sg.d3d11.ctx, 1, &vp);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {\r\n    SOKOL_ASSERT(_sg.d3d11.ctx);\r\n    SOKOL_ASSERT(_sg.d3d11.in_pass);\r\n    D3D11_RECT rect;\r\n    rect.left = x;\r\n    rect.top = (origin_top_left ? y : (_sg.d3d11.cur_height - (y + h)));\r\n    rect.right = x + w;\r\n    rect.bottom = origin_top_left ? (y + h) : (_sg.d3d11.cur_height - y);\r\n    _sg_d3d11_RSSetScissorRects(_sg.d3d11.ctx, 1, &rect);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_apply_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    SOKOL_ASSERT(pip->shader && (pip->cmn.shader_id.id == pip->shader->slot.id));\r\n    SOKOL_ASSERT(_sg.d3d11.ctx);\r\n    SOKOL_ASSERT(_sg.d3d11.in_pass);\r\n    SOKOL_ASSERT(pip->d3d11.rs && pip->d3d11.bs && pip->d3d11.dss && pip->d3d11.il);\r\n\r\n    _sg.d3d11.cur_pipeline = pip;\r\n    _sg.d3d11.cur_pipeline_id.id = pip->slot.id;\r\n    _sg.d3d11.use_indexed_draw = (pip->d3d11.index_format != DXGI_FORMAT_UNKNOWN);\r\n\r\n    _sg_d3d11_RSSetState(_sg.d3d11.ctx, pip->d3d11.rs);\r\n    _sg_d3d11_OMSetDepthStencilState(_sg.d3d11.ctx, pip->d3d11.dss, pip->d3d11.stencil_ref);\r\n    _sg_d3d11_OMSetBlendState(_sg.d3d11.ctx, pip->d3d11.bs, pip->cmn.blend_color, 0xFFFFFFFF);\r\n    _sg_d3d11_IASetPrimitiveTopology(_sg.d3d11.ctx, pip->d3d11.topology);\r\n    _sg_d3d11_IASetInputLayout(_sg.d3d11.ctx, pip->d3d11.il);\r\n    _sg_d3d11_VSSetShader(_sg.d3d11.ctx, pip->shader->d3d11.vs, NULL, 0);\r\n    _sg_d3d11_VSSetConstantBuffers(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_UBS, pip->shader->d3d11.stage[SG_SHADERSTAGE_VS].cbufs);\r\n    _sg_d3d11_PSSetShader(_sg.d3d11.ctx, pip->shader->d3d11.fs, NULL, 0);\r\n    _sg_d3d11_PSSetConstantBuffers(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_UBS, pip->shader->d3d11.stage[SG_SHADERSTAGE_FS].cbufs);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_apply_bindings(\r\n    _sg_pipeline_t* pip,\r\n    _sg_buffer_t** vbs, const int* vb_offsets, int num_vbs,\r\n    _sg_buffer_t* ib, int ib_offset,\r\n    _sg_image_t** vs_imgs, int num_vs_imgs,\r\n    _sg_image_t** fs_imgs, int num_fs_imgs)\r\n{\r\n    SOKOL_ASSERT(pip);\r\n    SOKOL_ASSERT(_sg.d3d11.ctx);\r\n    SOKOL_ASSERT(_sg.d3d11.in_pass);\r\n\r\n    /* gather all the D3D11 resources into arrays */\r\n    ID3D11Buffer* d3d11_ib = ib ? ib->d3d11.buf : 0;\r\n    ID3D11Buffer* d3d11_vbs[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    UINT d3d11_vb_offsets[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    ID3D11ShaderResourceView* d3d11_vs_srvs[SG_MAX_SHADERSTAGE_IMAGES];\r\n    ID3D11SamplerState* d3d11_vs_smps[SG_MAX_SHADERSTAGE_IMAGES];\r\n    ID3D11ShaderResourceView* d3d11_fs_srvs[SG_MAX_SHADERSTAGE_IMAGES];\r\n    ID3D11SamplerState* d3d11_fs_smps[SG_MAX_SHADERSTAGE_IMAGES];\r\n    int i;\r\n    for (i = 0; i < num_vbs; i++) {\r\n        SOKOL_ASSERT(vbs[i]->d3d11.buf);\r\n        d3d11_vbs[i] = vbs[i]->d3d11.buf;\r\n        d3d11_vb_offsets[i] = vb_offsets[i];\r\n    }\r\n    for (; i < SG_MAX_SHADERSTAGE_BUFFERS; i++) {\r\n        d3d11_vbs[i] = 0;\r\n        d3d11_vb_offsets[i] = 0;\r\n    }\r\n    for (i = 0; i < num_vs_imgs; i++) {\r\n        SOKOL_ASSERT(vs_imgs[i]->d3d11.srv);\r\n        SOKOL_ASSERT(vs_imgs[i]->d3d11.smp);\r\n        d3d11_vs_srvs[i] = vs_imgs[i]->d3d11.srv;\r\n        d3d11_vs_smps[i] = vs_imgs[i]->d3d11.smp;\r\n    }\r\n    for (; i < SG_MAX_SHADERSTAGE_IMAGES; i++) {\r\n        d3d11_vs_srvs[i] = 0;\r\n        d3d11_vs_smps[i] = 0;\r\n    }\r\n    for (i = 0; i < num_fs_imgs; i++) {\r\n        SOKOL_ASSERT(fs_imgs[i]->d3d11.srv);\r\n        SOKOL_ASSERT(fs_imgs[i]->d3d11.smp);\r\n        d3d11_fs_srvs[i] = fs_imgs[i]->d3d11.srv;\r\n        d3d11_fs_smps[i] = fs_imgs[i]->d3d11.smp;\r\n    }\r\n    for (; i < SG_MAX_SHADERSTAGE_IMAGES; i++) {\r\n        d3d11_fs_srvs[i] = 0;\r\n        d3d11_fs_smps[i] = 0;\r\n    }\r\n\r\n    _sg_d3d11_IASetVertexBuffers(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_BUFFERS, d3d11_vbs, pip->d3d11.vb_strides, d3d11_vb_offsets);\r\n    _sg_d3d11_IASetIndexBuffer(_sg.d3d11.ctx, d3d11_ib, pip->d3d11.index_format, ib_offset);\r\n    _sg_d3d11_VSSetShaderResources(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_IMAGES, d3d11_vs_srvs);\r\n    _sg_d3d11_VSSetSamplers(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_IMAGES, d3d11_vs_smps);\r\n    _sg_d3d11_PSSetShaderResources(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_IMAGES, d3d11_fs_srvs);\r\n    _sg_d3d11_PSSetSamplers(_sg.d3d11.ctx, 0, SG_MAX_SHADERSTAGE_IMAGES, d3d11_fs_smps);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_apply_uniforms(sg_shader_stage stage_index, int ub_index, const void* data, int num_bytes) {\r\n    _SOKOL_UNUSED(num_bytes);\r\n    SOKOL_ASSERT(_sg.d3d11.ctx && _sg.d3d11.in_pass);\r\n    SOKOL_ASSERT(data && (num_bytes > 0));\r\n    SOKOL_ASSERT((stage_index >= 0) && ((int)stage_index < SG_NUM_SHADER_STAGES));\r\n    SOKOL_ASSERT((ub_index >= 0) && (ub_index < SG_MAX_SHADERSTAGE_UBS));\r\n    SOKOL_ASSERT(_sg.d3d11.cur_pipeline && _sg.d3d11.cur_pipeline->slot.id == _sg.d3d11.cur_pipeline_id.id);\r\n    SOKOL_ASSERT(_sg.d3d11.cur_pipeline->shader && _sg.d3d11.cur_pipeline->shader->slot.id == _sg.d3d11.cur_pipeline->cmn.shader_id.id);\r\n    SOKOL_ASSERT(ub_index < _sg.d3d11.cur_pipeline->shader->cmn.stage[stage_index].num_uniform_blocks);\r\n    SOKOL_ASSERT(num_bytes == _sg.d3d11.cur_pipeline->shader->cmn.stage[stage_index].uniform_blocks[ub_index].size);\r\n    ID3D11Buffer* cb = _sg.d3d11.cur_pipeline->shader->d3d11.stage[stage_index].cbufs[ub_index];\r\n    SOKOL_ASSERT(cb);\r\n    _sg_d3d11_UpdateSubresource(_sg.d3d11.ctx, (ID3D11Resource*)cb, 0, NULL, data, 0, 0);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_draw(int base_element, int num_elements, int num_instances) {\r\n    SOKOL_ASSERT(_sg.d3d11.in_pass);\r\n    if (_sg.d3d11.use_indexed_draw) {\r\n        if (1 == num_instances) {\r\n            _sg_d3d11_DrawIndexed(_sg.d3d11.ctx, num_elements, base_element, 0);\r\n        }\r\n        else {\r\n            _sg_d3d11_DrawIndexedInstanced(_sg.d3d11.ctx, num_elements, num_instances, base_element, 0, 0);\r\n        }\r\n    }\r\n    else {\r\n        if (1 == num_instances) {\r\n            _sg_d3d11_Draw(_sg.d3d11.ctx, num_elements, base_element);\r\n        }\r\n        else {\r\n            _sg_d3d11_DrawInstanced(_sg.d3d11.ctx, num_elements, num_instances, base_element, 0);\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_commit(void) {\r\n    SOKOL_ASSERT(!_sg.d3d11.in_pass);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_update_buffer(_sg_buffer_t* buf, const void* data_ptr, uint32_t data_size) {\r\n    SOKOL_ASSERT(buf && data_ptr && (data_size > 0));\r\n    SOKOL_ASSERT(_sg.d3d11.ctx);\r\n    SOKOL_ASSERT(buf->d3d11.buf);\r\n    D3D11_MAPPED_SUBRESOURCE d3d11_msr;\r\n    HRESULT hr = _sg_d3d11_Map(_sg.d3d11.ctx, (ID3D11Resource*)buf->d3d11.buf, 0, D3D11_MAP_WRITE_DISCARD, 0, &d3d11_msr);\r\n    _SOKOL_UNUSED(hr);\r\n    SOKOL_ASSERT(SUCCEEDED(hr));\r\n    memcpy(d3d11_msr.pData, data_ptr, data_size);\r\n    _sg_d3d11_Unmap(_sg.d3d11.ctx, (ID3D11Resource*)buf->d3d11.buf, 0);\r\n}\r\n\r\n_SOKOL_PRIVATE uint32_t _sg_d3d11_append_buffer(_sg_buffer_t* buf, const void* data_ptr, uint32_t data_size, bool new_frame) {\r\n    SOKOL_ASSERT(buf && data_ptr && (data_size > 0));\r\n    SOKOL_ASSERT(_sg.d3d11.ctx);\r\n    SOKOL_ASSERT(buf->d3d11.buf);\r\n    D3D11_MAP map_type = new_frame ? D3D11_MAP_WRITE_DISCARD : D3D11_MAP_WRITE_NO_OVERWRITE;\r\n    D3D11_MAPPED_SUBRESOURCE d3d11_msr;\r\n    HRESULT hr = _sg_d3d11_Map(_sg.d3d11.ctx, (ID3D11Resource*)buf->d3d11.buf, 0, map_type, 0, &d3d11_msr);\r\n    _SOKOL_UNUSED(hr);\r\n    SOKOL_ASSERT(SUCCEEDED(hr));\r\n    uint8_t* dst_ptr = (uint8_t*)d3d11_msr.pData + buf->cmn.append_pos;\r\n    memcpy(dst_ptr, data_ptr, data_size);\r\n    _sg_d3d11_Unmap(_sg.d3d11.ctx, (ID3D11Resource*)buf->d3d11.buf, 0);\r\n    /* NOTE: this is a requirement from WebGPU, but we want identical behaviour across all backend */\r\n    return _sg_roundup(data_size, 4);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_d3d11_update_image(_sg_image_t* img, const sg_image_content* data) {\r\n    SOKOL_ASSERT(img && data);\r\n    SOKOL_ASSERT(_sg.d3d11.ctx);\r\n    SOKOL_ASSERT(img->d3d11.tex2d || img->d3d11.tex3d);\r\n    ID3D11Resource* d3d11_res = 0;\r\n    if (img->d3d11.tex3d) {\r\n        d3d11_res = (ID3D11Resource*) img->d3d11.tex3d;\r\n    }\r\n    else {\r\n        d3d11_res = (ID3D11Resource*) img->d3d11.tex2d;\r\n    }\r\n    SOKOL_ASSERT(d3d11_res);\r\n    const int num_faces = (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6:1;\r\n    const int num_slices = (img->cmn.type == SG_IMAGETYPE_ARRAY) ? img->cmn.depth:1;\r\n    int subres_index = 0;\r\n    HRESULT hr;\r\n    _SOKOL_UNUSED(hr);\r\n    D3D11_MAPPED_SUBRESOURCE d3d11_msr;\r\n    for (int face_index = 0; face_index < num_faces; face_index++) {\r\n        for (int slice_index = 0; slice_index < num_slices; slice_index++) {\r\n            for (int mip_index = 0; mip_index < img->cmn.num_mipmaps; mip_index++, subres_index++) {\r\n                SOKOL_ASSERT(subres_index < (SG_MAX_MIPMAPS * SG_MAX_TEXTUREARRAY_LAYERS));\r\n                const int mip_width = ((img->cmn.width>>mip_index)>0) ? img->cmn.width>>mip_index : 1;\r\n                const int mip_height = ((img->cmn.height>>mip_index)>0) ? img->cmn.height>>mip_index : 1;\r\n                const int src_pitch = _sg_row_pitch(img->cmn.pixel_format, mip_width, 1);\r\n                const sg_subimage_content* subimg_content = &(data->subimage[face_index][mip_index]);\r\n                const int slice_size = subimg_content->size / num_slices;\r\n                const int slice_offset = slice_size * slice_index;\r\n                const uint8_t* slice_ptr = ((const uint8_t*)subimg_content->ptr) + slice_offset;\r\n                hr = _sg_d3d11_Map(_sg.d3d11.ctx, d3d11_res, subres_index, D3D11_MAP_WRITE_DISCARD, 0, &d3d11_msr);\r\n                SOKOL_ASSERT(SUCCEEDED(hr));\r\n                /* FIXME: need to handle difference in depth-pitch for 3D textures as well! */\r\n                if (src_pitch == (int)d3d11_msr.RowPitch) {\r\n                    memcpy(d3d11_msr.pData, slice_ptr, slice_size);\r\n                }\r\n                else {\r\n                    SOKOL_ASSERT(src_pitch < (int)d3d11_msr.RowPitch);\r\n                    const uint8_t* src_ptr = slice_ptr;\r\n                    uint8_t* dst_ptr = (uint8_t*) d3d11_msr.pData;\r\n                    for (int row_index = 0; row_index < mip_height; row_index++) {\r\n                        memcpy(dst_ptr, src_ptr, src_pitch);\r\n                        src_ptr += src_pitch;\r\n                        dst_ptr += d3d11_msr.RowPitch;\r\n                    }\r\n                }\r\n                _sg_d3d11_Unmap(_sg.d3d11.ctx, d3d11_res, subres_index);\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n/*== METAL BACKEND IMPLEMENTATION ============================================*/\r\n#elif defined(SOKOL_METAL)\r\n\r\n#if __has_feature(objc_arc)\r\n#define _SG_OBJC_RETAIN(obj) { }\r\n#define _SG_OBJC_RELEASE(obj) { obj = nil; }\r\n#define _SG_OBJC_RELEASE_WITH_NULL(obj) { obj = [NSNull null]; }\r\n#else\r\n#define _SG_OBJC_RETAIN(obj) { [obj retain]; }\r\n#define _SG_OBJC_RELEASE(obj) { [obj release]; obj = nil; }\r\n#define _SG_OBJC_RELEASE_WITH_NULL(obj) { [obj release]; obj = [NSNull null]; }\r\n#endif\r\n\r\n/*-- enum translation functions ----------------------------------------------*/\r\n_SOKOL_PRIVATE MTLLoadAction _sg_mtl_load_action(sg_action a) {\r\n    switch (a) {\r\n        case SG_ACTION_CLEAR:       return MTLLoadActionClear;\r\n        case SG_ACTION_LOAD:        return MTLLoadActionLoad;\r\n        case SG_ACTION_DONTCARE:    return MTLLoadActionDontCare;\r\n        default: SOKOL_UNREACHABLE; return (MTLLoadAction)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLResourceOptions _sg_mtl_buffer_resource_options(sg_usage usg) {\r\n    switch (usg) {\r\n        case SG_USAGE_IMMUTABLE:\r\n            return MTLResourceStorageModeShared;\r\n        case SG_USAGE_DYNAMIC:\r\n        case SG_USAGE_STREAM:\r\n            #if defined(_SG_TARGET_MACOS)\r\n            return MTLCPUCacheModeWriteCombined|MTLResourceStorageModeManaged;\r\n            #else\r\n            return MTLCPUCacheModeWriteCombined;\r\n            #endif\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLVertexStepFunction _sg_mtl_step_function(sg_vertex_step step) {\r\n    switch (step) {\r\n        case SG_VERTEXSTEP_PER_VERTEX:      return MTLVertexStepFunctionPerVertex;\r\n        case SG_VERTEXSTEP_PER_INSTANCE:    return MTLVertexStepFunctionPerInstance;\r\n        default: SOKOL_UNREACHABLE; return (MTLVertexStepFunction)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLVertexFormat _sg_mtl_vertex_format(sg_vertex_format fmt) {\r\n    switch (fmt) {\r\n        case SG_VERTEXFORMAT_FLOAT:     return MTLVertexFormatFloat;\r\n        case SG_VERTEXFORMAT_FLOAT2:    return MTLVertexFormatFloat2;\r\n        case SG_VERTEXFORMAT_FLOAT3:    return MTLVertexFormatFloat3;\r\n        case SG_VERTEXFORMAT_FLOAT4:    return MTLVertexFormatFloat4;\r\n        case SG_VERTEXFORMAT_BYTE4:     return MTLVertexFormatChar4;\r\n        case SG_VERTEXFORMAT_BYTE4N:    return MTLVertexFormatChar4Normalized;\r\n        case SG_VERTEXFORMAT_UBYTE4:    return MTLVertexFormatUChar4;\r\n        case SG_VERTEXFORMAT_UBYTE4N:   return MTLVertexFormatUChar4Normalized;\r\n        case SG_VERTEXFORMAT_SHORT2:    return MTLVertexFormatShort2;\r\n        case SG_VERTEXFORMAT_SHORT2N:   return MTLVertexFormatShort2Normalized;\r\n        case SG_VERTEXFORMAT_USHORT2N:  return MTLVertexFormatUShort2Normalized;\r\n        case SG_VERTEXFORMAT_SHORT4:    return MTLVertexFormatShort4;\r\n        case SG_VERTEXFORMAT_SHORT4N:   return MTLVertexFormatShort4Normalized;\r\n        case SG_VERTEXFORMAT_USHORT4N:  return MTLVertexFormatUShort4Normalized;\r\n        case SG_VERTEXFORMAT_UINT10_N2: return MTLVertexFormatUInt1010102Normalized;\r\n        default: SOKOL_UNREACHABLE; return (MTLVertexFormat)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLPrimitiveType _sg_mtl_primitive_type(sg_primitive_type t) {\r\n    switch (t) {\r\n        case SG_PRIMITIVETYPE_POINTS:           return MTLPrimitiveTypePoint;\r\n        case SG_PRIMITIVETYPE_LINES:            return MTLPrimitiveTypeLine;\r\n        case SG_PRIMITIVETYPE_LINE_STRIP:       return MTLPrimitiveTypeLineStrip;\r\n        case SG_PRIMITIVETYPE_TRIANGLES:        return MTLPrimitiveTypeTriangle;\r\n        case SG_PRIMITIVETYPE_TRIANGLE_STRIP:   return MTLPrimitiveTypeTriangleStrip;\r\n        default: SOKOL_UNREACHABLE; return (MTLPrimitiveType)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLPixelFormat _sg_mtl_pixel_format(sg_pixel_format fmt) {\r\n    switch (fmt) {\r\n        case SG_PIXELFORMAT_R8:                     return MTLPixelFormatR8Unorm;\r\n        case SG_PIXELFORMAT_R8SN:                   return MTLPixelFormatR8Snorm;\r\n        case SG_PIXELFORMAT_R8UI:                   return MTLPixelFormatR8Uint;\r\n        case SG_PIXELFORMAT_R8SI:                   return MTLPixelFormatR8Sint;\r\n        case SG_PIXELFORMAT_R16:                    return MTLPixelFormatR16Unorm;\r\n        case SG_PIXELFORMAT_R16SN:                  return MTLPixelFormatR16Snorm;\r\n        case SG_PIXELFORMAT_R16UI:                  return MTLPixelFormatR16Uint;\r\n        case SG_PIXELFORMAT_R16SI:                  return MTLPixelFormatR16Sint;\r\n        case SG_PIXELFORMAT_R16F:                   return MTLPixelFormatR16Float;\r\n        case SG_PIXELFORMAT_RG8:                    return MTLPixelFormatRG8Unorm;\r\n        case SG_PIXELFORMAT_RG8SN:                  return MTLPixelFormatRG8Snorm;\r\n        case SG_PIXELFORMAT_RG8UI:                  return MTLPixelFormatRG8Uint;\r\n        case SG_PIXELFORMAT_RG8SI:                  return MTLPixelFormatRG8Sint;\r\n        case SG_PIXELFORMAT_R32UI:                  return MTLPixelFormatR32Uint;\r\n        case SG_PIXELFORMAT_R32SI:                  return MTLPixelFormatR32Sint;\r\n        case SG_PIXELFORMAT_R32F:                   return MTLPixelFormatR32Float;\r\n        case SG_PIXELFORMAT_RG16:                   return MTLPixelFormatRG16Unorm;\r\n        case SG_PIXELFORMAT_RG16SN:                 return MTLPixelFormatRG16Snorm;\r\n        case SG_PIXELFORMAT_RG16UI:                 return MTLPixelFormatRG16Uint;\r\n        case SG_PIXELFORMAT_RG16SI:                 return MTLPixelFormatRG16Sint;\r\n        case SG_PIXELFORMAT_RG16F:                  return MTLPixelFormatRG16Float;\r\n        case SG_PIXELFORMAT_RGBA8:                  return MTLPixelFormatRGBA8Unorm;\r\n        case SG_PIXELFORMAT_RGBA8SN:                return MTLPixelFormatRGBA8Snorm;\r\n        case SG_PIXELFORMAT_RGBA8UI:                return MTLPixelFormatRGBA8Uint;\r\n        case SG_PIXELFORMAT_RGBA8SI:                return MTLPixelFormatRGBA8Sint;\r\n        case SG_PIXELFORMAT_BGRA8:                  return MTLPixelFormatBGRA8Unorm;\r\n        case SG_PIXELFORMAT_RGB10A2:                return MTLPixelFormatRGB10A2Unorm;\r\n        case SG_PIXELFORMAT_RG11B10F:               return MTLPixelFormatRG11B10Float;\r\n        case SG_PIXELFORMAT_RG32UI:                 return MTLPixelFormatRG32Uint;\r\n        case SG_PIXELFORMAT_RG32SI:                 return MTLPixelFormatRG32Sint;\r\n        case SG_PIXELFORMAT_RG32F:                  return MTLPixelFormatRG32Float;\r\n        case SG_PIXELFORMAT_RGBA16:                 return MTLPixelFormatRGBA16Unorm;\r\n        case SG_PIXELFORMAT_RGBA16SN:               return MTLPixelFormatRGBA16Snorm;\r\n        case SG_PIXELFORMAT_RGBA16UI:               return MTLPixelFormatRGBA16Uint;\r\n        case SG_PIXELFORMAT_RGBA16SI:               return MTLPixelFormatRGBA16Sint;\r\n        case SG_PIXELFORMAT_RGBA16F:                return MTLPixelFormatRGBA16Float;\r\n        case SG_PIXELFORMAT_RGBA32UI:               return MTLPixelFormatRGBA32Uint;\r\n        case SG_PIXELFORMAT_RGBA32SI:               return MTLPixelFormatRGBA32Sint;\r\n        case SG_PIXELFORMAT_RGBA32F:                return MTLPixelFormatRGBA32Float;\r\n        case SG_PIXELFORMAT_DEPTH:                  return MTLPixelFormatDepth32Float;\r\n        case SG_PIXELFORMAT_DEPTH_STENCIL:          return MTLPixelFormatDepth32Float_Stencil8;\r\n        #if defined(_SG_TARGET_MACOS)\r\n        case SG_PIXELFORMAT_BC1_RGBA:               return MTLPixelFormatBC1_RGBA;\r\n        case SG_PIXELFORMAT_BC2_RGBA:               return MTLPixelFormatBC2_RGBA;\r\n        case SG_PIXELFORMAT_BC3_RGBA:               return MTLPixelFormatBC3_RGBA;\r\n        case SG_PIXELFORMAT_BC4_R:                  return MTLPixelFormatBC4_RUnorm;\r\n        case SG_PIXELFORMAT_BC4_RSN:                return MTLPixelFormatBC4_RSnorm;\r\n        case SG_PIXELFORMAT_BC5_RG:                 return MTLPixelFormatBC5_RGUnorm;\r\n        case SG_PIXELFORMAT_BC5_RGSN:               return MTLPixelFormatBC5_RGSnorm;\r\n        case SG_PIXELFORMAT_BC6H_RGBF:              return MTLPixelFormatBC6H_RGBFloat;\r\n        case SG_PIXELFORMAT_BC6H_RGBUF:             return MTLPixelFormatBC6H_RGBUfloat;\r\n        case SG_PIXELFORMAT_BC7_RGBA:               return MTLPixelFormatBC7_RGBAUnorm;\r\n        #else\r\n        case SG_PIXELFORMAT_PVRTC_RGB_2BPP:         return MTLPixelFormatPVRTC_RGB_2BPP;\r\n        case SG_PIXELFORMAT_PVRTC_RGB_4BPP:         return MTLPixelFormatPVRTC_RGB_4BPP;\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_2BPP:        return MTLPixelFormatPVRTC_RGBA_2BPP;\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_4BPP:        return MTLPixelFormatPVRTC_RGBA_4BPP;\r\n        case SG_PIXELFORMAT_ETC2_RGB8:              return MTLPixelFormatETC2_RGB8;\r\n        case SG_PIXELFORMAT_ETC2_RGB8A1:            return MTLPixelFormatETC2_RGB8A1;\r\n        case SG_PIXELFORMAT_ETC2_RGBA8:             return MTLPixelFormatEAC_RGBA8;\r\n        case SG_PIXELFORMAT_ETC2_RG11:              return MTLPixelFormatEAC_RG11Unorm;\r\n        case SG_PIXELFORMAT_ETC2_RG11SN:            return MTLPixelFormatEAC_RG11Snorm;\r\n        #endif\r\n        default: return MTLPixelFormatInvalid;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLColorWriteMask _sg_mtl_color_write_mask(sg_color_mask m) {\r\n    MTLColorWriteMask mtl_mask = MTLColorWriteMaskNone;\r\n    if (m & SG_COLORMASK_R) {\r\n        mtl_mask |= MTLColorWriteMaskRed;\r\n    }\r\n    if (m & SG_COLORMASK_G) {\r\n        mtl_mask |= MTLColorWriteMaskGreen;\r\n    }\r\n    if (m & SG_COLORMASK_B) {\r\n        mtl_mask |= MTLColorWriteMaskBlue;\r\n    }\r\n    if (m & SG_COLORMASK_A) {\r\n        mtl_mask |= MTLColorWriteMaskAlpha;\r\n    }\r\n    return mtl_mask;\r\n}\r\n\r\n_SOKOL_PRIVATE MTLBlendOperation _sg_mtl_blend_op(sg_blend_op op) {\r\n    switch (op) {\r\n        case SG_BLENDOP_ADD:                return MTLBlendOperationAdd;\r\n        case SG_BLENDOP_SUBTRACT:           return MTLBlendOperationSubtract;\r\n        case SG_BLENDOP_REVERSE_SUBTRACT:   return MTLBlendOperationReverseSubtract;\r\n        default: SOKOL_UNREACHABLE; return (MTLBlendOperation)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLBlendFactor _sg_mtl_blend_factor(sg_blend_factor f) {\r\n    switch (f) {\r\n        case SG_BLENDFACTOR_ZERO:                   return MTLBlendFactorZero;\r\n        case SG_BLENDFACTOR_ONE:                    return MTLBlendFactorOne;\r\n        case SG_BLENDFACTOR_SRC_COLOR:              return MTLBlendFactorSourceColor;\r\n        case SG_BLENDFACTOR_ONE_MINUS_SRC_COLOR:    return MTLBlendFactorOneMinusSourceColor;\r\n        case SG_BLENDFACTOR_SRC_ALPHA:              return MTLBlendFactorSourceAlpha;\r\n        case SG_BLENDFACTOR_ONE_MINUS_SRC_ALPHA:    return MTLBlendFactorOneMinusSourceAlpha;\r\n        case SG_BLENDFACTOR_DST_COLOR:              return MTLBlendFactorDestinationColor;\r\n        case SG_BLENDFACTOR_ONE_MINUS_DST_COLOR:    return MTLBlendFactorOneMinusDestinationColor;\r\n        case SG_BLENDFACTOR_DST_ALPHA:              return MTLBlendFactorDestinationAlpha;\r\n        case SG_BLENDFACTOR_ONE_MINUS_DST_ALPHA:    return MTLBlendFactorOneMinusDestinationAlpha;\r\n        case SG_BLENDFACTOR_SRC_ALPHA_SATURATED:    return MTLBlendFactorSourceAlphaSaturated;\r\n        case SG_BLENDFACTOR_BLEND_COLOR:            return MTLBlendFactorBlendColor;\r\n        case SG_BLENDFACTOR_ONE_MINUS_BLEND_COLOR:  return MTLBlendFactorOneMinusBlendColor;\r\n        case SG_BLENDFACTOR_BLEND_ALPHA:            return MTLBlendFactorBlendAlpha;\r\n        case SG_BLENDFACTOR_ONE_MINUS_BLEND_ALPHA:  return MTLBlendFactorOneMinusBlendAlpha;\r\n        default: SOKOL_UNREACHABLE; return (MTLBlendFactor)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLCompareFunction _sg_mtl_compare_func(sg_compare_func f) {\r\n    switch (f) {\r\n        case SG_COMPAREFUNC_NEVER:          return MTLCompareFunctionNever;\r\n        case SG_COMPAREFUNC_LESS:           return MTLCompareFunctionLess;\r\n        case SG_COMPAREFUNC_EQUAL:          return MTLCompareFunctionEqual;\r\n        case SG_COMPAREFUNC_LESS_EQUAL:     return MTLCompareFunctionLessEqual;\r\n        case SG_COMPAREFUNC_GREATER:        return MTLCompareFunctionGreater;\r\n        case SG_COMPAREFUNC_NOT_EQUAL:      return MTLCompareFunctionNotEqual;\r\n        case SG_COMPAREFUNC_GREATER_EQUAL:  return MTLCompareFunctionGreaterEqual;\r\n        case SG_COMPAREFUNC_ALWAYS:         return MTLCompareFunctionAlways;\r\n        default: SOKOL_UNREACHABLE; return (MTLCompareFunction)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLStencilOperation _sg_mtl_stencil_op(sg_stencil_op op) {\r\n    switch (op) {\r\n        case SG_STENCILOP_KEEP:         return MTLStencilOperationKeep;\r\n        case SG_STENCILOP_ZERO:         return MTLStencilOperationZero;\r\n        case SG_STENCILOP_REPLACE:      return MTLStencilOperationReplace;\r\n        case SG_STENCILOP_INCR_CLAMP:   return MTLStencilOperationIncrementClamp;\r\n        case SG_STENCILOP_DECR_CLAMP:   return MTLStencilOperationDecrementClamp;\r\n        case SG_STENCILOP_INVERT:       return MTLStencilOperationInvert;\r\n        case SG_STENCILOP_INCR_WRAP:    return MTLStencilOperationIncrementWrap;\r\n        case SG_STENCILOP_DECR_WRAP:    return MTLStencilOperationDecrementWrap;\r\n        default: SOKOL_UNREACHABLE; return (MTLStencilOperation)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLCullMode _sg_mtl_cull_mode(sg_cull_mode m) {\r\n    switch (m) {\r\n        case SG_CULLMODE_NONE:  return MTLCullModeNone;\r\n        case SG_CULLMODE_FRONT: return MTLCullModeFront;\r\n        case SG_CULLMODE_BACK:  return MTLCullModeBack;\r\n        default: SOKOL_UNREACHABLE; return (MTLCullMode)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLWinding _sg_mtl_winding(sg_face_winding w) {\r\n    switch (w) {\r\n        case SG_FACEWINDING_CW:     return MTLWindingClockwise;\r\n        case SG_FACEWINDING_CCW:    return MTLWindingCounterClockwise;\r\n        default: SOKOL_UNREACHABLE; return (MTLWinding)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLIndexType _sg_mtl_index_type(sg_index_type t) {\r\n    switch (t) {\r\n        case SG_INDEXTYPE_UINT16:   return MTLIndexTypeUInt16;\r\n        case SG_INDEXTYPE_UINT32:   return MTLIndexTypeUInt32;\r\n        default: SOKOL_UNREACHABLE; return (MTLIndexType)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE NSUInteger _sg_mtl_index_size(sg_index_type t) {\r\n    switch (t) {\r\n        case SG_INDEXTYPE_NONE:     return 0;\r\n        case SG_INDEXTYPE_UINT16:   return 2;\r\n        case SG_INDEXTYPE_UINT32:   return 4;\r\n        default: SOKOL_UNREACHABLE; return 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLTextureType _sg_mtl_texture_type(sg_image_type t) {\r\n    switch (t) {\r\n        case SG_IMAGETYPE_2D:       return MTLTextureType2D;\r\n        case SG_IMAGETYPE_CUBE:     return MTLTextureTypeCube;\r\n        case SG_IMAGETYPE_3D:       return MTLTextureType3D;\r\n        case SG_IMAGETYPE_ARRAY:    return MTLTextureType2DArray;\r\n        default: SOKOL_UNREACHABLE; return (MTLTextureType)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_mtl_is_pvrtc(sg_pixel_format fmt) {\r\n    switch (fmt) {\r\n        case SG_PIXELFORMAT_PVRTC_RGB_2BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGB_4BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_2BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_4BPP:\r\n            return true;\r\n        default:\r\n            return false;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLSamplerAddressMode _sg_mtl_address_mode(sg_wrap w) {\r\n    switch (w) {\r\n        case SG_WRAP_REPEAT:            return MTLSamplerAddressModeRepeat;\r\n        case SG_WRAP_CLAMP_TO_EDGE:     return MTLSamplerAddressModeClampToEdge;\r\n        #if defined(_SG_TARGET_MACOS)\r\n        case SG_WRAP_CLAMP_TO_BORDER:   return MTLSamplerAddressModeClampToBorderColor;\r\n        #else\r\n        /* clamp-to-border not supported on iOS, fall back to clamp-to-edge */\r\n        case SG_WRAP_CLAMP_TO_BORDER:   return MTLSamplerAddressModeClampToEdge;\r\n        #endif\r\n        case SG_WRAP_MIRRORED_REPEAT:   return MTLSamplerAddressModeMirrorRepeat;\r\n        default: SOKOL_UNREACHABLE; return (MTLSamplerAddressMode)0;\r\n    }\r\n}\r\n\r\n#if defined(_SG_TARGET_MACOS)\r\n_SOKOL_PRIVATE MTLSamplerBorderColor _sg_mtl_border_color(sg_border_color c) {\r\n    switch (c) {\r\n        case SG_BORDERCOLOR_TRANSPARENT_BLACK: return MTLSamplerBorderColorTransparentBlack;\r\n        case SG_BORDERCOLOR_OPAQUE_BLACK: return MTLSamplerBorderColorOpaqueBlack;\r\n        case SG_BORDERCOLOR_OPAQUE_WHITE: return MTLSamplerBorderColorOpaqueWhite;\r\n        default: SOKOL_UNREACHABLE; return (MTLSamplerBorderColor)0;\r\n    }\r\n}\r\n#endif\r\n\r\n_SOKOL_PRIVATE MTLSamplerMinMagFilter _sg_mtl_minmag_filter(sg_filter f) {\r\n    switch (f) {\r\n        case SG_FILTER_NEAREST:\r\n        case SG_FILTER_NEAREST_MIPMAP_NEAREST:\r\n        case SG_FILTER_NEAREST_MIPMAP_LINEAR:\r\n            return MTLSamplerMinMagFilterNearest;\r\n        case SG_FILTER_LINEAR:\r\n        case SG_FILTER_LINEAR_MIPMAP_NEAREST:\r\n        case SG_FILTER_LINEAR_MIPMAP_LINEAR:\r\n            return MTLSamplerMinMagFilterLinear;\r\n        default:\r\n            SOKOL_UNREACHABLE; return (MTLSamplerMinMagFilter)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE MTLSamplerMipFilter _sg_mtl_mip_filter(sg_filter f) {\r\n    switch (f) {\r\n        case SG_FILTER_NEAREST:\r\n        case SG_FILTER_LINEAR:\r\n            return MTLSamplerMipFilterNotMipmapped;\r\n        case SG_FILTER_NEAREST_MIPMAP_NEAREST:\r\n        case SG_FILTER_LINEAR_MIPMAP_NEAREST:\r\n            return MTLSamplerMipFilterNearest;\r\n        case SG_FILTER_NEAREST_MIPMAP_LINEAR:\r\n        case SG_FILTER_LINEAR_MIPMAP_LINEAR:\r\n            return MTLSamplerMipFilterLinear;\r\n        default:\r\n            SOKOL_UNREACHABLE; return (MTLSamplerMipFilter)0;\r\n    }\r\n}\r\n\r\n/*-- a pool for all Metal resource objects, with deferred release queue -------*/\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_init_pool(const sg_desc* desc) {\r\n    _sg.mtl.idpool.num_slots = 2 *\r\n        (\r\n            2 * desc->buffer_pool_size +\r\n            5 * desc->image_pool_size +\r\n            4 * desc->shader_pool_size +\r\n            2 * desc->pipeline_pool_size +\r\n            desc->pass_pool_size\r\n        );\r\n    _sg.mtl.idpool.pool = [NSMutableArray arrayWithCapacity:_sg.mtl.idpool.num_slots];\r\n    _SG_OBJC_RETAIN(_sg.mtl.idpool.pool);\r\n    NSNull* null = [NSNull null];\r\n    for (uint32_t i = 0; i < _sg.mtl.idpool.num_slots; i++) {\r\n        [_sg.mtl.idpool.pool addObject:null];\r\n    }\r\n    SOKOL_ASSERT([_sg.mtl.idpool.pool count] == _sg.mtl.idpool.num_slots);\r\n    /* a queue of currently free slot indices */\r\n    _sg.mtl.idpool.free_queue_top = 0;\r\n    _sg.mtl.idpool.free_queue = (uint32_t*)SOKOL_MALLOC(_sg.mtl.idpool.num_slots * sizeof(uint32_t));\r\n    /* pool slot 0 is reserved! */\r\n    for (int i = _sg.mtl.idpool.num_slots-1; i >= 1; i--) {\r\n        _sg.mtl.idpool.free_queue[_sg.mtl.idpool.free_queue_top++] = (uint32_t)i;\r\n    }\r\n    /* a circular queue which holds release items (frame index\r\n       when a resource is to be released, and the resource's\r\n       pool index\r\n    */\r\n    _sg.mtl.idpool.release_queue_front = 0;\r\n    _sg.mtl.idpool.release_queue_back = 0;\r\n    _sg.mtl.idpool.release_queue = (_sg_mtl_release_item_t*)SOKOL_MALLOC(_sg.mtl.idpool.num_slots * sizeof(_sg_mtl_release_item_t));\r\n    for (uint32_t i = 0; i < _sg.mtl.idpool.num_slots; i++) {\r\n        _sg.mtl.idpool.release_queue[i].frame_index = 0;\r\n        _sg.mtl.idpool.release_queue[i].slot_index = _SG_MTL_INVALID_SLOT_INDEX;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_destroy_pool(void) {\r\n    SOKOL_FREE(_sg.mtl.idpool.release_queue);  _sg.mtl.idpool.release_queue = 0;\r\n    SOKOL_FREE(_sg.mtl.idpool.free_queue);     _sg.mtl.idpool.free_queue = 0;\r\n    _SG_OBJC_RELEASE(_sg.mtl.idpool.pool);\r\n}\r\n\r\n/* get a new free resource pool slot */\r\n_SOKOL_PRIVATE uint32_t _sg_mtl_alloc_pool_slot(void) {\r\n    SOKOL_ASSERT(_sg.mtl.idpool.free_queue_top > 0);\r\n    const uint32_t slot_index = _sg.mtl.idpool.free_queue[--_sg.mtl.idpool.free_queue_top];\r\n    SOKOL_ASSERT((slot_index > 0) && (slot_index < _sg.mtl.idpool.num_slots));\r\n    return slot_index;\r\n}\r\n\r\n/* put a free resource pool slot back into the free-queue */\r\n_SOKOL_PRIVATE void _sg_mtl_free_pool_slot(uint32_t slot_index) {\r\n    SOKOL_ASSERT(_sg.mtl.idpool.free_queue_top < _sg.mtl.idpool.num_slots);\r\n    SOKOL_ASSERT((slot_index > 0) && (slot_index < _sg.mtl.idpool.num_slots));\r\n    _sg.mtl.idpool.free_queue[_sg.mtl.idpool.free_queue_top++] = slot_index;\r\n}\r\n\r\n/*  add an MTLResource to the pool, return pool index or 0 if input was 'nil' */\r\n_SOKOL_PRIVATE uint32_t _sg_mtl_add_resource(id res) {\r\n    if (nil == res) {\r\n        return _SG_MTL_INVALID_SLOT_INDEX;\r\n    }\r\n    const uint32_t slot_index = _sg_mtl_alloc_pool_slot();\r\n    SOKOL_ASSERT([NSNull null] == _sg.mtl.idpool.pool[slot_index]);\r\n    _sg.mtl.idpool.pool[slot_index] = res;\r\n    return slot_index;\r\n}\r\n\r\n/*  mark an MTLResource for release, this will put the resource into the\r\n    deferred-release queue, and the resource will then be released N frames later,\r\n    the special pool index 0 will be ignored (this means that a nil\r\n    value was provided to _sg_mtl_add_resource()\r\n*/\r\n_SOKOL_PRIVATE void _sg_mtl_release_resource(uint32_t frame_index, uint32_t slot_index) {\r\n    if (slot_index == _SG_MTL_INVALID_SLOT_INDEX) {\r\n        return;\r\n    }\r\n    SOKOL_ASSERT((slot_index > 0) && (slot_index < _sg.mtl.idpool.num_slots));\r\n    SOKOL_ASSERT([NSNull null] != _sg.mtl.idpool.pool[slot_index]);\r\n    int release_index = _sg.mtl.idpool.release_queue_front++;\r\n    if (_sg.mtl.idpool.release_queue_front >= _sg.mtl.idpool.num_slots) {\r\n        /* wrap-around */\r\n        _sg.mtl.idpool.release_queue_front = 0;\r\n    }\r\n    /* release queue full? */\r\n    SOKOL_ASSERT(_sg.mtl.idpool.release_queue_front != _sg.mtl.idpool.release_queue_back);\r\n    SOKOL_ASSERT(0 == _sg.mtl.idpool.release_queue[release_index].frame_index);\r\n    const uint32_t safe_to_release_frame_index = frame_index + SG_NUM_INFLIGHT_FRAMES + 1;\r\n    _sg.mtl.idpool.release_queue[release_index].frame_index = safe_to_release_frame_index;\r\n    _sg.mtl.idpool.release_queue[release_index].slot_index = slot_index;\r\n}\r\n\r\n/* run garbage-collection pass on all resources in the release-queue */\r\n_SOKOL_PRIVATE void _sg_mtl_garbage_collect(uint32_t frame_index) {\r\n    while (_sg.mtl.idpool.release_queue_back != _sg.mtl.idpool.release_queue_front) {\r\n        if (frame_index < _sg.mtl.idpool.release_queue[_sg.mtl.idpool.release_queue_back].frame_index) {\r\n            /* don't need to check further, release-items past this are too young */\r\n            break;\r\n        }\r\n        /* safe to release this resource */\r\n        const uint32_t slot_index = _sg.mtl.idpool.release_queue[_sg.mtl.idpool.release_queue_back].slot_index;\r\n        SOKOL_ASSERT((slot_index > 0) && (slot_index < _sg.mtl.idpool.num_slots));\r\n        SOKOL_ASSERT(_sg.mtl.idpool.pool[slot_index] != [NSNull null]);\r\n        _SG_OBJC_RELEASE_WITH_NULL(_sg.mtl.idpool.pool[slot_index]);\r\n        /* put the now free pool index back on the free queue */\r\n        _sg_mtl_free_pool_slot(slot_index);\r\n        /* reset the release queue slot and advance the back index */\r\n        _sg.mtl.idpool.release_queue[_sg.mtl.idpool.release_queue_back].frame_index = 0;\r\n        _sg.mtl.idpool.release_queue[_sg.mtl.idpool.release_queue_back].slot_index = _SG_MTL_INVALID_SLOT_INDEX;\r\n        _sg.mtl.idpool.release_queue_back++;\r\n        if (_sg.mtl.idpool.release_queue_back >= _sg.mtl.idpool.num_slots) {\r\n            /* wrap-around */\r\n            _sg.mtl.idpool.release_queue_back = 0;\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE id _sg_mtl_id(uint32_t slot_index) {\r\n    return _sg.mtl.idpool.pool[slot_index];\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_init_sampler_cache(const sg_desc* desc) {\r\n    SOKOL_ASSERT(desc->sampler_cache_size > 0);\r\n    _sg_smpcache_init(&_sg.mtl.sampler_cache, desc->sampler_cache_size);\r\n}\r\n\r\n/* destroy the sampler cache, and release all sampler objects */\r\n_SOKOL_PRIVATE void _sg_mtl_destroy_sampler_cache(uint32_t frame_index) {\r\n    SOKOL_ASSERT(_sg.mtl.sampler_cache.items);\r\n    SOKOL_ASSERT(_sg.mtl.sampler_cache.num_items <= _sg.mtl.sampler_cache.capacity);\r\n    for (int i = 0; i < _sg.mtl.sampler_cache.num_items; i++) {\r\n        _sg_mtl_release_resource(frame_index, (uint32_t)_sg_smpcache_sampler(&_sg.mtl.sampler_cache, i));\r\n    }\r\n    _sg_smpcache_discard(&_sg.mtl.sampler_cache);\r\n}\r\n\r\n/*\r\n    create and add an MTLSamplerStateObject and return its resource pool index,\r\n    reuse identical sampler state if one exists\r\n*/\r\n_SOKOL_PRIVATE uint32_t _sg_mtl_create_sampler(id<MTLDevice> mtl_device, const sg_image_desc* img_desc) {\r\n    SOKOL_ASSERT(img_desc);\r\n    int index = _sg_smpcache_find_item(&_sg.mtl.sampler_cache, img_desc);\r\n    if (index >= 0) {\r\n        /* reuse existing sampler */\r\n        return (uint32_t) _sg_smpcache_sampler(&_sg.mtl.sampler_cache, index);\r\n    }\r\n    else {\r\n        /* create a new Metal sampler state object and add to sampler cache */\r\n        MTLSamplerDescriptor* mtl_desc = [[MTLSamplerDescriptor alloc] init];\r\n        mtl_desc.sAddressMode = _sg_mtl_address_mode(img_desc->wrap_u);\r\n        mtl_desc.tAddressMode = _sg_mtl_address_mode(img_desc->wrap_v);\r\n        if (SG_IMAGETYPE_3D == img_desc->type) {\r\n            mtl_desc.rAddressMode = _sg_mtl_address_mode(img_desc->wrap_w);\r\n        }\r\n        #if defined(_SG_TARGET_MACOS)\r\n            mtl_desc.borderColor = _sg_mtl_border_color(img_desc->border_color);\r\n        #endif\r\n        mtl_desc.minFilter = _sg_mtl_minmag_filter(img_desc->min_filter);\r\n        mtl_desc.magFilter = _sg_mtl_minmag_filter(img_desc->mag_filter);\r\n        mtl_desc.mipFilter = _sg_mtl_mip_filter(img_desc->min_filter);\r\n        mtl_desc.lodMinClamp = img_desc->min_lod;\r\n        mtl_desc.lodMaxClamp = img_desc->max_lod;\r\n        mtl_desc.maxAnisotropy = img_desc->max_anisotropy;\r\n        mtl_desc.normalizedCoordinates = YES;\r\n        id<MTLSamplerState> mtl_sampler = [mtl_device newSamplerStateWithDescriptor:mtl_desc];\r\n        _SG_OBJC_RELEASE(mtl_desc);\r\n        uint32_t sampler_handle = _sg_mtl_add_resource(mtl_sampler);\r\n        _sg_smpcache_add_item(&_sg.mtl.sampler_cache, img_desc, sampler_handle);\r\n        return sampler_handle;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_clear_state_cache(void) {\r\n    memset(&_sg.mtl.state_cache, 0, sizeof(_sg.mtl.state_cache));\r\n}\r\n\r\n/* https://developer.apple.com/metal/Metal-Feature-Set-Tables.pdf */\r\n_SOKOL_PRIVATE void _sg_mtl_init_caps(void) {\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg.backend = SG_BACKEND_METAL_MACOS;\r\n    #elif defined(_SG_TARGET_IOS)\r\n        #if defined(_SG_TARGET_IOS_SIMULATOR)\r\n            _sg.backend = SG_BACKEND_METAL_SIMULATOR;\r\n        #else\r\n            _sg.backend = SG_BACKEND_METAL_IOS;\r\n        #endif\r\n    #endif\r\n    _sg.features.instancing = true;\r\n    _sg.features.origin_top_left = true;\r\n    _sg.features.multiple_render_targets = true;\r\n    _sg.features.msaa_render_targets = true;\r\n    _sg.features.imagetype_3d = true;\r\n    _sg.features.imagetype_array = true;\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg.features.image_clamp_to_border = true;\r\n    #else\r\n        _sg.features.image_clamp_to_border = false;\r\n    #endif\r\n\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg.limits.max_image_size_2d = 16 * 1024;\r\n        _sg.limits.max_image_size_cube = 16 * 1024;\r\n        _sg.limits.max_image_size_3d = 2 * 1024;\r\n        _sg.limits.max_image_size_array = 16 * 1024;\r\n        _sg.limits.max_image_array_layers = 2 * 1024;\r\n    #else\r\n        /* newer iOS devices support 16k textures */\r\n        _sg.limits.max_image_size_2d = 8 * 1024;\r\n        _sg.limits.max_image_size_cube = 8 * 1024;\r\n        _sg.limits.max_image_size_3d = 2 * 1024;\r\n        _sg.limits.max_image_size_array = 8 * 1024;\r\n        _sg.limits.max_image_array_layers = 2 * 1024;\r\n    #endif\r\n    _sg.limits.max_vertex_attrs = SG_MAX_VERTEX_ATTRIBUTES;\r\n\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R8]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R8SN]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R8UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R8SI]);\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16]);\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16SN]);\r\n    #else\r\n        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_R16]);\r\n        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_R16SN]);\r\n    #endif\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R16UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R16SI]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16F]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG8]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG8SN]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG8UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG8SI]);\r\n    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32UI]);\r\n    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32SI]);\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R32F]);\r\n    #else\r\n        _sg_pixelformat_sbr(&_sg.formats[SG_PIXELFORMAT_R32F]);\r\n    #endif\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16]);\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16SN]);\r\n    #else\r\n        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_RG16]);\r\n        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_RG16SN]);\r\n    #endif\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG16UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG16SI]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16F]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA8]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA8SN]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA8UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA8SI]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_BGRA8]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGB10A2]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG11B10F]);\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG32UI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG32SI]);\r\n    #else\r\n        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG32UI]);\r\n        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG32SI]);\r\n    #endif\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG32F]);\r\n    #else\r\n        _sg_pixelformat_sbr(&_sg.formats[SG_PIXELFORMAT_RG32F]);\r\n    #endif\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16]);\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16SN]);\r\n    #else\r\n        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_RGBA16]);\r\n        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_RGBA16SN]);\r\n    #endif\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA16UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA16SI]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);\r\n        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);\r\n        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n    #else\r\n        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);\r\n        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);\r\n        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n    #endif\r\n    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH]);\r\n    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH_STENCIL]);\r\n    #if defined(_SG_TARGET_MACOS)\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC1_RGBA]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC2_RGBA]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC3_RGBA]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_R]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_RSN]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RG]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RGSN]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBF]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBUF]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC7_RGBA]);\r\n    #else\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_PVRTC_RGB_2BPP]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_PVRTC_RGB_4BPP]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_PVRTC_RGBA_2BPP]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_PVRTC_RGBA_4BPP]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGB8]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGB8A1]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGBA8]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RG11]);\r\n        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RG11SN]);\r\n    #endif\r\n}\r\n\r\n/*-- main Metal backend state and functions ----------------------------------*/\r\n_SOKOL_PRIVATE void _sg_mtl_setup_backend(const sg_desc* desc) {\r\n    /* assume already zero-initialized */\r\n    SOKOL_ASSERT(desc);\r\n    SOKOL_ASSERT(desc->context.metal.device);\r\n    SOKOL_ASSERT(desc->context.metal.renderpass_descriptor_cb || desc->context.metal.renderpass_descriptor_userdata_cb);\r\n    SOKOL_ASSERT(desc->context.metal.drawable_cb || desc->context.metal.drawable_userdata_cb);\r\n    SOKOL_ASSERT(desc->uniform_buffer_size > 0);\r\n    _sg_mtl_init_pool(desc);\r\n    _sg_mtl_init_sampler_cache(desc);\r\n    _sg_mtl_clear_state_cache();\r\n    _sg.mtl.valid = true;\r\n    _sg.mtl.renderpass_descriptor_cb = desc->context.metal.renderpass_descriptor_cb;\r\n    _sg.mtl.renderpass_descriptor_userdata_cb = desc->context.metal.renderpass_descriptor_userdata_cb;\r\n    _sg.mtl.drawable_cb = desc->context.metal.drawable_cb;\r\n    _sg.mtl.drawable_userdata_cb = desc->context.metal.drawable_userdata_cb;\r\n    _sg.mtl.user_data = desc->context.metal.user_data;\r\n    _sg.mtl.frame_index = 1;\r\n    _sg.mtl.ub_size = desc->uniform_buffer_size;\r\n    _sg.mtl.sem = dispatch_semaphore_create(SG_NUM_INFLIGHT_FRAMES);\r\n    _sg.mtl.device = (__bridge id<MTLDevice>) desc->context.metal.device;\r\n    _sg.mtl.cmd_queue = [_sg.mtl.device newCommandQueue];\r\n    MTLResourceOptions res_opts = MTLResourceCPUCacheModeWriteCombined;\r\n    #if defined(_SG_TARGET_MACOS)\r\n    res_opts |= MTLResourceStorageModeManaged;\r\n    #endif\r\n    for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {\r\n        _sg.mtl.uniform_buffers[i] = [_sg.mtl.device\r\n            newBufferWithLength:_sg.mtl.ub_size\r\n            options:res_opts\r\n        ];\r\n    }\r\n    _sg_mtl_init_caps();\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_discard_backend(void) {\r\n    SOKOL_ASSERT(_sg.mtl.valid);\r\n    /* wait for the last frame to finish */\r\n    for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {\r\n        dispatch_semaphore_wait(_sg.mtl.sem, DISPATCH_TIME_FOREVER);\r\n    }\r\n    /* semaphore must be \"relinquished\" before destruction */\r\n    for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {\r\n        dispatch_semaphore_signal(_sg.mtl.sem);\r\n    }\r\n    _sg_mtl_destroy_sampler_cache(_sg.mtl.frame_index);\r\n    _sg_mtl_garbage_collect(_sg.mtl.frame_index + SG_NUM_INFLIGHT_FRAMES + 2);\r\n    _sg_mtl_destroy_pool();\r\n    _sg.mtl.valid = false;\r\n\r\n    _SG_OBJC_RELEASE(_sg.mtl.sem);\r\n    _SG_OBJC_RELEASE(_sg.mtl.device);\r\n    _SG_OBJC_RELEASE(_sg.mtl.cmd_queue);\r\n    for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {\r\n        _SG_OBJC_RELEASE(_sg.mtl.uniform_buffers[i]);\r\n    }\r\n    /* NOTE: MTLCommandBuffer and MTLRenderCommandEncoder are auto-released */\r\n    _sg.mtl.cmd_buffer = nil;\r\n    _sg.mtl.cmd_encoder = nil;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_bind_uniform_buffers(void) {\r\n    SOKOL_ASSERT(nil != _sg.mtl.cmd_encoder);\r\n    for (int slot = 0; slot < SG_MAX_SHADERSTAGE_UBS; slot++) {\r\n        [_sg.mtl.cmd_encoder\r\n            setVertexBuffer:_sg.mtl.uniform_buffers[_sg.mtl.cur_frame_rotate_index]\r\n            offset:0\r\n            atIndex:slot];\r\n        [_sg.mtl.cmd_encoder\r\n            setFragmentBuffer:_sg.mtl.uniform_buffers[_sg.mtl.cur_frame_rotate_index]\r\n            offset:0\r\n            atIndex:slot];\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_reset_state_cache(void) {\r\n    _sg_mtl_clear_state_cache();\r\n\r\n    /* need to restore the uniform buffer binding (normally happens in\r\n       _sg_mtl_begin_pass()\r\n    */\r\n    if (nil != _sg.mtl.cmd_encoder) {\r\n        _sg_mtl_bind_uniform_buffers();\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    _SOKOL_UNUSED(ctx);\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_destroy_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    _SOKOL_UNUSED(ctx);\r\n    /* empty */\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_activate_context(_sg_context_t* ctx) {\r\n    _SOKOL_UNUSED(ctx);\r\n    _sg_mtl_clear_state_cache();\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {\r\n    SOKOL_ASSERT(buf && desc);\r\n    _sg_buffer_common_init(&buf->cmn, desc);\r\n    const bool injected = (0 != desc->mtl_buffers[0]);\r\n    MTLResourceOptions mtl_options = _sg_mtl_buffer_resource_options(buf->cmn.usage);\r\n    for (int slot = 0; slot < buf->cmn.num_slots; slot++) {\r\n        id<MTLBuffer> mtl_buf;\r\n        if (injected) {\r\n            SOKOL_ASSERT(desc->mtl_buffers[slot]);\r\n            mtl_buf = (__bridge id<MTLBuffer>) desc->mtl_buffers[slot];\r\n        }\r\n        else {\r\n            if (buf->cmn.usage == SG_USAGE_IMMUTABLE) {\r\n                SOKOL_ASSERT(desc->content);\r\n                mtl_buf = [_sg.mtl.device newBufferWithBytes:desc->content length:buf->cmn.size options:mtl_options];\r\n            }\r\n            else {\r\n                mtl_buf = [_sg.mtl.device newBufferWithLength:buf->cmn.size options:mtl_options];\r\n            }\r\n        }\r\n        buf->mtl.buf[slot] = _sg_mtl_add_resource(mtl_buf);\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_destroy_buffer(_sg_buffer_t* buf) {\r\n    SOKOL_ASSERT(buf);\r\n    for (int slot = 0; slot < buf->cmn.num_slots; slot++) {\r\n        /* it's valid to call release resource with '0' */\r\n        _sg_mtl_release_resource(_sg.mtl.frame_index, buf->mtl.buf[slot]);\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_copy_image_content(const _sg_image_t* img, __unsafe_unretained id<MTLTexture> mtl_tex, const sg_image_content* content) {\r\n    const int num_faces = (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6:1;\r\n    const int num_slices = (img->cmn.type == SG_IMAGETYPE_ARRAY) ? img->cmn.depth : 1;\r\n    for (int face_index = 0; face_index < num_faces; face_index++) {\r\n        for (int mip_index = 0; mip_index < img->cmn.num_mipmaps; mip_index++) {\r\n            SOKOL_ASSERT(content->subimage[face_index][mip_index].ptr);\r\n            SOKOL_ASSERT(content->subimage[face_index][mip_index].size > 0);\r\n            const uint8_t* data_ptr = (const uint8_t*)content->subimage[face_index][mip_index].ptr;\r\n            const int mip_width = _sg_max(img->cmn.width >> mip_index, 1);\r\n            const int mip_height = _sg_max(img->cmn.height >> mip_index, 1);\r\n            /* special case PVRTC formats: bytePerRow must be 0 */\r\n            int bytes_per_row = 0;\r\n            int bytes_per_slice = _sg_surface_pitch(img->cmn.pixel_format, mip_width, mip_height, 1);\r\n            if (!_sg_mtl_is_pvrtc(img->cmn.pixel_format)) {\r\n                bytes_per_row = _sg_row_pitch(img->cmn.pixel_format, mip_width, 1);\r\n            }\r\n            MTLRegion region;\r\n            if (img->cmn.type == SG_IMAGETYPE_3D) {\r\n                const int mip_depth = _sg_max(img->cmn.depth >> mip_index, 1);\r\n                region = MTLRegionMake3D(0, 0, 0, mip_width, mip_height, mip_depth);\r\n                /* FIXME: apparently the minimal bytes_per_image size for 3D texture\r\n                 is 4 KByte... somehow need to handle this */\r\n            }\r\n            else {\r\n                region = MTLRegionMake2D(0, 0, mip_width, mip_height);\r\n            }\r\n            for (int slice_index = 0; slice_index < num_slices; slice_index++) {\r\n                const int mtl_slice_index = (img->cmn.type == SG_IMAGETYPE_CUBE) ? face_index : slice_index;\r\n                const int slice_offset = slice_index * bytes_per_slice;\r\n                SOKOL_ASSERT((slice_offset + bytes_per_slice) <= (int)content->subimage[face_index][mip_index].size);\r\n                [mtl_tex replaceRegion:region\r\n                    mipmapLevel:mip_index\r\n                    slice:mtl_slice_index\r\n                    withBytes:data_ptr + slice_offset\r\n                    bytesPerRow:bytes_per_row\r\n                    bytesPerImage:bytes_per_slice];\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n/*\r\n    FIXME: METAL RESOURCE STORAGE MODE FOR macOS AND iOS\r\n\r\n    For immutable textures on macOS, the recommended procedure is to create\r\n    a MTLStorageModeManaged texture with the immutable content first,\r\n    and then use the GPU to blit the content into a MTLStorageModePrivate\r\n    texture before the first use.\r\n\r\n    On iOS use the same one-time-blit procedure, but from a\r\n    MTLStorageModeShared to a MTLStorageModePrivate texture.\r\n\r\n    It probably makes sense to handle this in a separate 'resource manager'\r\n    with a recycable pool of blit-source-textures?\r\n*/\r\n\r\n/* initialize MTLTextureDescritor with common attributes */\r\n_SOKOL_PRIVATE bool _sg_mtl_init_texdesc_common(MTLTextureDescriptor* mtl_desc, _sg_image_t* img) {\r\n    mtl_desc.textureType = _sg_mtl_texture_type(img->cmn.type);\r\n    mtl_desc.pixelFormat = _sg_mtl_pixel_format(img->cmn.pixel_format);\r\n    if (MTLPixelFormatInvalid == mtl_desc.pixelFormat) {\r\n        SOKOL_LOG(\"Unsupported texture pixel format!\\n\");\r\n        return false;\r\n    }\r\n    mtl_desc.width = img->cmn.width;\r\n    mtl_desc.height = img->cmn.height;\r\n    if (SG_IMAGETYPE_3D == img->cmn.type) {\r\n        mtl_desc.depth = img->cmn.depth;\r\n    }\r\n    else {\r\n        mtl_desc.depth = 1;\r\n    }\r\n    mtl_desc.mipmapLevelCount = img->cmn.num_mipmaps;\r\n    if (SG_IMAGETYPE_ARRAY == img->cmn.type) {\r\n        mtl_desc.arrayLength = img->cmn.depth;\r\n    }\r\n    else {\r\n        mtl_desc.arrayLength = 1;\r\n    }\r\n    mtl_desc.usage = MTLTextureUsageShaderRead;\r\n    if (img->cmn.usage != SG_USAGE_IMMUTABLE) {\r\n        mtl_desc.cpuCacheMode = MTLCPUCacheModeWriteCombined;\r\n    }\r\n    #if defined(_SG_TARGET_MACOS)\r\n        /* macOS: use managed textures */\r\n        mtl_desc.resourceOptions = MTLResourceStorageModeManaged;\r\n        mtl_desc.storageMode = MTLStorageModeManaged;\r\n    #else\r\n        /* iOS: use CPU/GPU shared memory */\r\n        mtl_desc.resourceOptions = MTLResourceStorageModeShared;\r\n        mtl_desc.storageMode = MTLStorageModeShared;\r\n    #endif\r\n    return true;\r\n}\r\n\r\n/* initialize MTLTextureDescritor with rendertarget attributes */\r\n_SOKOL_PRIVATE void _sg_mtl_init_texdesc_rt(MTLTextureDescriptor* mtl_desc, _sg_image_t* img) {\r\n    SOKOL_ASSERT(img->cmn.render_target);\r\n    _SOKOL_UNUSED(img);\r\n    /* reset the cpuCacheMode to 'default' */\r\n    mtl_desc.cpuCacheMode = MTLCPUCacheModeDefaultCache;\r\n    /* render targets are only visible to the GPU */\r\n    mtl_desc.resourceOptions = MTLResourceStorageModePrivate;\r\n    mtl_desc.storageMode = MTLStorageModePrivate;\r\n    /* non-MSAA render targets are shader-readable */\r\n    mtl_desc.usage = MTLTextureUsageShaderRead | MTLTextureUsageRenderTarget;\r\n}\r\n\r\n/* initialize MTLTextureDescritor with MSAA attributes */\r\n_SOKOL_PRIVATE void _sg_mtl_init_texdesc_rt_msaa(MTLTextureDescriptor* mtl_desc, _sg_image_t* img) {\r\n    SOKOL_ASSERT(img->cmn.sample_count > 1);\r\n    /* reset the cpuCacheMode to 'default' */\r\n    mtl_desc.cpuCacheMode = MTLCPUCacheModeDefaultCache;\r\n    /* render targets are only visible to the GPU */\r\n    mtl_desc.resourceOptions = MTLResourceStorageModePrivate;\r\n    mtl_desc.storageMode = MTLStorageModePrivate;\r\n    /* MSAA render targets are not shader-readable (instead they are resolved) */\r\n    mtl_desc.usage = MTLTextureUsageRenderTarget;\r\n    mtl_desc.textureType = MTLTextureType2DMultisample;\r\n    mtl_desc.depth = 1;\r\n    mtl_desc.arrayLength = 1;\r\n    mtl_desc.mipmapLevelCount = 1;\r\n    mtl_desc.sampleCount = img->cmn.sample_count;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_image(_sg_image_t* img, const sg_image_desc* desc) {\r\n    SOKOL_ASSERT(img && desc);\r\n    _sg_image_common_init(&img->cmn, desc);\r\n    const bool injected = (0 != desc->mtl_textures[0]);\r\n    const bool msaa = (img->cmn.sample_count > 1);\r\n\r\n    /* first initialize all Metal resource pool slots to 'empty' */\r\n    for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {\r\n        img->mtl.tex[i] = _sg_mtl_add_resource(nil);\r\n    }\r\n    img->mtl.sampler_state = _sg_mtl_add_resource(nil);\r\n    img->mtl.depth_tex = _sg_mtl_add_resource(nil);\r\n    img->mtl.msaa_tex = _sg_mtl_add_resource(nil);\r\n\r\n    /* initialize a Metal texture descriptor with common attributes */\r\n    MTLTextureDescriptor* mtl_desc = [[MTLTextureDescriptor alloc] init];\r\n    if (!_sg_mtl_init_texdesc_common(mtl_desc, img)) {\r\n        _SG_OBJC_RELEASE(mtl_desc);\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n\r\n    /* special case depth-stencil-buffer? */\r\n    if (_sg_is_valid_rendertarget_depth_format(img->cmn.pixel_format)) {\r\n        /* depth-stencil buffer texture must always be a render target */\r\n        SOKOL_ASSERT(img->cmn.render_target);\r\n        SOKOL_ASSERT(img->cmn.type == SG_IMAGETYPE_2D);\r\n        SOKOL_ASSERT(img->cmn.num_mipmaps == 1);\r\n        SOKOL_ASSERT(!injected);\r\n        if (msaa) {\r\n            _sg_mtl_init_texdesc_rt_msaa(mtl_desc, img);\r\n        }\r\n        else {\r\n            _sg_mtl_init_texdesc_rt(mtl_desc, img);\r\n        }\r\n        id<MTLTexture> tex = [_sg.mtl.device newTextureWithDescriptor:mtl_desc];\r\n        SOKOL_ASSERT(nil != tex);\r\n        img->mtl.depth_tex = _sg_mtl_add_resource(tex);\r\n    }\r\n    else {\r\n        /* create the color texture\r\n            In case this is a render target without MSAA, add the relevant\r\n            render-target descriptor attributes.\r\n            In case this is a render target *with* MSAA, the color texture\r\n            will serve as MSAA-resolve target (not as render target), and rendering\r\n            will go into a separate render target texture of type\r\n            MTLTextureType2DMultisample.\r\n        */\r\n        if (img->cmn.render_target && !msaa) {\r\n            _sg_mtl_init_texdesc_rt(mtl_desc, img);\r\n        }\r\n        for (int slot = 0; slot < img->cmn.num_slots; slot++) {\r\n            id<MTLTexture> tex;\r\n            if (injected) {\r\n                SOKOL_ASSERT(desc->mtl_textures[slot]);\r\n                tex = (__bridge id<MTLTexture>) desc->mtl_textures[slot];\r\n            }\r\n            else {\r\n                tex = [_sg.mtl.device newTextureWithDescriptor:mtl_desc];\r\n                if ((img->cmn.usage == SG_USAGE_IMMUTABLE) && !img->cmn.render_target) {\r\n                    _sg_mtl_copy_image_content(img, tex, &desc->content);\r\n                }\r\n            }\r\n            img->mtl.tex[slot] = _sg_mtl_add_resource(tex);\r\n        }\r\n\r\n        /* if MSAA color render target, create an additional MSAA render-surface texture */\r\n        if (img->cmn.render_target && msaa) {\r\n            _sg_mtl_init_texdesc_rt_msaa(mtl_desc, img);\r\n            id<MTLTexture> tex = [_sg.mtl.device newTextureWithDescriptor:mtl_desc];\r\n            img->mtl.msaa_tex = _sg_mtl_add_resource(tex);\r\n        }\r\n\r\n        /* create (possibly shared) sampler state */\r\n        img->mtl.sampler_state = _sg_mtl_create_sampler(_sg.mtl.device, desc);\r\n    }\r\n    _SG_OBJC_RELEASE(mtl_desc);\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_destroy_image(_sg_image_t* img) {\r\n    SOKOL_ASSERT(img);\r\n    /* it's valid to call release resource with a 'null resource' */\r\n    for (int slot = 0; slot < img->cmn.num_slots; slot++) {\r\n        _sg_mtl_release_resource(_sg.mtl.frame_index, img->mtl.tex[slot]);\r\n    }\r\n    _sg_mtl_release_resource(_sg.mtl.frame_index, img->mtl.depth_tex);\r\n    _sg_mtl_release_resource(_sg.mtl.frame_index, img->mtl.msaa_tex);\r\n    /* NOTE: sampler state objects are shared and not released until shutdown */\r\n}\r\n\r\n_SOKOL_PRIVATE id<MTLLibrary> _sg_mtl_compile_library(const char* src) {\r\n    NSError* err = NULL;\r\n    id<MTLLibrary> lib = [_sg.mtl.device\r\n        newLibraryWithSource:[NSString stringWithUTF8String:src]\r\n        options:nil\r\n        error:&err\r\n    ];\r\n    if (err) {\r\n        SOKOL_LOG([err.localizedDescription UTF8String]);\r\n    }\r\n    return lib;\r\n}\r\n\r\n_SOKOL_PRIVATE id<MTLLibrary> _sg_mtl_library_from_bytecode(const uint8_t* ptr, int num_bytes) {\r\n    NSError* err = NULL;\r\n    dispatch_data_t lib_data = dispatch_data_create(ptr, num_bytes, NULL, DISPATCH_DATA_DESTRUCTOR_DEFAULT);\r\n    id<MTLLibrary> lib = [_sg.mtl.device newLibraryWithData:lib_data error:&err];\r\n    if (err) {\r\n        SOKOL_LOG([err.localizedDescription UTF8String]);\r\n    }\r\n    _SG_OBJC_RELEASE(lib_data);\r\n    return lib;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {\r\n    SOKOL_ASSERT(shd && desc);\r\n\r\n    _sg_shader_common_init(&shd->cmn, desc);\r\n\r\n    /* create metal libray objects and lookup entry functions */\r\n    id<MTLLibrary> vs_lib;\r\n    id<MTLLibrary> fs_lib;\r\n    id<MTLFunction> vs_func;\r\n    id<MTLFunction> fs_func;\r\n    const char* vs_entry = desc->vs.entry;\r\n    const char* fs_entry = desc->fs.entry;\r\n    if (desc->vs.byte_code && desc->fs.byte_code) {\r\n        /* separate byte code provided */\r\n        vs_lib = _sg_mtl_library_from_bytecode(desc->vs.byte_code, desc->vs.byte_code_size);\r\n        fs_lib = _sg_mtl_library_from_bytecode(desc->fs.byte_code, desc->fs.byte_code_size);\r\n        if (nil == vs_lib || nil == fs_lib) {\r\n            return SG_RESOURCESTATE_FAILED;\r\n        }\r\n        vs_func = [vs_lib newFunctionWithName:[NSString stringWithUTF8String:vs_entry]];\r\n        fs_func = [fs_lib newFunctionWithName:[NSString stringWithUTF8String:fs_entry]];\r\n    }\r\n    else if (desc->vs.source && desc->fs.source) {\r\n        /* separate sources provided */\r\n        vs_lib = _sg_mtl_compile_library(desc->vs.source);\r\n        fs_lib = _sg_mtl_compile_library(desc->fs.source);\r\n        if (nil == vs_lib || nil == fs_lib) {\r\n            return SG_RESOURCESTATE_FAILED;\r\n        }\r\n        vs_func = [vs_lib newFunctionWithName:[NSString stringWithUTF8String:vs_entry]];\r\n        fs_func = [fs_lib newFunctionWithName:[NSString stringWithUTF8String:fs_entry]];\r\n    }\r\n    else {\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n    if (nil == vs_func) {\r\n        SOKOL_LOG(\"vertex shader entry function not found\\n\");\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n    if (nil == fs_func) {\r\n        SOKOL_LOG(\"fragment shader entry function not found\\n\");\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n    /* it is legal to call _sg_mtl_add_resource with a nil value, this will return a special 0xFFFFFFFF index */\r\n    shd->mtl.stage[SG_SHADERSTAGE_VS].mtl_lib  = _sg_mtl_add_resource(vs_lib);\r\n    shd->mtl.stage[SG_SHADERSTAGE_FS].mtl_lib  = _sg_mtl_add_resource(fs_lib);\r\n    shd->mtl.stage[SG_SHADERSTAGE_VS].mtl_func = _sg_mtl_add_resource(vs_func);\r\n    shd->mtl.stage[SG_SHADERSTAGE_FS].mtl_func = _sg_mtl_add_resource(fs_func);\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_destroy_shader(_sg_shader_t* shd) {\r\n    SOKOL_ASSERT(shd);\r\n    /* it is valid to call _sg_mtl_release_resource with a 'null resource' */\r\n    _sg_mtl_release_resource(_sg.mtl.frame_index, shd->mtl.stage[SG_SHADERSTAGE_VS].mtl_func);\r\n    _sg_mtl_release_resource(_sg.mtl.frame_index, shd->mtl.stage[SG_SHADERSTAGE_VS].mtl_lib);\r\n    _sg_mtl_release_resource(_sg.mtl.frame_index, shd->mtl.stage[SG_SHADERSTAGE_FS].mtl_func);\r\n    _sg_mtl_release_resource(_sg.mtl.frame_index, shd->mtl.stage[SG_SHADERSTAGE_FS].mtl_lib);\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {\r\n    SOKOL_ASSERT(pip && shd && desc);\r\n    SOKOL_ASSERT(desc->shader.id == shd->slot.id);\r\n\r\n    pip->shader = shd;\r\n    _sg_pipeline_common_init(&pip->cmn, desc);\r\n\r\n    sg_primitive_type prim_type = desc->primitive_type;\r\n    pip->mtl.prim_type = _sg_mtl_primitive_type(prim_type);\r\n    pip->mtl.index_size = _sg_mtl_index_size(pip->cmn.index_type);\r\n    if (SG_INDEXTYPE_NONE != pip->cmn.index_type) {\r\n        pip->mtl.index_type = _sg_mtl_index_type(pip->cmn.index_type);\r\n    }\r\n    pip->mtl.cull_mode = _sg_mtl_cull_mode(desc->rasterizer.cull_mode);\r\n    pip->mtl.winding = _sg_mtl_winding(desc->rasterizer.face_winding);\r\n    pip->mtl.stencil_ref = desc->depth_stencil.stencil_ref;\r\n\r\n    /* create vertex-descriptor */\r\n    MTLVertexDescriptor* vtx_desc = [MTLVertexDescriptor vertexDescriptor];\r\n    for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {\r\n        const sg_vertex_attr_desc* a_desc = &desc->layout.attrs[attr_index];\r\n        if (a_desc->format == SG_VERTEXFORMAT_INVALID) {\r\n            break;\r\n        }\r\n        SOKOL_ASSERT((a_desc->buffer_index >= 0) && (a_desc->buffer_index < SG_MAX_SHADERSTAGE_BUFFERS));\r\n        vtx_desc.attributes[attr_index].format = _sg_mtl_vertex_format(a_desc->format);\r\n        vtx_desc.attributes[attr_index].offset = a_desc->offset;\r\n        vtx_desc.attributes[attr_index].bufferIndex = a_desc->buffer_index + SG_MAX_SHADERSTAGE_UBS;\r\n        pip->cmn.vertex_layout_valid[a_desc->buffer_index] = true;\r\n    }\r\n    for (int layout_index = 0; layout_index < SG_MAX_SHADERSTAGE_BUFFERS; layout_index++) {\r\n        if (pip->cmn.vertex_layout_valid[layout_index]) {\r\n            const sg_buffer_layout_desc* l_desc = &desc->layout.buffers[layout_index];\r\n            const int mtl_vb_slot = layout_index + SG_MAX_SHADERSTAGE_UBS;\r\n            SOKOL_ASSERT(l_desc->stride > 0);\r\n            vtx_desc.layouts[mtl_vb_slot].stride = l_desc->stride;\r\n            vtx_desc.layouts[mtl_vb_slot].stepFunction = _sg_mtl_step_function(l_desc->step_func);\r\n            vtx_desc.layouts[mtl_vb_slot].stepRate = l_desc->step_rate;\r\n        }\r\n    }\r\n\r\n    /* render-pipeline descriptor */\r\n    MTLRenderPipelineDescriptor* rp_desc = [[MTLRenderPipelineDescriptor alloc] init];\r\n    rp_desc.vertexDescriptor = vtx_desc;\r\n    SOKOL_ASSERT(shd->mtl.stage[SG_SHADERSTAGE_VS].mtl_func != _SG_MTL_INVALID_SLOT_INDEX);\r\n    rp_desc.vertexFunction = _sg_mtl_id(shd->mtl.stage[SG_SHADERSTAGE_VS].mtl_func);\r\n    SOKOL_ASSERT(shd->mtl.stage[SG_SHADERSTAGE_FS].mtl_func != _SG_MTL_INVALID_SLOT_INDEX);\r\n    rp_desc.fragmentFunction = _sg_mtl_id(shd->mtl.stage[SG_SHADERSTAGE_FS].mtl_func);\r\n    rp_desc.sampleCount = desc->rasterizer.sample_count;\r\n    rp_desc.alphaToCoverageEnabled = desc->rasterizer.alpha_to_coverage_enabled;\r\n    rp_desc.alphaToOneEnabled = NO;\r\n    rp_desc.rasterizationEnabled = YES;\r\n    rp_desc.depthAttachmentPixelFormat = _sg_mtl_pixel_format(desc->blend.depth_format);\r\n    if (desc->blend.depth_format == SG_PIXELFORMAT_DEPTH_STENCIL) {\r\n        rp_desc.stencilAttachmentPixelFormat = _sg_mtl_pixel_format(desc->blend.depth_format);\r\n    }\r\n    /* FIXME: this only works on macOS 10.13!\r\n    for (int i = 0; i < (SG_MAX_SHADERSTAGE_UBS+SG_MAX_SHADERSTAGE_BUFFERS); i++) {\r\n        rp_desc.vertexBuffers[i].mutability = MTLMutabilityImmutable;\r\n    }\r\n    for (int i = 0; i < SG_MAX_SHADERSTAGE_UBS; i++) {\r\n        rp_desc.fragmentBuffers[i].mutability = MTLMutabilityImmutable;\r\n    }\r\n    */\r\n    const int att_count = desc->blend.color_attachment_count;\r\n    for (int i = 0; i < att_count; i++) {\r\n        rp_desc.colorAttachments[i].pixelFormat = _sg_mtl_pixel_format(desc->blend.color_format);\r\n        rp_desc.colorAttachments[i].writeMask = _sg_mtl_color_write_mask((sg_color_mask)desc->blend.color_write_mask);\r\n        rp_desc.colorAttachments[i].blendingEnabled = desc->blend.enabled;\r\n        rp_desc.colorAttachments[i].alphaBlendOperation = _sg_mtl_blend_op(desc->blend.op_alpha);\r\n        rp_desc.colorAttachments[i].rgbBlendOperation = _sg_mtl_blend_op(desc->blend.op_rgb);\r\n        rp_desc.colorAttachments[i].destinationAlphaBlendFactor = _sg_mtl_blend_factor(desc->blend.dst_factor_alpha);\r\n        rp_desc.colorAttachments[i].destinationRGBBlendFactor = _sg_mtl_blend_factor(desc->blend.dst_factor_rgb);\r\n        rp_desc.colorAttachments[i].sourceAlphaBlendFactor = _sg_mtl_blend_factor(desc->blend.src_factor_alpha);\r\n        rp_desc.colorAttachments[i].sourceRGBBlendFactor = _sg_mtl_blend_factor(desc->blend.src_factor_rgb);\r\n    }\r\n    NSError* err = NULL;\r\n    id<MTLRenderPipelineState> mtl_rps = [_sg.mtl.device newRenderPipelineStateWithDescriptor:rp_desc error:&err];\r\n    _SG_OBJC_RELEASE(rp_desc);\r\n    if (nil == mtl_rps) {\r\n        SOKOL_ASSERT(err);\r\n        SOKOL_LOG([err.localizedDescription UTF8String]);\r\n        return SG_RESOURCESTATE_FAILED;\r\n    }\r\n\r\n    /* depth-stencil-state */\r\n    MTLDepthStencilDescriptor* ds_desc = [[MTLDepthStencilDescriptor alloc] init];\r\n    ds_desc.depthCompareFunction = _sg_mtl_compare_func(desc->depth_stencil.depth_compare_func);\r\n    ds_desc.depthWriteEnabled = desc->depth_stencil.depth_write_enabled;\r\n    if (desc->depth_stencil.stencil_enabled) {\r\n        const sg_stencil_state* sb = &desc->depth_stencil.stencil_back;\r\n        ds_desc.backFaceStencil = [[MTLStencilDescriptor alloc] init];\r\n        ds_desc.backFaceStencil.stencilFailureOperation = _sg_mtl_stencil_op(sb->fail_op);\r\n        ds_desc.backFaceStencil.depthFailureOperation = _sg_mtl_stencil_op(sb->depth_fail_op);\r\n        ds_desc.backFaceStencil.depthStencilPassOperation = _sg_mtl_stencil_op(sb->pass_op);\r\n        ds_desc.backFaceStencil.stencilCompareFunction = _sg_mtl_compare_func(sb->compare_func);\r\n        ds_desc.backFaceStencil.readMask = desc->depth_stencil.stencil_read_mask;\r\n        ds_desc.backFaceStencil.writeMask = desc->depth_stencil.stencil_write_mask;\r\n        const sg_stencil_state* sf = &desc->depth_stencil.stencil_front;\r\n        ds_desc.frontFaceStencil = [[MTLStencilDescriptor alloc] init];\r\n        ds_desc.frontFaceStencil.stencilFailureOperation = _sg_mtl_stencil_op(sf->fail_op);\r\n        ds_desc.frontFaceStencil.depthFailureOperation = _sg_mtl_stencil_op(sf->depth_fail_op);\r\n        ds_desc.frontFaceStencil.depthStencilPassOperation = _sg_mtl_stencil_op(sf->pass_op);\r\n        ds_desc.frontFaceStencil.stencilCompareFunction = _sg_mtl_compare_func(sf->compare_func);\r\n        ds_desc.frontFaceStencil.readMask = desc->depth_stencil.stencil_read_mask;\r\n        ds_desc.frontFaceStencil.writeMask = desc->depth_stencil.stencil_write_mask;\r\n    }\r\n    id<MTLDepthStencilState> mtl_dss = [_sg.mtl.device newDepthStencilStateWithDescriptor:ds_desc];\r\n    _SG_OBJC_RELEASE(ds_desc);\r\n    pip->mtl.rps = _sg_mtl_add_resource(mtl_rps);\r\n    pip->mtl.dss = _sg_mtl_add_resource(mtl_dss);\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_destroy_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    /* it's valid to call release resource with a 'null resource' */\r\n    _sg_mtl_release_resource(_sg.mtl.frame_index, pip->mtl.rps);\r\n    _sg_mtl_release_resource(_sg.mtl.frame_index, pip->mtl.dss);\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_pass(_sg_pass_t* pass, _sg_image_t** att_images, const sg_pass_desc* desc) {\r\n    SOKOL_ASSERT(pass && desc);\r\n    SOKOL_ASSERT(att_images && att_images[0]);\r\n\r\n    _sg_pass_common_init(&pass->cmn, desc);\r\n\r\n    /* copy image pointers */\r\n    const sg_attachment_desc* att_desc;\r\n    for (int i = 0; i < pass->cmn.num_color_atts; i++) {\r\n        att_desc = &desc->color_attachments[i];\r\n        if (att_desc->image.id != SG_INVALID_ID) {\r\n            SOKOL_ASSERT(att_desc->image.id != SG_INVALID_ID);\r\n            SOKOL_ASSERT(0 == pass->mtl.color_atts[i].image);\r\n            SOKOL_ASSERT(att_images[i] && (att_images[i]->slot.id == att_desc->image.id));\r\n            SOKOL_ASSERT(_sg_is_valid_rendertarget_color_format(att_images[i]->cmn.pixel_format));\r\n            pass->mtl.color_atts[i].image = att_images[i];\r\n        }\r\n    }\r\n    SOKOL_ASSERT(0 == pass->mtl.ds_att.image);\r\n    att_desc = &desc->depth_stencil_attachment;\r\n    if (att_desc->image.id != SG_INVALID_ID) {\r\n        const int ds_img_index = SG_MAX_COLOR_ATTACHMENTS;\r\n        SOKOL_ASSERT(att_images[ds_img_index] && (att_images[ds_img_index]->slot.id == att_desc->image.id));\r\n        SOKOL_ASSERT(_sg_is_valid_rendertarget_depth_format(att_images[ds_img_index]->cmn.pixel_format));\r\n        pass->mtl.ds_att.image = att_images[ds_img_index];\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_destroy_pass(_sg_pass_t* pass) {\r\n    SOKOL_ASSERT(pass);\r\n    _SOKOL_UNUSED(pass);\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_mtl_pass_color_image(const _sg_pass_t* pass, int index) {\r\n    SOKOL_ASSERT(pass && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));\r\n    /* NOTE: may return null */\r\n    return pass->mtl.color_atts[index].image;\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_mtl_pass_ds_image(const _sg_pass_t* pass) {\r\n    /* NOTE: may return null */\r\n    SOKOL_ASSERT(pass);\r\n    return pass->mtl.ds_att.image;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_begin_pass(_sg_pass_t* pass, const sg_pass_action* action, int w, int h) {\r\n    SOKOL_ASSERT(action);\r\n    SOKOL_ASSERT(!_sg.mtl.in_pass);\r\n    SOKOL_ASSERT(_sg.mtl.cmd_queue);\r\n    SOKOL_ASSERT(nil == _sg.mtl.cmd_encoder);\r\n    SOKOL_ASSERT(_sg.mtl.renderpass_descriptor_cb || _sg.mtl.renderpass_descriptor_userdata_cb);\r\n    _sg.mtl.in_pass = true;\r\n    _sg.mtl.cur_width = w;\r\n    _sg.mtl.cur_height = h;\r\n    _sg_mtl_clear_state_cache();\r\n\r\n    /* if this is the first pass in the frame, create a command buffer */\r\n    if (nil == _sg.mtl.cmd_buffer) {\r\n        /* block until the oldest frame in flight has finished */\r\n        dispatch_semaphore_wait(_sg.mtl.sem, DISPATCH_TIME_FOREVER);\r\n        _sg.mtl.cmd_buffer = [_sg.mtl.cmd_queue commandBufferWithUnretainedReferences];\r\n    }\r\n\r\n    /* if this is first pass in frame, get uniform buffer base pointer */\r\n    if (0 == _sg.mtl.cur_ub_base_ptr) {\r\n        _sg.mtl.cur_ub_base_ptr = (uint8_t*)[_sg.mtl.uniform_buffers[_sg.mtl.cur_frame_rotate_index] contents];\r\n    }\r\n\r\n    /* initialize a render pass descriptor */\r\n    MTLRenderPassDescriptor* pass_desc = nil;\r\n    if (pass) {\r\n        /* offscreen render pass */\r\n        pass_desc = [MTLRenderPassDescriptor renderPassDescriptor];\r\n    }\r\n    else {\r\n        /* default render pass, call user-provided callback to provide render pass descriptor */\r\n        if (_sg.mtl.renderpass_descriptor_cb) {\r\n            pass_desc = (__bridge MTLRenderPassDescriptor*) _sg.mtl.renderpass_descriptor_cb();\r\n        }\r\n        else {\r\n            pass_desc = (__bridge MTLRenderPassDescriptor*) _sg.mtl.renderpass_descriptor_userdata_cb(_sg.mtl.user_data);\r\n        }\r\n\r\n    }\r\n    if (pass_desc) {\r\n        _sg.mtl.pass_valid = true;\r\n    }\r\n    else {\r\n        /* default pass descriptor will not be valid if window is minimized,\r\n           don't do any rendering in this case */\r\n        _sg.mtl.pass_valid = false;\r\n        return;\r\n    }\r\n    if (pass) {\r\n        /* setup pass descriptor for offscreen rendering */\r\n        SOKOL_ASSERT(pass->slot.state == SG_RESOURCESTATE_VALID);\r\n        for (int i = 0; i < pass->cmn.num_color_atts; i++) {\r\n            const _sg_attachment_t* cmn_att = &pass->cmn.color_atts[i];\r\n            const _sg_mtl_attachment_t* mtl_att = &pass->mtl.color_atts[i];\r\n            const _sg_image_t* att_img = mtl_att->image;\r\n            SOKOL_ASSERT(att_img->slot.state == SG_RESOURCESTATE_VALID);\r\n            SOKOL_ASSERT(att_img->slot.id == cmn_att->image_id.id);\r\n            const bool is_msaa = (att_img->cmn.sample_count > 1);\r\n            pass_desc.colorAttachments[i].loadAction = _sg_mtl_load_action(action->colors[i].action);\r\n            pass_desc.colorAttachments[i].storeAction = is_msaa ? MTLStoreActionMultisampleResolve : MTLStoreActionStore;\r\n            const float* c = &(action->colors[i].val[0]);\r\n            pass_desc.colorAttachments[i].clearColor = MTLClearColorMake(c[0], c[1], c[2], c[3]);\r\n            if (is_msaa) {\r\n                SOKOL_ASSERT(att_img->mtl.msaa_tex != _SG_MTL_INVALID_SLOT_INDEX);\r\n                SOKOL_ASSERT(att_img->mtl.tex[mtl_att->image->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);\r\n                pass_desc.colorAttachments[i].texture = _sg_mtl_id(att_img->mtl.msaa_tex);\r\n                pass_desc.colorAttachments[i].resolveTexture = _sg_mtl_id(att_img->mtl.tex[att_img->cmn.active_slot]);\r\n                pass_desc.colorAttachments[i].resolveLevel = cmn_att->mip_level;\r\n                switch (att_img->cmn.type) {\r\n                    case SG_IMAGETYPE_CUBE:\r\n                    case SG_IMAGETYPE_ARRAY:\r\n                        pass_desc.colorAttachments[i].resolveSlice = cmn_att->slice;\r\n                        break;\r\n                    case SG_IMAGETYPE_3D:\r\n                        pass_desc.colorAttachments[i].resolveDepthPlane = cmn_att->slice;\r\n                        break;\r\n                    default: break;\r\n                }\r\n            }\r\n            else {\r\n                SOKOL_ASSERT(att_img->mtl.tex[att_img->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);\r\n                pass_desc.colorAttachments[i].texture = _sg_mtl_id(att_img->mtl.tex[att_img->cmn.active_slot]);\r\n                pass_desc.colorAttachments[i].level = cmn_att->mip_level;\r\n                switch (att_img->cmn.type) {\r\n                    case SG_IMAGETYPE_CUBE:\r\n                    case SG_IMAGETYPE_ARRAY:\r\n                        pass_desc.colorAttachments[i].slice = cmn_att->slice;\r\n                        break;\r\n                    case SG_IMAGETYPE_3D:\r\n                        pass_desc.colorAttachments[i].depthPlane = cmn_att->slice;\r\n                        break;\r\n                    default: break;\r\n                }\r\n            }\r\n        }\r\n        const _sg_image_t* ds_att_img = pass->mtl.ds_att.image;\r\n        if (0 != ds_att_img) {\r\n            SOKOL_ASSERT(ds_att_img->slot.state == SG_RESOURCESTATE_VALID);\r\n            SOKOL_ASSERT(ds_att_img->slot.id == pass->cmn.ds_att.image_id.id);\r\n            SOKOL_ASSERT(ds_att_img->mtl.depth_tex != _SG_MTL_INVALID_SLOT_INDEX);\r\n            pass_desc.depthAttachment.texture = _sg_mtl_id(ds_att_img->mtl.depth_tex);\r\n            pass_desc.depthAttachment.loadAction = _sg_mtl_load_action(action->depth.action);\r\n            pass_desc.depthAttachment.clearDepth = action->depth.val;\r\n            if (_sg_is_depth_stencil_format(ds_att_img->cmn.pixel_format)) {\r\n                pass_desc.stencilAttachment.texture = _sg_mtl_id(ds_att_img->mtl.depth_tex);\r\n                pass_desc.stencilAttachment.loadAction = _sg_mtl_load_action(action->stencil.action);\r\n                pass_desc.stencilAttachment.clearStencil = action->stencil.val;\r\n            }\r\n        }\r\n    }\r\n    else {\r\n        /* setup pass descriptor for default rendering */\r\n        pass_desc.colorAttachments[0].loadAction = _sg_mtl_load_action(action->colors[0].action);\r\n        const float* c = &(action->colors[0].val[0]);\r\n        pass_desc.colorAttachments[0].clearColor = MTLClearColorMake(c[0], c[1], c[2], c[3]);\r\n        pass_desc.depthAttachment.loadAction = _sg_mtl_load_action(action->depth.action);\r\n        pass_desc.depthAttachment.clearDepth = action->depth.val;\r\n        pass_desc.stencilAttachment.loadAction = _sg_mtl_load_action(action->stencil.action);\r\n        pass_desc.stencilAttachment.clearStencil = action->stencil.val;\r\n    }\r\n\r\n    /* create a render command encoder, this might return nil if window is minimized */\r\n    _sg.mtl.cmd_encoder = [_sg.mtl.cmd_buffer renderCommandEncoderWithDescriptor:pass_desc];\r\n    if (nil == _sg.mtl.cmd_encoder) {\r\n        _sg.mtl.pass_valid = false;\r\n        return;\r\n    }\r\n\r\n    /* bind the global uniform buffer, this only happens once per pass */\r\n    _sg_mtl_bind_uniform_buffers();\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_end_pass(void) {\r\n    SOKOL_ASSERT(_sg.mtl.in_pass);\r\n    _sg.mtl.in_pass = false;\r\n    _sg.mtl.pass_valid = false;\r\n    if (nil != _sg.mtl.cmd_encoder) {\r\n        [_sg.mtl.cmd_encoder endEncoding];\r\n        /* NOTE: MTLRenderCommandEncoder is autoreleased */\r\n        _sg.mtl.cmd_encoder = nil;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_commit(void) {\r\n    SOKOL_ASSERT(!_sg.mtl.in_pass);\r\n    SOKOL_ASSERT(!_sg.mtl.pass_valid);\r\n    SOKOL_ASSERT(_sg.mtl.drawable_cb || _sg.mtl.drawable_userdata_cb);\r\n    SOKOL_ASSERT(nil == _sg.mtl.cmd_encoder);\r\n    SOKOL_ASSERT(nil != _sg.mtl.cmd_buffer);\r\n\r\n    #if defined(_SG_TARGET_MACOS)\r\n    [_sg.mtl.uniform_buffers[_sg.mtl.cur_frame_rotate_index] didModifyRange:NSMakeRange(0, _sg.mtl.cur_ub_offset)];\r\n    #endif\r\n\r\n    /* present, commit and signal semaphore when done */\r\n    id<MTLDrawable> cur_drawable = nil;\r\n    if (_sg.mtl.drawable_cb) {\r\n        cur_drawable = (__bridge id<MTLDrawable>) _sg.mtl.drawable_cb();\r\n    }\r\n    else {\r\n        cur_drawable = (__bridge id<MTLDrawable>) _sg.mtl.drawable_userdata_cb(_sg.mtl.user_data);\r\n    }\r\n    [_sg.mtl.cmd_buffer presentDrawable:cur_drawable];\r\n    [_sg.mtl.cmd_buffer addCompletedHandler:^(id<MTLCommandBuffer> cmd_buffer) {\r\n        _SOKOL_UNUSED(cmd_buffer);\r\n        dispatch_semaphore_signal(_sg.mtl.sem);\r\n    }];\r\n    [_sg.mtl.cmd_buffer commit];\r\n\r\n    /* garbage-collect resources pending for release */\r\n    _sg_mtl_garbage_collect(_sg.mtl.frame_index);\r\n\r\n    /* rotate uniform buffer slot */\r\n    if (++_sg.mtl.cur_frame_rotate_index >= SG_NUM_INFLIGHT_FRAMES) {\r\n        _sg.mtl.cur_frame_rotate_index = 0;\r\n    }\r\n    _sg.mtl.frame_index++;\r\n    _sg.mtl.cur_ub_offset = 0;\r\n    _sg.mtl.cur_ub_base_ptr = 0;\r\n    /* NOTE: MTLCommandBuffer is autoreleased */\r\n    _sg.mtl.cmd_buffer = nil;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {\r\n    SOKOL_ASSERT(_sg.mtl.in_pass);\r\n    if (!_sg.mtl.pass_valid) {\r\n        return;\r\n    }\r\n    SOKOL_ASSERT(nil != _sg.mtl.cmd_encoder);\r\n    MTLViewport vp;\r\n    vp.originX = (double) x;\r\n    vp.originY = (double) (origin_top_left ? y : (_sg.mtl.cur_height - (y + h)));\r\n    vp.width   = (double) w;\r\n    vp.height  = (double) h;\r\n    vp.znear   = 0.0;\r\n    vp.zfar    = 1.0;\r\n    [_sg.mtl.cmd_encoder setViewport:vp];\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {\r\n    SOKOL_ASSERT(_sg.mtl.in_pass);\r\n    if (!_sg.mtl.pass_valid) {\r\n        return;\r\n    }\r\n    SOKOL_ASSERT(nil != _sg.mtl.cmd_encoder);\r\n    /* clip against framebuffer rect */\r\n    x = _sg_min(_sg_max(0, x), _sg.mtl.cur_width-1);\r\n    y = _sg_min(_sg_max(0, y), _sg.mtl.cur_height-1);\r\n    if ((x + w) > _sg.mtl.cur_width) {\r\n        w = _sg.mtl.cur_width - x;\r\n    }\r\n    if ((y + h) > _sg.mtl.cur_height) {\r\n        h = _sg.mtl.cur_height - y;\r\n    }\r\n    w = _sg_max(w, 1);\r\n    h = _sg_max(h, 1);\r\n\r\n    MTLScissorRect r;\r\n    r.x = x;\r\n    r.y = origin_top_left ? y : (_sg.mtl.cur_height - (y + h));\r\n    r.width = w;\r\n    r.height = h;\r\n    [_sg.mtl.cmd_encoder setScissorRect:r];\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_apply_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    SOKOL_ASSERT(pip->shader && (pip->cmn.shader_id.id == pip->shader->slot.id));\r\n    SOKOL_ASSERT(_sg.mtl.in_pass);\r\n    if (!_sg.mtl.pass_valid) {\r\n        return;\r\n    }\r\n    SOKOL_ASSERT(nil != _sg.mtl.cmd_encoder);\r\n\r\n    if ((_sg.mtl.state_cache.cur_pipeline != pip) || (_sg.mtl.state_cache.cur_pipeline_id.id != pip->slot.id)) {\r\n        _sg.mtl.state_cache.cur_pipeline = pip;\r\n        _sg.mtl.state_cache.cur_pipeline_id.id = pip->slot.id;\r\n        const float* c = pip->cmn.blend_color;\r\n        [_sg.mtl.cmd_encoder setBlendColorRed:c[0] green:c[1] blue:c[2] alpha:c[3]];\r\n        [_sg.mtl.cmd_encoder setCullMode:pip->mtl.cull_mode];\r\n        [_sg.mtl.cmd_encoder setFrontFacingWinding:pip->mtl.winding];\r\n        [_sg.mtl.cmd_encoder setStencilReferenceValue:pip->mtl.stencil_ref];\r\n        [_sg.mtl.cmd_encoder setDepthBias:pip->cmn.depth_bias slopeScale:pip->cmn.depth_bias_slope_scale clamp:pip->cmn.depth_bias_clamp];\r\n        SOKOL_ASSERT(pip->mtl.rps != _SG_MTL_INVALID_SLOT_INDEX);\r\n        [_sg.mtl.cmd_encoder setRenderPipelineState:_sg_mtl_id(pip->mtl.rps)];\r\n        SOKOL_ASSERT(pip->mtl.dss != _SG_MTL_INVALID_SLOT_INDEX);\r\n        [_sg.mtl.cmd_encoder setDepthStencilState:_sg_mtl_id(pip->mtl.dss)];\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_apply_bindings(\r\n    _sg_pipeline_t* pip,\r\n    _sg_buffer_t** vbs, const int* vb_offsets, int num_vbs,\r\n    _sg_buffer_t* ib, int ib_offset,\r\n    _sg_image_t** vs_imgs, int num_vs_imgs,\r\n    _sg_image_t** fs_imgs, int num_fs_imgs)\r\n{\r\n    _SOKOL_UNUSED(pip);\r\n    SOKOL_ASSERT(_sg.mtl.in_pass);\r\n    if (!_sg.mtl.pass_valid) {\r\n        return;\r\n    }\r\n    SOKOL_ASSERT(nil != _sg.mtl.cmd_encoder);\r\n\r\n    /* store index buffer binding, this will be needed later in sg_draw() */\r\n    _sg.mtl.state_cache.cur_indexbuffer = ib;\r\n    _sg.mtl.state_cache.cur_indexbuffer_offset = ib_offset;\r\n    if (ib) {\r\n        SOKOL_ASSERT(pip->cmn.index_type != SG_INDEXTYPE_NONE);\r\n        _sg.mtl.state_cache.cur_indexbuffer_id.id = ib->slot.id;\r\n    }\r\n    else {\r\n        SOKOL_ASSERT(pip->cmn.index_type == SG_INDEXTYPE_NONE);\r\n        _sg.mtl.state_cache.cur_indexbuffer_id.id = SG_INVALID_ID;\r\n    }\r\n\r\n    /* apply vertex buffers */\r\n    int slot;\r\n    for (slot = 0; slot < num_vbs; slot++) {\r\n        const _sg_buffer_t* vb = vbs[slot];\r\n        if ((_sg.mtl.state_cache.cur_vertexbuffers[slot] != vb) ||\r\n            (_sg.mtl.state_cache.cur_vertexbuffer_offsets[slot] != vb_offsets[slot]) ||\r\n            (_sg.mtl.state_cache.cur_vertexbuffer_ids[slot].id != vb->slot.id))\r\n        {\r\n            _sg.mtl.state_cache.cur_vertexbuffers[slot] = vb;\r\n            _sg.mtl.state_cache.cur_vertexbuffer_offsets[slot] = vb_offsets[slot];\r\n            _sg.mtl.state_cache.cur_vertexbuffer_ids[slot].id = vb->slot.id;\r\n            const NSUInteger mtl_slot = SG_MAX_SHADERSTAGE_UBS + slot;\r\n            SOKOL_ASSERT(vb->mtl.buf[vb->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);\r\n            [_sg.mtl.cmd_encoder setVertexBuffer:_sg_mtl_id(vb->mtl.buf[vb->cmn.active_slot])\r\n                offset:vb_offsets[slot]\r\n                atIndex:mtl_slot];\r\n        }\r\n    }\r\n\r\n    /* apply vertex shader images */\r\n    for (slot = 0; slot < num_vs_imgs; slot++) {\r\n        const _sg_image_t* img = vs_imgs[slot];\r\n        if ((_sg.mtl.state_cache.cur_vs_images[slot] != img) || (_sg.mtl.state_cache.cur_vs_image_ids[slot].id != img->slot.id)) {\r\n            _sg.mtl.state_cache.cur_vs_images[slot] = img;\r\n            _sg.mtl.state_cache.cur_vs_image_ids[slot].id = img->slot.id;\r\n            SOKOL_ASSERT(img->mtl.tex[img->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);\r\n            [_sg.mtl.cmd_encoder setVertexTexture:_sg_mtl_id(img->mtl.tex[img->cmn.active_slot]) atIndex:slot];\r\n            SOKOL_ASSERT(img->mtl.sampler_state != _SG_MTL_INVALID_SLOT_INDEX);\r\n            [_sg.mtl.cmd_encoder setVertexSamplerState:_sg_mtl_id(img->mtl.sampler_state) atIndex:slot];\r\n        }\r\n    }\r\n\r\n    /* apply fragment shader images */\r\n    for (slot = 0; slot < num_fs_imgs; slot++) {\r\n        const _sg_image_t* img = fs_imgs[slot];\r\n        if ((_sg.mtl.state_cache.cur_fs_images[slot] != img) || (_sg.mtl.state_cache.cur_fs_image_ids[slot].id != img->slot.id)) {\r\n            _sg.mtl.state_cache.cur_fs_images[slot] = img;\r\n            _sg.mtl.state_cache.cur_fs_image_ids[slot].id = img->slot.id;\r\n            SOKOL_ASSERT(img->mtl.tex[img->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);\r\n            [_sg.mtl.cmd_encoder setFragmentTexture:_sg_mtl_id(img->mtl.tex[img->cmn.active_slot]) atIndex:slot];\r\n            SOKOL_ASSERT(img->mtl.sampler_state != _SG_MTL_INVALID_SLOT_INDEX);\r\n            [_sg.mtl.cmd_encoder setFragmentSamplerState:_sg_mtl_id(img->mtl.sampler_state) atIndex:slot];\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_apply_uniforms(sg_shader_stage stage_index, int ub_index, const void* data, int num_bytes) {\r\n    SOKOL_ASSERT(_sg.mtl.in_pass);\r\n    if (!_sg.mtl.pass_valid) {\r\n        return;\r\n    }\r\n    SOKOL_ASSERT(nil != _sg.mtl.cmd_encoder);\r\n    SOKOL_ASSERT(data && (num_bytes > 0));\r\n    SOKOL_ASSERT((stage_index >= 0) && ((int)stage_index < SG_NUM_SHADER_STAGES));\r\n    SOKOL_ASSERT((ub_index >= 0) && (ub_index < SG_MAX_SHADERSTAGE_UBS));\r\n    SOKOL_ASSERT((_sg.mtl.cur_ub_offset + num_bytes) <= _sg.mtl.ub_size);\r\n    SOKOL_ASSERT((_sg.mtl.cur_ub_offset & (_SG_MTL_UB_ALIGN-1)) == 0);\r\n    SOKOL_ASSERT(_sg.mtl.state_cache.cur_pipeline && _sg.mtl.state_cache.cur_pipeline->shader);\r\n    SOKOL_ASSERT(_sg.mtl.state_cache.cur_pipeline->slot.id == _sg.mtl.state_cache.cur_pipeline_id.id);\r\n    SOKOL_ASSERT(_sg.mtl.state_cache.cur_pipeline->shader->slot.id == _sg.mtl.state_cache.cur_pipeline->cmn.shader_id.id);\r\n    SOKOL_ASSERT(ub_index < _sg.mtl.state_cache.cur_pipeline->shader->cmn.stage[stage_index].num_uniform_blocks);\r\n    SOKOL_ASSERT(num_bytes <= _sg.mtl.state_cache.cur_pipeline->shader->cmn.stage[stage_index].uniform_blocks[ub_index].size);\r\n\r\n    /* copy to global uniform buffer, record offset into cmd encoder, and advance offset */\r\n    uint8_t* dst = &_sg.mtl.cur_ub_base_ptr[_sg.mtl.cur_ub_offset];\r\n    memcpy(dst, data, num_bytes);\r\n    if (stage_index == SG_SHADERSTAGE_VS) {\r\n        [_sg.mtl.cmd_encoder setVertexBufferOffset:_sg.mtl.cur_ub_offset atIndex:ub_index];\r\n    }\r\n    else {\r\n        [_sg.mtl.cmd_encoder setFragmentBufferOffset:_sg.mtl.cur_ub_offset atIndex:ub_index];\r\n    }\r\n    _sg.mtl.cur_ub_offset = _sg_roundup(_sg.mtl.cur_ub_offset + num_bytes, _SG_MTL_UB_ALIGN);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_draw(int base_element, int num_elements, int num_instances) {\r\n    SOKOL_ASSERT(_sg.mtl.in_pass);\r\n    if (!_sg.mtl.pass_valid) {\r\n        return;\r\n    }\r\n    SOKOL_ASSERT(nil != _sg.mtl.cmd_encoder);\r\n    SOKOL_ASSERT(_sg.mtl.state_cache.cur_pipeline && (_sg.mtl.state_cache.cur_pipeline->slot.id == _sg.mtl.state_cache.cur_pipeline_id.id));\r\n    if (SG_INDEXTYPE_NONE != _sg.mtl.state_cache.cur_pipeline->cmn.index_type) {\r\n        /* indexed rendering */\r\n        SOKOL_ASSERT(_sg.mtl.state_cache.cur_indexbuffer && (_sg.mtl.state_cache.cur_indexbuffer->slot.id == _sg.mtl.state_cache.cur_indexbuffer_id.id));\r\n        const _sg_buffer_t* ib = _sg.mtl.state_cache.cur_indexbuffer;\r\n        SOKOL_ASSERT(ib->mtl.buf[ib->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);\r\n        const NSUInteger index_buffer_offset = _sg.mtl.state_cache.cur_indexbuffer_offset +\r\n            base_element * _sg.mtl.state_cache.cur_pipeline->mtl.index_size;\r\n        [_sg.mtl.cmd_encoder drawIndexedPrimitives:_sg.mtl.state_cache.cur_pipeline->mtl.prim_type\r\n            indexCount:num_elements\r\n            indexType:_sg.mtl.state_cache.cur_pipeline->mtl.index_type\r\n            indexBuffer:_sg_mtl_id(ib->mtl.buf[ib->cmn.active_slot])\r\n            indexBufferOffset:index_buffer_offset\r\n            instanceCount:num_instances];\r\n    }\r\n    else {\r\n        /* non-indexed rendering */\r\n        [_sg.mtl.cmd_encoder drawPrimitives:_sg.mtl.state_cache.cur_pipeline->mtl.prim_type\r\n            vertexStart:base_element\r\n            vertexCount:num_elements\r\n            instanceCount:num_instances];\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_update_buffer(_sg_buffer_t* buf, const void* data, uint32_t data_size) {\r\n    SOKOL_ASSERT(buf && data && (data_size > 0));\r\n    if (++buf->cmn.active_slot >= buf->cmn.num_slots) {\r\n        buf->cmn.active_slot = 0;\r\n    }\r\n    __unsafe_unretained id<MTLBuffer> mtl_buf = _sg_mtl_id(buf->mtl.buf[buf->cmn.active_slot]);\r\n    void* dst_ptr = [mtl_buf contents];\r\n    memcpy(dst_ptr, data, data_size);\r\n    #if defined(_SG_TARGET_MACOS)\r\n    [mtl_buf didModifyRange:NSMakeRange(0, data_size)];\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE uint32_t _sg_mtl_append_buffer(_sg_buffer_t* buf, const void* data, uint32_t data_size, bool new_frame) {\r\n    SOKOL_ASSERT(buf && data && (data_size > 0));\r\n    if (new_frame) {\r\n        if (++buf->cmn.active_slot >= buf->cmn.num_slots) {\r\n            buf->cmn.active_slot = 0;\r\n        }\r\n    }\r\n    __unsafe_unretained id<MTLBuffer> mtl_buf = _sg_mtl_id(buf->mtl.buf[buf->cmn.active_slot]);\r\n    uint8_t* dst_ptr = (uint8_t*) [mtl_buf contents];\r\n    dst_ptr += buf->cmn.append_pos;\r\n    memcpy(dst_ptr, data, data_size);\r\n    #if defined(_SG_TARGET_MACOS)\r\n    [mtl_buf didModifyRange:NSMakeRange(buf->cmn.append_pos, data_size)];\r\n    #endif\r\n    /* NOTE: this is a requirement from WebGPU, but we want identical behaviour across all backend */\r\n    return _sg_roundup(data_size, 4);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_mtl_update_image(_sg_image_t* img, const sg_image_content* data) {\r\n    SOKOL_ASSERT(img && data);\r\n    if (++img->cmn.active_slot >= img->cmn.num_slots) {\r\n        img->cmn.active_slot = 0;\r\n    }\r\n    __unsafe_unretained id<MTLTexture> mtl_tex = _sg_mtl_id(img->mtl.tex[img->cmn.active_slot]);\r\n    _sg_mtl_copy_image_content(img, mtl_tex, data);\r\n}\r\n\r\n/*== WEBGPU BACKEND IMPLEMENTATION ===========================================*/\r\n#elif defined(SOKOL_WGPU)\r\n\r\n_SOKOL_PRIVATE WGPUBufferUsageFlags _sg_wgpu_buffer_usage(sg_buffer_type t, sg_usage u) {\r\n    WGPUBufferUsageFlags res = 0;\r\n    if (SG_BUFFERTYPE_VERTEXBUFFER == t) {\r\n        res |= WGPUBufferUsage_Vertex;\r\n    }\r\n    else {\r\n        res |= WGPUBufferUsage_Index;\r\n    }\r\n    if (SG_USAGE_IMMUTABLE != u) {\r\n        res |= WGPUBufferUsage_CopyDst;\r\n    }\r\n    return res;\r\n}\r\n\r\n_SOKOL_PRIVATE WGPULoadOp _sg_wgpu_load_op(sg_action a) {\r\n    switch (a) {\r\n        case SG_ACTION_CLEAR:\r\n        case SG_ACTION_DONTCARE:\r\n            return WGPULoadOp_Clear;\r\n        case SG_ACTION_LOAD:\r\n            return WGPULoadOp_Load;\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return (WGPULoadOp)0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUTextureViewDimension _sg_wgpu_tex_viewdim(sg_image_type t) {\r\n    switch (t) {\r\n        case SG_IMAGETYPE_2D:       return WGPUTextureViewDimension_2D;\r\n        case SG_IMAGETYPE_CUBE:     return WGPUTextureViewDimension_Cube;\r\n        case SG_IMAGETYPE_3D:       return WGPUTextureViewDimension_3D;\r\n        case SG_IMAGETYPE_ARRAY:    return WGPUTextureViewDimension_2DArray;\r\n        default: SOKOL_UNREACHABLE; return WGPUTextureViewDimension_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUTextureComponentType _sg_wgpu_tex_comptype(sg_sampler_type t) {\r\n    switch (t) {\r\n        case SG_SAMPLERTYPE_FLOAT:  return WGPUTextureComponentType_Float;\r\n        case SG_SAMPLERTYPE_SINT:   return WGPUTextureComponentType_Sint;\r\n        case SG_SAMPLERTYPE_UINT:   return WGPUTextureComponentType_Uint;\r\n        default: SOKOL_UNREACHABLE; return WGPUTextureComponentType_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUTextureDimension _sg_wgpu_tex_dim(sg_image_type t) {\r\n    if (SG_IMAGETYPE_3D == t) {\r\n        return WGPUTextureDimension_3D;\r\n    }\r\n    else {\r\n        return WGPUTextureDimension_2D;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUAddressMode _sg_wgpu_sampler_addrmode(sg_wrap m) {\r\n    switch (m) {\r\n        case SG_WRAP_REPEAT:\r\n            return WGPUAddressMode_Repeat;\r\n        case SG_WRAP_CLAMP_TO_EDGE:\r\n        case SG_WRAP_CLAMP_TO_BORDER:\r\n            return WGPUAddressMode_ClampToEdge;\r\n        case SG_WRAP_MIRRORED_REPEAT:\r\n            return WGPUAddressMode_MirrorRepeat;\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return WGPUAddressMode_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUFilterMode _sg_wgpu_sampler_minmagfilter(sg_filter f) {\r\n    switch (f) {\r\n        case SG_FILTER_NEAREST:\r\n        case SG_FILTER_NEAREST_MIPMAP_NEAREST:\r\n        case SG_FILTER_NEAREST_MIPMAP_LINEAR:\r\n            return WGPUFilterMode_Nearest;\r\n        case SG_FILTER_LINEAR:\r\n        case SG_FILTER_LINEAR_MIPMAP_NEAREST:\r\n        case SG_FILTER_LINEAR_MIPMAP_LINEAR:\r\n            return WGPUFilterMode_Linear;\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return WGPUFilterMode_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUFilterMode _sg_wgpu_sampler_mipfilter(sg_filter f) {\r\n    switch (f) {\r\n        case SG_FILTER_NEAREST:\r\n        case SG_FILTER_LINEAR:\r\n        case SG_FILTER_NEAREST_MIPMAP_NEAREST:\r\n        case SG_FILTER_LINEAR_MIPMAP_NEAREST:\r\n            return WGPUFilterMode_Nearest;\r\n        case SG_FILTER_NEAREST_MIPMAP_LINEAR:\r\n        case SG_FILTER_LINEAR_MIPMAP_LINEAR:\r\n            return WGPUFilterMode_Linear;\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return WGPUFilterMode_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUIndexFormat _sg_wgpu_indexformat(sg_index_type t) {\r\n    /* NOTE: there's no WGPUIndexFormat_None */\r\n    return (t == SG_INDEXTYPE_UINT16) ? WGPUIndexFormat_Uint16 : WGPUIndexFormat_Uint32;\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUInputStepMode _sg_wgpu_stepmode(sg_vertex_step s) {\r\n    return (s == SG_VERTEXSTEP_PER_VERTEX) ? WGPUInputStepMode_Vertex : WGPUInputStepMode_Instance;\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUVertexFormat _sg_wgpu_vertexformat(sg_vertex_format f) {\r\n    switch (f) {\r\n        case SG_VERTEXFORMAT_FLOAT:         return WGPUVertexFormat_Float;\r\n        case SG_VERTEXFORMAT_FLOAT2:        return WGPUVertexFormat_Float2;\r\n        case SG_VERTEXFORMAT_FLOAT3:        return WGPUVertexFormat_Float3;\r\n        case SG_VERTEXFORMAT_FLOAT4:        return WGPUVertexFormat_Float4;\r\n        case SG_VERTEXFORMAT_BYTE4:         return WGPUVertexFormat_Char4;\r\n        case SG_VERTEXFORMAT_BYTE4N:        return WGPUVertexFormat_Char4Norm;\r\n        case SG_VERTEXFORMAT_UBYTE4:        return WGPUVertexFormat_UChar4;\r\n        case SG_VERTEXFORMAT_UBYTE4N:       return WGPUVertexFormat_UChar4Norm;\r\n        case SG_VERTEXFORMAT_SHORT2:        return WGPUVertexFormat_Short2;\r\n        case SG_VERTEXFORMAT_SHORT2N:       return WGPUVertexFormat_Short2Norm;\r\n        case SG_VERTEXFORMAT_USHORT2N:      return WGPUVertexFormat_UShort2Norm;\r\n        case SG_VERTEXFORMAT_SHORT4:        return WGPUVertexFormat_Short4;\r\n        case SG_VERTEXFORMAT_SHORT4N:       return WGPUVertexFormat_Short4Norm;\r\n        case SG_VERTEXFORMAT_USHORT4N:      return WGPUVertexFormat_UShort4Norm;\r\n        /* FIXME! UINT10_N2 */\r\n        case SG_VERTEXFORMAT_UINT10_N2:\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return WGPUVertexFormat_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUPrimitiveTopology _sg_wgpu_topology(sg_primitive_type t) {\r\n    switch (t) {\r\n        case SG_PRIMITIVETYPE_POINTS:           return WGPUPrimitiveTopology_PointList;\r\n        case SG_PRIMITIVETYPE_LINES:            return WGPUPrimitiveTopology_LineList;\r\n        case SG_PRIMITIVETYPE_LINE_STRIP:       return WGPUPrimitiveTopology_LineStrip;\r\n        case SG_PRIMITIVETYPE_TRIANGLES:        return WGPUPrimitiveTopology_TriangleList;\r\n        case SG_PRIMITIVETYPE_TRIANGLE_STRIP:   return WGPUPrimitiveTopology_TriangleStrip;\r\n        default: SOKOL_UNREACHABLE; return WGPUPrimitiveTopology_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUFrontFace _sg_wgpu_frontface(sg_face_winding fw) {\r\n    return (fw == SG_FACEWINDING_CCW) ? WGPUFrontFace_CCW : WGPUFrontFace_CW;\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUCullMode _sg_wgpu_cullmode(sg_cull_mode cm) {\r\n    switch (cm) {\r\n        case SG_CULLMODE_NONE:      return WGPUCullMode_None;\r\n        case SG_CULLMODE_FRONT:     return WGPUCullMode_Front;\r\n        case SG_CULLMODE_BACK:      return WGPUCullMode_Back;\r\n        default: SOKOL_UNREACHABLE; return WGPUCullMode_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUTextureFormat _sg_wgpu_textureformat(sg_pixel_format p) {\r\n    switch (p) {\r\n        case SG_PIXELFORMAT_NONE:           return WGPUTextureFormat_Undefined;\r\n        case SG_PIXELFORMAT_R8:             return WGPUTextureFormat_R8Unorm;\r\n        case SG_PIXELFORMAT_R8SN:           return WGPUTextureFormat_R8Snorm;\r\n        case SG_PIXELFORMAT_R8UI:           return WGPUTextureFormat_R8Uint;\r\n        case SG_PIXELFORMAT_R8SI:           return WGPUTextureFormat_R8Sint;\r\n        case SG_PIXELFORMAT_R16UI:          return WGPUTextureFormat_R16Uint;\r\n        case SG_PIXELFORMAT_R16SI:          return WGPUTextureFormat_R16Sint;\r\n        case SG_PIXELFORMAT_R16F:           return WGPUTextureFormat_R16Float;\r\n        case SG_PIXELFORMAT_RG8:            return WGPUTextureFormat_RG8Unorm;\r\n        case SG_PIXELFORMAT_RG8SN:          return WGPUTextureFormat_RG8Snorm;\r\n        case SG_PIXELFORMAT_RG8UI:          return WGPUTextureFormat_RG8Uint;\r\n        case SG_PIXELFORMAT_RG8SI:          return WGPUTextureFormat_RG8Sint;\r\n        case SG_PIXELFORMAT_R32UI:          return WGPUTextureFormat_R32Uint;\r\n        case SG_PIXELFORMAT_R32SI:          return WGPUTextureFormat_R32Sint;\r\n        case SG_PIXELFORMAT_R32F:           return WGPUTextureFormat_R32Float;\r\n        case SG_PIXELFORMAT_RG16UI:         return WGPUTextureFormat_RG16Uint;\r\n        case SG_PIXELFORMAT_RG16SI:         return WGPUTextureFormat_RG16Sint;\r\n        case SG_PIXELFORMAT_RG16F:          return WGPUTextureFormat_RG16Float;\r\n        case SG_PIXELFORMAT_RGBA8:          return WGPUTextureFormat_RGBA8Unorm;\r\n        case SG_PIXELFORMAT_RGBA8SN:        return WGPUTextureFormat_RGBA8Snorm;\r\n        case SG_PIXELFORMAT_RGBA8UI:        return WGPUTextureFormat_RGBA8Uint;\r\n        case SG_PIXELFORMAT_RGBA8SI:        return WGPUTextureFormat_RGBA8Sint;\r\n        case SG_PIXELFORMAT_BGRA8:          return WGPUTextureFormat_BGRA8Unorm;\r\n        case SG_PIXELFORMAT_RGB10A2:        return WGPUTextureFormat_RGB10A2Unorm;\r\n        case SG_PIXELFORMAT_RG11B10F:       return WGPUTextureFormat_RG11B10Float;\r\n        case SG_PIXELFORMAT_RG32UI:         return WGPUTextureFormat_RG32Uint;\r\n        case SG_PIXELFORMAT_RG32SI:         return WGPUTextureFormat_RG32Sint;\r\n        case SG_PIXELFORMAT_RG32F:          return WGPUTextureFormat_RG32Float;\r\n        case SG_PIXELFORMAT_RGBA16UI:       return WGPUTextureFormat_RGBA16Uint;\r\n        case SG_PIXELFORMAT_RGBA16SI:       return WGPUTextureFormat_RGBA16Sint;\r\n        case SG_PIXELFORMAT_RGBA16F:        return WGPUTextureFormat_RGBA16Float;\r\n        case SG_PIXELFORMAT_RGBA32UI:       return WGPUTextureFormat_RGBA32Uint;\r\n        case SG_PIXELFORMAT_RGBA32SI:       return WGPUTextureFormat_RGBA32Sint;\r\n        case SG_PIXELFORMAT_RGBA32F:        return WGPUTextureFormat_RGBA32Float;\r\n        case SG_PIXELFORMAT_DEPTH:          return WGPUTextureFormat_Depth24Plus;\r\n        case SG_PIXELFORMAT_DEPTH_STENCIL:  return WGPUTextureFormat_Depth24PlusStencil8;\r\n        case SG_PIXELFORMAT_BC1_RGBA:       return WGPUTextureFormat_BC1RGBAUnorm;\r\n        case SG_PIXELFORMAT_BC2_RGBA:       return WGPUTextureFormat_BC2RGBAUnorm;\r\n        case SG_PIXELFORMAT_BC3_RGBA:       return WGPUTextureFormat_BC3RGBAUnorm;\r\n        case SG_PIXELFORMAT_BC4_R:          return WGPUTextureFormat_BC4RUnorm;\r\n        case SG_PIXELFORMAT_BC4_RSN:        return WGPUTextureFormat_BC4RSnorm;\r\n        case SG_PIXELFORMAT_BC5_RG:         return WGPUTextureFormat_BC5RGUnorm;\r\n        case SG_PIXELFORMAT_BC5_RGSN:       return WGPUTextureFormat_BC5RGSnorm;\r\n        case SG_PIXELFORMAT_BC6H_RGBF:      return WGPUTextureFormat_BC6HRGBSfloat;\r\n        case SG_PIXELFORMAT_BC6H_RGBUF:     return WGPUTextureFormat_BC6HRGBUfloat;\r\n        case SG_PIXELFORMAT_BC7_RGBA:       return WGPUTextureFormat_BC7RGBAUnorm;\r\n\r\n        /* NOT SUPPORTED */\r\n        case SG_PIXELFORMAT_R16:\r\n        case SG_PIXELFORMAT_R16SN:\r\n        case SG_PIXELFORMAT_RG16:\r\n        case SG_PIXELFORMAT_RG16SN:\r\n        case SG_PIXELFORMAT_RGBA16:\r\n        case SG_PIXELFORMAT_RGBA16SN:\r\n        case SG_PIXELFORMAT_PVRTC_RGB_2BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGB_4BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_2BPP:\r\n        case SG_PIXELFORMAT_PVRTC_RGBA_4BPP:\r\n        case SG_PIXELFORMAT_ETC2_RGB8:\r\n        case SG_PIXELFORMAT_ETC2_RGB8A1:\r\n        case SG_PIXELFORMAT_ETC2_RGBA8:\r\n        case SG_PIXELFORMAT_ETC2_RG11:\r\n        case SG_PIXELFORMAT_ETC2_RG11SN:\r\n        default:\r\n            SOKOL_UNREACHABLE;\r\n            return WGPUTextureFormat_Force32;\r\n    }\r\n}\r\n\r\n/*\r\nFIXME ??? this isn't needed anywhere?\r\n_SOKOL_PRIVATE WGPUTextureAspect _sg_wgpu_texture_aspect(sg_pixel_format fmt) {\r\n    if (_sg_is_valid_rendertarget_depth_format(fmt)) {\r\n        if (!_sg_is_depth_stencil_format(fmt)) {\r\n            return WGPUTextureAspect_DepthOnly;\r\n        }\r\n    }\r\n    return WGPUTextureAspect_All;\r\n}\r\n*/\r\n\r\n_SOKOL_PRIVATE WGPUCompareFunction _sg_wgpu_comparefunc(sg_compare_func f) {\r\n    switch (f) {\r\n        case SG_COMPAREFUNC_NEVER:          return WGPUCompareFunction_Never;\r\n        case SG_COMPAREFUNC_LESS:           return WGPUCompareFunction_Less;\r\n        case SG_COMPAREFUNC_EQUAL:          return WGPUCompareFunction_Equal;\r\n        case SG_COMPAREFUNC_LESS_EQUAL:     return WGPUCompareFunction_LessEqual;\r\n        case SG_COMPAREFUNC_GREATER:        return WGPUCompareFunction_Greater;\r\n        case SG_COMPAREFUNC_NOT_EQUAL:      return WGPUCompareFunction_NotEqual;\r\n        case SG_COMPAREFUNC_GREATER_EQUAL:  return WGPUCompareFunction_GreaterEqual;\r\n        case SG_COMPAREFUNC_ALWAYS:         return WGPUCompareFunction_Always;\r\n        default: SOKOL_UNREACHABLE; return WGPUCompareFunction_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUStencilOperation _sg_wgpu_stencilop(sg_stencil_op op) {\r\n    switch (op) {\r\n        case SG_STENCILOP_KEEP:         return WGPUStencilOperation_Keep;\r\n        case SG_STENCILOP_ZERO:         return WGPUStencilOperation_Zero;\r\n        case SG_STENCILOP_REPLACE:      return WGPUStencilOperation_Replace;\r\n        case SG_STENCILOP_INCR_CLAMP:   return WGPUStencilOperation_IncrementClamp;\r\n        case SG_STENCILOP_DECR_CLAMP:   return WGPUStencilOperation_DecrementClamp;\r\n        case SG_STENCILOP_INVERT:       return WGPUStencilOperation_Invert;\r\n        case SG_STENCILOP_INCR_WRAP:    return WGPUStencilOperation_IncrementWrap;\r\n        case SG_STENCILOP_DECR_WRAP:    return WGPUStencilOperation_DecrementWrap;\r\n        default: SOKOL_UNREACHABLE; return WGPUStencilOperation_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUBlendOperation _sg_wgpu_blendop(sg_blend_op op) {\r\n    switch (op) {\r\n        case SG_BLENDOP_ADD:                return WGPUBlendOperation_Add;\r\n        case SG_BLENDOP_SUBTRACT:           return WGPUBlendOperation_Subtract;\r\n        case SG_BLENDOP_REVERSE_SUBTRACT:   return WGPUBlendOperation_ReverseSubtract;\r\n        default: SOKOL_UNREACHABLE; return WGPUBlendOperation_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUBlendFactor _sg_wgpu_blendfactor(sg_blend_factor f) {\r\n    switch (f) {\r\n        case SG_BLENDFACTOR_ZERO:                   return WGPUBlendFactor_Zero;\r\n        case SG_BLENDFACTOR_ONE:                    return WGPUBlendFactor_One;\r\n        case SG_BLENDFACTOR_SRC_COLOR:              return WGPUBlendFactor_SrcColor;\r\n        case SG_BLENDFACTOR_ONE_MINUS_SRC_COLOR:    return WGPUBlendFactor_OneMinusSrcColor;\r\n        case SG_BLENDFACTOR_SRC_ALPHA:              return WGPUBlendFactor_SrcAlpha;\r\n        case SG_BLENDFACTOR_ONE_MINUS_SRC_ALPHA:    return WGPUBlendFactor_OneMinusSrcAlpha;\r\n        case SG_BLENDFACTOR_DST_COLOR:              return WGPUBlendFactor_DstColor;\r\n        case SG_BLENDFACTOR_ONE_MINUS_DST_COLOR:    return WGPUBlendFactor_OneMinusDstColor;\r\n        case SG_BLENDFACTOR_DST_ALPHA:              return WGPUBlendFactor_DstAlpha;\r\n        case SG_BLENDFACTOR_ONE_MINUS_DST_ALPHA:    return WGPUBlendFactor_OneMinusDstAlpha;\r\n        case SG_BLENDFACTOR_SRC_ALPHA_SATURATED:    return WGPUBlendFactor_SrcAlphaSaturated;\r\n        case SG_BLENDFACTOR_BLEND_COLOR:            return WGPUBlendFactor_BlendColor;\r\n        case SG_BLENDFACTOR_ONE_MINUS_BLEND_COLOR:  return WGPUBlendFactor_OneMinusBlendColor;\r\n        /* FIXME: separate blend alpha value not supported? */\r\n        case SG_BLENDFACTOR_BLEND_ALPHA:            return WGPUBlendFactor_BlendColor;\r\n        case SG_BLENDFACTOR_ONE_MINUS_BLEND_ALPHA:  return WGPUBlendFactor_OneMinusBlendColor;\r\n        default:\r\n            SOKOL_UNREACHABLE; return WGPUBlendFactor_Force32;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUColorWriteMaskFlags _sg_wgpu_colorwritemask(uint8_t m) {\r\n    WGPUColorWriteMaskFlags res = 0;\r\n    if (0 != (m & SG_COLORMASK_R)) {\r\n        res |= WGPUColorWriteMask_Red;\r\n    }\r\n    if (0 != (m & SG_COLORMASK_G)) {\r\n        res |= WGPUColorWriteMask_Green;\r\n    }\r\n    if (0 != (m & SG_COLORMASK_B)) {\r\n        res |= WGPUColorWriteMask_Blue;\r\n    }\r\n    if (0 != (m & SG_COLORMASK_A)) {\r\n        res |= WGPUColorWriteMask_Alpha;\r\n    }\r\n    return res;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_init_caps(void) {\r\n    _sg.backend = SG_BACKEND_WGPU;\r\n    _sg.features.instancing = true;\r\n    _sg.features.origin_top_left = true;\r\n    _sg.features.multiple_render_targets = true;\r\n    _sg.features.msaa_render_targets = true;\r\n    _sg.features.imagetype_3d = true;\r\n    _sg.features.imagetype_array = true;\r\n    _sg.features.image_clamp_to_border = false;\r\n\r\n    /* FIXME: max images size??? */\r\n    _sg.limits.max_image_size_2d = 8 * 1024;\r\n    _sg.limits.max_image_size_cube = 8 * 1024;\r\n    _sg.limits.max_image_size_3d = 2 * 1024;\r\n    _sg.limits.max_image_size_array = 8 * 1024;\r\n    _sg.limits.max_image_array_layers = 2 * 1024;\r\n    _sg.limits.max_vertex_attrs = SG_MAX_VERTEX_ATTRIBUTES;\r\n\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R8]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R8SN]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R8UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R8SI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R16UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R16SI]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16F]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG8]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG8SN]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG8UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG8SI]);\r\n    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32UI]);\r\n    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32SI]);\r\n    _sg_pixelformat_sbr(&_sg.formats[SG_PIXELFORMAT_R32F]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG16UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG16SI]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16F]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA8]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGBA8SN]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA8UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA8SI]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_BGRA8]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGB10A2]);\r\n    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG32UI]);\r\n    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG32SI]);\r\n    _sg_pixelformat_sbr(&_sg.formats[SG_PIXELFORMAT_RG32F]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA16UI]);\r\n    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA16SI]);\r\n    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);\r\n    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);\r\n    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);\r\n    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);\r\n    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH]);\r\n    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH_STENCIL]);\r\n\r\n    /* FIXME FIXME FIXME: need to check if BC texture compression is\r\n        actually supported, currently the WebGPU C-API doesn't allow this\r\n    */\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC1_RGBA]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC2_RGBA]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC3_RGBA]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_R]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_RSN]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RG]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RGSN]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBF]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBUF]);\r\n    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC7_RGBA]);\r\n}\r\n\r\n/*\r\n    WGPU uniform buffer pool implementation:\r\n\r\n    At start of frame, a mapped buffer is grabbed from the pool,\r\n    or a new buffer is created if there is no mapped buffer available.\r\n\r\n    At end of frame, the current buffer is unmapped before queue submit,\r\n    and async-mapped immediately again.\r\n\r\n    UNIFORM BUFFER FIXME:\r\n\r\n    - As per WebGPU spec, it should be possible to create a Uniform|MapWrite\r\n      buffer, but this isn't currently allowed in Dawn.\r\n*/\r\n_SOKOL_PRIVATE void _sg_wgpu_ubpool_init(const sg_desc* desc) {\r\n\r\n    /* Add the max-uniform-update size (64 KB) to the requested buffer size,\r\n       this is to prevent validation errors in the WebGPU implementation\r\n       if the entire buffer size is used per frame. 64 KB is the allowed\r\n       max uniform update size on NVIDIA\r\n    */\r\n    _sg.wgpu.ub.num_bytes = desc->uniform_buffer_size + _SG_WGPU_MAX_UNIFORM_UPDATE_SIZE;\r\n\r\n    WGPUBufferDescriptor ub_desc;\r\n    memset(&ub_desc, 0, sizeof(ub_desc));\r\n    ub_desc.size = _sg.wgpu.ub.num_bytes;\r\n    ub_desc.usage = WGPUBufferUsage_Uniform|WGPUBufferUsage_CopyDst;\r\n    _sg.wgpu.ub.buf = wgpuDeviceCreateBuffer(_sg.wgpu.dev, &ub_desc);\r\n    SOKOL_ASSERT(_sg.wgpu.ub.buf);\r\n\r\n    WGPUBindGroupLayoutBinding ub_bglb_desc[SG_NUM_SHADER_STAGES][SG_MAX_SHADERSTAGE_UBS];\r\n    memset(ub_bglb_desc, 0, sizeof(ub_bglb_desc));\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        WGPUShaderStage vis = (stage_index == SG_SHADERSTAGE_VS) ? WGPUShaderStage_Vertex : WGPUShaderStage_Fragment;\r\n        for (int ub_index = 0; ub_index < SG_MAX_SHADERSTAGE_UBS; ub_index++) {\r\n            int bind_index = stage_index * SG_MAX_SHADERSTAGE_UBS + ub_index;\r\n            ub_bglb_desc[stage_index][ub_index].binding = bind_index;\r\n            ub_bglb_desc[stage_index][ub_index].visibility = vis;\r\n            ub_bglb_desc[stage_index][ub_index].type = WGPUBindingType_UniformBuffer;\r\n            ub_bglb_desc[stage_index][ub_index].hasDynamicOffset = true;\r\n        }\r\n    }\r\n\r\n    WGPUBindGroupLayoutDescriptor ub_bgl_desc;\r\n    memset(&ub_bgl_desc, 0, sizeof(ub_bgl_desc));\r\n    ub_bgl_desc.bindingCount = SG_NUM_SHADER_STAGES * SG_MAX_SHADERSTAGE_UBS;\r\n    ub_bgl_desc.bindings = &ub_bglb_desc[0][0];\r\n    _sg.wgpu.ub.bindgroup_layout = wgpuDeviceCreateBindGroupLayout(_sg.wgpu.dev, &ub_bgl_desc);\r\n    SOKOL_ASSERT(_sg.wgpu.ub.bindgroup_layout);\r\n\r\n    WGPUBindGroupBinding ub_bgb[SG_NUM_SHADER_STAGES][SG_MAX_SHADERSTAGE_UBS];\r\n    memset(ub_bgb, 0, sizeof(ub_bgb));\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        for (int ub_index = 0; ub_index < SG_MAX_SHADERSTAGE_UBS; ub_index++) {\r\n            int bind_index = stage_index * SG_MAX_SHADERSTAGE_UBS + ub_index;\r\n            ub_bgb[stage_index][ub_index].binding = bind_index;\r\n            ub_bgb[stage_index][ub_index].buffer = _sg.wgpu.ub.buf;\r\n            // FIXME FIXME FIXME FIXME: HACK FOR VALIDATION BUG IN DAWN\r\n            ub_bgb[stage_index][ub_index].size = (1<<16);\r\n        }\r\n    }\r\n    WGPUBindGroupDescriptor bg_desc;\r\n    memset(&bg_desc, 0, sizeof(bg_desc));\r\n    bg_desc.layout = _sg.wgpu.ub.bindgroup_layout;\r\n    bg_desc.bindingCount = SG_NUM_SHADER_STAGES * SG_MAX_SHADERSTAGE_UBS;\r\n    bg_desc.bindings = &ub_bgb[0][0];\r\n    _sg.wgpu.ub.bindgroup = wgpuDeviceCreateBindGroup(_sg.wgpu.dev, &bg_desc);\r\n    SOKOL_ASSERT(_sg.wgpu.ub.bindgroup);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_ubpool_discard(void) {\r\n    if (_sg.wgpu.ub.buf) {\r\n        wgpuBufferRelease(_sg.wgpu.ub.buf);\r\n        _sg.wgpu.ub.buf = 0;\r\n    }\r\n    if (_sg.wgpu.ub.bindgroup) {\r\n        wgpuBindGroupRelease(_sg.wgpu.ub.bindgroup);\r\n        _sg.wgpu.ub.bindgroup = 0;\r\n    }\r\n    if (_sg.wgpu.ub.bindgroup_layout) {\r\n        wgpuBindGroupLayoutRelease(_sg.wgpu.ub.bindgroup_layout);\r\n        _sg.wgpu.ub.bindgroup_layout = 0;\r\n    }\r\n    for (int i = 0; i < _sg.wgpu.ub.stage.num; i++) {\r\n        if (_sg.wgpu.ub.stage.buf[i]) {\r\n            wgpuBufferRelease(_sg.wgpu.ub.stage.buf[i]);\r\n            _sg.wgpu.ub.stage.buf[i] = 0;\r\n            _sg.wgpu.ub.stage.ptr[i] = 0;\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_ubpool_mapped_callback(WGPUBufferMapAsyncStatus status, void* data, uint64_t data_len, void* user_data) {\r\n    if (!_sg.wgpu.valid) {\r\n        return;\r\n    }\r\n    /* FIXME: better handling for this */\r\n    if (WGPUBufferMapAsyncStatus_Success != status) {\r\n        SOKOL_LOG(\"Mapping uniform buffer failed!\\n\");\r\n        SOKOL_ASSERT(false);\r\n    }\r\n    SOKOL_ASSERT(data && (data_len == _sg.wgpu.ub.num_bytes));\r\n    int index = (int)(intptr_t) user_data;\r\n    SOKOL_ASSERT(index < _sg.wgpu.ub.stage.num);\r\n    SOKOL_ASSERT(0 == _sg.wgpu.ub.stage.ptr[index]);\r\n    _sg.wgpu.ub.stage.ptr[index] = (uint8_t*) data;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_ubpool_next_frame(bool first_frame) {\r\n\r\n    /* immediately request a new mapping for the last frame's current staging buffer */\r\n    if (!first_frame) {\r\n        WGPUBuffer ub_src = _sg.wgpu.ub.stage.buf[_sg.wgpu.ub.stage.cur];\r\n        wgpuBufferMapWriteAsync(ub_src, _sg_wgpu_ubpool_mapped_callback, (void*)(intptr_t)_sg.wgpu.ub.stage.cur);\r\n    }\r\n\r\n    /* rewind per-frame offsets */\r\n    _sg.wgpu.ub.offset = 0;\r\n    memset(&_sg.wgpu.ub.bind_offsets, 0, sizeof(_sg.wgpu.ub.bind_offsets));\r\n\r\n    /* check if a mapped staging buffer is available, otherwise create one */\r\n    for (int i = 0; i < _sg.wgpu.ub.stage.num; i++) {\r\n        if (_sg.wgpu.ub.stage.ptr[i]) {\r\n            _sg.wgpu.ub.stage.cur = i;\r\n            return;\r\n        }\r\n    }\r\n\r\n    /* no mapped uniform buffer available, create one */\r\n    SOKOL_ASSERT(_sg.wgpu.ub.stage.num < _SG_WGPU_STAGING_PIPELINE_SIZE);\r\n    _sg.wgpu.ub.stage.cur = _sg.wgpu.ub.stage.num++;\r\n    const int cur = _sg.wgpu.ub.stage.cur;\r\n\r\n    WGPUBufferDescriptor desc;\r\n    memset(&desc, 0, sizeof(desc));\r\n    desc.size = _sg.wgpu.ub.num_bytes;\r\n    desc.usage = WGPUBufferUsage_CopySrc|WGPUBufferUsage_MapWrite;\r\n    WGPUCreateBufferMappedResult res = wgpuDeviceCreateBufferMapped(_sg.wgpu.dev, &desc);\r\n    _sg.wgpu.ub.stage.buf[cur] = res.buffer;\r\n    _sg.wgpu.ub.stage.ptr[cur] = (uint8_t*) res.data;\r\n    SOKOL_ASSERT(_sg.wgpu.ub.stage.buf[cur]);\r\n    SOKOL_ASSERT(_sg.wgpu.ub.stage.ptr[cur]);\r\n    SOKOL_ASSERT(res.dataLength == _sg.wgpu.ub.num_bytes);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_ubpool_flush(void) {\r\n    /* unmap staging buffer and copy to uniform buffer */\r\n    const int cur = _sg.wgpu.ub.stage.cur;\r\n    SOKOL_ASSERT(_sg.wgpu.ub.stage.ptr[cur]);\r\n    _sg.wgpu.ub.stage.ptr[cur] = 0;\r\n    WGPUBuffer src_buf = _sg.wgpu.ub.stage.buf[cur];\r\n    wgpuBufferUnmap(src_buf);\r\n    if (_sg.wgpu.ub.offset > 0) {\r\n        WGPUBuffer dst_buf = _sg.wgpu.ub.buf;\r\n        wgpuCommandEncoderCopyBufferToBuffer(_sg.wgpu.render_cmd_enc, src_buf, 0, dst_buf, 0, _sg.wgpu.ub.offset);\r\n    }\r\n}\r\n\r\n/* helper function to compute number of bytes needed in staging buffer to copy image data */\r\n_SOKOL_PRIVATE uint32_t _sg_wgpu_image_content_buffer_size(const _sg_image_t* img, const sg_image_content* content) {\r\n    uint32_t num_bytes = 0;\r\n    const uint32_t num_faces = (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6:1;\r\n    const uint32_t num_slices = (img->cmn.type == SG_IMAGETYPE_ARRAY) ? img->cmn.depth : 1;\r\n    for (int mip_index = 0; mip_index < img->cmn.num_mipmaps; mip_index++) {\r\n        const uint32_t mip_width = _sg_max(img->cmn.width >> mip_index, 1);\r\n        const uint32_t mip_height = _sg_max(img->cmn.height >> mip_index, 1);\r\n        /* row-pitch must be 256-aligend */\r\n        const uint32_t bytes_per_slice = _sg_surface_pitch(img->cmn.pixel_format, mip_width, mip_height, _SG_WGPU_ROWPITCH_ALIGN);\r\n        num_bytes += bytes_per_slice * num_slices * num_faces;\r\n    }\r\n    return num_bytes;\r\n}\r\n\r\n/* helper function to copy image data into a texture via a staging buffer, returns number of\r\n   bytes copied\r\n*/\r\n_SOKOL_PRIVATE uint32_t _sg_wgpu_copy_image_content(WGPUBuffer stg_buf, uint8_t* stg_base_ptr, uint32_t stg_base_offset, _sg_image_t* img, const sg_image_content* content) {\r\n    SOKOL_ASSERT(_sg.wgpu.staging_cmd_enc);\r\n    SOKOL_ASSERT(stg_buf && stg_base_ptr);\r\n    SOKOL_ASSERT(img);\r\n    SOKOL_ASSERT(content);\r\n    uint32_t stg_offset = stg_base_offset;\r\n    const uint32_t num_faces = (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6:1;\r\n    const uint32_t num_slices = (img->cmn.type == SG_IMAGETYPE_ARRAY) ? img->cmn.depth : 1;\r\n    const sg_pixel_format fmt = img->cmn.pixel_format;\r\n    WGPUBufferCopyView src_view;\r\n    memset(&src_view, 0, sizeof(src_view));\r\n    src_view.buffer = stg_buf;\r\n    WGPUTextureCopyView dst_view;\r\n    memset(&dst_view, 0, sizeof(dst_view));\r\n    dst_view.texture = img->wgpu.tex;\r\n    WGPUExtent3D extent;\r\n    memset(&extent, 0, sizeof(extent));\r\n\r\n    for (uint32_t face_index = 0; face_index < num_faces; face_index++) {\r\n        for (uint32_t mip_index = 0; mip_index < (uint32_t)img->cmn.num_mipmaps; mip_index++) {\r\n            SOKOL_ASSERT(content->subimage[face_index][mip_index].ptr);\r\n            SOKOL_ASSERT(content->subimage[face_index][mip_index].size > 0);\r\n            const uint8_t* src_base_ptr = (const uint8_t*)content->subimage[face_index][mip_index].ptr;\r\n            SOKOL_ASSERT(src_base_ptr);\r\n            uint8_t* dst_base_ptr = stg_base_ptr + stg_offset;\r\n\r\n            const uint32_t mip_width  = _sg_max(img->cmn.width >> mip_index, 1);\r\n            const uint32_t mip_height = _sg_max(img->cmn.height >> mip_index, 1);\r\n            const uint32_t mip_depth  = (img->cmn.type == SG_IMAGETYPE_3D) ? _sg_max(img->cmn.depth >> mip_index, 1) : 1;\r\n            const uint32_t num_rows   = _sg_num_rows(fmt, mip_height);\r\n            const uint32_t src_bytes_per_row   = _sg_row_pitch(fmt, mip_width, 1);\r\n            const uint32_t dst_bytes_per_row   = _sg_row_pitch(fmt, mip_width, _SG_WGPU_ROWPITCH_ALIGN);\r\n            const uint32_t src_bytes_per_slice = _sg_surface_pitch(fmt, mip_width, mip_height, 1);\r\n            const uint32_t dst_bytes_per_slice = _sg_surface_pitch(fmt, mip_width, mip_height, _SG_WGPU_ROWPITCH_ALIGN);\r\n            SOKOL_ASSERT((uint32_t)content->subimage[face_index][mip_index].size == (src_bytes_per_slice * num_slices));\r\n            SOKOL_ASSERT(src_bytes_per_row <= dst_bytes_per_row);\r\n            SOKOL_ASSERT(src_bytes_per_slice == (src_bytes_per_row * num_rows));\r\n            SOKOL_ASSERT(dst_bytes_per_slice == (dst_bytes_per_row * num_rows));\r\n            _SOKOL_UNUSED(src_bytes_per_slice);\r\n\r\n            /* copy content into mapped staging buffer */\r\n            if (src_bytes_per_row == dst_bytes_per_row) {\r\n                /* can do a single memcpy */\r\n                uint32_t num_bytes = content->subimage[face_index][mip_index].size;\r\n                memcpy(dst_base_ptr, src_base_ptr, num_bytes);\r\n            }\r\n            else {\r\n                /* src/dst pitch doesn't match, need to copy row by row */\r\n                uint8_t* dst_ptr = dst_base_ptr;\r\n                const uint8_t* src_ptr = src_base_ptr;\r\n                for (uint32_t slice_index = 0; slice_index < num_slices; slice_index++) {\r\n                    SOKOL_ASSERT(dst_ptr == dst_base_ptr + slice_index * dst_bytes_per_slice);\r\n                    for (uint32_t row_index = 0; row_index < num_rows; row_index++) {\r\n                        memcpy(dst_ptr, src_ptr, src_bytes_per_row);\r\n                        src_ptr += src_bytes_per_row;\r\n                        dst_ptr += dst_bytes_per_row;\r\n                    }\r\n                }\r\n            }\r\n\r\n            /* record the staging copy operation into command encoder */\r\n            src_view.imageHeight = mip_height;\r\n            src_view.rowPitch = dst_bytes_per_row;\r\n            dst_view.mipLevel = mip_index;\r\n            extent.width = mip_width;\r\n            extent.height = mip_height;\r\n            extent.depth = mip_depth;\r\n            SOKOL_ASSERT((img->cmn.type != SG_IMAGETYPE_CUBE) || (num_slices == 1));\r\n            for (uint32_t slice_index = 0; slice_index < num_slices; slice_index++) {\r\n                const uint32_t layer_index = (img->cmn.type == SG_IMAGETYPE_ARRAY) ? slice_index : face_index;\r\n                src_view.offset = stg_offset;\r\n                dst_view.arrayLayer = layer_index;\r\n                wgpuCommandEncoderCopyBufferToTexture(_sg.wgpu.staging_cmd_enc, &src_view, &dst_view, &extent);\r\n                stg_offset += dst_bytes_per_slice;\r\n                SOKOL_ASSERT(stg_offset <= _sg.wgpu.staging.num_bytes);\r\n            }\r\n        }\r\n    }\r\n    SOKOL_ASSERT(stg_offset >= stg_base_offset);\r\n    return (stg_offset - stg_base_offset);\r\n}\r\n\r\n/*\r\n    The WGPU staging buffer implementation:\r\n\r\n    Very similar to the uniform buffer pool, there's a pool of big\r\n    per-frame staging buffers, each must be big enough to hold\r\n    all data uploaded to dynamic resources for one frame.\r\n\r\n    Staging buffers are created on demand and reused, because the\r\n    'frame pipeline depth' of WGPU isn't predictable.\r\n\r\n    The difference to the uniform buffer system is that there isn't\r\n    a 1:1 relationship for source- and destination for the\r\n    data-copy operation. There's always one staging buffer as copy-source\r\n    per frame, but many copy-destinations (regular vertex/index buffers\r\n    or images). Instead of one big copy-operation at the end of the frame,\r\n    multiple copy-operations will be written throughout the frame.\r\n*/\r\n_SOKOL_PRIVATE void _sg_wgpu_staging_init(const sg_desc* desc) {\r\n    SOKOL_ASSERT(desc && (desc->staging_buffer_size > 0));\r\n    _sg.wgpu.staging.num_bytes = desc->staging_buffer_size;\r\n    /* there's actually nothing more to do here */\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_staging_discard(void) {\r\n    for (int i = 0; i < _sg.wgpu.staging.num; i++) {\r\n        if (_sg.wgpu.staging.buf[i]) {\r\n            wgpuBufferRelease(_sg.wgpu.staging.buf[i]);\r\n            _sg.wgpu.staging.buf[i] = 0;\r\n            _sg.wgpu.staging.ptr[i] = 0;\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_staging_mapped_callback(WGPUBufferMapAsyncStatus status, void* data, uint64_t data_len, void* user_data) {\r\n    if (!_sg.wgpu.valid) {\r\n        return;\r\n    }\r\n    /* FIXME: better handling for this */\r\n    if (WGPUBufferMapAsyncStatus_Success != status) {\r\n        SOKOL_ASSERT(\"Mapping staging buffer failed!\\n\");\r\n        SOKOL_ASSERT(false);\r\n    }\r\n    SOKOL_ASSERT(data && (data_len == _sg.wgpu.staging.num_bytes));\r\n    int index = (int)(intptr_t) user_data;\r\n    SOKOL_ASSERT(index < _sg.wgpu.staging.num);\r\n    SOKOL_ASSERT(0 == _sg.wgpu.staging.ptr[index]);\r\n    _sg.wgpu.staging.ptr[index] = (uint8_t*) data;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_staging_next_frame(bool first_frame) {\r\n\r\n    /* immediately request a new mapping for the last frame's current staging buffer */\r\n    if (!first_frame) {\r\n        WGPUBuffer cur_buf = _sg.wgpu.staging.buf[_sg.wgpu.staging.cur];\r\n        wgpuBufferMapWriteAsync(cur_buf, _sg_wgpu_staging_mapped_callback, (void*)(intptr_t)_sg.wgpu.staging.cur);\r\n    }\r\n\r\n    /* rewind staging-buffer offset */\r\n    _sg.wgpu.staging.offset = 0;\r\n\r\n    /* check if mapped staging buffer is available, otherwise create one */\r\n    for (int i = 0; i < _sg.wgpu.staging.num; i++) {\r\n        if (_sg.wgpu.staging.ptr[i]) {\r\n            _sg.wgpu.staging.cur = i;\r\n            return;\r\n        }\r\n    }\r\n\r\n    /* no mapped buffer available, create one */\r\n    SOKOL_ASSERT(_sg.wgpu.staging.num < _SG_WGPU_STAGING_PIPELINE_SIZE);\r\n    _sg.wgpu.staging.cur = _sg.wgpu.staging.num++;\r\n    const int cur = _sg.wgpu.staging.cur;\r\n\r\n    WGPUBufferDescriptor desc;\r\n    memset(&desc, 0, sizeof(desc));\r\n    desc.size = _sg.wgpu.staging.num_bytes;\r\n    desc.usage = WGPUBufferUsage_CopySrc|WGPUBufferUsage_MapWrite;\r\n    WGPUCreateBufferMappedResult res = wgpuDeviceCreateBufferMapped(_sg.wgpu.dev, &desc);\r\n    _sg.wgpu.staging.buf[cur] = res.buffer;\r\n    _sg.wgpu.staging.ptr[cur] = (uint8_t*) res.data;\r\n    SOKOL_ASSERT(_sg.wgpu.staging.buf[cur]);\r\n    SOKOL_ASSERT(_sg.wgpu.staging.ptr[cur]);\r\n    SOKOL_ASSERT(res.dataLength == _sg.wgpu.staging.num_bytes);\r\n}\r\n\r\n_SOKOL_PRIVATE uint32_t _sg_wgpu_staging_copy_to_buffer(WGPUBuffer dst_buf, uint32_t dst_buf_offset, const void* data, uint32_t data_num_bytes) {\r\n    /* Copy a chunk of data into the staging buffer, and record a blit-operation into\r\n        the command encoder, bump the offset for the next data chunk, return 0 if there\r\n        was not enough room in the staging buffer, return the number of actually\r\n        copied bytes on success.\r\n\r\n        NOTE: that the number of staging bytes to be copied must be a multiple of 4.\r\n\r\n    */\r\n    SOKOL_ASSERT(_sg.wgpu.staging_cmd_enc);\r\n    SOKOL_ASSERT((dst_buf_offset & 3) == 0);\r\n    SOKOL_ASSERT(data_num_bytes > 0);\r\n    uint32_t copy_num_bytes = _sg_roundup(data_num_bytes, 4);\r\n    if ((_sg.wgpu.staging.offset + copy_num_bytes) >= _sg.wgpu.staging.num_bytes) {\r\n        SOKOL_LOG(\"WGPU: Per frame staging buffer full (in _sg_wgpu_staging_copy_to_buffer())!\\n\");\r\n        return false;\r\n    }\r\n    const int cur = _sg.wgpu.staging.cur;\r\n    SOKOL_ASSERT(_sg.wgpu.staging.ptr[cur]);\r\n    uint32_t stg_buf_offset = _sg.wgpu.staging.offset;\r\n    uint8_t* stg_ptr = _sg.wgpu.staging.ptr[cur] + stg_buf_offset;\r\n    memcpy(stg_ptr, data, data_num_bytes);\r\n    WGPUBuffer stg_buf = _sg.wgpu.staging.buf[cur];\r\n    wgpuCommandEncoderCopyBufferToBuffer(_sg.wgpu.staging_cmd_enc, stg_buf, stg_buf_offset, dst_buf, dst_buf_offset, copy_num_bytes);\r\n    _sg.wgpu.staging.offset = stg_buf_offset + copy_num_bytes;\r\n    return copy_num_bytes;\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_wgpu_staging_copy_to_texture(_sg_image_t* img, const sg_image_content* content) {\r\n    /* similar to _sg_wgpu_staging_copy_to_buffer(), but with image data instead */\r\n    SOKOL_ASSERT(_sg.wgpu.staging_cmd_enc);\r\n    uint32_t num_bytes = _sg_wgpu_image_content_buffer_size(img, content);\r\n    if ((_sg.wgpu.staging.offset + num_bytes) >= _sg.wgpu.staging.num_bytes) {\r\n        SOKOL_LOG(\"WGPU: Per frame staging buffer full (in _sg_wgpu_staging_copy_to_texture)!\\n\");\r\n        return false;\r\n    }\r\n    const int cur = _sg.wgpu.staging.cur;\r\n    SOKOL_ASSERT(_sg.wgpu.staging.ptr[cur]);\r\n    uint32_t stg_offset = _sg.wgpu.staging.offset;\r\n    uint8_t* stg_ptr = _sg.wgpu.staging.ptr[cur];\r\n    WGPUBuffer stg_buf = _sg.wgpu.staging.buf[cur];\r\n    uint32_t bytes_copied = _sg_wgpu_copy_image_content(stg_buf, stg_ptr, stg_offset, img, content);\r\n    _SOKOL_UNUSED(bytes_copied);\r\n    SOKOL_ASSERT(bytes_copied == num_bytes);\r\n    _sg.wgpu.staging.offset = _sg_roundup(stg_offset + num_bytes, _SG_WGPU_STAGING_ALIGN);\r\n    return true;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_staging_unmap(void) {\r\n    /* called at end of frame before queue-submit */\r\n    const int cur = _sg.wgpu.staging.cur;\r\n    SOKOL_ASSERT(_sg.wgpu.staging.ptr[cur]);\r\n    _sg.wgpu.staging.ptr[cur] = 0;\r\n    wgpuBufferUnmap(_sg.wgpu.staging.buf[cur]);\r\n}\r\n\r\n/*--- WGPU sampler cache functions ---*/\r\n_SOKOL_PRIVATE void _sg_wgpu_init_sampler_cache(const sg_desc* desc) {\r\n    SOKOL_ASSERT(desc->sampler_cache_size > 0);\r\n    _sg_smpcache_init(&_sg.wgpu.sampler_cache, desc->sampler_cache_size);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_destroy_sampler_cache(void) {\r\n    SOKOL_ASSERT(_sg.wgpu.sampler_cache.items);\r\n    SOKOL_ASSERT(_sg.wgpu.sampler_cache.num_items <= _sg.wgpu.sampler_cache.capacity);\r\n    for (int i = 0; i < _sg.wgpu.sampler_cache.num_items; i++) {\r\n        wgpuSamplerRelease((WGPUSampler)_sg_smpcache_sampler(&_sg.wgpu.sampler_cache, i));\r\n    }\r\n    _sg_smpcache_discard(&_sg.wgpu.sampler_cache);\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUSampler _sg_wgpu_create_sampler(const sg_image_desc* img_desc) {\r\n    SOKOL_ASSERT(img_desc);\r\n    int index = _sg_smpcache_find_item(&_sg.wgpu.sampler_cache, img_desc);\r\n    if (index >= 0) {\r\n        /* reuse existing sampler */\r\n        return (WGPUSampler) _sg_smpcache_sampler(&_sg.wgpu.sampler_cache, index);\r\n    }\r\n    else {\r\n        /* create a new WGPU sampler and add to sampler cache */\r\n        /* FIXME: anisotropic filtering not supported? */\r\n        WGPUSamplerDescriptor smp_desc;\r\n        memset(&smp_desc, 0, sizeof(smp_desc));\r\n        smp_desc.addressModeU = _sg_wgpu_sampler_addrmode(img_desc->wrap_u);\r\n        smp_desc.addressModeV = _sg_wgpu_sampler_addrmode(img_desc->wrap_v);\r\n        smp_desc.addressModeW = _sg_wgpu_sampler_addrmode(img_desc->wrap_w);\r\n        smp_desc.magFilter = _sg_wgpu_sampler_minmagfilter(img_desc->mag_filter);\r\n        smp_desc.minFilter = _sg_wgpu_sampler_minmagfilter(img_desc->min_filter);\r\n        smp_desc.mipmapFilter = _sg_wgpu_sampler_mipfilter(img_desc->min_filter);\r\n        smp_desc.lodMinClamp = img_desc->min_lod;\r\n        smp_desc.lodMaxClamp = img_desc->max_lod;\r\n        WGPUSampler smp = wgpuDeviceCreateSampler(_sg.wgpu.dev, &smp_desc);\r\n        SOKOL_ASSERT(smp);\r\n        _sg_smpcache_add_item(&_sg.wgpu.sampler_cache, img_desc, (uintptr_t)smp);\r\n        return smp;\r\n    }\r\n}\r\n\r\n/*--- WGPU backend API functions ---*/\r\n_SOKOL_PRIVATE void _sg_wgpu_setup_backend(const sg_desc* desc) {\r\n    SOKOL_ASSERT(desc);\r\n    SOKOL_ASSERT(desc->context.wgpu.device);\r\n    SOKOL_ASSERT(desc->context.wgpu.render_view_cb || desc->context.wgpu.render_view_userdata_cb);\r\n    SOKOL_ASSERT(desc->context.wgpu.resolve_view_cb || desc->context.wgpu.resolve_view_userdata_cb);\r\n    SOKOL_ASSERT(desc->context.wgpu.depth_stencil_view_cb || desc->context.wgpu.depth_stencil_view_userdata_cb);\r\n    SOKOL_ASSERT(desc->uniform_buffer_size > 0);\r\n    SOKOL_ASSERT(desc->staging_buffer_size > 0);\r\n    _sg.backend = SG_BACKEND_WGPU;\r\n    _sg.wgpu.valid = true;\r\n    _sg.wgpu.dev = (WGPUDevice) desc->context.wgpu.device;\r\n    _sg.wgpu.render_view_cb = (WGPUTextureView(*)(void)) desc->context.wgpu.render_view_cb;\r\n    _sg.wgpu.render_view_userdata_cb = (WGPUTextureView(*)(void*)) desc->context.wgpu.render_view_userdata_cb;\r\n    _sg.wgpu.resolve_view_cb = (WGPUTextureView(*)(void)) desc->context.wgpu.resolve_view_cb;\r\n    _sg.wgpu.resolve_view_userdata_cb = (WGPUTextureView(*)(void*)) desc->context.wgpu.resolve_view_userdata_cb;\r\n    _sg.wgpu.depth_stencil_view_cb = (WGPUTextureView(*)(void)) desc->context.wgpu.depth_stencil_view_cb;\r\n    _sg.wgpu.depth_stencil_view_userdata_cb = (WGPUTextureView(*)(void*)) desc->context.wgpu.depth_stencil_view_userdata_cb;\r\n    _sg.wgpu.user_data = desc->context.wgpu.user_data;\r\n    _sg.wgpu.queue = wgpuDeviceCreateQueue(_sg.wgpu.dev);\r\n    SOKOL_ASSERT(_sg.wgpu.queue);\r\n\r\n    /* setup WebGPU features and limits */\r\n    _sg_wgpu_init_caps();\r\n\r\n    /* setup the sampler cache, uniform and staging buffer pools */\r\n    _sg_wgpu_init_sampler_cache(&_sg.desc);\r\n    _sg_wgpu_ubpool_init(desc);\r\n    _sg_wgpu_ubpool_next_frame(true);\r\n    _sg_wgpu_staging_init(desc);\r\n    _sg_wgpu_staging_next_frame(true);\r\n\r\n    /* create an empty bind group for shader stages without bound images */\r\n    WGPUBindGroupLayoutDescriptor bgl_desc;\r\n    memset(&bgl_desc, 0, sizeof(bgl_desc));\r\n    WGPUBindGroupLayout empty_bgl = wgpuDeviceCreateBindGroupLayout(_sg.wgpu.dev, &bgl_desc);\r\n    SOKOL_ASSERT(empty_bgl);\r\n    WGPUBindGroupDescriptor bg_desc;\r\n    memset(&bg_desc, 0, sizeof(bg_desc));\r\n    bg_desc.layout = empty_bgl;\r\n    _sg.wgpu.empty_bind_group = wgpuDeviceCreateBindGroup(_sg.wgpu.dev, &bg_desc);\r\n    SOKOL_ASSERT(_sg.wgpu.empty_bind_group);\r\n    wgpuBindGroupLayoutRelease(empty_bgl);\r\n\r\n    /* create initial per-frame command encoders */\r\n    WGPUCommandEncoderDescriptor cmd_enc_desc;\r\n    memset(&cmd_enc_desc, 0, sizeof(cmd_enc_desc));\r\n    _sg.wgpu.render_cmd_enc = wgpuDeviceCreateCommandEncoder(_sg.wgpu.dev, &cmd_enc_desc);\r\n    SOKOL_ASSERT(_sg.wgpu.render_cmd_enc);\r\n    _sg.wgpu.staging_cmd_enc = wgpuDeviceCreateCommandEncoder(_sg.wgpu.dev, &cmd_enc_desc);\r\n    SOKOL_ASSERT(_sg.wgpu.staging_cmd_enc);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_discard_backend(void) {\r\n    SOKOL_ASSERT(_sg.wgpu.valid);\r\n    SOKOL_ASSERT(_sg.wgpu.render_cmd_enc);\r\n    SOKOL_ASSERT(_sg.wgpu.staging_cmd_enc);\r\n    _sg.wgpu.valid = false;\r\n    _sg_wgpu_ubpool_discard();\r\n    _sg_wgpu_staging_discard();\r\n    _sg_wgpu_destroy_sampler_cache();\r\n    wgpuBindGroupRelease(_sg.wgpu.empty_bind_group);\r\n    wgpuCommandEncoderRelease(_sg.wgpu.render_cmd_enc);\r\n    _sg.wgpu.render_cmd_enc = 0;\r\n    wgpuCommandEncoderRelease(_sg.wgpu.staging_cmd_enc);\r\n    _sg.wgpu.staging_cmd_enc = 0;\r\n    if (_sg.wgpu.queue) {\r\n        wgpuQueueRelease(_sg.wgpu.queue);\r\n        _sg.wgpu.queue = 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_reset_state_cache(void) {\r\n    SOKOL_LOG(\"_sg_wgpu_reset_state_cache: FIXME\\n\");\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    _SOKOL_UNUSED(ctx);\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_destroy_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    _SOKOL_UNUSED(ctx);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_activate_context(_sg_context_t* ctx) {\r\n    SOKOL_LOG(\"_sg_wgpu_activate_context: FIXME\\n\");\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {\r\n    SOKOL_ASSERT(buf && desc);\r\n    const bool injected = (0 != desc->wgpu_buffer);\r\n    _sg_buffer_common_init(&buf->cmn, desc);\r\n    if (injected) {\r\n        buf->wgpu.buf = (WGPUBuffer) desc->wgpu_buffer;\r\n        wgpuBufferReference(buf->wgpu.buf);\r\n    }\r\n    else {\r\n        WGPUBufferDescriptor wgpu_buf_desc;\r\n        memset(&wgpu_buf_desc, 0, sizeof(wgpu_buf_desc));\r\n        wgpu_buf_desc.usage = _sg_wgpu_buffer_usage(buf->cmn.type, buf->cmn.usage);\r\n        wgpu_buf_desc.size = buf->cmn.size;\r\n        if (SG_USAGE_IMMUTABLE == buf->cmn.usage) {\r\n            SOKOL_ASSERT(desc->content);\r\n            WGPUCreateBufferMappedResult res = wgpuDeviceCreateBufferMapped(_sg.wgpu.dev, &wgpu_buf_desc);\r\n            buf->wgpu.buf = res.buffer;\r\n            SOKOL_ASSERT(res.data && ((int)res.dataLength == buf->cmn.size));\r\n            memcpy(res.data, desc->content, buf->cmn.size);\r\n            wgpuBufferUnmap(res.buffer);\r\n        }\r\n        else {\r\n            buf->wgpu.buf = wgpuDeviceCreateBuffer(_sg.wgpu.dev, &wgpu_buf_desc);\r\n        }\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_destroy_buffer(_sg_buffer_t* buf) {\r\n    SOKOL_ASSERT(buf);\r\n    WGPUBuffer wgpu_buf = buf->wgpu.buf;\r\n    if (0 != wgpu_buf) {\r\n        wgpuBufferRelease(wgpu_buf);\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_init_texdesc_common(WGPUTextureDescriptor* wgpu_tex_desc, const sg_image_desc* desc) {\r\n    wgpu_tex_desc->usage = WGPUTextureUsage_Sampled|WGPUTextureUsage_CopyDst;\r\n    wgpu_tex_desc->dimension = _sg_wgpu_tex_dim(desc->type);\r\n    wgpu_tex_desc->size.width = desc->width;\r\n    wgpu_tex_desc->size.height = desc->height;\r\n    if (desc->type == SG_IMAGETYPE_3D) {\r\n        wgpu_tex_desc->size.depth = desc->depth;\r\n        wgpu_tex_desc->arrayLayerCount = 1;\r\n    }\r\n    else if (desc->type == SG_IMAGETYPE_CUBE) {\r\n        wgpu_tex_desc->size.depth = 1;\r\n        wgpu_tex_desc->arrayLayerCount = 6;\r\n    }\r\n    else {\r\n        wgpu_tex_desc->size.depth = 1;\r\n        wgpu_tex_desc->arrayLayerCount = desc->layers;\r\n    }\r\n    wgpu_tex_desc->format = _sg_wgpu_textureformat(desc->pixel_format);\r\n    wgpu_tex_desc->mipLevelCount = desc->num_mipmaps;\r\n    wgpu_tex_desc->sampleCount = 1;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_image(_sg_image_t* img, const sg_image_desc* desc) {\r\n    SOKOL_ASSERT(img && desc);\r\n    SOKOL_ASSERT(_sg.wgpu.dev);\r\n    SOKOL_ASSERT(_sg.wgpu.staging_cmd_enc);\r\n\r\n    _sg_image_common_init(&img->cmn, desc);\r\n\r\n    const bool injected = (0 != desc->wgpu_texture);\r\n    const bool is_msaa = desc->sample_count > 1;\r\n    WGPUTextureDescriptor wgpu_tex_desc;\r\n    memset(&wgpu_tex_desc, 0, sizeof(wgpu_tex_desc));\r\n    _sg_wgpu_init_texdesc_common(&wgpu_tex_desc, desc);\r\n    if (_sg_is_valid_rendertarget_depth_format(img->cmn.pixel_format)) {\r\n        SOKOL_ASSERT(img->cmn.render_target);\r\n        SOKOL_ASSERT(img->cmn.type == SG_IMAGETYPE_2D);\r\n        SOKOL_ASSERT(img->cmn.num_mipmaps == 1);\r\n        SOKOL_ASSERT(!injected);\r\n        /* NOTE: a depth-stencil texture will never be MSAA-resolved, so there\r\n           won't be a separate MSAA- and resolve-texture\r\n        */\r\n        wgpu_tex_desc.usage = WGPUTextureUsage_OutputAttachment;\r\n        wgpu_tex_desc.sampleCount = desc->sample_count;\r\n        img->wgpu.tex = wgpuDeviceCreateTexture(_sg.wgpu.dev, &wgpu_tex_desc);\r\n        SOKOL_ASSERT(img->wgpu.tex);\r\n    }\r\n    else {\r\n        if (injected) {\r\n            img->wgpu.tex = (WGPUTexture) desc->wgpu_texture;\r\n            wgpuTextureReference(img->wgpu.tex);\r\n        }\r\n        else {\r\n            /* NOTE: in the MSAA-rendertarget case, both the MSAA texture *and*\r\n               the resolve texture need OutputAttachment usage\r\n            */\r\n            if (img->cmn.render_target) {\r\n                wgpu_tex_desc.usage = WGPUTextureUsage_Sampled|WGPUTextureUsage_OutputAttachment;\r\n            }\r\n            img->wgpu.tex = wgpuDeviceCreateTexture(_sg.wgpu.dev, &wgpu_tex_desc);\r\n            SOKOL_ASSERT(img->wgpu.tex);\r\n\r\n            /* copy content into texture via a throw-away staging buffer */\r\n            if (desc->usage == SG_USAGE_IMMUTABLE && !desc->render_target) {\r\n                WGPUBufferDescriptor wgpu_buf_desc;\r\n                memset(&wgpu_buf_desc, 0, sizeof(wgpu_buf_desc));\r\n                wgpu_buf_desc.size = _sg_wgpu_image_content_buffer_size(img, &desc->content);\r\n                wgpu_buf_desc.usage = WGPUBufferUsage_CopySrc|WGPUBufferUsage_CopyDst;\r\n                WGPUCreateBufferMappedResult map = wgpuDeviceCreateBufferMapped(_sg.wgpu.dev, &wgpu_buf_desc);\r\n                SOKOL_ASSERT(map.buffer && map.data);\r\n                uint32_t num_bytes = _sg_wgpu_copy_image_content(map.buffer, (uint8_t*)map.data, 0, img, &desc->content);\r\n                _SOKOL_UNUSED(num_bytes);\r\n                SOKOL_ASSERT(num_bytes == wgpu_buf_desc.size);\r\n                wgpuBufferUnmap(map.buffer);\r\n                wgpuBufferRelease(map.buffer);\r\n            }\r\n        }\r\n\r\n        /* create texture view object */\r\n        WGPUTextureViewDescriptor wgpu_view_desc;\r\n        memset(&wgpu_view_desc, 0, sizeof(wgpu_view_desc));\r\n        wgpu_view_desc.dimension = _sg_wgpu_tex_viewdim(desc->type);\r\n        img->wgpu.tex_view = wgpuTextureCreateView(img->wgpu.tex, &wgpu_view_desc);\r\n\r\n        /* if render target and MSAA, then a separate texture in MSAA format is needed\r\n           which will be resolved into the regular texture at the end of the\r\n           offscreen-render pass\r\n        */\r\n        if (desc->render_target && is_msaa) {\r\n            wgpu_tex_desc.dimension = WGPUTextureDimension_2D;\r\n            wgpu_tex_desc.size.depth = 1;\r\n            wgpu_tex_desc.arrayLayerCount = 1;\r\n            wgpu_tex_desc.mipLevelCount = 1;\r\n            wgpu_tex_desc.usage = WGPUTextureUsage_OutputAttachment;\r\n            wgpu_tex_desc.sampleCount = desc->sample_count;\r\n            img->wgpu.msaa_tex = wgpuDeviceCreateTexture(_sg.wgpu.dev, &wgpu_tex_desc);\r\n            SOKOL_ASSERT(img->wgpu.msaa_tex);\r\n        }\r\n\r\n        /* create sampler via shared-sampler-cache */\r\n        img->wgpu.sampler = _sg_wgpu_create_sampler(desc);\r\n        SOKOL_ASSERT(img->wgpu.sampler);\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_destroy_image(_sg_image_t* img) {\r\n    SOKOL_ASSERT(img);\r\n    if (img->wgpu.tex) {\r\n        wgpuTextureRelease(img->wgpu.tex);\r\n        img->wgpu.tex = 0;\r\n    }\r\n    if (img->wgpu.tex_view) {\r\n        wgpuTextureViewRelease(img->wgpu.tex_view);\r\n        img->wgpu.tex_view = 0;\r\n    }\r\n    if (img->wgpu.msaa_tex) {\r\n        wgpuTextureRelease(img->wgpu.msaa_tex);\r\n        img->wgpu.msaa_tex = 0;\r\n    }\r\n    /* NOTE: do *not* destroy the sampler from the shared-sampler-cache */\r\n    img->wgpu.sampler = 0;\r\n}\r\n\r\n/*\r\n    How BindGroups work in WebGPU:\r\n\r\n    - up to 4 bind groups can be bound simultanously\r\n    - up to 16 bindings per bind group\r\n    - 'binding' slots are local per bind group\r\n    - in the shader:\r\n        layout(set=0, binding=1) corresponds to bind group 0, binding 1\r\n\r\n    Now how to map this to sokol-gfx's bind model:\r\n\r\n    Reduce SG_MAX_SHADERSTAGE_IMAGES to 8, then:\r\n\r\n        1 bind group for all 8 uniform buffers\r\n        1 bind group for vertex shader textures + samplers\r\n        1 bind group for fragment shader textures + samples\r\n\r\n    Alternatively:\r\n\r\n        1 bind group for 8 uniform buffer slots\r\n        1 bind group for 8 vs images + 8 vs samplers\r\n        1 bind group for 12 fs images\r\n        1 bind group for 12 fs samplers\r\n\r\n    I guess this means that we need to create BindGroups on the\r\n    fly during sg_apply_bindings() :/\r\n*/\r\n_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {\r\n    SOKOL_ASSERT(shd && desc);\r\n    SOKOL_ASSERT(desc->vs.byte_code && desc->fs.byte_code);\r\n    _sg_shader_common_init(&shd->cmn, desc);\r\n\r\n    bool success = true;\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        const sg_shader_stage_desc* stage_desc = (stage_index == SG_SHADERSTAGE_VS) ? &desc->vs : &desc->fs;\r\n        SOKOL_ASSERT((stage_desc->byte_code_size & 3) == 0);\r\n\r\n        _sg_shader_stage_t* cmn_stage = &shd->cmn.stage[stage_index];\r\n        _sg_wgpu_shader_stage_t* wgpu_stage = &shd->wgpu.stage[stage_index];\r\n\r\n        _sg_strcpy(&wgpu_stage->entry, stage_desc->entry);\r\n        WGPUShaderModuleDescriptor wgpu_shdmod_desc;\r\n        memset(&wgpu_shdmod_desc, 0, sizeof(wgpu_shdmod_desc));\r\n        wgpu_shdmod_desc.codeSize = stage_desc->byte_code_size >> 2;\r\n        wgpu_shdmod_desc.code = (const uint32_t*) stage_desc->byte_code;\r\n        wgpu_stage->module = wgpuDeviceCreateShaderModule(_sg.wgpu.dev, &wgpu_shdmod_desc);\r\n        if (0 == wgpu_stage->module) {\r\n            success = false;\r\n        }\r\n\r\n        /* create image/sampler bind group for the shader stage */\r\n        WGPUShaderStage vis = (stage_index == SG_SHADERSTAGE_VS) ? WGPUShaderStage_Vertex : WGPUShaderStage_Fragment;\r\n        int num_imgs = cmn_stage->num_images;\r\n        if (num_imgs > _SG_WGPU_MAX_SHADERSTAGE_IMAGES) {\r\n            num_imgs = _SG_WGPU_MAX_SHADERSTAGE_IMAGES;\r\n        }\r\n        WGPUBindGroupLayoutBinding bglb_desc[_SG_WGPU_MAX_SHADERSTAGE_IMAGES * 2];\r\n        memset(bglb_desc, 0, sizeof(bglb_desc));\r\n        for (int img_index = 0; img_index < num_imgs; img_index++) {\r\n            /* texture- and sampler-bindings */\r\n            WGPUBindGroupLayoutBinding* tex_desc = &bglb_desc[img_index*2 + 0];\r\n            WGPUBindGroupLayoutBinding* smp_desc = &bglb_desc[img_index*2 + 1];\r\n\r\n            tex_desc->binding = img_index;\r\n            tex_desc->visibility = vis;\r\n            tex_desc->type = WGPUBindingType_SampledTexture;\r\n            tex_desc->textureDimension = _sg_wgpu_tex_viewdim(cmn_stage->images[img_index].type);\r\n            tex_desc->textureComponentType = _sg_wgpu_tex_comptype(cmn_stage->images[img_index].sampler_type);\r\n\r\n            smp_desc->binding = img_index + _SG_WGPU_MAX_SHADERSTAGE_IMAGES;\r\n            smp_desc->visibility = vis;\r\n            smp_desc->type = WGPUBindingType_Sampler;\r\n        }\r\n        WGPUBindGroupLayoutDescriptor img_bgl_desc;\r\n        memset(&img_bgl_desc, 0, sizeof(img_bgl_desc));\r\n        img_bgl_desc.bindingCount = num_imgs * 2;\r\n        img_bgl_desc.bindings = &bglb_desc[0];\r\n        wgpu_stage->bind_group_layout = wgpuDeviceCreateBindGroupLayout(_sg.wgpu.dev, &img_bgl_desc);\r\n        SOKOL_ASSERT(wgpu_stage->bind_group_layout);\r\n    }\r\n    return success ? SG_RESOURCESTATE_VALID : SG_RESOURCESTATE_FAILED;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_destroy_shader(_sg_shader_t* shd) {\r\n    SOKOL_ASSERT(shd);\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        _sg_wgpu_shader_stage_t* wgpu_stage = &shd->wgpu.stage[stage_index];\r\n        if (wgpu_stage->module) {\r\n            wgpuShaderModuleRelease(wgpu_stage->module);\r\n            wgpu_stage->module = 0;\r\n        }\r\n        if (wgpu_stage->bind_group_layout) {\r\n            wgpuBindGroupLayoutRelease(wgpu_stage->bind_group_layout);\r\n            wgpu_stage->bind_group_layout = 0;\r\n        }\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {\r\n    SOKOL_ASSERT(pip && shd && desc);\r\n    SOKOL_ASSERT(desc->shader.id == shd->slot.id);\r\n    SOKOL_ASSERT(shd->wgpu.stage[SG_SHADERSTAGE_VS].bind_group_layout);\r\n    SOKOL_ASSERT(shd->wgpu.stage[SG_SHADERSTAGE_FS].bind_group_layout);\r\n    pip->shader = shd;\r\n    _sg_pipeline_common_init(&pip->cmn, desc);\r\n    pip->wgpu.stencil_ref = (uint32_t) desc->depth_stencil.stencil_ref;\r\n\r\n    WGPUBindGroupLayout pip_bgl[3] = {\r\n        _sg.wgpu.ub.bindgroup_layout,\r\n        shd->wgpu.stage[SG_SHADERSTAGE_VS].bind_group_layout,\r\n        shd->wgpu.stage[SG_SHADERSTAGE_FS].bind_group_layout\r\n    };\r\n    WGPUPipelineLayoutDescriptor pl_desc;\r\n    memset(&pl_desc, 0, sizeof(pl_desc));\r\n    pl_desc.bindGroupLayoutCount = 3;\r\n    pl_desc.bindGroupLayouts = &pip_bgl[0];\r\n    WGPUPipelineLayout pip_layout = wgpuDeviceCreatePipelineLayout(_sg.wgpu.dev, &pl_desc);\r\n\r\n    WGPUVertexBufferLayoutDescriptor vb_desc[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    memset(&vb_desc, 0, sizeof(vb_desc));\r\n    WGPUVertexAttributeDescriptor va_desc[SG_MAX_SHADERSTAGE_BUFFERS][SG_MAX_VERTEX_ATTRIBUTES];\r\n    memset(&va_desc, 0, sizeof(va_desc));\r\n    int vb_idx = 0;\r\n    for (; vb_idx < SG_MAX_SHADERSTAGE_BUFFERS; vb_idx++) {\r\n        const sg_buffer_layout_desc* src_vb_desc = &desc->layout.buffers[vb_idx];\r\n        if (0 == src_vb_desc->stride) {\r\n            break;\r\n        }\r\n        vb_desc[vb_idx].arrayStride = src_vb_desc->stride;\r\n        vb_desc[vb_idx].stepMode = _sg_wgpu_stepmode(src_vb_desc->step_func);\r\n        /* NOTE: WebGPU has no support for vertex step rate (because that's\r\n           not supported by Core Vulkan\r\n        */\r\n        int va_idx = 0;\r\n        for (int va_loc = 0; va_loc < SG_MAX_VERTEX_ATTRIBUTES; va_loc++) {\r\n            const sg_vertex_attr_desc* src_va_desc = &desc->layout.attrs[va_loc];\r\n            if (SG_VERTEXFORMAT_INVALID == src_va_desc->format) {\r\n                break;\r\n            }\r\n            pip->cmn.vertex_layout_valid[src_va_desc->buffer_index] = true;\r\n            if (vb_idx == src_va_desc->buffer_index) {\r\n                va_desc[vb_idx][va_idx].format = _sg_wgpu_vertexformat(src_va_desc->format);\r\n                va_desc[vb_idx][va_idx].offset = src_va_desc->offset;\r\n                va_desc[vb_idx][va_idx].shaderLocation = va_loc;\r\n                va_idx++;\r\n            }\r\n        }\r\n        vb_desc[vb_idx].attributeCount = va_idx;\r\n        vb_desc[vb_idx].attributes = &va_desc[vb_idx][0];\r\n    }\r\n    WGPUVertexStateDescriptor vx_state_desc;\r\n    memset(&vx_state_desc, 0, sizeof(vx_state_desc));\r\n    vx_state_desc.indexFormat = _sg_wgpu_indexformat(desc->index_type);\r\n    vx_state_desc.vertexBufferCount = vb_idx;\r\n    vx_state_desc.vertexBuffers = vb_desc;\r\n\r\n    WGPURasterizationStateDescriptor rs_desc;\r\n    memset(&rs_desc, 0, sizeof(rs_desc));\r\n    rs_desc.frontFace = _sg_wgpu_frontface(desc->rasterizer.face_winding);\r\n    rs_desc.cullMode = _sg_wgpu_cullmode(desc->rasterizer.cull_mode);\r\n    rs_desc.depthBias = (int32_t) desc->rasterizer.depth_bias;\r\n    rs_desc.depthBiasClamp = desc->rasterizer.depth_bias_clamp;\r\n    rs_desc.depthBiasSlopeScale = desc->rasterizer.depth_bias_slope_scale;\r\n\r\n    WGPUDepthStencilStateDescriptor ds_desc;\r\n    memset(&ds_desc, 0, sizeof(ds_desc));\r\n    ds_desc.format = _sg_wgpu_textureformat(desc->blend.depth_format);\r\n    ds_desc.depthWriteEnabled = desc->depth_stencil.depth_write_enabled;\r\n    ds_desc.depthCompare = _sg_wgpu_comparefunc(desc->depth_stencil.depth_compare_func);\r\n    ds_desc.stencilReadMask = desc->depth_stencil.stencil_read_mask;\r\n    ds_desc.stencilWriteMask = desc->depth_stencil.stencil_write_mask;\r\n    ds_desc.stencilFront.compare = _sg_wgpu_comparefunc(desc->depth_stencil.stencil_front.compare_func);\r\n    ds_desc.stencilFront.failOp = _sg_wgpu_stencilop(desc->depth_stencil.stencil_front.fail_op);\r\n    ds_desc.stencilFront.depthFailOp = _sg_wgpu_stencilop(desc->depth_stencil.stencil_front.depth_fail_op);\r\n    ds_desc.stencilFront.passOp = _sg_wgpu_stencilop(desc->depth_stencil.stencil_front.pass_op);\r\n    ds_desc.stencilBack.compare = _sg_wgpu_comparefunc(desc->depth_stencil.stencil_back.compare_func);\r\n    ds_desc.stencilBack.failOp = _sg_wgpu_stencilop(desc->depth_stencil.stencil_back.fail_op);\r\n    ds_desc.stencilBack.depthFailOp = _sg_wgpu_stencilop(desc->depth_stencil.stencil_back.depth_fail_op);\r\n    ds_desc.stencilBack.passOp = _sg_wgpu_stencilop(desc->depth_stencil.stencil_back.pass_op);\r\n\r\n    WGPUProgrammableStageDescriptor fs_desc;\r\n    memset(&fs_desc, 0, sizeof(fs_desc));\r\n    fs_desc.module = shd->wgpu.stage[SG_SHADERSTAGE_FS].module;\r\n    fs_desc.entryPoint = shd->wgpu.stage[SG_SHADERSTAGE_VS].entry.buf;\r\n\r\n    WGPUColorStateDescriptor cs_desc[SG_MAX_COLOR_ATTACHMENTS];\r\n    memset(cs_desc, 0, sizeof(cs_desc));\r\n    cs_desc[0].format = _sg_wgpu_textureformat(desc->blend.color_format);\r\n    cs_desc[0].colorBlend.operation = _sg_wgpu_blendop(desc->blend.op_rgb);\r\n    cs_desc[0].colorBlend.srcFactor = _sg_wgpu_blendfactor(desc->blend.src_factor_rgb);\r\n    cs_desc[0].colorBlend.dstFactor = _sg_wgpu_blendfactor(desc->blend.dst_factor_rgb);\r\n    cs_desc[0].alphaBlend.operation = _sg_wgpu_blendop(desc->blend.op_alpha);\r\n    cs_desc[0].alphaBlend.srcFactor = _sg_wgpu_blendfactor(desc->blend.src_factor_alpha);\r\n    cs_desc[0].alphaBlend.dstFactor = _sg_wgpu_blendfactor(desc->blend.dst_factor_alpha);\r\n    cs_desc[0].writeMask = _sg_wgpu_colorwritemask(desc->blend.color_write_mask);\r\n    SOKOL_ASSERT(desc->blend.color_attachment_count <= SG_MAX_COLOR_ATTACHMENTS);\r\n    for (int i = 1; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n        cs_desc[i] = cs_desc[0];\r\n    }\r\n\r\n    WGPURenderPipelineDescriptor pip_desc;\r\n    memset(&pip_desc, 0, sizeof(pip_desc));\r\n    pip_desc.layout = pip_layout;\r\n    pip_desc.vertexStage.module = shd->wgpu.stage[SG_SHADERSTAGE_VS].module;\r\n    pip_desc.vertexStage.entryPoint = shd->wgpu.stage[SG_SHADERSTAGE_VS].entry.buf;\r\n    pip_desc.fragmentStage = &fs_desc;\r\n    pip_desc.vertexState = &vx_state_desc;\r\n    pip_desc.primitiveTopology  = _sg_wgpu_topology(desc->primitive_type);\r\n    pip_desc.rasterizationState = &rs_desc;\r\n    pip_desc.sampleCount = desc->rasterizer.sample_count;\r\n    if (SG_PIXELFORMAT_NONE != desc->blend.depth_format) {\r\n        pip_desc.depthStencilState = &ds_desc;\r\n    }\r\n    pip_desc.colorStateCount = desc->blend.color_attachment_count;\r\n    pip_desc.colorStates = cs_desc;\r\n    pip_desc.sampleMask = 0xFFFFFFFF;   /* FIXME: ??? */\r\n    pip->wgpu.pip = wgpuDeviceCreateRenderPipeline(_sg.wgpu.dev, &pip_desc);\r\n    SOKOL_ASSERT(0 != pip->wgpu.pip);\r\n    wgpuPipelineLayoutRelease(pip_layout);\r\n\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_destroy_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    if (pip->wgpu.pip) {\r\n        wgpuRenderPipelineRelease(pip->wgpu.pip);\r\n        pip->wgpu.pip = 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_pass(_sg_pass_t* pass, _sg_image_t** att_images, const sg_pass_desc* desc) {\r\n    SOKOL_ASSERT(pass && desc);\r\n    SOKOL_ASSERT(att_images && att_images[0]);\r\n    _sg_pass_common_init(&pass->cmn, desc);\r\n\r\n    /* copy image pointers and create render-texture views */\r\n    const sg_attachment_desc* att_desc;\r\n    for (int i = 0; i < pass->cmn.num_color_atts; i++) {\r\n        att_desc = &desc->color_attachments[i];\r\n        if (att_desc->image.id != SG_INVALID_ID) {\r\n            SOKOL_ASSERT(att_desc->image.id != SG_INVALID_ID);\r\n            SOKOL_ASSERT(0 == pass->wgpu.color_atts[i].image);\r\n            _sg_image_t* img = att_images[i];\r\n            SOKOL_ASSERT(img && (img->slot.id == att_desc->image.id));\r\n            SOKOL_ASSERT(_sg_is_valid_rendertarget_color_format(img->cmn.pixel_format));\r\n            pass->wgpu.color_atts[i].image = img;\r\n            /* create a render-texture-view to render into the right sub-surface */\r\n            const bool is_msaa = img->cmn.sample_count > 1;\r\n            WGPUTextureViewDescriptor view_desc;\r\n            memset(&view_desc, 0, sizeof(view_desc));\r\n            view_desc.baseMipLevel = is_msaa ? 0 : att_desc->mip_level;\r\n            view_desc.mipLevelCount = 1;\r\n            view_desc.baseArrayLayer = is_msaa ? 0 : att_desc->slice;\r\n            view_desc.arrayLayerCount = 1;\r\n            WGPUTexture wgpu_tex = is_msaa ? img->wgpu.msaa_tex : img->wgpu.tex;\r\n            SOKOL_ASSERT(wgpu_tex);\r\n            pass->wgpu.color_atts[i].render_tex_view = wgpuTextureCreateView(wgpu_tex, &view_desc);\r\n            SOKOL_ASSERT(pass->wgpu.color_atts[i].render_tex_view);\r\n            /* ... and if needed a separate resolve texture view */\r\n            if (is_msaa) {\r\n                view_desc.baseMipLevel = att_desc->mip_level;\r\n                view_desc.baseArrayLayer = att_desc->slice;\r\n                WGPUTexture wgpu_tex = img->wgpu.tex;\r\n                pass->wgpu.color_atts[i].resolve_tex_view = wgpuTextureCreateView(wgpu_tex, &view_desc);\r\n                SOKOL_ASSERT(pass->wgpu.color_atts[i].resolve_tex_view);\r\n            }\r\n        }\r\n    }\r\n    SOKOL_ASSERT(0 == pass->wgpu.ds_att.image);\r\n    att_desc = &desc->depth_stencil_attachment;\r\n    if (att_desc->image.id != SG_INVALID_ID) {\r\n        const int ds_img_index = SG_MAX_COLOR_ATTACHMENTS;\r\n        SOKOL_ASSERT(att_images[ds_img_index] && (att_images[ds_img_index]->slot.id == att_desc->image.id));\r\n        SOKOL_ASSERT(_sg_is_valid_rendertarget_depth_format(att_images[ds_img_index]->cmn.pixel_format));\r\n        _sg_image_t* ds_img = att_images[ds_img_index];\r\n        pass->wgpu.ds_att.image = ds_img;\r\n        /* create a render-texture view */\r\n        SOKOL_ASSERT(0 == att_desc->mip_level);\r\n        SOKOL_ASSERT(0 == att_desc->slice);\r\n        WGPUTextureViewDescriptor view_desc;\r\n        memset(&view_desc, 0, sizeof(view_desc));\r\n        WGPUTexture wgpu_tex = ds_img->wgpu.tex;\r\n        SOKOL_ASSERT(wgpu_tex);\r\n        pass->wgpu.ds_att.render_tex_view = wgpuTextureCreateView(wgpu_tex, &view_desc);\r\n        SOKOL_ASSERT(pass->wgpu.ds_att.render_tex_view);\r\n    }\r\n    return SG_RESOURCESTATE_VALID;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_destroy_pass(_sg_pass_t* pass) {\r\n    SOKOL_ASSERT(pass);\r\n    for (int i = 0; i < pass->cmn.num_color_atts; i++) {\r\n        if (pass->wgpu.color_atts[i].render_tex_view) {\r\n            wgpuTextureViewRelease(pass->wgpu.color_atts[i].render_tex_view);\r\n            pass->wgpu.color_atts[i].render_tex_view = 0;\r\n        }\r\n        if (pass->wgpu.color_atts[i].resolve_tex_view) {\r\n            wgpuTextureViewRelease(pass->wgpu.color_atts[i].resolve_tex_view);\r\n            pass->wgpu.color_atts[i].resolve_tex_view = 0;\r\n        }\r\n    }\r\n    if (pass->wgpu.ds_att.render_tex_view) {\r\n        wgpuTextureViewRelease(pass->wgpu.ds_att.render_tex_view);\r\n        pass->wgpu.ds_att.render_tex_view = 0;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_wgpu_pass_color_image(const _sg_pass_t* pass, int index) {\r\n    SOKOL_ASSERT(pass && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));\r\n    /* NOTE: may return null */\r\n    return pass->wgpu.color_atts[index].image;\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_wgpu_pass_ds_image(const _sg_pass_t* pass) {\r\n    /* NOTE: may return null */\r\n    SOKOL_ASSERT(pass);\r\n    return pass->wgpu.ds_att.image;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_begin_pass(_sg_pass_t* pass, const sg_pass_action* action, int w, int h) {\r\n    SOKOL_ASSERT(action);\r\n    SOKOL_ASSERT(!_sg.wgpu.in_pass);\r\n    SOKOL_ASSERT(_sg.wgpu.render_cmd_enc);\r\n    SOKOL_ASSERT(_sg.wgpu.dev);\r\n    SOKOL_ASSERT(_sg.wgpu.render_view_cb || _sg.wgpu.render_view_userdata_cb);\r\n    SOKOL_ASSERT(_sg.wgpu.resolve_view_cb || _sg.wgpu.resolve_view_userdata_cb);\r\n    SOKOL_ASSERT(_sg.wgpu.depth_stencil_view_cb || _sg.wgpu.depth_stencil_view_userdata_cb);\r\n    _sg.wgpu.in_pass = true;\r\n    _sg.wgpu.cur_width = w;\r\n    _sg.wgpu.cur_height = h;\r\n    _sg.wgpu.cur_pipeline = 0;\r\n    _sg.wgpu.cur_pipeline_id.id = SG_INVALID_ID;\r\n\r\n    SOKOL_ASSERT(_sg.wgpu.render_cmd_enc);\r\n    if (pass) {\r\n        WGPURenderPassDescriptor wgpu_pass_desc;\r\n        memset(&wgpu_pass_desc, 0, sizeof(wgpu_pass_desc));\r\n        WGPURenderPassColorAttachmentDescriptor wgpu_color_att_desc[SG_MAX_COLOR_ATTACHMENTS];\r\n        memset(&wgpu_color_att_desc, 0, sizeof(wgpu_color_att_desc));\r\n        SOKOL_ASSERT(pass->slot.state == SG_RESOURCESTATE_VALID);\r\n        for (int i = 0; i < pass->cmn.num_color_atts; i++) {\r\n            const _sg_wgpu_attachment_t* wgpu_att = &pass->wgpu.color_atts[i];\r\n            wgpu_color_att_desc[i].loadOp = _sg_wgpu_load_op(action->colors[i].action);\r\n            wgpu_color_att_desc[i].storeOp = WGPUStoreOp_Store;\r\n            wgpu_color_att_desc[i].clearColor.r = action->colors[i].val[0];\r\n            wgpu_color_att_desc[i].clearColor.g = action->colors[i].val[1];\r\n            wgpu_color_att_desc[i].clearColor.b = action->colors[i].val[2];\r\n            wgpu_color_att_desc[i].clearColor.a = action->colors[i].val[3];\r\n            wgpu_color_att_desc[i].attachment = wgpu_att->render_tex_view;\r\n            if (wgpu_att->image->cmn.sample_count > 1) {\r\n                wgpu_color_att_desc[i].resolveTarget = wgpu_att->resolve_tex_view;\r\n            }\r\n        }\r\n        wgpu_pass_desc.colorAttachmentCount = pass->cmn.num_color_atts;\r\n        wgpu_pass_desc.colorAttachments = &wgpu_color_att_desc[0];\r\n        if (pass->wgpu.ds_att.image) {\r\n            WGPURenderPassDepthStencilAttachmentDescriptor wgpu_ds_att_desc;\r\n            memset(&wgpu_ds_att_desc, 0, sizeof(wgpu_ds_att_desc));\r\n            wgpu_ds_att_desc.depthLoadOp = _sg_wgpu_load_op(action->depth.action);\r\n            wgpu_ds_att_desc.clearDepth = action->depth.val;\r\n            wgpu_ds_att_desc.stencilLoadOp = _sg_wgpu_load_op(action->stencil.action);\r\n            wgpu_ds_att_desc.clearStencil = action->stencil.val;\r\n            wgpu_ds_att_desc.attachment = pass->wgpu.ds_att.render_tex_view;\r\n            wgpu_pass_desc.depthStencilAttachment = &wgpu_ds_att_desc;\r\n            _sg.wgpu.pass_enc = wgpuCommandEncoderBeginRenderPass(_sg.wgpu.render_cmd_enc, &wgpu_pass_desc);\r\n        }\r\n    }\r\n    else {\r\n        /* default render pass */\r\n        WGPUTextureView wgpu_render_view = _sg.wgpu.render_view_cb ? _sg.wgpu.render_view_cb() : _sg.wgpu.render_view_userdata_cb(_sg.wgpu.user_data);\r\n        WGPUTextureView wgpu_resolve_view = _sg.wgpu.resolve_view_cb ? _sg.wgpu.resolve_view_cb() : _sg.wgpu.resolve_view_userdata_cb(_sg.wgpu.user_data);\r\n        WGPUTextureView wgpu_depth_stencil_view = _sg.wgpu.depth_stencil_view_cb ? _sg.wgpu.depth_stencil_view_cb() : _sg.wgpu.depth_stencil_view_userdata_cb(_sg.wgpu.user_data);\r\n\r\n        WGPURenderPassDescriptor pass_desc;\r\n        memset(&pass_desc, 0, sizeof(pass_desc));\r\n        WGPURenderPassColorAttachmentDescriptor color_att_desc;\r\n        memset(&color_att_desc, 0, sizeof(color_att_desc));\r\n        color_att_desc.loadOp = _sg_wgpu_load_op(action->colors[0].action);\r\n        color_att_desc.clearColor.r = action->colors[0].val[0];\r\n        color_att_desc.clearColor.g = action->colors[0].val[1];\r\n        color_att_desc.clearColor.b = action->colors[0].val[2];\r\n        color_att_desc.clearColor.a = action->colors[0].val[3];\r\n        color_att_desc.attachment = wgpu_render_view;\r\n        color_att_desc.resolveTarget = wgpu_resolve_view;   /* null if no MSAA rendering */\r\n        pass_desc.colorAttachmentCount = 1;\r\n        pass_desc.colorAttachments = &color_att_desc;\r\n        WGPURenderPassDepthStencilAttachmentDescriptor ds_att_desc;\r\n        memset(&ds_att_desc, 0, sizeof(ds_att_desc));\r\n        ds_att_desc.attachment = wgpu_depth_stencil_view;\r\n        SOKOL_ASSERT(0 != ds_att_desc.attachment);\r\n        ds_att_desc.depthLoadOp = _sg_wgpu_load_op(action->depth.action);\r\n        ds_att_desc.clearDepth = action->depth.val;\r\n        ds_att_desc.stencilLoadOp = _sg_wgpu_load_op(action->stencil.action);\r\n        ds_att_desc.clearStencil = action->stencil.val;\r\n        pass_desc.depthStencilAttachment = &ds_att_desc;\r\n        _sg.wgpu.pass_enc = wgpuCommandEncoderBeginRenderPass(_sg.wgpu.render_cmd_enc, &pass_desc);\r\n    }\r\n    SOKOL_ASSERT(_sg.wgpu.pass_enc);\r\n\r\n    /* initial uniform buffer binding (required even if no uniforms are set in the frame) */\r\n    wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.pass_enc,\r\n                                      0, /* groupIndex 0 is reserved for uniform buffers */\r\n                                      _sg.wgpu.ub.bindgroup,\r\n                                      SG_NUM_SHADER_STAGES * SG_MAX_SHADERSTAGE_UBS,\r\n                                      &_sg.wgpu.ub.bind_offsets[0][0]);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_end_pass(void) {\r\n    SOKOL_ASSERT(_sg.wgpu.in_pass);\r\n    SOKOL_ASSERT(_sg.wgpu.pass_enc);\r\n    _sg.wgpu.in_pass = false;\r\n    wgpuRenderPassEncoderEndPass(_sg.wgpu.pass_enc);\r\n    wgpuRenderPassEncoderRelease(_sg.wgpu.pass_enc);\r\n    _sg.wgpu.pass_enc = 0;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_commit(void) {\r\n    SOKOL_ASSERT(!_sg.wgpu.in_pass);\r\n    SOKOL_ASSERT(_sg.wgpu.queue);\r\n    SOKOL_ASSERT(_sg.wgpu.render_cmd_enc);\r\n    SOKOL_ASSERT(_sg.wgpu.staging_cmd_enc);\r\n\r\n    /* finish and submit this frame's work */\r\n    _sg_wgpu_ubpool_flush();\r\n    _sg_wgpu_staging_unmap();\r\n\r\n    WGPUCommandBuffer cmd_bufs[2];\r\n\r\n    WGPUCommandBufferDescriptor cmd_buf_desc;\r\n    memset(&cmd_buf_desc, 0, sizeof(cmd_buf_desc));\r\n    cmd_bufs[0] = wgpuCommandEncoderFinish(_sg.wgpu.staging_cmd_enc, &cmd_buf_desc);\r\n    SOKOL_ASSERT(cmd_bufs[0]);\r\n    wgpuCommandEncoderRelease(_sg.wgpu.staging_cmd_enc);\r\n    _sg.wgpu.staging_cmd_enc = 0;\r\n\r\n    cmd_bufs[1] = wgpuCommandEncoderFinish(_sg.wgpu.render_cmd_enc, &cmd_buf_desc);\r\n    SOKOL_ASSERT(cmd_bufs[1]);\r\n    wgpuCommandEncoderRelease(_sg.wgpu.render_cmd_enc);\r\n    _sg.wgpu.render_cmd_enc = 0;\r\n\r\n    wgpuQueueSubmit(_sg.wgpu.queue, 2, &cmd_bufs[0]);\r\n\r\n    wgpuCommandBufferRelease(cmd_bufs[0]);\r\n    wgpuCommandBufferRelease(cmd_bufs[1]);\r\n\r\n    /* create a new render- and staging-command-encoders for next frame */\r\n    WGPUCommandEncoderDescriptor cmd_enc_desc;\r\n    memset(&cmd_enc_desc, 0, sizeof(cmd_enc_desc));\r\n    _sg.wgpu.staging_cmd_enc = wgpuDeviceCreateCommandEncoder(_sg.wgpu.dev, &cmd_enc_desc);\r\n    _sg.wgpu.render_cmd_enc = wgpuDeviceCreateCommandEncoder(_sg.wgpu.dev, &cmd_enc_desc);\r\n\r\n    /* grab new staging buffers for uniform- and vertex/image-updates */\r\n    _sg_wgpu_ubpool_next_frame(false);\r\n    _sg_wgpu_staging_next_frame(false);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {\r\n    SOKOL_ASSERT(_sg.wgpu.in_pass);\r\n    SOKOL_ASSERT(_sg.wgpu.pass_enc);\r\n    float xf = (float) x;\r\n    float yf = (float) (origin_top_left ? y : (_sg.wgpu.cur_height - (y + h)));\r\n    float wf = (float) w;\r\n    float hf = (float) h;\r\n    wgpuRenderPassEncoderSetViewport(_sg.wgpu.pass_enc, xf, yf, wf, hf, 0.0f, 1.0f);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {\r\n    SOKOL_ASSERT(_sg.wgpu.in_pass);\r\n    SOKOL_ASSERT(_sg.wgpu.pass_enc);\r\n    SOKOL_ASSERT(_sg.wgpu.in_pass);\r\n    SOKOL_ASSERT(_sg.wgpu.pass_enc);\r\n\r\n    /* clip against framebuffer rect */\r\n    x = _sg_min(_sg_max(0, x), _sg.wgpu.cur_width-1);\r\n    y = _sg_min(_sg_max(0, y), _sg.wgpu.cur_height-1);\r\n    if ((x + w) > _sg.wgpu.cur_width) {\r\n        w = _sg.wgpu.cur_width - x;\r\n    }\r\n    if ((y + h) > _sg.wgpu.cur_height) {\r\n        h = _sg.wgpu.cur_height - y;\r\n    }\r\n    w = _sg_max(w, 1);\r\n    h = _sg_max(h, 1);\r\n\r\n    uint32_t sx = (uint32_t) x;\r\n    uint32_t sy = origin_top_left ? y : (_sg.wgpu.cur_height - (y + h));\r\n    uint32_t sw = w;\r\n    uint32_t sh = h;\r\n    wgpuRenderPassEncoderSetScissorRect(_sg.wgpu.pass_enc, sx, sy, sw, sh);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_apply_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    SOKOL_ASSERT(pip->wgpu.pip);\r\n    SOKOL_ASSERT(_sg.wgpu.in_pass);\r\n    SOKOL_ASSERT(_sg.wgpu.pass_enc);\r\n    _sg.wgpu.draw_indexed = (pip->cmn.index_type != SG_INDEXTYPE_NONE);\r\n    _sg.wgpu.cur_pipeline = pip;\r\n    _sg.wgpu.cur_pipeline_id.id = pip->slot.id;\r\n    wgpuRenderPassEncoderSetPipeline(_sg.wgpu.pass_enc, pip->wgpu.pip);\r\n    wgpuRenderPassEncoderSetBlendColor(_sg.wgpu.pass_enc, (WGPUColor*)pip->cmn.blend_color);\r\n    wgpuRenderPassEncoderSetStencilReference(_sg.wgpu.pass_enc, pip->wgpu.stencil_ref);\r\n}\r\n\r\n_SOKOL_PRIVATE WGPUBindGroup _sg_wgpu_create_images_bindgroup(WGPUBindGroupLayout bgl, _sg_image_t** imgs, int num_imgs) {\r\n    SOKOL_ASSERT(_sg.wgpu.dev);\r\n    SOKOL_ASSERT(num_imgs <= _SG_WGPU_MAX_SHADERSTAGE_IMAGES);\r\n    WGPUBindGroupBinding img_bgb[_SG_WGPU_MAX_SHADERSTAGE_IMAGES * 2];\r\n    memset(&img_bgb, 0, sizeof(img_bgb));\r\n    for (int img_index = 0; img_index < num_imgs; img_index++) {\r\n        WGPUBindGroupBinding* tex_bdg = &img_bgb[img_index*2 + 0];\r\n        WGPUBindGroupBinding* smp_bdg = &img_bgb[img_index*2 + 1];\r\n        tex_bdg->binding = img_index;\r\n        tex_bdg->textureView = imgs[img_index]->wgpu.tex_view;\r\n        smp_bdg->binding = img_index + _SG_WGPU_MAX_SHADERSTAGE_IMAGES;\r\n        smp_bdg->sampler = imgs[img_index]->wgpu.sampler;\r\n    }\r\n    WGPUBindGroupDescriptor bg_desc;\r\n    memset(&bg_desc, 0, sizeof(bg_desc));\r\n    bg_desc.layout = bgl;\r\n    bg_desc.bindingCount = 2 * num_imgs;\r\n    bg_desc.bindings = &img_bgb[0];\r\n    WGPUBindGroup bg = wgpuDeviceCreateBindGroup(_sg.wgpu.dev, &bg_desc);\r\n    SOKOL_ASSERT(bg);\r\n    return bg;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_apply_bindings(\r\n    _sg_pipeline_t* pip,\r\n    _sg_buffer_t** vbs, const int* vb_offsets, int num_vbs,\r\n    _sg_buffer_t* ib, int ib_offset,\r\n    _sg_image_t** vs_imgs, int num_vs_imgs,\r\n    _sg_image_t** fs_imgs, int num_fs_imgs)\r\n{\r\n    SOKOL_ASSERT(_sg.wgpu.in_pass);\r\n    SOKOL_ASSERT(_sg.wgpu.pass_enc);\r\n    SOKOL_ASSERT(pip->shader && (pip->cmn.shader_id.id == pip->shader->slot.id));\r\n\r\n    /* index buffer */\r\n    if (ib) {\r\n        wgpuRenderPassEncoderSetIndexBuffer(_sg.wgpu.pass_enc, ib->wgpu.buf, ib_offset);\r\n    }\r\n\r\n    /* vertex buffers */\r\n    for (uint32_t slot = 0; slot < (uint32_t)num_vbs; slot++) {\r\n        wgpuRenderPassEncoderSetVertexBuffer(_sg.wgpu.pass_enc, slot, vbs[slot]->wgpu.buf, (uint64_t)vb_offsets[slot]);\r\n    }\r\n\r\n    /* need to create throw-away bind groups for images */\r\n    if (num_vs_imgs > 0) {\r\n        if (num_vs_imgs > _SG_WGPU_MAX_SHADERSTAGE_IMAGES) {\r\n            num_vs_imgs = _SG_WGPU_MAX_SHADERSTAGE_IMAGES;\r\n        }\r\n        WGPUBindGroupLayout vs_bgl = pip->shader->wgpu.stage[SG_SHADERSTAGE_VS].bind_group_layout;\r\n        SOKOL_ASSERT(vs_bgl);\r\n        WGPUBindGroup vs_img_bg = _sg_wgpu_create_images_bindgroup(vs_bgl, vs_imgs, num_vs_imgs);\r\n        wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.pass_enc, 1, vs_img_bg, 0, 0);\r\n        wgpuBindGroupRelease(vs_img_bg);\r\n    }\r\n    else {\r\n        wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.pass_enc, 1, _sg.wgpu.empty_bind_group, 0, 0);\r\n    }\r\n    if (num_fs_imgs > 0) {\r\n        if (num_fs_imgs > _SG_WGPU_MAX_SHADERSTAGE_IMAGES) {\r\n            num_fs_imgs = _SG_WGPU_MAX_SHADERSTAGE_IMAGES;\r\n        }\r\n        WGPUBindGroupLayout fs_bgl = pip->shader->wgpu.stage[SG_SHADERSTAGE_FS].bind_group_layout;\r\n        SOKOL_ASSERT(fs_bgl);\r\n        WGPUBindGroup fs_img_bg = _sg_wgpu_create_images_bindgroup(fs_bgl, fs_imgs, num_fs_imgs);\r\n        wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.pass_enc, 2, fs_img_bg, 0, 0);\r\n        wgpuBindGroupRelease(fs_img_bg);\r\n    }\r\n    else {\r\n        wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.pass_enc, 2, _sg.wgpu.empty_bind_group, 0, 0);\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_apply_uniforms(sg_shader_stage stage_index, int ub_index, const void* data, int num_bytes) {\r\n    SOKOL_ASSERT(_sg.wgpu.in_pass);\r\n    SOKOL_ASSERT(_sg.wgpu.pass_enc);\r\n    SOKOL_ASSERT(data && (num_bytes > 0));\r\n    SOKOL_ASSERT((stage_index >= 0) && ((int)stage_index < SG_NUM_SHADER_STAGES));\r\n    SOKOL_ASSERT((ub_index >= 0) && (ub_index < SG_MAX_SHADERSTAGE_UBS));\r\n    SOKOL_ASSERT((_sg.wgpu.ub.offset + num_bytes) <= _sg.wgpu.ub.num_bytes);\r\n    SOKOL_ASSERT((_sg.wgpu.ub.offset & (_SG_WGPU_STAGING_ALIGN-1)) == 0);\r\n    SOKOL_ASSERT(_sg.wgpu.cur_pipeline && _sg.wgpu.cur_pipeline->shader);\r\n    SOKOL_ASSERT(_sg.wgpu.cur_pipeline->slot.id == _sg.wgpu.cur_pipeline_id.id);\r\n    SOKOL_ASSERT(_sg.wgpu.cur_pipeline->shader->slot.id == _sg.wgpu.cur_pipeline->cmn.shader_id.id);\r\n    SOKOL_ASSERT(ub_index < _sg.wgpu.cur_pipeline->shader->cmn.stage[stage_index].num_uniform_blocks);\r\n    SOKOL_ASSERT(num_bytes <= _sg.wgpu.cur_pipeline->shader->cmn.stage[stage_index].uniform_blocks[ub_index].size);\r\n    SOKOL_ASSERT(num_bytes <= _SG_WGPU_MAX_UNIFORM_UPDATE_SIZE);\r\n    SOKOL_ASSERT(0 != _sg.wgpu.ub.stage.ptr[_sg.wgpu.ub.stage.cur]);\r\n\r\n    uint8_t* dst_ptr = _sg.wgpu.ub.stage.ptr[_sg.wgpu.ub.stage.cur] + _sg.wgpu.ub.offset;\r\n    memcpy(dst_ptr, data, num_bytes);\r\n    _sg.wgpu.ub.bind_offsets[stage_index][ub_index] = _sg.wgpu.ub.offset;\r\n    wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.pass_enc,\r\n                                      0, /* groupIndex 0 is reserved for uniform buffers */\r\n                                      _sg.wgpu.ub.bindgroup,\r\n                                      SG_NUM_SHADER_STAGES * SG_MAX_SHADERSTAGE_UBS,\r\n                                      &_sg.wgpu.ub.bind_offsets[0][0]);\r\n    _sg.wgpu.ub.offset = _sg_roundup(_sg.wgpu.ub.offset + num_bytes, _SG_WGPU_STAGING_ALIGN);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_draw(int base_element, int num_elements, int num_instances) {\r\n    SOKOL_ASSERT(_sg.wgpu.in_pass);\r\n    SOKOL_ASSERT(_sg.wgpu.pass_enc);\r\n    if (_sg.wgpu.draw_indexed) {\r\n        wgpuRenderPassEncoderDrawIndexed(_sg.wgpu.pass_enc, num_elements, num_instances, base_element, 0, 0);\r\n    }\r\n    else {\r\n        wgpuRenderPassEncoderDraw(_sg.wgpu.pass_enc, num_elements, num_instances, base_element, 0);\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_update_buffer(_sg_buffer_t* buf, const void* data, uint32_t num_bytes) {\r\n    SOKOL_ASSERT(buf && data && (num_bytes > 0));\r\n    uint32_t copied_num_bytes = _sg_wgpu_staging_copy_to_buffer(buf->wgpu.buf, 0, data, (uint32_t)num_bytes);\r\n    SOKOL_ASSERT(copied_num_bytes > 0); _SOKOL_UNUSED(copied_num_bytes);\r\n}\r\n\r\n_SOKOL_PRIVATE uint32_t _sg_wgpu_append_buffer(_sg_buffer_t* buf, const void* data, uint32_t num_bytes, bool new_frame) {\r\n    SOKOL_ASSERT(buf && data && (num_bytes > 0));\r\n    _SOKOL_UNUSED(new_frame);\r\n    uint32_t copied_num_bytes = _sg_wgpu_staging_copy_to_buffer(buf->wgpu.buf, buf->cmn.append_pos, data, num_bytes);\r\n    SOKOL_ASSERT(copied_num_bytes > 0); _SOKOL_UNUSED(copied_num_bytes);\r\n    return copied_num_bytes;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_wgpu_update_image(_sg_image_t* img, const sg_image_content* data) {\r\n    SOKOL_ASSERT(img && data);\r\n    bool success = _sg_wgpu_staging_copy_to_texture(img, data);\r\n    SOKOL_ASSERT(success);\r\n    _SOKOL_UNUSED(success);\r\n}\r\n#endif\r\n\r\n/*== BACKEND API WRAPPERS ====================================================*/\r\nstatic inline void _sg_setup_backend(const sg_desc* desc) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_setup_backend(desc);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_setup_backend(desc);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_setup_backend(desc);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_setup_backend(desc);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_setup_backend(desc);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_discard_backend(void) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_discard_backend();\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_discard_backend();\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_discard_backend();\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_discard_backend();\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_discard_backend();\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_reset_state_cache(void) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_reset_state_cache();\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_reset_state_cache();\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_reset_state_cache();\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_reset_state_cache();\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_reset_state_cache();\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_activate_context(_sg_context_t* ctx) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_activate_context(ctx);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_activate_context(ctx);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_activate_context(ctx);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_activate_context(ctx);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_activate_context(ctx);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline sg_resource_state _sg_create_context(_sg_context_t* ctx) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    return _sg_gl_create_context(ctx);\r\n    #elif defined(SOKOL_METAL)\r\n    return _sg_mtl_create_context(ctx);\r\n    #elif defined(SOKOL_D3D11)\r\n    return _sg_d3d11_create_context(ctx);\r\n    #elif defined(SOKOL_WGPU)\r\n    return _sg_wgpu_create_context(ctx);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    return _sg_dummy_create_context(ctx);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_destroy_context(_sg_context_t* ctx) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_destroy_context(ctx);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_destroy_context(ctx);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_destroy_context(ctx);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_destroy_context(ctx);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_destroy_context(ctx);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline sg_resource_state _sg_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    return _sg_gl_create_buffer(buf, desc);\r\n    #elif defined(SOKOL_METAL)\r\n    return _sg_mtl_create_buffer(buf, desc);\r\n    #elif defined(SOKOL_D3D11)\r\n    return _sg_d3d11_create_buffer(buf, desc);\r\n    #elif defined(SOKOL_WGPU)\r\n    return _sg_wgpu_create_buffer(buf, desc);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    return _sg_dummy_create_buffer(buf, desc);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_destroy_buffer(_sg_buffer_t* buf) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_destroy_buffer(buf);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_destroy_buffer(buf);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_destroy_buffer(buf);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_destroy_buffer(buf);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_destroy_buffer(buf);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline sg_resource_state _sg_create_image(_sg_image_t* img, const sg_image_desc* desc) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    return _sg_gl_create_image(img, desc);\r\n    #elif defined(SOKOL_METAL)\r\n    return _sg_mtl_create_image(img, desc);\r\n    #elif defined(SOKOL_D3D11)\r\n    return _sg_d3d11_create_image(img, desc);\r\n    #elif defined(SOKOL_WGPU)\r\n    return _sg_wgpu_create_image(img, desc);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    return _sg_dummy_create_image(img, desc);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_destroy_image(_sg_image_t* img) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_destroy_image(img);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_destroy_image(img);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_destroy_image(img);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_destroy_image(img);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_destroy_image(img);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline sg_resource_state _sg_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    return _sg_gl_create_shader(shd, desc);\r\n    #elif defined(SOKOL_METAL)\r\n    return _sg_mtl_create_shader(shd, desc);\r\n    #elif defined(SOKOL_D3D11)\r\n    return _sg_d3d11_create_shader(shd, desc);\r\n    #elif defined(SOKOL_WGPU)\r\n    return _sg_wgpu_create_shader(shd, desc);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    return _sg_dummy_create_shader(shd, desc);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_destroy_shader(_sg_shader_t* shd) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_destroy_shader(shd);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_destroy_shader(shd);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_destroy_shader(shd);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_destroy_shader(shd);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_destroy_shader(shd);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline sg_resource_state _sg_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    return _sg_gl_create_pipeline(pip, shd, desc);\r\n    #elif defined(SOKOL_METAL)\r\n    return _sg_mtl_create_pipeline(pip, shd, desc);\r\n    #elif defined(SOKOL_D3D11)\r\n    return _sg_d3d11_create_pipeline(pip, shd, desc);\r\n    #elif defined(SOKOL_WGPU)\r\n    return _sg_wgpu_create_pipeline(pip, shd, desc);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    return _sg_dummy_create_pipeline(pip, shd, desc);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_destroy_pipeline(_sg_pipeline_t* pip) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_destroy_pipeline(pip);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_destroy_pipeline(pip);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_destroy_pipeline(pip);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_destroy_pipeline(pip);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_destroy_pipeline(pip);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline sg_resource_state _sg_create_pass(_sg_pass_t* pass, _sg_image_t** att_images, const sg_pass_desc* desc) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    return _sg_gl_create_pass(pass, att_images, desc);\r\n    #elif defined(SOKOL_METAL)\r\n    return _sg_mtl_create_pass(pass, att_images, desc);\r\n    #elif defined(SOKOL_D3D11)\r\n    return _sg_d3d11_create_pass(pass, att_images, desc);\r\n    #elif defined(SOKOL_WGPU)\r\n    return _sg_wgpu_create_pass(pass, att_images, desc);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    return _sg_dummy_create_pass(pass, att_images, desc);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_destroy_pass(_sg_pass_t* pass) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_destroy_pass(pass);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_destroy_pass(pass);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_destroy_pass(pass);\r\n    #elif defined(SOKOL_WGPU)\r\n    return _sg_wgpu_destroy_pass(pass);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_destroy_pass(pass);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline _sg_image_t* _sg_pass_color_image(const _sg_pass_t* pass, int index) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    return _sg_gl_pass_color_image(pass, index);\r\n    #elif defined(SOKOL_METAL)\r\n    return _sg_mtl_pass_color_image(pass, index);\r\n    #elif defined(SOKOL_D3D11)\r\n    return _sg_d3d11_pass_color_image(pass, index);\r\n    #elif defined(SOKOL_WGPU)\r\n    return _sg_wgpu_pass_color_image(pass, index);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    return _sg_dummy_pass_color_image(pass, index);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline _sg_image_t* _sg_pass_ds_image(const _sg_pass_t* pass) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    return _sg_gl_pass_ds_image(pass);\r\n    #elif defined(SOKOL_METAL)\r\n    return _sg_mtl_pass_ds_image(pass);\r\n    #elif defined(SOKOL_D3D11)\r\n    return _sg_d3d11_pass_ds_image(pass);\r\n    #elif defined(SOKOL_WGPU)\r\n    return _sg_wgpu_pass_ds_image(pass);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    return _sg_dummy_pass_ds_image(pass);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_begin_pass(_sg_pass_t* pass, const sg_pass_action* action, int w, int h) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_begin_pass(pass, action, w, h);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_begin_pass(pass, action, w, h);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_begin_pass(pass, action, w, h);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_begin_pass(pass, action, w, h);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_begin_pass(pass, action, w, h);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_end_pass(void) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_end_pass();\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_end_pass();\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_end_pass();\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_end_pass();\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_end_pass();\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_apply_viewport(x, y, w, h, origin_top_left);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_apply_viewport(x, y, w, h, origin_top_left);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_apply_viewport(x, y, w, h, origin_top_left);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_apply_viewport(x, y, w, h, origin_top_left);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_apply_viewport(x, y, w, h, origin_top_left);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_apply_scissor_rect(x, y, w, h, origin_top_left);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_apply_scissor_rect(x, y, w, h, origin_top_left);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_apply_scissor_rect(x, y, w, h, origin_top_left);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_apply_scissor_rect(x, y, w, h, origin_top_left);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_apply_scissor_rect(x, y, w, h, origin_top_left);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_apply_pipeline(_sg_pipeline_t* pip) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_apply_pipeline(pip);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_apply_pipeline(pip);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_apply_pipeline(pip);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_apply_pipeline(pip);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_apply_pipeline(pip);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_apply_bindings(\r\n    _sg_pipeline_t* pip,\r\n    _sg_buffer_t** vbs, const int* vb_offsets, int num_vbs,\r\n    _sg_buffer_t* ib, int ib_offset,\r\n    _sg_image_t** vs_imgs, int num_vs_imgs,\r\n    _sg_image_t** fs_imgs, int num_fs_imgs)\r\n{\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_apply_bindings(pip, vbs, vb_offsets, num_vbs, ib, ib_offset, vs_imgs, num_vs_imgs, fs_imgs, num_fs_imgs);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_apply_bindings(pip, vbs, vb_offsets, num_vbs, ib, ib_offset, vs_imgs, num_vs_imgs, fs_imgs, num_fs_imgs);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_apply_bindings(pip, vbs, vb_offsets, num_vbs, ib, ib_offset, vs_imgs, num_vs_imgs, fs_imgs, num_fs_imgs);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_apply_bindings(pip, vbs, vb_offsets, num_vbs, ib, ib_offset, vs_imgs, num_vs_imgs, fs_imgs, num_fs_imgs);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_apply_bindings(pip, vbs, vb_offsets, num_vbs, ib, ib_offset, vs_imgs, num_vs_imgs, fs_imgs, num_fs_imgs);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_apply_uniforms(sg_shader_stage stage_index, int ub_index, const void* data, int num_bytes) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_apply_uniforms(stage_index, ub_index, data, num_bytes);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_apply_uniforms(stage_index, ub_index, data, num_bytes);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_apply_uniforms(stage_index, ub_index, data, num_bytes);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_apply_uniforms(stage_index, ub_index, data, num_bytes);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_apply_uniforms(stage_index, ub_index, data, num_bytes);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_draw(int base_element, int num_elements, int num_instances) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_draw(base_element, num_elements, num_instances);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_draw(base_element, num_elements, num_instances);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_draw(base_element, num_elements, num_instances);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_draw(base_element, num_elements, num_instances);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_draw(base_element, num_elements, num_instances);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_commit(void) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_commit();\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_commit();\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_commit();\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_commit();\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_commit();\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_update_buffer(_sg_buffer_t* buf, const void* data_ptr, uint32_t data_size) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_update_buffer(buf, data_ptr, data_size);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_update_buffer(buf, data_ptr, data_size);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_update_buffer(buf, data_ptr, data_size);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_update_buffer(buf, data_ptr, data_size);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_update_buffer(buf, data_ptr, data_size);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline uint32_t _sg_append_buffer(_sg_buffer_t* buf, const void* data_ptr, uint32_t data_size, bool new_frame) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    return _sg_gl_append_buffer(buf, data_ptr, data_size, new_frame);\r\n    #elif defined(SOKOL_METAL)\r\n    return _sg_mtl_append_buffer(buf, data_ptr, data_size, new_frame);\r\n    #elif defined(SOKOL_D3D11)\r\n    return _sg_d3d11_append_buffer(buf, data_ptr, data_size, new_frame);\r\n    #elif defined(SOKOL_WGPU)\r\n    return _sg_wgpu_append_buffer(buf, data_ptr, data_size, new_frame);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    return _sg_dummy_append_buffer(buf, data_ptr, data_size, new_frame);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\nstatic inline void _sg_update_image(_sg_image_t* img, const sg_image_content* data) {\r\n    #if defined(_SOKOL_ANY_GL)\r\n    _sg_gl_update_image(img, data);\r\n    #elif defined(SOKOL_METAL)\r\n    _sg_mtl_update_image(img, data);\r\n    #elif defined(SOKOL_D3D11)\r\n    _sg_d3d11_update_image(img, data);\r\n    #elif defined(SOKOL_WGPU)\r\n    _sg_wgpu_update_image(img, data);\r\n    #elif defined(SOKOL_DUMMY_BACKEND)\r\n    _sg_dummy_update_image(img, data);\r\n    #else\r\n    #error(\"INVALID BACKEND\");\r\n    #endif\r\n}\r\n\r\n/*== RESOURCE POOLS ==========================================================*/\r\n\r\n_SOKOL_PRIVATE void _sg_init_pool(_sg_pool_t* pool, int num) {\r\n    SOKOL_ASSERT(pool && (num >= 1));\r\n    /* slot 0 is reserved for the 'invalid id', so bump the pool size by 1 */\r\n    pool->size = num + 1;\r\n    pool->queue_top = 0;\r\n    /* generation counters indexable by pool slot index, slot 0 is reserved */\r\n    size_t gen_ctrs_size = sizeof(uint32_t) * pool->size;\r\n    pool->gen_ctrs = (uint32_t*) SOKOL_MALLOC(gen_ctrs_size);\r\n    SOKOL_ASSERT(pool->gen_ctrs);\r\n    memset(pool->gen_ctrs, 0, gen_ctrs_size);\r\n    /* it's not a bug to only reserve 'num' here */\r\n    pool->free_queue = (int*) SOKOL_MALLOC(sizeof(int)*num);\r\n    SOKOL_ASSERT(pool->free_queue);\r\n    /* never allocate the zero-th pool item since the invalid id is 0 */\r\n    for (int i = pool->size-1; i >= 1; i--) {\r\n        pool->free_queue[pool->queue_top++] = i;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_discard_pool(_sg_pool_t* pool) {\r\n    SOKOL_ASSERT(pool);\r\n    SOKOL_ASSERT(pool->free_queue);\r\n    SOKOL_FREE(pool->free_queue);\r\n    pool->free_queue = 0;\r\n    SOKOL_ASSERT(pool->gen_ctrs);\r\n    SOKOL_FREE(pool->gen_ctrs);\r\n    pool->gen_ctrs = 0;\r\n    pool->size = 0;\r\n    pool->queue_top = 0;\r\n}\r\n\r\n_SOKOL_PRIVATE int _sg_pool_alloc_index(_sg_pool_t* pool) {\r\n    SOKOL_ASSERT(pool);\r\n    SOKOL_ASSERT(pool->free_queue);\r\n    if (pool->queue_top > 0) {\r\n        int slot_index = pool->free_queue[--pool->queue_top];\r\n        SOKOL_ASSERT((slot_index > 0) && (slot_index < pool->size));\r\n        return slot_index;\r\n    }\r\n    else {\r\n        /* pool exhausted */\r\n        return _SG_INVALID_SLOT_INDEX;\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_pool_free_index(_sg_pool_t* pool, int slot_index) {\r\n    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < pool->size));\r\n    SOKOL_ASSERT(pool);\r\n    SOKOL_ASSERT(pool->free_queue);\r\n    SOKOL_ASSERT(pool->queue_top < pool->size);\r\n    #ifdef SOKOL_DEBUG\r\n    /* debug check against double-free */\r\n    for (int i = 0; i < pool->queue_top; i++) {\r\n        SOKOL_ASSERT(pool->free_queue[i] != slot_index);\r\n    }\r\n    #endif\r\n    pool->free_queue[pool->queue_top++] = slot_index;\r\n    SOKOL_ASSERT(pool->queue_top <= (pool->size-1));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_reset_buffer(_sg_buffer_t* buf) {\r\n    SOKOL_ASSERT(buf);\r\n    memset(buf, 0, sizeof(_sg_buffer_t));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_reset_image(_sg_image_t* img) {\r\n    SOKOL_ASSERT(img);\r\n    memset(img, 0, sizeof(_sg_image_t));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_reset_shader(_sg_shader_t* shd) {\r\n    SOKOL_ASSERT(shd);\r\n    memset(shd, 0, sizeof(_sg_shader_t));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_reset_pipeline(_sg_pipeline_t* pip) {\r\n    SOKOL_ASSERT(pip);\r\n    memset(pip, 0, sizeof(_sg_pipeline_t));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_reset_pass(_sg_pass_t* pass) {\r\n    SOKOL_ASSERT(pass);\r\n    memset(pass, 0, sizeof(_sg_pass_t));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_reset_context(_sg_context_t* ctx) {\r\n    SOKOL_ASSERT(ctx);\r\n    memset(ctx, 0, sizeof(_sg_context_t));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_setup_pools(_sg_pools_t* p, const sg_desc* desc) {\r\n    SOKOL_ASSERT(p);\r\n    SOKOL_ASSERT(desc);\r\n    /* note: the pools here will have an additional item, since slot 0 is reserved */\r\n    SOKOL_ASSERT((desc->buffer_pool_size > 0) && (desc->buffer_pool_size < _SG_MAX_POOL_SIZE));\r\n    _sg_init_pool(&p->buffer_pool, desc->buffer_pool_size);\r\n    size_t buffer_pool_byte_size = sizeof(_sg_buffer_t) * p->buffer_pool.size;\r\n    p->buffers = (_sg_buffer_t*) SOKOL_MALLOC(buffer_pool_byte_size);\r\n    SOKOL_ASSERT(p->buffers);\r\n    memset(p->buffers, 0, buffer_pool_byte_size);\r\n\r\n    SOKOL_ASSERT((desc->image_pool_size > 0) && (desc->image_pool_size < _SG_MAX_POOL_SIZE));\r\n    _sg_init_pool(&p->image_pool, desc->image_pool_size);\r\n    size_t image_pool_byte_size = sizeof(_sg_image_t) * p->image_pool.size;\r\n    p->images = (_sg_image_t*) SOKOL_MALLOC(image_pool_byte_size);\r\n    SOKOL_ASSERT(p->images);\r\n    memset(p->images, 0, image_pool_byte_size);\r\n\r\n    SOKOL_ASSERT((desc->shader_pool_size > 0) && (desc->shader_pool_size < _SG_MAX_POOL_SIZE));\r\n    _sg_init_pool(&p->shader_pool, desc->shader_pool_size);\r\n    size_t shader_pool_byte_size = sizeof(_sg_shader_t) * p->shader_pool.size;\r\n    p->shaders = (_sg_shader_t*) SOKOL_MALLOC(shader_pool_byte_size);\r\n    SOKOL_ASSERT(p->shaders);\r\n    memset(p->shaders, 0, shader_pool_byte_size);\r\n\r\n    SOKOL_ASSERT((desc->pipeline_pool_size > 0) && (desc->pipeline_pool_size < _SG_MAX_POOL_SIZE));\r\n    _sg_init_pool(&p->pipeline_pool, desc->pipeline_pool_size);\r\n    size_t pipeline_pool_byte_size = sizeof(_sg_pipeline_t) * p->pipeline_pool.size;\r\n    p->pipelines = (_sg_pipeline_t*) SOKOL_MALLOC(pipeline_pool_byte_size);\r\n    SOKOL_ASSERT(p->pipelines);\r\n    memset(p->pipelines, 0, pipeline_pool_byte_size);\r\n\r\n    SOKOL_ASSERT((desc->pass_pool_size > 0) && (desc->pass_pool_size < _SG_MAX_POOL_SIZE));\r\n    _sg_init_pool(&p->pass_pool, desc->pass_pool_size);\r\n    size_t pass_pool_byte_size = sizeof(_sg_pass_t) * p->pass_pool.size;\r\n    p->passes = (_sg_pass_t*) SOKOL_MALLOC(pass_pool_byte_size);\r\n    SOKOL_ASSERT(p->passes);\r\n    memset(p->passes, 0, pass_pool_byte_size);\r\n\r\n    SOKOL_ASSERT((desc->context_pool_size > 0) && (desc->context_pool_size < _SG_MAX_POOL_SIZE));\r\n    _sg_init_pool(&p->context_pool, desc->context_pool_size);\r\n    size_t context_pool_byte_size = sizeof(_sg_context_t) * p->context_pool.size;\r\n    p->contexts = (_sg_context_t*) SOKOL_MALLOC(context_pool_byte_size);\r\n    SOKOL_ASSERT(p->contexts);\r\n    memset(p->contexts, 0, context_pool_byte_size);\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_discard_pools(_sg_pools_t* p) {\r\n    SOKOL_ASSERT(p);\r\n    SOKOL_FREE(p->contexts);    p->contexts = 0;\r\n    SOKOL_FREE(p->passes);      p->passes = 0;\r\n    SOKOL_FREE(p->pipelines);   p->pipelines = 0;\r\n    SOKOL_FREE(p->shaders);     p->shaders = 0;\r\n    SOKOL_FREE(p->images);      p->images = 0;\r\n    SOKOL_FREE(p->buffers);     p->buffers = 0;\r\n    _sg_discard_pool(&p->context_pool);\r\n    _sg_discard_pool(&p->pass_pool);\r\n    _sg_discard_pool(&p->pipeline_pool);\r\n    _sg_discard_pool(&p->shader_pool);\r\n    _sg_discard_pool(&p->image_pool);\r\n    _sg_discard_pool(&p->buffer_pool);\r\n}\r\n\r\n/* allocate the slot at slot_index:\r\n    - bump the slot's generation counter\r\n    - create a resource id from the generation counter and slot index\r\n    - set the slot's id to this id\r\n    - set the slot's state to ALLOC\r\n    - return the resource id\r\n*/\r\n_SOKOL_PRIVATE uint32_t _sg_slot_alloc(_sg_pool_t* pool, _sg_slot_t* slot, int slot_index) {\r\n    /* FIXME: add handling for an overflowing generation counter,\r\n       for now, just overflow (another option is to disable\r\n       the slot)\r\n    */\r\n    SOKOL_ASSERT(pool && pool->gen_ctrs);\r\n    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < pool->size));\r\n    SOKOL_ASSERT((slot->state == SG_RESOURCESTATE_INITIAL) && (slot->id == SG_INVALID_ID));\r\n    uint32_t ctr = ++pool->gen_ctrs[slot_index];\r\n    slot->id = (ctr<<_SG_SLOT_SHIFT)|(slot_index & _SG_SLOT_MASK);\r\n    slot->state = SG_RESOURCESTATE_ALLOC;\r\n    return slot->id;\r\n}\r\n\r\n/* extract slot index from id */\r\n_SOKOL_PRIVATE int _sg_slot_index(uint32_t id) {\r\n    int slot_index = (int) (id & _SG_SLOT_MASK);\r\n    SOKOL_ASSERT(_SG_INVALID_SLOT_INDEX != slot_index);\r\n    return slot_index;\r\n}\r\n\r\n/* returns pointer to resource by id without matching id check */\r\n_SOKOL_PRIVATE _sg_buffer_t* _sg_buffer_at(const _sg_pools_t* p, uint32_t buf_id) {\r\n    SOKOL_ASSERT(p && (SG_INVALID_ID != buf_id));\r\n    int slot_index = _sg_slot_index(buf_id);\r\n    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->buffer_pool.size));\r\n    return &p->buffers[slot_index];\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_image_at(const _sg_pools_t* p, uint32_t img_id) {\r\n    SOKOL_ASSERT(p && (SG_INVALID_ID != img_id));\r\n    int slot_index = _sg_slot_index(img_id);\r\n    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->image_pool.size));\r\n    return &p->images[slot_index];\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_shader_t* _sg_shader_at(const _sg_pools_t* p, uint32_t shd_id) {\r\n    SOKOL_ASSERT(p && (SG_INVALID_ID != shd_id));\r\n    int slot_index = _sg_slot_index(shd_id);\r\n    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->shader_pool.size));\r\n    return &p->shaders[slot_index];\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_pipeline_t* _sg_pipeline_at(const _sg_pools_t* p, uint32_t pip_id) {\r\n    SOKOL_ASSERT(p && (SG_INVALID_ID != pip_id));\r\n    int slot_index = _sg_slot_index(pip_id);\r\n    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->pipeline_pool.size));\r\n    return &p->pipelines[slot_index];\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_pass_t* _sg_pass_at(const _sg_pools_t* p, uint32_t pass_id) {\r\n    SOKOL_ASSERT(p && (SG_INVALID_ID != pass_id));\r\n    int slot_index = _sg_slot_index(pass_id);\r\n    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->pass_pool.size));\r\n    return &p->passes[slot_index];\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_context_t* _sg_context_at(const _sg_pools_t* p, uint32_t context_id) {\r\n    SOKOL_ASSERT(p && (SG_INVALID_ID != context_id));\r\n    int slot_index = _sg_slot_index(context_id);\r\n    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->context_pool.size));\r\n    return &p->contexts[slot_index];\r\n}\r\n\r\n/* returns pointer to resource with matching id check, may return 0 */\r\n_SOKOL_PRIVATE _sg_buffer_t* _sg_lookup_buffer(const _sg_pools_t* p, uint32_t buf_id) {\r\n    if (SG_INVALID_ID != buf_id) {\r\n        _sg_buffer_t* buf = _sg_buffer_at(p, buf_id);\r\n        if (buf->slot.id == buf_id) {\r\n            return buf;\r\n        }\r\n    }\r\n    return 0;\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_image_t* _sg_lookup_image(const _sg_pools_t* p, uint32_t img_id) {\r\n    if (SG_INVALID_ID != img_id) {\r\n        _sg_image_t* img = _sg_image_at(p, img_id);\r\n        if (img->slot.id == img_id) {\r\n            return img;\r\n        }\r\n    }\r\n    return 0;\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_shader_t* _sg_lookup_shader(const _sg_pools_t* p, uint32_t shd_id) {\r\n    SOKOL_ASSERT(p);\r\n    if (SG_INVALID_ID != shd_id) {\r\n        _sg_shader_t* shd = _sg_shader_at(p, shd_id);\r\n        if (shd->slot.id == shd_id) {\r\n            return shd;\r\n        }\r\n    }\r\n    return 0;\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_pipeline_t* _sg_lookup_pipeline(const _sg_pools_t* p, uint32_t pip_id) {\r\n    SOKOL_ASSERT(p);\r\n    if (SG_INVALID_ID != pip_id) {\r\n        _sg_pipeline_t* pip = _sg_pipeline_at(p, pip_id);\r\n        if (pip->slot.id == pip_id) {\r\n            return pip;\r\n        }\r\n    }\r\n    return 0;\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_pass_t* _sg_lookup_pass(const _sg_pools_t* p, uint32_t pass_id) {\r\n    SOKOL_ASSERT(p);\r\n    if (SG_INVALID_ID != pass_id) {\r\n        _sg_pass_t* pass = _sg_pass_at(p, pass_id);\r\n        if (pass->slot.id == pass_id) {\r\n            return pass;\r\n        }\r\n    }\r\n    return 0;\r\n}\r\n\r\n_SOKOL_PRIVATE _sg_context_t* _sg_lookup_context(const _sg_pools_t* p, uint32_t ctx_id) {\r\n    SOKOL_ASSERT(p);\r\n    if (SG_INVALID_ID != ctx_id) {\r\n        _sg_context_t* ctx = _sg_context_at(p, ctx_id);\r\n        if (ctx->slot.id == ctx_id) {\r\n            return ctx;\r\n        }\r\n    }\r\n    return 0;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_destroy_all_resources(_sg_pools_t* p, uint32_t ctx_id) {\r\n    /*  this is a bit dumb since it loops over all pool slots to\r\n        find the occupied slots, on the other hand it is only ever\r\n        executed at shutdown\r\n        NOTE: ONLY EXECUTE THIS AT SHUTDOWN\r\n              ...because the free queues will not be reset\r\n              and the resource slots not be cleared!\r\n    */\r\n    for (int i = 1; i < p->buffer_pool.size; i++) {\r\n        if (p->buffers[i].slot.ctx_id == ctx_id) {\r\n            sg_resource_state state = p->buffers[i].slot.state;\r\n            if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {\r\n                _sg_destroy_buffer(&p->buffers[i]);\r\n            }\r\n        }\r\n    }\r\n    for (int i = 1; i < p->image_pool.size; i++) {\r\n        if (p->images[i].slot.ctx_id == ctx_id) {\r\n            sg_resource_state state = p->images[i].slot.state;\r\n            if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {\r\n                _sg_destroy_image(&p->images[i]);\r\n            }\r\n        }\r\n    }\r\n    for (int i = 1; i < p->shader_pool.size; i++) {\r\n        if (p->shaders[i].slot.ctx_id == ctx_id) {\r\n            sg_resource_state state = p->shaders[i].slot.state;\r\n            if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {\r\n                _sg_destroy_shader(&p->shaders[i]);\r\n            }\r\n        }\r\n    }\r\n    for (int i = 1; i < p->pipeline_pool.size; i++) {\r\n        if (p->pipelines[i].slot.ctx_id == ctx_id) {\r\n            sg_resource_state state = p->pipelines[i].slot.state;\r\n            if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {\r\n                _sg_destroy_pipeline(&p->pipelines[i]);\r\n            }\r\n        }\r\n    }\r\n    for (int i = 1; i < p->pass_pool.size; i++) {\r\n        if (p->passes[i].slot.ctx_id == ctx_id) {\r\n            sg_resource_state state = p->passes[i].slot.state;\r\n            if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {\r\n                _sg_destroy_pass(&p->passes[i]);\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n/*== VALIDATION LAYER ========================================================*/\r\n#if defined(SOKOL_DEBUG)\r\n/* return a human readable string for an _sg_validate_error */\r\n_SOKOL_PRIVATE const char* _sg_validate_string(_sg_validate_error_t err) {\r\n    switch (err) {\r\n        /* buffer creation validation errors */\r\n        case _SG_VALIDATE_BUFFERDESC_CANARY:        return \"sg_buffer_desc not initialized\";\r\n        case _SG_VALIDATE_BUFFERDESC_SIZE:          return \"sg_buffer_desc.size cannot be 0\";\r\n        case _SG_VALIDATE_BUFFERDESC_CONTENT:       return \"immutable buffers must be initialized with content (sg_buffer_desc.content)\";\r\n        case _SG_VALIDATE_BUFFERDESC_NO_CONTENT:    return \"dynamic/stream usage buffers cannot be initialized with content\";\r\n\r\n        /* image creation validation errros */\r\n        case _SG_VALIDATE_IMAGEDESC_CANARY:             return \"sg_image_desc not initialized\";\r\n        case _SG_VALIDATE_IMAGEDESC_WIDTH:              return \"sg_image_desc.width must be > 0\";\r\n        case _SG_VALIDATE_IMAGEDESC_HEIGHT:             return \"sg_image_desc.height must be > 0\";\r\n        case _SG_VALIDATE_IMAGEDESC_RT_PIXELFORMAT:     return \"invalid pixel format for render-target image\";\r\n        case _SG_VALIDATE_IMAGEDESC_NONRT_PIXELFORMAT:  return \"invalid pixel format for non-render-target image\";\r\n        case _SG_VALIDATE_IMAGEDESC_MSAA_BUT_NO_RT:     return \"non-render-target images cannot be multisampled\";\r\n        case _SG_VALIDATE_IMAGEDESC_NO_MSAA_RT_SUPPORT: return \"MSAA not supported for this pixel format\";\r\n        case _SG_VALIDATE_IMAGEDESC_RT_IMMUTABLE:       return \"render target images must be SG_USAGE_IMMUTABLE\";\r\n        case _SG_VALIDATE_IMAGEDESC_RT_NO_CONTENT:      return \"render target images cannot be initialized with content\";\r\n        case _SG_VALIDATE_IMAGEDESC_CONTENT:            return \"missing or invalid content for immutable image\";\r\n        case _SG_VALIDATE_IMAGEDESC_NO_CONTENT:         return \"dynamic/stream usage images cannot be initialized with content\";\r\n\r\n        /* shader creation */\r\n        case _SG_VALIDATE_SHADERDESC_CANARY:                return \"sg_shader_desc not initialized\";\r\n        case _SG_VALIDATE_SHADERDESC_SOURCE:                return \"shader source code required\";\r\n        case _SG_VALIDATE_SHADERDESC_BYTECODE:              return \"shader byte code required\";\r\n        case _SG_VALIDATE_SHADERDESC_SOURCE_OR_BYTECODE:    return \"shader source or byte code required\";\r\n        case _SG_VALIDATE_SHADERDESC_NO_BYTECODE_SIZE:      return \"shader byte code length (in bytes) required\";\r\n        case _SG_VALIDATE_SHADERDESC_NO_CONT_UBS:           return \"shader uniform blocks must occupy continuous slots\";\r\n        case _SG_VALIDATE_SHADERDESC_NO_CONT_UB_MEMBERS:    return \"uniform block members must occupy continuous slots\";\r\n        case _SG_VALIDATE_SHADERDESC_NO_UB_MEMBERS:         return \"GL backend requires uniform block member declarations\";\r\n        case _SG_VALIDATE_SHADERDESC_UB_MEMBER_NAME:        return \"uniform block member name missing\";\r\n        case _SG_VALIDATE_SHADERDESC_UB_SIZE_MISMATCH:      return \"size of uniform block members doesn't match uniform block size\";\r\n        case _SG_VALIDATE_SHADERDESC_NO_CONT_IMGS:          return \"shader images must occupy continuous slots\";\r\n        case _SG_VALIDATE_SHADERDESC_IMG_NAME:              return \"GL backend requires uniform block member names\";\r\n        case _SG_VALIDATE_SHADERDESC_ATTR_NAMES:            return \"GLES2 backend requires vertex attribute names\";\r\n        case _SG_VALIDATE_SHADERDESC_ATTR_SEMANTICS:        return \"D3D11 backend requires vertex attribute semantics\";\r\n        case _SG_VALIDATE_SHADERDESC_ATTR_STRING_TOO_LONG:  return \"vertex attribute name/semantic string too long (max len 16)\";\r\n\r\n        /* pipeline creation */\r\n        case _SG_VALIDATE_PIPELINEDESC_CANARY:          return \"sg_pipeline_desc not initialized\";\r\n        case _SG_VALIDATE_PIPELINEDESC_SHADER:          return \"sg_pipeline_desc.shader missing or invalid\";\r\n        case _SG_VALIDATE_PIPELINEDESC_NO_ATTRS:        return \"sg_pipeline_desc.layout.attrs is empty or not continuous\";\r\n        case _SG_VALIDATE_PIPELINEDESC_LAYOUT_STRIDE4:  return \"sg_pipeline_desc.layout.buffers[].stride must be multiple of 4\";\r\n        case _SG_VALIDATE_PIPELINEDESC_ATTR_NAME:       return \"GLES2/WebGL missing vertex attribute name in shader\";\r\n        case _SG_VALIDATE_PIPELINEDESC_ATTR_SEMANTICS:  return \"D3D11 missing vertex attribute semantics in shader\";\r\n\r\n        /* pass creation */\r\n        case _SG_VALIDATE_PASSDESC_CANARY:                  return \"sg_pass_desc not initialized\";\r\n        case _SG_VALIDATE_PASSDESC_NO_COLOR_ATTS:           return \"sg_pass_desc.color_attachments[0] must be valid\";\r\n        case _SG_VALIDATE_PASSDESC_NO_CONT_COLOR_ATTS:      return \"color attachments must occupy continuous slots\";\r\n        case _SG_VALIDATE_PASSDESC_IMAGE:                   return \"pass attachment image is not valid\";\r\n        case _SG_VALIDATE_PASSDESC_MIPLEVEL:                return \"pass attachment mip level is bigger than image has mipmaps\";\r\n        case _SG_VALIDATE_PASSDESC_FACE:                    return \"pass attachment image is cubemap, but face index is too big\";\r\n        case _SG_VALIDATE_PASSDESC_LAYER:                   return \"pass attachment image is array texture, but layer index is too big\";\r\n        case _SG_VALIDATE_PASSDESC_SLICE:                   return \"pass attachment image is 3d texture, but slice value is too big\";\r\n        case _SG_VALIDATE_PASSDESC_IMAGE_NO_RT:             return \"pass attachment image must be render targets\";\r\n        case _SG_VALIDATE_PASSDESC_COLOR_PIXELFORMATS:      return \"all pass color attachment images must have the same pixel format\";\r\n        case _SG_VALIDATE_PASSDESC_COLOR_INV_PIXELFORMAT:   return \"pass color-attachment images must have a renderable pixel format\";\r\n        case _SG_VALIDATE_PASSDESC_DEPTH_INV_PIXELFORMAT:   return \"pass depth-attachment image must have depth pixel format\";\r\n        case _SG_VALIDATE_PASSDESC_IMAGE_SIZES:             return \"all pass attachments must have the same size\";\r\n        case _SG_VALIDATE_PASSDESC_IMAGE_SAMPLE_COUNTS:     return \"all pass attachments must have the same sample count\";\r\n\r\n        /* sg_begin_pass */\r\n        case _SG_VALIDATE_BEGINPASS_PASS:       return \"sg_begin_pass: pass must be valid\";\r\n        case _SG_VALIDATE_BEGINPASS_IMAGE:      return \"sg_begin_pass: one or more attachment images are not valid\";\r\n\r\n        /* sg_apply_pipeline */\r\n        case _SG_VALIDATE_APIP_PIPELINE_VALID_ID:   return \"sg_apply_pipeline: invalid pipeline id provided\";\r\n        case _SG_VALIDATE_APIP_PIPELINE_EXISTS:     return \"sg_apply_pipeline: pipeline object no longer alive\";\r\n        case _SG_VALIDATE_APIP_PIPELINE_VALID:      return \"sg_apply_pipeline: pipeline object not in valid state\";\r\n        case _SG_VALIDATE_APIP_SHADER_EXISTS:       return \"sg_apply_pipeline: shader object no longer alive\";\r\n        case _SG_VALIDATE_APIP_SHADER_VALID:        return \"sg_apply_pipeline: shader object not in valid state\";\r\n        case _SG_VALIDATE_APIP_ATT_COUNT:           return \"sg_apply_pipeline: color_attachment_count in pipeline doesn't match number of pass color attachments\";\r\n        case _SG_VALIDATE_APIP_COLOR_FORMAT:        return \"sg_apply_pipeline: color_format in pipeline doesn't match pass color attachment pixel format\";\r\n        case _SG_VALIDATE_APIP_DEPTH_FORMAT:        return \"sg_apply_pipeline: depth_format in pipeline doesn't match pass depth attachment pixel format\";\r\n        case _SG_VALIDATE_APIP_SAMPLE_COUNT:        return \"sg_apply_pipeline: MSAA sample count in pipeline doesn't match render pass attachment sample count\";\r\n\r\n        /* sg_apply_bindings */\r\n        case _SG_VALIDATE_ABND_PIPELINE:            return \"sg_apply_bindings: must be called after sg_apply_pipeline\";\r\n        case _SG_VALIDATE_ABND_PIPELINE_EXISTS:     return \"sg_apply_bindings: currently applied pipeline object no longer alive\";\r\n        case _SG_VALIDATE_ABND_PIPELINE_VALID:      return \"sg_apply_bindings: currently applied pipeline object not in valid state\";\r\n        case _SG_VALIDATE_ABND_VBS:                 return \"sg_apply_bindings: number of vertex buffers doesn't match number of pipeline vertex layouts\";\r\n        case _SG_VALIDATE_ABND_VB_EXISTS:           return \"sg_apply_bindings: vertex buffer no longer alive\";\r\n        case _SG_VALIDATE_ABND_VB_TYPE:             return \"sg_apply_bindings: buffer in vertex buffer slot is not a SG_BUFFERTYPE_VERTEXBUFFER\";\r\n        case _SG_VALIDATE_ABND_VB_OVERFLOW:         return \"sg_apply_bindings: buffer in vertex buffer slot is overflown\";\r\n        case _SG_VALIDATE_ABND_NO_IB:               return \"sg_apply_bindings: pipeline object defines indexed rendering, but no index buffer provided\";\r\n        case _SG_VALIDATE_ABND_IB:                  return \"sg_apply_bindings: pipeline object defines non-indexed rendering, but index buffer provided\";\r\n        case _SG_VALIDATE_ABND_IB_EXISTS:           return \"sg_apply_bindings: index buffer no longer alive\";\r\n        case _SG_VALIDATE_ABND_IB_TYPE:             return \"sg_apply_bindings: buffer in index buffer slot is not a SG_BUFFERTYPE_INDEXBUFFER\";\r\n        case _SG_VALIDATE_ABND_IB_OVERFLOW:         return \"sg_apply_bindings: buffer in index buffer slot is overflown\";\r\n        case _SG_VALIDATE_ABND_VS_IMGS:             return \"sg_apply_bindings: vertex shader image count doesn't match sg_shader_desc\";\r\n        case _SG_VALIDATE_ABND_VS_IMG_EXISTS:       return \"sg_apply_bindings: vertex shader image no longer alive\";\r\n        case _SG_VALIDATE_ABND_VS_IMG_TYPES:        return \"sg_apply_bindings: one or more vertex shader image types don't match sg_shader_desc\";\r\n        case _SG_VALIDATE_ABND_FS_IMGS:             return \"sg_apply_bindings: fragment shader image count doesn't match sg_shader_desc\";\r\n        case _SG_VALIDATE_ABND_FS_IMG_EXISTS:       return \"sg_apply_bindings: fragment shader image no longer alive\";\r\n        case _SG_VALIDATE_ABND_FS_IMG_TYPES:        return \"sg_apply_bindings: one or more fragment shader image types don't match sg_shader_desc\";\r\n\r\n        /* sg_apply_uniforms */\r\n        case _SG_VALIDATE_AUB_NO_PIPELINE:      return \"sg_apply_uniforms: must be called after sg_apply_pipeline()\";\r\n        case _SG_VALIDATE_AUB_NO_UB_AT_SLOT:    return \"sg_apply_uniforms: no uniform block declaration at this shader stage UB slot\";\r\n        case _SG_VALIDATE_AUB_SIZE:             return \"sg_apply_uniforms: data size exceeds declared uniform block size\";\r\n\r\n        /* sg_update_buffer */\r\n        case _SG_VALIDATE_UPDATEBUF_USAGE:      return \"sg_update_buffer: cannot update immutable buffer\";\r\n        case _SG_VALIDATE_UPDATEBUF_SIZE:       return \"sg_update_buffer: update size is bigger than buffer size\";\r\n        case _SG_VALIDATE_UPDATEBUF_ONCE:       return \"sg_update_buffer: only one update allowed per buffer and frame\";\r\n        case _SG_VALIDATE_UPDATEBUF_APPEND:     return \"sg_update_buffer: cannot call sg_update_buffer and sg_append_buffer in same frame\";\r\n\r\n        /* sg_append_buffer */\r\n        case _SG_VALIDATE_APPENDBUF_USAGE:      return \"sg_append_buffer: cannot append to immutable buffer\";\r\n        case _SG_VALIDATE_APPENDBUF_SIZE:       return \"sg_append_buffer: overall appended size is bigger than buffer size\";\r\n        case _SG_VALIDATE_APPENDBUF_UPDATE:     return \"sg_append_buffer: cannot call sg_append_buffer and sg_update_buffer in same frame\";\r\n\r\n        /* sg_update_image */\r\n        case _SG_VALIDATE_UPDIMG_USAGE:         return \"sg_update_image: cannot update immutable image\";\r\n        case _SG_VALIDATE_UPDIMG_NOTENOUGHDATA: return \"sg_update_image: not enough subimage data provided\";\r\n        case _SG_VALIDATE_UPDIMG_SIZE:          return \"sg_update_image: provided subimage data size too big\";\r\n        case _SG_VALIDATE_UPDIMG_COMPRESSED:    return \"sg_update_image: cannot update images with compressed format\";\r\n        case _SG_VALIDATE_UPDIMG_ONCE:          return \"sg_update_image: only one update allowed per image and frame\";\r\n\r\n        default: return \"unknown validation error\";\r\n    }\r\n}\r\n#endif /* defined(SOKOL_DEBUG) */\r\n\r\n/*-- validation checks -------------------------------------------------------*/\r\n#if defined(SOKOL_DEBUG)\r\n_SOKOL_PRIVATE void _sg_validate_begin(void) {\r\n    _sg.validate_error = _SG_VALIDATE_SUCCESS;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_validate(bool cond, _sg_validate_error_t err) {\r\n    if (!cond) {\r\n        _sg.validate_error = err;\r\n        SOKOL_LOG(_sg_validate_string(err));\r\n    }\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_end(void) {\r\n    if (_sg.validate_error != _SG_VALIDATE_SUCCESS) {\r\n        #if !defined(SOKOL_VALIDATE_NON_FATAL)\r\n            SOKOL_LOG(\"^^^^  VALIDATION FAILED, TERMINATING ^^^^\");\r\n            SOKOL_ASSERT(false);\r\n        #endif\r\n        return false;\r\n    }\r\n    else {\r\n        return true;\r\n    }\r\n}\r\n#endif\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_buffer_desc(const sg_buffer_desc* desc) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(desc);\r\n        return true;\r\n    #else\r\n        SOKOL_ASSERT(desc);\r\n        SOKOL_VALIDATE_BEGIN();\r\n        SOKOL_VALIDATE(desc->_start_canary == 0, _SG_VALIDATE_BUFFERDESC_CANARY);\r\n        SOKOL_VALIDATE(desc->_end_canary == 0, _SG_VALIDATE_BUFFERDESC_CANARY);\r\n        SOKOL_VALIDATE(desc->size > 0, _SG_VALIDATE_BUFFERDESC_SIZE);\r\n        bool injected = (0 != desc->gl_buffers[0]) ||\r\n                        (0 != desc->mtl_buffers[0]) ||\r\n                        (0 != desc->d3d11_buffer) ||\r\n                        (0 != desc->wgpu_buffer);\r\n        if (!injected && (desc->usage == SG_USAGE_IMMUTABLE)) {\r\n            SOKOL_VALIDATE(0 != desc->content, _SG_VALIDATE_BUFFERDESC_CONTENT);\r\n        }\r\n        else {\r\n            SOKOL_VALIDATE(0 == desc->content, _SG_VALIDATE_BUFFERDESC_NO_CONTENT);\r\n        }\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_image_desc(const sg_image_desc* desc) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(desc);\r\n        return true;\r\n    #else\r\n        SOKOL_ASSERT(desc);\r\n        SOKOL_VALIDATE_BEGIN();\r\n        SOKOL_VALIDATE(desc->_start_canary == 0, _SG_VALIDATE_IMAGEDESC_CANARY);\r\n        SOKOL_VALIDATE(desc->_end_canary == 0, _SG_VALIDATE_IMAGEDESC_CANARY);\r\n        SOKOL_VALIDATE(desc->width > 0, _SG_VALIDATE_IMAGEDESC_WIDTH);\r\n        SOKOL_VALIDATE(desc->height > 0, _SG_VALIDATE_IMAGEDESC_HEIGHT);\r\n        const sg_pixel_format fmt = desc->pixel_format;\r\n        const sg_usage usage = desc->usage;\r\n        const bool injected = (0 != desc->gl_textures[0]) ||\r\n                              (0 != desc->mtl_textures[0]) ||\r\n                              (0 != desc->d3d11_texture) ||\r\n                              (0 != desc->wgpu_texture);\r\n        if (desc->render_target) {\r\n            SOKOL_ASSERT(((int)fmt >= 0) && ((int)fmt < _SG_PIXELFORMAT_NUM));\r\n            SOKOL_VALIDATE(_sg.formats[fmt].render, _SG_VALIDATE_IMAGEDESC_RT_PIXELFORMAT);\r\n            /* on GLES2, sample count for render targets is completely ignored */\r\n            #if defined(SOKOL_GLES2) || defined(SOKOL_GLES3)\r\n            if (!_sg.gl.gles2) {\r\n            #endif\r\n                if (desc->sample_count > 1) {\r\n                    SOKOL_VALIDATE(_sg.features.msaa_render_targets && _sg.formats[fmt].msaa, _SG_VALIDATE_IMAGEDESC_NO_MSAA_RT_SUPPORT);\r\n                }\r\n            #if defined(SOKOL_GLES2) || defined(SOKOL_GLES3)\r\n            }\r\n            #endif\r\n            SOKOL_VALIDATE(usage == SG_USAGE_IMMUTABLE, _SG_VALIDATE_IMAGEDESC_RT_IMMUTABLE);\r\n            SOKOL_VALIDATE(desc->content.subimage[0][0].ptr==0, _SG_VALIDATE_IMAGEDESC_RT_NO_CONTENT);\r\n        }\r\n        else {\r\n            SOKOL_VALIDATE(desc->sample_count <= 1, _SG_VALIDATE_IMAGEDESC_MSAA_BUT_NO_RT);\r\n            const bool valid_nonrt_fmt = !_sg_is_valid_rendertarget_depth_format(fmt);\r\n            SOKOL_VALIDATE(valid_nonrt_fmt, _SG_VALIDATE_IMAGEDESC_NONRT_PIXELFORMAT);\r\n            /* FIXME: should use the same \"expected size\" computation as in _sg_validate_update_image() here */\r\n            if (!injected && (usage == SG_USAGE_IMMUTABLE)) {\r\n                const int num_faces = desc->type == SG_IMAGETYPE_CUBE ? 6:1;\r\n                const int num_mips = desc->num_mipmaps;\r\n                for (int face_index = 0; face_index < num_faces; face_index++) {\r\n                    for (int mip_index = 0; mip_index < num_mips; mip_index++) {\r\n                        const bool has_data = desc->content.subimage[face_index][mip_index].ptr != 0;\r\n                        const bool has_size = desc->content.subimage[face_index][mip_index].size > 0;\r\n                        SOKOL_VALIDATE(has_data && has_size, _SG_VALIDATE_IMAGEDESC_CONTENT);\r\n                    }\r\n                }\r\n            }\r\n            else {\r\n                for (int face_index = 0; face_index < SG_CUBEFACE_NUM; face_index++) {\r\n                    for (int mip_index = 0; mip_index < SG_MAX_MIPMAPS; mip_index++) {\r\n                        const bool no_data = 0 == desc->content.subimage[face_index][mip_index].ptr;\r\n                        const bool no_size = 0 == desc->content.subimage[face_index][mip_index].size;\r\n                        SOKOL_VALIDATE(no_data && no_size, _SG_VALIDATE_IMAGEDESC_NO_CONTENT);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_shader_desc(const sg_shader_desc* desc) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(desc);\r\n        return true;\r\n    #else\r\n        SOKOL_ASSERT(desc);\r\n        SOKOL_VALIDATE_BEGIN();\r\n        SOKOL_VALIDATE(desc->_start_canary == 0, _SG_VALIDATE_SHADERDESC_CANARY);\r\n        SOKOL_VALIDATE(desc->_end_canary == 0, _SG_VALIDATE_SHADERDESC_CANARY);\r\n        #if defined(SOKOL_GLES2)\r\n            SOKOL_VALIDATE(0 != desc->attrs[0].name, _SG_VALIDATE_SHADERDESC_ATTR_NAMES);\r\n        #elif defined(SOKOL_D3D11)\r\n            SOKOL_VALIDATE(0 != desc->attrs[0].sem_name, _SG_VALIDATE_SHADERDESC_ATTR_SEMANTICS);\r\n        #endif\r\n        #if defined(SOKOL_GLCORE33) || defined(SOKOL_GLES2) || defined(SOKOL_GLES3)\r\n            /* on GL, must provide shader source code */\r\n            SOKOL_VALIDATE(0 != desc->vs.source, _SG_VALIDATE_SHADERDESC_SOURCE);\r\n            SOKOL_VALIDATE(0 != desc->fs.source, _SG_VALIDATE_SHADERDESC_SOURCE);\r\n        #elif defined(SOKOL_METAL) || defined(SOKOL_D3D11)\r\n            /* on Metal or D3D11, must provide shader source code or byte code */\r\n            SOKOL_VALIDATE((0 != desc->vs.source)||(0 != desc->vs.byte_code), _SG_VALIDATE_SHADERDESC_SOURCE_OR_BYTECODE);\r\n            SOKOL_VALIDATE((0 != desc->fs.source)||(0 != desc->fs.byte_code), _SG_VALIDATE_SHADERDESC_SOURCE_OR_BYTECODE);\r\n        #elif defined(SOKOL_WGPU)\r\n            /* on WGPU byte code must be provided */\r\n            SOKOL_VALIDATE((0 != desc->vs.byte_code), _SG_VALIDATE_SHADERDESC_BYTECODE);\r\n            SOKOL_VALIDATE((0 != desc->fs.byte_code), _SG_VALIDATE_SHADERDESC_BYTECODE);\r\n        #else\r\n            /* Dummy Backend, don't require source or bytecode */\r\n        #endif\r\n        for (int i = 0; i < SG_MAX_VERTEX_ATTRIBUTES; i++) {\r\n            if (desc->attrs[i].name) {\r\n                SOKOL_VALIDATE(strlen(desc->attrs[i].name) < _SG_STRING_SIZE, _SG_VALIDATE_SHADERDESC_ATTR_STRING_TOO_LONG);\r\n            }\r\n            if (desc->attrs[i].sem_name) {\r\n                SOKOL_VALIDATE(strlen(desc->attrs[i].sem_name) < _SG_STRING_SIZE, _SG_VALIDATE_SHADERDESC_ATTR_STRING_TOO_LONG);\r\n            }\r\n        }\r\n        /* if shader byte code, the size must also be provided */\r\n        if (0 != desc->vs.byte_code) {\r\n            SOKOL_VALIDATE(desc->vs.byte_code_size > 0, _SG_VALIDATE_SHADERDESC_NO_BYTECODE_SIZE);\r\n        }\r\n        if (0 != desc->fs.byte_code) {\r\n            SOKOL_VALIDATE(desc->fs.byte_code_size > 0, _SG_VALIDATE_SHADERDESC_NO_BYTECODE_SIZE);\r\n        }\r\n        for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n            const sg_shader_stage_desc* stage_desc = (stage_index == 0)? &desc->vs : &desc->fs;\r\n            bool uniform_blocks_continuous = true;\r\n            for (int ub_index = 0; ub_index < SG_MAX_SHADERSTAGE_UBS; ub_index++) {\r\n                const sg_shader_uniform_block_desc* ub_desc = &stage_desc->uniform_blocks[ub_index];\r\n                if (ub_desc->size > 0) {\r\n                    SOKOL_VALIDATE(uniform_blocks_continuous, _SG_VALIDATE_SHADERDESC_NO_CONT_UBS);\r\n                    bool uniforms_continuous = true;\r\n                    int uniform_offset = 0;\r\n                    int num_uniforms = 0;\r\n                    for (int u_index = 0; u_index < SG_MAX_UB_MEMBERS; u_index++) {\r\n                        const sg_shader_uniform_desc* u_desc = &ub_desc->uniforms[u_index];\r\n                        if (u_desc->type != SG_UNIFORMTYPE_INVALID) {\r\n                            SOKOL_VALIDATE(uniforms_continuous, _SG_VALIDATE_SHADERDESC_NO_CONT_UB_MEMBERS);\r\n                            #if defined(SOKOL_GLES2) || defined(SOKOL_GLES3)\r\n                            SOKOL_VALIDATE(u_desc->name, _SG_VALIDATE_SHADERDESC_UB_MEMBER_NAME);\r\n                            #endif\r\n                            const int array_count = u_desc->array_count;\r\n                            uniform_offset += _sg_uniform_size(u_desc->type, array_count);\r\n                            num_uniforms++;\r\n                        }\r\n                        else {\r\n                            uniforms_continuous = false;\r\n                        }\r\n                    }\r\n                    #if defined(SOKOL_GLCORE33) || defined(SOKOL_GLES2) || defined(SOKOL_GLES3)\r\n                    SOKOL_VALIDATE(uniform_offset == ub_desc->size, _SG_VALIDATE_SHADERDESC_UB_SIZE_MISMATCH);\r\n                    SOKOL_VALIDATE(num_uniforms > 0, _SG_VALIDATE_SHADERDESC_NO_UB_MEMBERS);\r\n                    #endif\r\n                }\r\n                else {\r\n                    uniform_blocks_continuous = false;\r\n                }\r\n            }\r\n            bool images_continuous = true;\r\n            for (int img_index = 0; img_index < SG_MAX_SHADERSTAGE_IMAGES; img_index++) {\r\n                const sg_shader_image_desc* img_desc = &stage_desc->images[img_index];\r\n                if (img_desc->type != _SG_IMAGETYPE_DEFAULT) {\r\n                    SOKOL_VALIDATE(images_continuous, _SG_VALIDATE_SHADERDESC_NO_CONT_IMGS);\r\n                    #if defined(SOKOL_GLES2)\r\n                    SOKOL_VALIDATE(img_desc->name, _SG_VALIDATE_SHADERDESC_IMG_NAME);\r\n                    #endif\r\n                }\r\n                else {\r\n                    images_continuous = false;\r\n                }\r\n            }\r\n        }\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_pipeline_desc(const sg_pipeline_desc* desc) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(desc);\r\n        return true;\r\n    #else\r\n        SOKOL_ASSERT(desc);\r\n        SOKOL_VALIDATE_BEGIN();\r\n        SOKOL_VALIDATE(desc->_start_canary == 0, _SG_VALIDATE_PIPELINEDESC_CANARY);\r\n        SOKOL_VALIDATE(desc->_end_canary == 0, _SG_VALIDATE_PIPELINEDESC_CANARY);\r\n        SOKOL_VALIDATE(desc->shader.id != SG_INVALID_ID, _SG_VALIDATE_PIPELINEDESC_SHADER);\r\n        for (int buf_index = 0; buf_index < SG_MAX_SHADERSTAGE_BUFFERS; buf_index++) {\r\n            const sg_buffer_layout_desc* l_desc = &desc->layout.buffers[buf_index];\r\n            if (l_desc->stride == 0) {\r\n                continue;\r\n            }\r\n            SOKOL_VALIDATE((l_desc->stride & 3) == 0, _SG_VALIDATE_PIPELINEDESC_LAYOUT_STRIDE4);\r\n        }\r\n        SOKOL_VALIDATE(desc->layout.attrs[0].format != SG_VERTEXFORMAT_INVALID, _SG_VALIDATE_PIPELINEDESC_NO_ATTRS);\r\n        const _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, desc->shader.id);\r\n        SOKOL_VALIDATE(shd, _SG_VALIDATE_PIPELINEDESC_SHADER);\r\n        if (shd) {\r\n            SOKOL_VALIDATE(shd->slot.state == SG_RESOURCESTATE_VALID, _SG_VALIDATE_PIPELINEDESC_SHADER);\r\n            bool attrs_cont = true;\r\n            for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {\r\n                const sg_vertex_attr_desc* a_desc = &desc->layout.attrs[attr_index];\r\n                if (a_desc->format == SG_VERTEXFORMAT_INVALID) {\r\n                    attrs_cont = false;\r\n                    continue;\r\n                }\r\n                SOKOL_VALIDATE(attrs_cont, _SG_VALIDATE_PIPELINEDESC_NO_ATTRS);\r\n                SOKOL_ASSERT(a_desc->buffer_index < SG_MAX_SHADERSTAGE_BUFFERS);\r\n                #if defined(SOKOL_GLES2)\r\n                /* on GLES2, vertex attribute names must be provided */\r\n                SOKOL_VALIDATE(!_sg_strempty(&shd->gl.attrs[attr_index].name), _SG_VALIDATE_PIPELINEDESC_ATTR_NAME);\r\n                #elif defined(SOKOL_D3D11)\r\n                /* on D3D11, semantic names (and semantic indices) must be provided */\r\n                SOKOL_VALIDATE(!_sg_strempty(&shd->d3d11.attrs[attr_index].sem_name), _SG_VALIDATE_PIPELINEDESC_ATTR_SEMANTICS);\r\n                #endif\r\n            }\r\n        }\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_pass_desc(const sg_pass_desc* desc) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(desc);\r\n        return true;\r\n    #else\r\n        SOKOL_ASSERT(desc);\r\n        SOKOL_VALIDATE_BEGIN();\r\n        SOKOL_VALIDATE(desc->_start_canary == 0, _SG_VALIDATE_PASSDESC_CANARY);\r\n        SOKOL_VALIDATE(desc->_end_canary == 0, _SG_VALIDATE_PASSDESC_CANARY);\r\n        bool atts_cont = true;\r\n        sg_pixel_format color_fmt = SG_PIXELFORMAT_NONE;\r\n        int width = -1, height = -1, sample_count = -1;\r\n        for (int att_index = 0; att_index < SG_MAX_COLOR_ATTACHMENTS; att_index++) {\r\n            const sg_attachment_desc* att = &desc->color_attachments[att_index];\r\n            if (att->image.id == SG_INVALID_ID) {\r\n                SOKOL_VALIDATE(att_index > 0, _SG_VALIDATE_PASSDESC_NO_COLOR_ATTS);\r\n                atts_cont = false;\r\n                continue;\r\n            }\r\n            SOKOL_VALIDATE(atts_cont, _SG_VALIDATE_PASSDESC_NO_CONT_COLOR_ATTS);\r\n            const _sg_image_t* img = _sg_lookup_image(&_sg.pools, att->image.id);\r\n            SOKOL_VALIDATE(img && img->slot.state == SG_RESOURCESTATE_VALID, _SG_VALIDATE_PASSDESC_IMAGE);\r\n            SOKOL_VALIDATE(att->mip_level < img->cmn.num_mipmaps, _SG_VALIDATE_PASSDESC_MIPLEVEL);\r\n            if (img->cmn.type == SG_IMAGETYPE_CUBE) {\r\n                SOKOL_VALIDATE(att->face < 6, _SG_VALIDATE_PASSDESC_FACE);\r\n            }\r\n            else if (img->cmn.type == SG_IMAGETYPE_ARRAY) {\r\n                SOKOL_VALIDATE(att->layer < img->cmn.depth, _SG_VALIDATE_PASSDESC_LAYER);\r\n            }\r\n            else if (img->cmn.type == SG_IMAGETYPE_3D) {\r\n                SOKOL_VALIDATE(att->slice < img->cmn.depth, _SG_VALIDATE_PASSDESC_SLICE);\r\n            }\r\n            SOKOL_VALIDATE(img->cmn.render_target, _SG_VALIDATE_PASSDESC_IMAGE_NO_RT);\r\n            if (att_index == 0) {\r\n                color_fmt = img->cmn.pixel_format;\r\n                width = img->cmn.width >> att->mip_level;\r\n                height = img->cmn.height >> att->mip_level;\r\n                sample_count = img->cmn.sample_count;\r\n            }\r\n            else {\r\n                SOKOL_VALIDATE(img->cmn.pixel_format == color_fmt, _SG_VALIDATE_PASSDESC_COLOR_PIXELFORMATS);\r\n                SOKOL_VALIDATE(width == img->cmn.width >> att->mip_level, _SG_VALIDATE_PASSDESC_IMAGE_SIZES);\r\n                SOKOL_VALIDATE(height == img->cmn.height >> att->mip_level, _SG_VALIDATE_PASSDESC_IMAGE_SIZES);\r\n                SOKOL_VALIDATE(sample_count == img->cmn.sample_count, _SG_VALIDATE_PASSDESC_IMAGE_SAMPLE_COUNTS);\r\n            }\r\n            SOKOL_VALIDATE(_sg_is_valid_rendertarget_color_format(img->cmn.pixel_format), _SG_VALIDATE_PASSDESC_COLOR_INV_PIXELFORMAT);\r\n        }\r\n        if (desc->depth_stencil_attachment.image.id != SG_INVALID_ID) {\r\n            const sg_attachment_desc* att = &desc->depth_stencil_attachment;\r\n            const _sg_image_t* img = _sg_lookup_image(&_sg.pools, att->image.id);\r\n            SOKOL_VALIDATE(img && img->slot.state == SG_RESOURCESTATE_VALID, _SG_VALIDATE_PASSDESC_IMAGE);\r\n            SOKOL_VALIDATE(att->mip_level < img->cmn.num_mipmaps, _SG_VALIDATE_PASSDESC_MIPLEVEL);\r\n            if (img->cmn.type == SG_IMAGETYPE_CUBE) {\r\n                SOKOL_VALIDATE(att->face < 6, _SG_VALIDATE_PASSDESC_FACE);\r\n            }\r\n            else if (img->cmn.type == SG_IMAGETYPE_ARRAY) {\r\n                SOKOL_VALIDATE(att->layer < img->cmn.depth, _SG_VALIDATE_PASSDESC_LAYER);\r\n            }\r\n            else if (img->cmn.type == SG_IMAGETYPE_3D) {\r\n                SOKOL_VALIDATE(att->slice < img->cmn.depth, _SG_VALIDATE_PASSDESC_SLICE);\r\n            }\r\n            SOKOL_VALIDATE(img->cmn.render_target, _SG_VALIDATE_PASSDESC_IMAGE_NO_RT);\r\n            SOKOL_VALIDATE(width == img->cmn.width >> att->mip_level, _SG_VALIDATE_PASSDESC_IMAGE_SIZES);\r\n            SOKOL_VALIDATE(height == img->cmn.height >> att->mip_level, _SG_VALIDATE_PASSDESC_IMAGE_SIZES);\r\n            SOKOL_VALIDATE(sample_count == img->cmn.sample_count, _SG_VALIDATE_PASSDESC_IMAGE_SAMPLE_COUNTS);\r\n            SOKOL_VALIDATE(_sg_is_valid_rendertarget_depth_format(img->cmn.pixel_format), _SG_VALIDATE_PASSDESC_DEPTH_INV_PIXELFORMAT);\r\n        }\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_begin_pass(_sg_pass_t* pass) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(pass);\r\n        return true;\r\n    #else\r\n        SOKOL_VALIDATE_BEGIN();\r\n        SOKOL_VALIDATE(pass->slot.state == SG_RESOURCESTATE_VALID, _SG_VALIDATE_BEGINPASS_PASS);\r\n\r\n        for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n            const _sg_attachment_t* att = &pass->cmn.color_atts[i];\r\n            const _sg_image_t* img = _sg_pass_color_image(pass, i);\r\n            if (img) {\r\n                SOKOL_VALIDATE(img->slot.state == SG_RESOURCESTATE_VALID, _SG_VALIDATE_BEGINPASS_IMAGE);\r\n                SOKOL_VALIDATE(img->slot.id == att->image_id.id, _SG_VALIDATE_BEGINPASS_IMAGE);\r\n            }\r\n        }\r\n        const _sg_image_t* ds_img = _sg_pass_ds_image(pass);\r\n        if (ds_img) {\r\n            const _sg_attachment_t* att = &pass->cmn.ds_att;\r\n            SOKOL_VALIDATE(ds_img->slot.state == SG_RESOURCESTATE_VALID, _SG_VALIDATE_BEGINPASS_IMAGE);\r\n            SOKOL_VALIDATE(ds_img->slot.id == att->image_id.id, _SG_VALIDATE_BEGINPASS_IMAGE);\r\n        }\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_apply_pipeline(sg_pipeline pip_id) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(pip_id);\r\n        return true;\r\n    #else\r\n        SOKOL_VALIDATE_BEGIN();\r\n        /* the pipeline object must be alive and valid */\r\n        SOKOL_VALIDATE(pip_id.id != SG_INVALID_ID, _SG_VALIDATE_APIP_PIPELINE_VALID_ID);\r\n        const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);\r\n        SOKOL_VALIDATE(pip != 0, _SG_VALIDATE_APIP_PIPELINE_EXISTS);\r\n        if (!pip) {\r\n            return SOKOL_VALIDATE_END();\r\n        }\r\n        SOKOL_VALIDATE(pip->slot.state == SG_RESOURCESTATE_VALID, _SG_VALIDATE_APIP_PIPELINE_VALID);\r\n        /* the pipeline's shader must be alive and valid */\r\n        SOKOL_ASSERT(pip->shader);\r\n        SOKOL_VALIDATE(pip->shader->slot.id == pip->cmn.shader_id.id, _SG_VALIDATE_APIP_SHADER_EXISTS);\r\n        SOKOL_VALIDATE(pip->shader->slot.state == SG_RESOURCESTATE_VALID, _SG_VALIDATE_APIP_SHADER_VALID);\r\n        /* check that pipeline attributes match current pass attributes */\r\n        const _sg_pass_t* pass = _sg_lookup_pass(&_sg.pools, _sg.cur_pass.id);\r\n        if (pass) {\r\n            /* an offscreen pass */\r\n            const _sg_image_t* att_img = _sg_pass_color_image(pass, 0);\r\n            SOKOL_VALIDATE(pip->cmn.color_attachment_count == pass->cmn.num_color_atts, _SG_VALIDATE_APIP_ATT_COUNT);\r\n            SOKOL_VALIDATE(pip->cmn.color_format == att_img->cmn.pixel_format, _SG_VALIDATE_APIP_COLOR_FORMAT);\r\n            SOKOL_VALIDATE(pip->cmn.sample_count == att_img->cmn.sample_count, _SG_VALIDATE_APIP_SAMPLE_COUNT);\r\n            const _sg_image_t* att_dsimg = _sg_pass_ds_image(pass);\r\n            if (att_dsimg) {\r\n                SOKOL_VALIDATE(pip->cmn.depth_format == att_dsimg->cmn.pixel_format, _SG_VALIDATE_APIP_DEPTH_FORMAT);\r\n            }\r\n            else {\r\n                SOKOL_VALIDATE(pip->cmn.depth_format == SG_PIXELFORMAT_NONE, _SG_VALIDATE_APIP_DEPTH_FORMAT);\r\n            }\r\n        }\r\n        else {\r\n            /* default pass */\r\n            SOKOL_VALIDATE(pip->cmn.color_attachment_count == 1, _SG_VALIDATE_APIP_ATT_COUNT);\r\n            SOKOL_VALIDATE(pip->cmn.color_format == _sg.desc.context.color_format, _SG_VALIDATE_APIP_COLOR_FORMAT);\r\n            SOKOL_VALIDATE(pip->cmn.depth_format == _sg.desc.context.depth_format, _SG_VALIDATE_APIP_DEPTH_FORMAT);\r\n            SOKOL_VALIDATE(pip->cmn.sample_count == _sg.desc.context.sample_count, _SG_VALIDATE_APIP_SAMPLE_COUNT);\r\n        }\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_apply_bindings(const sg_bindings* bindings) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(bindings);\r\n        return true;\r\n    #else\r\n        SOKOL_VALIDATE_BEGIN();\r\n\r\n        /* a pipeline object must have been applied */\r\n        SOKOL_VALIDATE(_sg.cur_pipeline.id != SG_INVALID_ID, _SG_VALIDATE_ABND_PIPELINE);\r\n        const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, _sg.cur_pipeline.id);\r\n        SOKOL_VALIDATE(pip != 0, _SG_VALIDATE_ABND_PIPELINE_EXISTS);\r\n        if (!pip) {\r\n            return SOKOL_VALIDATE_END();\r\n        }\r\n        SOKOL_VALIDATE(pip->slot.state == SG_RESOURCESTATE_VALID, _SG_VALIDATE_ABND_PIPELINE_VALID);\r\n        SOKOL_ASSERT(pip->shader && (pip->cmn.shader_id.id == pip->shader->slot.id));\r\n\r\n        /* has expected vertex buffers, and vertex buffers still exist */\r\n        for (int i = 0; i < SG_MAX_SHADERSTAGE_BUFFERS; i++) {\r\n            if (bindings->vertex_buffers[i].id != SG_INVALID_ID) {\r\n                SOKOL_VALIDATE(pip->cmn.vertex_layout_valid[i], _SG_VALIDATE_ABND_VBS);\r\n                /* buffers in vertex-buffer-slots must be of type SG_BUFFERTYPE_VERTEXBUFFER */\r\n                const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, bindings->vertex_buffers[i].id);\r\n                SOKOL_VALIDATE(buf != 0, _SG_VALIDATE_ABND_VB_EXISTS);\r\n                if (buf && buf->slot.state == SG_RESOURCESTATE_VALID) {\r\n                    SOKOL_VALIDATE(SG_BUFFERTYPE_VERTEXBUFFER == buf->cmn.type, _SG_VALIDATE_ABND_VB_TYPE);\r\n                    SOKOL_VALIDATE(!buf->cmn.append_overflow, _SG_VALIDATE_ABND_VB_OVERFLOW);\r\n                }\r\n            }\r\n            else {\r\n                /* vertex buffer provided in a slot which has no vertex layout in pipeline */\r\n                SOKOL_VALIDATE(!pip->cmn.vertex_layout_valid[i], _SG_VALIDATE_ABND_VBS);\r\n            }\r\n        }\r\n\r\n        /* index buffer expected or not, and index buffer still exists */\r\n        if (pip->cmn.index_type == SG_INDEXTYPE_NONE) {\r\n            /* pipeline defines non-indexed rendering, but index buffer provided */\r\n            SOKOL_VALIDATE(bindings->index_buffer.id == SG_INVALID_ID, _SG_VALIDATE_ABND_IB);\r\n        }\r\n        else {\r\n            /* pipeline defines indexed rendering, but no index buffer provided */\r\n            SOKOL_VALIDATE(bindings->index_buffer.id != SG_INVALID_ID, _SG_VALIDATE_ABND_NO_IB);\r\n        }\r\n        if (bindings->index_buffer.id != SG_INVALID_ID) {\r\n            /* buffer in index-buffer-slot must be of type SG_BUFFERTYPE_INDEXBUFFER */\r\n            const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, bindings->index_buffer.id);\r\n            SOKOL_VALIDATE(buf != 0, _SG_VALIDATE_ABND_IB_EXISTS);\r\n            if (buf && buf->slot.state == SG_RESOURCESTATE_VALID) {\r\n                SOKOL_VALIDATE(SG_BUFFERTYPE_INDEXBUFFER == buf->cmn.type, _SG_VALIDATE_ABND_IB_TYPE);\r\n                SOKOL_VALIDATE(!buf->cmn.append_overflow, _SG_VALIDATE_ABND_IB_OVERFLOW);\r\n            }\r\n        }\r\n\r\n        /* has expected vertex shader images */\r\n        for (int i = 0; i < SG_MAX_SHADERSTAGE_IMAGES; i++) {\r\n            _sg_shader_stage_t* stage = &pip->shader->cmn.stage[SG_SHADERSTAGE_VS];\r\n            if (bindings->vs_images[i].id != SG_INVALID_ID) {\r\n                SOKOL_VALIDATE(i < stage->num_images, _SG_VALIDATE_ABND_VS_IMGS);\r\n                const _sg_image_t* img = _sg_lookup_image(&_sg.pools, bindings->vs_images[i].id);\r\n                SOKOL_VALIDATE(img != 0, _SG_VALIDATE_ABND_VS_IMG_EXISTS);\r\n                if (img && img->slot.state == SG_RESOURCESTATE_VALID) {\r\n                    SOKOL_VALIDATE(img->cmn.type == stage->images[i].type, _SG_VALIDATE_ABND_VS_IMG_TYPES);\r\n                }\r\n            }\r\n            else {\r\n                SOKOL_VALIDATE(i >= stage->num_images, _SG_VALIDATE_ABND_VS_IMGS);\r\n            }\r\n        }\r\n\r\n        /* has expected fragment shader images */\r\n        for (int i = 0; i < SG_MAX_SHADERSTAGE_IMAGES; i++) {\r\n            _sg_shader_stage_t* stage = &pip->shader->cmn.stage[SG_SHADERSTAGE_FS];\r\n            if (bindings->fs_images[i].id != SG_INVALID_ID) {\r\n                SOKOL_VALIDATE(i < stage->num_images, _SG_VALIDATE_ABND_FS_IMGS);\r\n                const _sg_image_t* img = _sg_lookup_image(&_sg.pools, bindings->fs_images[i].id);\r\n                SOKOL_VALIDATE(img != 0, _SG_VALIDATE_ABND_FS_IMG_EXISTS);\r\n                if (img && img->slot.state == SG_RESOURCESTATE_VALID) {\r\n                    SOKOL_VALIDATE(img->cmn.type == stage->images[i].type, _SG_VALIDATE_ABND_FS_IMG_TYPES);\r\n                }\r\n            }\r\n            else {\r\n                SOKOL_VALIDATE(i >= stage->num_images, _SG_VALIDATE_ABND_FS_IMGS);\r\n            }\r\n        }\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_apply_uniforms(sg_shader_stage stage_index, int ub_index, const void* data, int num_bytes) {\r\n    _SOKOL_UNUSED(data);\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(stage_index);\r\n        _SOKOL_UNUSED(ub_index);\r\n        _SOKOL_UNUSED(num_bytes);\r\n        return true;\r\n    #else\r\n        SOKOL_ASSERT((stage_index == SG_SHADERSTAGE_VS) || (stage_index == SG_SHADERSTAGE_FS));\r\n        SOKOL_ASSERT((ub_index >= 0) && (ub_index < SG_MAX_SHADERSTAGE_UBS));\r\n        SOKOL_VALIDATE_BEGIN();\r\n        SOKOL_VALIDATE(_sg.cur_pipeline.id != SG_INVALID_ID, _SG_VALIDATE_AUB_NO_PIPELINE);\r\n        const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, _sg.cur_pipeline.id);\r\n        SOKOL_ASSERT(pip && (pip->slot.id == _sg.cur_pipeline.id));\r\n        SOKOL_ASSERT(pip->shader && (pip->shader->slot.id == pip->cmn.shader_id.id));\r\n\r\n        /* check that there is a uniform block at 'stage' and 'ub_index' */\r\n        const _sg_shader_stage_t* stage = &pip->shader->cmn.stage[stage_index];\r\n        SOKOL_VALIDATE(ub_index < stage->num_uniform_blocks, _SG_VALIDATE_AUB_NO_UB_AT_SLOT);\r\n\r\n        /* check that the provided data size doesn't exceed the uniform block size */\r\n        SOKOL_VALIDATE(num_bytes <= stage->uniform_blocks[ub_index].size, _SG_VALIDATE_AUB_SIZE);\r\n\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_update_buffer(const _sg_buffer_t* buf, const void* data, int size) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(buf);\r\n        _SOKOL_UNUSED(data);\r\n        _SOKOL_UNUSED(size);\r\n        return true;\r\n    #else\r\n        SOKOL_ASSERT(buf && data);\r\n        SOKOL_VALIDATE_BEGIN();\r\n        SOKOL_VALIDATE(buf->cmn.usage != SG_USAGE_IMMUTABLE, _SG_VALIDATE_UPDATEBUF_USAGE);\r\n        SOKOL_VALIDATE(buf->cmn.size >= size, _SG_VALIDATE_UPDATEBUF_SIZE);\r\n        SOKOL_VALIDATE(buf->cmn.update_frame_index != _sg.frame_index, _SG_VALIDATE_UPDATEBUF_ONCE);\r\n        SOKOL_VALIDATE(buf->cmn.append_frame_index != _sg.frame_index, _SG_VALIDATE_UPDATEBUF_APPEND);\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_append_buffer(const _sg_buffer_t* buf, const void* data, int size) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(buf);\r\n        _SOKOL_UNUSED(data);\r\n        _SOKOL_UNUSED(size);\r\n        return true;\r\n    #else\r\n        SOKOL_ASSERT(buf && data);\r\n        SOKOL_VALIDATE_BEGIN();\r\n        SOKOL_VALIDATE(buf->cmn.usage != SG_USAGE_IMMUTABLE, _SG_VALIDATE_APPENDBUF_USAGE);\r\n        SOKOL_VALIDATE(buf->cmn.size >= (buf->cmn.append_pos+size), _SG_VALIDATE_APPENDBUF_SIZE);\r\n        SOKOL_VALIDATE(buf->cmn.update_frame_index != _sg.frame_index, _SG_VALIDATE_APPENDBUF_UPDATE);\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n_SOKOL_PRIVATE bool _sg_validate_update_image(const _sg_image_t* img, const sg_image_content* data) {\r\n    #if !defined(SOKOL_DEBUG)\r\n        _SOKOL_UNUSED(img);\r\n        _SOKOL_UNUSED(data);\r\n        return true;\r\n    #else\r\n        SOKOL_ASSERT(img && data);\r\n        SOKOL_VALIDATE_BEGIN();\r\n        SOKOL_VALIDATE(img->cmn.usage != SG_USAGE_IMMUTABLE, _SG_VALIDATE_UPDIMG_USAGE);\r\n        SOKOL_VALIDATE(img->cmn.upd_frame_index != _sg.frame_index, _SG_VALIDATE_UPDIMG_ONCE);\r\n        SOKOL_VALIDATE(!_sg_is_compressed_pixel_format(img->cmn.pixel_format), _SG_VALIDATE_UPDIMG_COMPRESSED);\r\n        const int num_faces = (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6 : 1;\r\n        const int num_mips = img->cmn.num_mipmaps;\r\n        for (int face_index = 0; face_index < num_faces; face_index++) {\r\n            for (int mip_index = 0; mip_index < num_mips; mip_index++) {\r\n                SOKOL_VALIDATE(0 != data->subimage[face_index][mip_index].ptr, _SG_VALIDATE_UPDIMG_NOTENOUGHDATA);\r\n                const int mip_width = _sg_max(img->cmn.width >> mip_index, 1);\r\n                const int mip_height = _sg_max(img->cmn.height >> mip_index, 1);\r\n                const int bytes_per_slice = _sg_surface_pitch(img->cmn.pixel_format, mip_width, mip_height, 1);\r\n                const int expected_size = bytes_per_slice * img->cmn.depth;\r\n                SOKOL_VALIDATE(data->subimage[face_index][mip_index].size <= expected_size, _SG_VALIDATE_UPDIMG_SIZE);\r\n            }\r\n        }\r\n        return SOKOL_VALIDATE_END();\r\n    #endif\r\n}\r\n\r\n/*== fill in desc default values =============================================*/\r\n_SOKOL_PRIVATE sg_buffer_desc _sg_buffer_desc_defaults(const sg_buffer_desc* desc) {\r\n    sg_buffer_desc def = *desc;\r\n    def.type = _sg_def(def.type, SG_BUFFERTYPE_VERTEXBUFFER);\r\n    def.usage = _sg_def(def.usage, SG_USAGE_IMMUTABLE);\r\n    return def;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_image_desc _sg_image_desc_defaults(const sg_image_desc* desc) {\r\n    sg_image_desc def = *desc;\r\n    def.type = _sg_def(def.type, SG_IMAGETYPE_2D);\r\n    def.depth = _sg_def(def.depth, 1);\r\n    def.num_mipmaps = _sg_def(def.num_mipmaps, 1);\r\n    def.usage = _sg_def(def.usage, SG_USAGE_IMMUTABLE);\r\n    if (desc->render_target) {\r\n        def.pixel_format = _sg_def(def.pixel_format, _sg.desc.context.color_format);\r\n        def.sample_count = _sg_def(def.sample_count, _sg.desc.context.sample_count);\r\n    }\r\n    else {\r\n        def.pixel_format = _sg_def(def.pixel_format, SG_PIXELFORMAT_RGBA8);\r\n        def.sample_count = _sg_def(def.sample_count, 1);\r\n    }\r\n    def.min_filter = _sg_def(def.min_filter, SG_FILTER_NEAREST);\r\n    def.mag_filter = _sg_def(def.mag_filter, SG_FILTER_NEAREST);\r\n    def.wrap_u = _sg_def(def.wrap_u, SG_WRAP_REPEAT);\r\n    def.wrap_v = _sg_def(def.wrap_v, SG_WRAP_REPEAT);\r\n    def.wrap_w = _sg_def(def.wrap_w, SG_WRAP_REPEAT);\r\n    def.border_color = _sg_def(def.border_color, SG_BORDERCOLOR_OPAQUE_BLACK);\r\n    def.max_anisotropy = _sg_def(def.max_anisotropy, 1);\r\n    def.max_lod = _sg_def_flt(def.max_lod, FLT_MAX);\r\n    return def;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_shader_desc _sg_shader_desc_defaults(const sg_shader_desc* desc) {\r\n    sg_shader_desc def = *desc;\r\n    #if defined(SOKOL_METAL)\r\n        def.vs.entry = _sg_def(def.vs.entry, \"_main\");\r\n        def.fs.entry = _sg_def(def.fs.entry, \"_main\");\r\n    #else\r\n        def.vs.entry = _sg_def(def.vs.entry, \"main\");\r\n        def.fs.entry = _sg_def(def.fs.entry, \"main\");\r\n    #endif\r\n    #if defined(SOKOL_D3D11)\r\n        if (def.vs.source) {\r\n            def.vs.d3d11_target = _sg_def(def.vs.d3d11_target, \"vs_4_0\");\r\n        }\r\n        if (def.fs.source) {\r\n            def.fs.d3d11_target = _sg_def(def.fs.d3d11_target, \"ps_4_0\");\r\n        }\r\n    #endif\r\n    for (int stage_index = 0; stage_index < SG_NUM_SHADER_STAGES; stage_index++) {\r\n        sg_shader_stage_desc* stage_desc = (stage_index == SG_SHADERSTAGE_VS)? &def.vs : &def.fs;\r\n        for (int ub_index = 0; ub_index < SG_MAX_SHADERSTAGE_UBS; ub_index++) {\r\n            sg_shader_uniform_block_desc* ub_desc = &stage_desc->uniform_blocks[ub_index];\r\n            if (0 == ub_desc->size) {\r\n                break;\r\n            }\r\n            for (int u_index = 0; u_index < SG_MAX_UB_MEMBERS; u_index++) {\r\n                sg_shader_uniform_desc* u_desc = &ub_desc->uniforms[u_index];\r\n                if (u_desc->type == SG_UNIFORMTYPE_INVALID) {\r\n                    break;\r\n                }\r\n                u_desc->array_count = _sg_def(u_desc->array_count, 1);\r\n            }\r\n        }\r\n        for (int img_index = 0; img_index < SG_MAX_SHADERSTAGE_IMAGES; img_index++) {\r\n            sg_shader_image_desc* img_desc = &stage_desc->images[img_index];\r\n            if (img_desc->type == _SG_IMAGETYPE_DEFAULT) {\r\n                break;\r\n            }\r\n            img_desc->sampler_type = _sg_def(img_desc->sampler_type, SG_SAMPLERTYPE_FLOAT);\r\n        }\r\n    }\r\n    return def;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_pipeline_desc _sg_pipeline_desc_defaults(const sg_pipeline_desc* desc) {\r\n    sg_pipeline_desc def = *desc;\r\n\r\n    def.primitive_type = _sg_def(def.primitive_type, SG_PRIMITIVETYPE_TRIANGLES);\r\n    def.index_type = _sg_def(def.index_type, SG_INDEXTYPE_NONE);\r\n\r\n    def.depth_stencil.stencil_front.fail_op = _sg_def(def.depth_stencil.stencil_front.fail_op, SG_STENCILOP_KEEP);\r\n    def.depth_stencil.stencil_front.depth_fail_op = _sg_def(def.depth_stencil.stencil_front.depth_fail_op, SG_STENCILOP_KEEP);\r\n    def.depth_stencil.stencil_front.pass_op = _sg_def(def.depth_stencil.stencil_front.pass_op, SG_STENCILOP_KEEP);\r\n    def.depth_stencil.stencil_front.compare_func = _sg_def(def.depth_stencil.stencil_front.compare_func, SG_COMPAREFUNC_ALWAYS);\r\n    def.depth_stencil.stencil_back.fail_op = _sg_def(def.depth_stencil.stencil_back.fail_op, SG_STENCILOP_KEEP);\r\n    def.depth_stencil.stencil_back.depth_fail_op = _sg_def(def.depth_stencil.stencil_back.depth_fail_op, SG_STENCILOP_KEEP);\r\n    def.depth_stencil.stencil_back.pass_op = _sg_def(def.depth_stencil.stencil_back.pass_op, SG_STENCILOP_KEEP);\r\n    def.depth_stencil.stencil_back.compare_func = _sg_def(def.depth_stencil.stencil_back.compare_func, SG_COMPAREFUNC_ALWAYS);\r\n    def.depth_stencil.depth_compare_func = _sg_def(def.depth_stencil.depth_compare_func, SG_COMPAREFUNC_ALWAYS);\r\n\r\n    def.blend.src_factor_rgb = _sg_def(def.blend.src_factor_rgb, SG_BLENDFACTOR_ONE);\r\n    def.blend.dst_factor_rgb = _sg_def(def.blend.dst_factor_rgb, SG_BLENDFACTOR_ZERO);\r\n    def.blend.op_rgb = _sg_def(def.blend.op_rgb, SG_BLENDOP_ADD);\r\n    def.blend.src_factor_alpha = _sg_def(def.blend.src_factor_alpha, SG_BLENDFACTOR_ONE);\r\n    def.blend.dst_factor_alpha = _sg_def(def.blend.dst_factor_alpha, SG_BLENDFACTOR_ZERO);\r\n    def.blend.op_alpha = _sg_def(def.blend.op_alpha, SG_BLENDOP_ADD);\r\n    if (def.blend.color_write_mask == SG_COLORMASK_NONE) {\r\n        def.blend.color_write_mask = 0;\r\n    }\r\n    else {\r\n        def.blend.color_write_mask = (uint8_t) _sg_def((sg_color_mask)def.blend.color_write_mask, SG_COLORMASK_RGBA);\r\n    }\r\n    def.blend.color_attachment_count = _sg_def(def.blend.color_attachment_count, 1);\r\n    def.blend.color_format = _sg_def(def.blend.color_format, _sg.desc.context.color_format);\r\n    def.blend.depth_format = _sg_def(def.blend.depth_format, _sg.desc.context.depth_format);\r\n\r\n    def.rasterizer.cull_mode = _sg_def(def.rasterizer.cull_mode, SG_CULLMODE_NONE);\r\n    def.rasterizer.face_winding = _sg_def(def.rasterizer.face_winding, SG_FACEWINDING_CW);\r\n    def.rasterizer.sample_count = _sg_def(def.rasterizer.sample_count, _sg.desc.context.sample_count);\r\n\r\n    for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {\r\n        sg_vertex_attr_desc* a_desc = &def.layout.attrs[attr_index];\r\n        if (a_desc->format == SG_VERTEXFORMAT_INVALID) {\r\n            break;\r\n        }\r\n        SOKOL_ASSERT((a_desc->buffer_index >= 0) && (a_desc->buffer_index < SG_MAX_SHADERSTAGE_BUFFERS));\r\n        sg_buffer_layout_desc* b_desc = &def.layout.buffers[a_desc->buffer_index];\r\n        b_desc->step_func = _sg_def(b_desc->step_func, SG_VERTEXSTEP_PER_VERTEX);\r\n        b_desc->step_rate = _sg_def(b_desc->step_rate, 1);\r\n    }\r\n\r\n    /* resolve vertex layout strides and offsets */\r\n    int auto_offset[SG_MAX_SHADERSTAGE_BUFFERS];\r\n    memset(auto_offset, 0, sizeof(auto_offset));\r\n    bool use_auto_offset = true;\r\n    for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {\r\n        /* to use computed offsets, *all* attr offsets must be 0 */\r\n        if (def.layout.attrs[attr_index].offset != 0) {\r\n            use_auto_offset = false;\r\n        }\r\n    }\r\n    for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {\r\n        sg_vertex_attr_desc* a_desc = &def.layout.attrs[attr_index];\r\n        if (a_desc->format == SG_VERTEXFORMAT_INVALID) {\r\n            break;\r\n        }\r\n        SOKOL_ASSERT((a_desc->buffer_index >= 0) && (a_desc->buffer_index < SG_MAX_SHADERSTAGE_BUFFERS));\r\n        if (use_auto_offset) {\r\n            a_desc->offset = auto_offset[a_desc->buffer_index];\r\n        }\r\n        auto_offset[a_desc->buffer_index] += _sg_vertexformat_bytesize(a_desc->format);\r\n    }\r\n    /* compute vertex strides if needed */\r\n    for (int buf_index = 0; buf_index < SG_MAX_SHADERSTAGE_BUFFERS; buf_index++) {\r\n        sg_buffer_layout_desc* l_desc = &def.layout.buffers[buf_index];\r\n        if (l_desc->stride == 0) {\r\n            l_desc->stride = auto_offset[buf_index];\r\n        }\r\n    }\r\n\r\n    return def;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_pass_desc _sg_pass_desc_defaults(const sg_pass_desc* desc) {\r\n    /* FIXME: no values to replace in sg_pass_desc? */\r\n    sg_pass_desc def = *desc;\r\n    return def;\r\n}\r\n\r\n/*== allocate/initialize resource private functions ==========================*/\r\n_SOKOL_PRIVATE sg_buffer _sg_alloc_buffer(void) {\r\n    sg_buffer res;\r\n    int slot_index = _sg_pool_alloc_index(&_sg.pools.buffer_pool);\r\n    if (_SG_INVALID_SLOT_INDEX != slot_index) {\r\n        res.id = _sg_slot_alloc(&_sg.pools.buffer_pool, &_sg.pools.buffers[slot_index].slot, slot_index);\r\n    }\r\n    else {\r\n        /* pool is exhausted */\r\n        res.id = SG_INVALID_ID;\r\n    }\r\n    return res;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_image _sg_alloc_image(void) {\r\n    sg_image res;\r\n    int slot_index = _sg_pool_alloc_index(&_sg.pools.image_pool);\r\n    if (_SG_INVALID_SLOT_INDEX != slot_index) {\r\n        res.id = _sg_slot_alloc(&_sg.pools.image_pool, &_sg.pools.images[slot_index].slot, slot_index);\r\n    }\r\n    else {\r\n        /* pool is exhausted */\r\n        res.id = SG_INVALID_ID;\r\n    }\r\n    return res;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_shader _sg_alloc_shader(void) {\r\n    sg_shader res;\r\n    int slot_index = _sg_pool_alloc_index(&_sg.pools.shader_pool);\r\n    if (_SG_INVALID_SLOT_INDEX != slot_index) {\r\n        res.id = _sg_slot_alloc(&_sg.pools.shader_pool, &_sg.pools.shaders[slot_index].slot, slot_index);\r\n    }\r\n    else {\r\n        /* pool is exhausted */\r\n        res.id = SG_INVALID_ID;\r\n    }\r\n    return res;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_pipeline _sg_alloc_pipeline(void) {\r\n    sg_pipeline res;\r\n    int slot_index = _sg_pool_alloc_index(&_sg.pools.pipeline_pool);\r\n    if (_SG_INVALID_SLOT_INDEX != slot_index) {\r\n        res.id =_sg_slot_alloc(&_sg.pools.pipeline_pool, &_sg.pools.pipelines[slot_index].slot, slot_index);\r\n    }\r\n    else {\r\n        /* pool is exhausted */\r\n        res.id = SG_INVALID_ID;\r\n    }\r\n    return res;\r\n}\r\n\r\n_SOKOL_PRIVATE sg_pass _sg_alloc_pass(void) {\r\n    sg_pass res;\r\n    int slot_index = _sg_pool_alloc_index(&_sg.pools.pass_pool);\r\n    if (_SG_INVALID_SLOT_INDEX != slot_index) {\r\n        res.id = _sg_slot_alloc(&_sg.pools.pass_pool, &_sg.pools.passes[slot_index].slot, slot_index);\r\n    }\r\n    else {\r\n        /* pool is exhausted */\r\n        res.id = SG_INVALID_ID;\r\n    }\r\n    return res;\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_init_buffer(sg_buffer buf_id, const sg_buffer_desc* desc) {\r\n    SOKOL_ASSERT(buf_id.id != SG_INVALID_ID && desc);\r\n    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);\r\n    SOKOL_ASSERT(buf && buf->slot.state == SG_RESOURCESTATE_ALLOC);\r\n    buf->slot.ctx_id = _sg.active_context.id;\r\n    if (_sg_validate_buffer_desc(desc)) {\r\n        buf->slot.state = _sg_create_buffer(buf, desc);\r\n    }\r\n    else {\r\n        buf->slot.state = SG_RESOURCESTATE_FAILED;\r\n    }\r\n    SOKOL_ASSERT((buf->slot.state == SG_RESOURCESTATE_VALID)||(buf->slot.state == SG_RESOURCESTATE_FAILED));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_init_image(sg_image img_id, const sg_image_desc* desc) {\r\n    SOKOL_ASSERT(img_id.id != SG_INVALID_ID && desc);\r\n    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);\r\n    SOKOL_ASSERT(img && img->slot.state == SG_RESOURCESTATE_ALLOC);\r\n    img->slot.ctx_id = _sg.active_context.id;\r\n    if (_sg_validate_image_desc(desc)) {\r\n        img->slot.state = _sg_create_image(img, desc);\r\n    }\r\n    else {\r\n        img->slot.state = SG_RESOURCESTATE_FAILED;\r\n    }\r\n    SOKOL_ASSERT((img->slot.state == SG_RESOURCESTATE_VALID)||(img->slot.state == SG_RESOURCESTATE_FAILED));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_init_shader(sg_shader shd_id, const sg_shader_desc* desc) {\r\n    SOKOL_ASSERT(shd_id.id != SG_INVALID_ID && desc);\r\n    _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);\r\n    SOKOL_ASSERT(shd && shd->slot.state == SG_RESOURCESTATE_ALLOC);\r\n    shd->slot.ctx_id = _sg.active_context.id;\r\n    if (_sg_validate_shader_desc(desc)) {\r\n        shd->slot.state = _sg_create_shader(shd, desc);\r\n    }\r\n    else {\r\n        shd->slot.state = SG_RESOURCESTATE_FAILED;\r\n    }\r\n    SOKOL_ASSERT((shd->slot.state == SG_RESOURCESTATE_VALID)||(shd->slot.state == SG_RESOURCESTATE_FAILED));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_init_pipeline(sg_pipeline pip_id, const sg_pipeline_desc* desc) {\r\n    SOKOL_ASSERT(pip_id.id != SG_INVALID_ID && desc);\r\n    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);\r\n    SOKOL_ASSERT(pip && pip->slot.state == SG_RESOURCESTATE_ALLOC);\r\n    pip->slot.ctx_id = _sg.active_context.id;\r\n    if (_sg_validate_pipeline_desc(desc)) {\r\n        _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, desc->shader.id);\r\n        if (shd && (shd->slot.state == SG_RESOURCESTATE_VALID)) {\r\n            pip->slot.state = _sg_create_pipeline(pip, shd, desc);\r\n        }\r\n        else {\r\n            pip->slot.state = SG_RESOURCESTATE_FAILED;\r\n        }\r\n    }\r\n    else {\r\n        pip->slot.state = SG_RESOURCESTATE_FAILED;\r\n    }\r\n    SOKOL_ASSERT((pip->slot.state == SG_RESOURCESTATE_VALID)||(pip->slot.state == SG_RESOURCESTATE_FAILED));\r\n}\r\n\r\n_SOKOL_PRIVATE void _sg_init_pass(sg_pass pass_id, const sg_pass_desc* desc) {\r\n    SOKOL_ASSERT(pass_id.id != SG_INVALID_ID && desc);\r\n    _sg_pass_t* pass = _sg_lookup_pass(&_sg.pools, pass_id.id);\r\n    SOKOL_ASSERT(pass && pass->slot.state == SG_RESOURCESTATE_ALLOC);\r\n    pass->slot.ctx_id = _sg.active_context.id;\r\n    if (_sg_validate_pass_desc(desc)) {\r\n        /* lookup pass attachment image pointers */\r\n        _sg_image_t* att_imgs[SG_MAX_COLOR_ATTACHMENTS + 1];\r\n        for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {\r\n            if (desc->color_attachments[i].image.id) {\r\n                att_imgs[i] = _sg_lookup_image(&_sg.pools, desc->color_attachments[i].image.id);\r\n                /* FIXME: this shouldn't be an assertion, but result in a SG_RESOURCESTATE_FAILED pass */\r\n                SOKOL_ASSERT(att_imgs[i] && att_imgs[i]->slot.state == SG_RESOURCESTATE_VALID);\r\n            }\r\n            else {\r\n                att_imgs[i] = 0;\r\n            }\r\n        }\r\n        const int ds_att_index = SG_MAX_COLOR_ATTACHMENTS;\r\n        if (desc->depth_stencil_attachment.image.id) {\r\n            att_imgs[ds_att_index] = _sg_lookup_image(&_sg.pools, desc->depth_stencil_attachment.image.id);\r\n            /* FIXME: this shouldn't be an assertion, but result in a SG_RESOURCESTATE_FAILED pass */\r\n            SOKOL_ASSERT(att_imgs[ds_att_index] && att_imgs[ds_att_index]->slot.state == SG_RESOURCESTATE_VALID);\r\n        }\r\n        else {\r\n            att_imgs[ds_att_index] = 0;\r\n        }\r\n        pass->slot.state = _sg_create_pass(pass, att_imgs, desc);\r\n    }\r\n    else {\r\n        pass->slot.state = SG_RESOURCESTATE_FAILED;\r\n    }\r\n    SOKOL_ASSERT((pass->slot.state == SG_RESOURCESTATE_VALID)||(pass->slot.state == SG_RESOURCESTATE_FAILED));\r\n}\r\n\r\n/*== PUBLIC API FUNCTIONS ====================================================*/\r\n\r\n#if defined(SOKOL_METAL)\r\n    // this is ARC compatible\r\n    #if defined(__cplusplus)\r\n        #define _SG_CLEAR(type, item) { item = { }; }\r\n    #else\r\n        #define _SG_CLEAR(type, item) { item = (type) { 0 }; }\r\n    #endif\r\n#else\r\n    #define _SG_CLEAR(type, item) { memset(&item, 0, sizeof(item)); }\r\n#endif\r\n\r\nSOKOL_API_IMPL void sg_setup(const sg_desc* desc) {\r\n    SOKOL_ASSERT(desc);\r\n    SOKOL_ASSERT((desc->_start_canary == 0) && (desc->_end_canary == 0));\r\n    _SG_CLEAR(_sg_state_t, _sg);\r\n    _sg.desc = *desc;\r\n\r\n    /* replace zero-init items with their default values\r\n        NOTE: on WebGPU, the default color pixel format MUST be provided,\r\n        cannot be a default compile-time constant.\r\n    */\r\n    #if defined(SOKOL_WGPU)\r\n        SOKOL_ASSERT(SG_PIXELFORMAT_NONE != _sg.desc.context.color_format);\r\n    #elif defined(SOKOL_METAL) || defined(SOKOL_D3D11)\r\n        _sg.desc.context.color_format = _sg_def(_sg.desc.context.color_format, SG_PIXELFORMAT_BGRA8);\r\n    #else\r\n        _sg.desc.context.color_format = _sg_def(_sg.desc.context.color_format, SG_PIXELFORMAT_RGBA8);\r\n    #endif\r\n    _sg.desc.context.depth_format = _sg_def(_sg.desc.context.depth_format, SG_PIXELFORMAT_DEPTH_STENCIL);\r\n    _sg.desc.context.sample_count = _sg_def(_sg.desc.context.sample_count, 1);\r\n    _sg.desc.buffer_pool_size = _sg_def(_sg.desc.buffer_pool_size, _SG_DEFAULT_BUFFER_POOL_SIZE);\r\n    _sg.desc.image_pool_size = _sg_def(_sg.desc.image_pool_size, _SG_DEFAULT_IMAGE_POOL_SIZE);\r\n    _sg.desc.shader_pool_size = _sg_def(_sg.desc.shader_pool_size, _SG_DEFAULT_SHADER_POOL_SIZE);\r\n    _sg.desc.pipeline_pool_size = _sg_def(_sg.desc.pipeline_pool_size, _SG_DEFAULT_PIPELINE_POOL_SIZE);\r\n    _sg.desc.pass_pool_size = _sg_def(_sg.desc.pass_pool_size, _SG_DEFAULT_PASS_POOL_SIZE);\r\n    _sg.desc.context_pool_size = _sg_def(_sg.desc.context_pool_size, _SG_DEFAULT_CONTEXT_POOL_SIZE);\r\n    _sg.desc.uniform_buffer_size = _sg_def(_sg.desc.uniform_buffer_size, _SG_DEFAULT_UB_SIZE);\r\n    _sg.desc.staging_buffer_size = _sg_def(_sg.desc.staging_buffer_size, _SG_DEFAULT_STAGING_SIZE);\r\n    _sg.desc.sampler_cache_size = _sg_def(_sg.desc.sampler_cache_size, _SG_DEFAULT_SAMPLER_CACHE_CAPACITY);\r\n\r\n    _sg_setup_pools(&_sg.pools, &_sg.desc);\r\n    _sg.frame_index = 1;\r\n    _sg_setup_backend(&_sg.desc);\r\n    _sg.valid = true;\r\n    sg_setup_context();\r\n}\r\n\r\nSOKOL_API_IMPL void sg_shutdown(void) {\r\n    /* can only delete resources for the currently set context here, if multiple\r\n    contexts are used, the app code must take care of properly releasing them\r\n    (since only the app code can switch between 3D-API contexts)\r\n    */\r\n    if (_sg.active_context.id != SG_INVALID_ID) {\r\n        _sg_context_t* ctx = _sg_lookup_context(&_sg.pools, _sg.active_context.id);\r\n        if (ctx) {\r\n            _sg_destroy_all_resources(&_sg.pools, _sg.active_context.id);\r\n            _sg_destroy_context(ctx);\r\n        }\r\n    }\r\n    _sg_discard_backend();\r\n    _sg_discard_pools(&_sg.pools);\r\n    _sg.valid = false;\r\n}\r\n\r\nSOKOL_API_IMPL bool sg_isvalid(void) {\r\n    return _sg.valid;\r\n}\r\n\r\nSOKOL_API_IMPL sg_desc sg_query_desc(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    return _sg.desc;\r\n}\r\n\r\nSOKOL_API_IMPL sg_backend sg_query_backend(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    return _sg.backend;\r\n}\r\n\r\nSOKOL_API_IMPL sg_features sg_query_features(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    return _sg.features;\r\n}\r\n\r\nSOKOL_API_IMPL sg_limits sg_query_limits(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    return _sg.limits;\r\n}\r\n\r\nSOKOL_API_IMPL sg_pixelformat_info sg_query_pixelformat(sg_pixel_format fmt) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    int fmt_index = (int) fmt;\r\n    SOKOL_ASSERT((fmt_index > SG_PIXELFORMAT_NONE) && (fmt_index < _SG_PIXELFORMAT_NUM));\r\n    return _sg.formats[fmt_index];\r\n}\r\n\r\nSOKOL_API_IMPL sg_context sg_setup_context(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_context res;\r\n    int slot_index = _sg_pool_alloc_index(&_sg.pools.context_pool);\r\n    if (_SG_INVALID_SLOT_INDEX != slot_index) {\r\n        res.id = _sg_slot_alloc(&_sg.pools.context_pool, &_sg.pools.contexts[slot_index].slot, slot_index);\r\n        _sg_context_t* ctx = _sg_context_at(&_sg.pools, res.id);\r\n        ctx->slot.state = _sg_create_context(ctx);\r\n        SOKOL_ASSERT(ctx->slot.state == SG_RESOURCESTATE_VALID);\r\n        _sg_activate_context(ctx);\r\n    }\r\n    else {\r\n        /* pool is exhausted */\r\n        res.id = SG_INVALID_ID;\r\n    }\r\n    _sg.active_context = res;\r\n    return res;\r\n}\r\n\r\nSOKOL_API_IMPL void sg_discard_context(sg_context ctx_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_destroy_all_resources(&_sg.pools, ctx_id.id);\r\n    _sg_context_t* ctx = _sg_lookup_context(&_sg.pools, ctx_id.id);\r\n    if (ctx) {\r\n        _sg_destroy_context(ctx);\r\n        _sg_reset_context(ctx);\r\n        _sg_pool_free_index(&_sg.pools.context_pool, _sg_slot_index(ctx_id.id));\r\n    }\r\n    _sg.active_context.id = SG_INVALID_ID;\r\n    _sg_activate_context(0);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_activate_context(sg_context ctx_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg.active_context = ctx_id;\r\n    _sg_context_t* ctx = _sg_lookup_context(&_sg.pools, ctx_id.id);\r\n    /* NOTE: ctx can be 0 here if the context is no longer valid */\r\n    _sg_activate_context(ctx);\r\n}\r\n\r\nSOKOL_API_IMPL sg_trace_hooks sg_install_trace_hooks(const sg_trace_hooks* trace_hooks) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(trace_hooks);\r\n    _SOKOL_UNUSED(trace_hooks);\r\n    #if defined(SOKOL_TRACE_HOOKS)\r\n        sg_trace_hooks old_hooks = _sg.hooks;\r\n        _sg.hooks = *trace_hooks;\r\n    #else\r\n        static sg_trace_hooks old_hooks;\r\n        SOKOL_LOG(\"sg_install_trace_hooks() called, but SG_TRACE_HOOKS is not defined!\");\r\n    #endif\r\n    return old_hooks;\r\n}\r\n\r\nSOKOL_API_IMPL sg_buffer sg_alloc_buffer(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_buffer res = _sg_alloc_buffer();\r\n    _SG_TRACE_ARGS(alloc_buffer, res);\r\n    return res;\r\n}\r\n\r\nSOKOL_API_IMPL sg_image sg_alloc_image(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_image res = _sg_alloc_image();\r\n    _SG_TRACE_ARGS(alloc_image, res);\r\n    return res;\r\n}\r\n\r\nSOKOL_API_IMPL sg_shader sg_alloc_shader(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_shader res = _sg_alloc_shader();\r\n    _SG_TRACE_ARGS(alloc_shader, res);\r\n    return res;\r\n}\r\n\r\nSOKOL_API_IMPL sg_pipeline sg_alloc_pipeline(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_pipeline res = _sg_alloc_pipeline();\r\n    _SG_TRACE_ARGS(alloc_pipeline, res);\r\n    return res;\r\n}\r\n\r\nSOKOL_API_IMPL sg_pass sg_alloc_pass(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_pass res = _sg_alloc_pass();\r\n    _SG_TRACE_ARGS(alloc_pass, res);\r\n    return res;\r\n}\r\n\r\nSOKOL_API_IMPL void sg_init_buffer(sg_buffer buf_id, const sg_buffer_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_buffer_desc desc_def = _sg_buffer_desc_defaults(desc);\r\n    _sg_init_buffer(buf_id, &desc_def);\r\n    _SG_TRACE_ARGS(init_buffer, buf_id, &desc_def);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_init_image(sg_image img_id, const sg_image_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_image_desc desc_def = _sg_image_desc_defaults(desc);\r\n    _sg_init_image(img_id, &desc_def);\r\n    _SG_TRACE_ARGS(init_image, img_id, &desc_def);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_init_shader(sg_shader shd_id, const sg_shader_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_shader_desc desc_def = _sg_shader_desc_defaults(desc);\r\n    _sg_init_shader(shd_id, &desc_def);\r\n    _SG_TRACE_ARGS(init_shader, shd_id, &desc_def);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_init_pipeline(sg_pipeline pip_id, const sg_pipeline_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_pipeline_desc desc_def = _sg_pipeline_desc_defaults(desc);\r\n    _sg_init_pipeline(pip_id, &desc_def);\r\n    _SG_TRACE_ARGS(init_pipeline, pip_id, &desc_def);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_init_pass(sg_pass pass_id, const sg_pass_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_pass_desc desc_def = _sg_pass_desc_defaults(desc);\r\n    _sg_init_pass(pass_id, &desc_def);\r\n    _SG_TRACE_ARGS(init_pass, pass_id, &desc_def);\r\n}\r\n\r\n/*-- set allocated resource to failed state ----------------------------------*/\r\nSOKOL_API_IMPL void sg_fail_buffer(sg_buffer buf_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(buf_id.id != SG_INVALID_ID);\r\n    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);\r\n    SOKOL_ASSERT(buf && buf->slot.state == SG_RESOURCESTATE_ALLOC);\r\n    buf->slot.ctx_id = _sg.active_context.id;\r\n    buf->slot.state = SG_RESOURCESTATE_FAILED;\r\n    _SG_TRACE_ARGS(fail_buffer, buf_id);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_fail_image(sg_image img_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(img_id.id != SG_INVALID_ID);\r\n    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);\r\n    SOKOL_ASSERT(img && img->slot.state == SG_RESOURCESTATE_ALLOC);\r\n    img->slot.ctx_id = _sg.active_context.id;\r\n    img->slot.state = SG_RESOURCESTATE_FAILED;\r\n    _SG_TRACE_ARGS(fail_image, img_id);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_fail_shader(sg_shader shd_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(shd_id.id != SG_INVALID_ID);\r\n    _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);\r\n    SOKOL_ASSERT(shd && shd->slot.state == SG_RESOURCESTATE_ALLOC);\r\n    shd->slot.ctx_id = _sg.active_context.id;\r\n    shd->slot.state = SG_RESOURCESTATE_FAILED;\r\n    _SG_TRACE_ARGS(fail_shader, shd_id);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_fail_pipeline(sg_pipeline pip_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(pip_id.id != SG_INVALID_ID);\r\n    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);\r\n    SOKOL_ASSERT(pip && pip->slot.state == SG_RESOURCESTATE_ALLOC);\r\n    pip->slot.ctx_id = _sg.active_context.id;\r\n    pip->slot.state = SG_RESOURCESTATE_FAILED;\r\n    _SG_TRACE_ARGS(fail_pipeline, pip_id);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_fail_pass(sg_pass pass_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(pass_id.id != SG_INVALID_ID);\r\n    _sg_pass_t* pass = _sg_lookup_pass(&_sg.pools, pass_id.id);\r\n    SOKOL_ASSERT(pass && pass->slot.state == SG_RESOURCESTATE_ALLOC);\r\n    pass->slot.ctx_id = _sg.active_context.id;\r\n    pass->slot.state = SG_RESOURCESTATE_FAILED;\r\n    _SG_TRACE_ARGS(fail_pass, pass_id);\r\n}\r\n\r\n/*-- get resource state */\r\nSOKOL_API_IMPL sg_resource_state sg_query_buffer_state(sg_buffer buf_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);\r\n    sg_resource_state res = buf ? buf->slot.state : SG_RESOURCESTATE_INVALID;\r\n    return res;\r\n}\r\n\r\nSOKOL_API_IMPL sg_resource_state sg_query_image_state(sg_image img_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);\r\n    sg_resource_state res = img ? img->slot.state : SG_RESOURCESTATE_INVALID;\r\n    return res;\r\n}\r\n\r\nSOKOL_API_IMPL sg_resource_state sg_query_shader_state(sg_shader shd_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);\r\n    sg_resource_state res = shd ? shd->slot.state : SG_RESOURCESTATE_INVALID;\r\n    return res;\r\n}\r\n\r\nSOKOL_API_IMPL sg_resource_state sg_query_pipeline_state(sg_pipeline pip_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);\r\n    sg_resource_state res = pip ? pip->slot.state : SG_RESOURCESTATE_INVALID;\r\n    return res;\r\n}\r\n\r\nSOKOL_API_IMPL sg_resource_state sg_query_pass_state(sg_pass pass_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_pass_t* pass = _sg_lookup_pass(&_sg.pools, pass_id.id);\r\n    sg_resource_state res = pass ? pass->slot.state : SG_RESOURCESTATE_INVALID;\r\n    return res;\r\n}\r\n\r\n/*-- allocate and initialize resource ----------------------------------------*/\r\nSOKOL_API_IMPL sg_buffer sg_make_buffer(const sg_buffer_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(desc);\r\n    sg_buffer_desc desc_def = _sg_buffer_desc_defaults(desc);\r\n    sg_buffer buf_id = _sg_alloc_buffer();\r\n    if (buf_id.id != SG_INVALID_ID) {\r\n        _sg_init_buffer(buf_id, &desc_def);\r\n    }\r\n    else {\r\n        SOKOL_LOG(\"buffer pool exhausted!\");\r\n        _SG_TRACE_NOARGS(err_buffer_pool_exhausted);\r\n    }\r\n    _SG_TRACE_ARGS(make_buffer, &desc_def, buf_id);\r\n    return buf_id;\r\n}\r\n\r\nSOKOL_API_IMPL sg_image sg_make_image(const sg_image_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(desc);\r\n    sg_image_desc desc_def = _sg_image_desc_defaults(desc);\r\n    sg_image img_id = _sg_alloc_image();\r\n    if (img_id.id != SG_INVALID_ID) {\r\n        _sg_init_image(img_id, &desc_def);\r\n    }\r\n    else {\r\n        SOKOL_LOG(\"image pool exhausted!\");\r\n        _SG_TRACE_NOARGS(err_image_pool_exhausted);\r\n    }\r\n    _SG_TRACE_ARGS(make_image, &desc_def, img_id);\r\n    return img_id;\r\n}\r\n\r\nSOKOL_API_IMPL sg_shader sg_make_shader(const sg_shader_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(desc);\r\n    sg_shader_desc desc_def = _sg_shader_desc_defaults(desc);\r\n    sg_shader shd_id = _sg_alloc_shader();\r\n    if (shd_id.id != SG_INVALID_ID) {\r\n        _sg_init_shader(shd_id, &desc_def);\r\n    }\r\n    else {\r\n        SOKOL_LOG(\"shader pool exhausted!\");\r\n        _SG_TRACE_NOARGS(err_shader_pool_exhausted);\r\n    }\r\n    _SG_TRACE_ARGS(make_shader, &desc_def, shd_id);\r\n    return shd_id;\r\n}\r\n\r\nSOKOL_API_IMPL sg_pipeline sg_make_pipeline(const sg_pipeline_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(desc);\r\n    sg_pipeline_desc desc_def = _sg_pipeline_desc_defaults(desc);\r\n    sg_pipeline pip_id = _sg_alloc_pipeline();\r\n    if (pip_id.id != SG_INVALID_ID) {\r\n        _sg_init_pipeline(pip_id, &desc_def);\r\n    }\r\n    else {\r\n        SOKOL_LOG(\"pipeline pool exhausted!\");\r\n        _SG_TRACE_NOARGS(err_pipeline_pool_exhausted);\r\n    }\r\n    _SG_TRACE_ARGS(make_pipeline, &desc_def, pip_id);\r\n    return pip_id;\r\n}\r\n\r\nSOKOL_API_IMPL sg_pass sg_make_pass(const sg_pass_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(desc);\r\n    sg_pass_desc desc_def = _sg_pass_desc_defaults(desc);\r\n    sg_pass pass_id = _sg_alloc_pass();\r\n    if (pass_id.id != SG_INVALID_ID) {\r\n        _sg_init_pass(pass_id, &desc_def);\r\n    }\r\n    else {\r\n        SOKOL_LOG(\"pass pool exhausted!\");\r\n        _SG_TRACE_NOARGS(err_pass_pool_exhausted);\r\n    }\r\n    _SG_TRACE_ARGS(make_pass, &desc_def, pass_id);\r\n    return pass_id;\r\n}\r\n\r\n/*-- destroy resource --------------------------------------------------------*/\r\nSOKOL_API_IMPL void sg_destroy_buffer(sg_buffer buf_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _SG_TRACE_ARGS(destroy_buffer, buf_id);\r\n    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);\r\n    if (buf) {\r\n        if (buf->slot.ctx_id == _sg.active_context.id) {\r\n            _sg_destroy_buffer(buf);\r\n            _sg_reset_buffer(buf);\r\n            _sg_pool_free_index(&_sg.pools.buffer_pool, _sg_slot_index(buf_id.id));\r\n        }\r\n        else {\r\n            SOKOL_LOG(\"sg_destroy_buffer: active context mismatch (must be same as for creation)\");\r\n            _SG_TRACE_NOARGS(err_context_mismatch);\r\n        }\r\n    }\r\n}\r\n\r\nSOKOL_API_IMPL void sg_destroy_image(sg_image img_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _SG_TRACE_ARGS(destroy_image, img_id);\r\n    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);\r\n    if (img) {\r\n        if (img->slot.ctx_id == _sg.active_context.id) {\r\n            _sg_destroy_image(img);\r\n            _sg_reset_image(img);\r\n            _sg_pool_free_index(&_sg.pools.image_pool, _sg_slot_index(img_id.id));\r\n        }\r\n        else {\r\n            SOKOL_LOG(\"sg_destroy_image: active context mismatch (must be same as for creation)\");\r\n            _SG_TRACE_NOARGS(err_context_mismatch);\r\n        }\r\n    }\r\n}\r\n\r\nSOKOL_API_IMPL void sg_destroy_shader(sg_shader shd_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _SG_TRACE_ARGS(destroy_shader, shd_id);\r\n    _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);\r\n    if (shd) {\r\n        if (shd->slot.ctx_id == _sg.active_context.id) {\r\n            _sg_destroy_shader(shd);\r\n            _sg_reset_shader(shd);\r\n            _sg_pool_free_index(&_sg.pools.shader_pool, _sg_slot_index(shd_id.id));\r\n        }\r\n        else {\r\n            SOKOL_LOG(\"sg_destroy_shader: active context mismatch (must be same as for creation)\");\r\n            _SG_TRACE_NOARGS(err_context_mismatch);\r\n        }\r\n    }\r\n}\r\n\r\nSOKOL_API_IMPL void sg_destroy_pipeline(sg_pipeline pip_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _SG_TRACE_ARGS(destroy_pipeline, pip_id);\r\n    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);\r\n    if (pip) {\r\n        if (pip->slot.ctx_id == _sg.active_context.id) {\r\n            _sg_destroy_pipeline(pip);\r\n            _sg_reset_pipeline(pip);\r\n            _sg_pool_free_index(&_sg.pools.pipeline_pool, _sg_slot_index(pip_id.id));\r\n        }\r\n        else {\r\n            SOKOL_LOG(\"sg_destroy_pipeline: active context mismatch (must be same as for creation)\");\r\n            _SG_TRACE_NOARGS(err_context_mismatch);\r\n        }\r\n    }\r\n}\r\n\r\nSOKOL_API_IMPL void sg_destroy_pass(sg_pass pass_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _SG_TRACE_ARGS(destroy_pass, pass_id);\r\n    _sg_pass_t* pass = _sg_lookup_pass(&_sg.pools, pass_id.id);\r\n    if (pass) {\r\n        if (pass->slot.ctx_id == _sg.active_context.id) {\r\n            _sg_destroy_pass(pass);\r\n            _sg_reset_pass(pass);\r\n            _sg_pool_free_index(&_sg.pools.pass_pool, _sg_slot_index(pass_id.id));\r\n        }\r\n        else {\r\n            SOKOL_LOG(\"sg_destroy_pass: active context mismatch (must be same as for creation)\");\r\n            _SG_TRACE_NOARGS(err_context_mismatch);\r\n        }\r\n    }\r\n}\r\n\r\nSOKOL_API_IMPL void sg_begin_default_pass(const sg_pass_action* pass_action, int width, int height) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(pass_action);\r\n    SOKOL_ASSERT((pass_action->_start_canary == 0) && (pass_action->_end_canary == 0));\r\n    sg_pass_action pa;\r\n    _sg_resolve_default_pass_action(pass_action, &pa);\r\n    _sg.cur_pass.id = SG_INVALID_ID;\r\n    _sg.pass_valid = true;\r\n    _sg_begin_pass(0, &pa, width, height);\r\n    _SG_TRACE_ARGS(begin_default_pass, pass_action, width, height);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_begin_pass(sg_pass pass_id, const sg_pass_action* pass_action) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(pass_action);\r\n    SOKOL_ASSERT((pass_action->_start_canary == 0) && (pass_action->_end_canary == 0));\r\n    _sg.cur_pass = pass_id;\r\n    _sg_pass_t* pass = _sg_lookup_pass(&_sg.pools, pass_id.id);\r\n    if (pass && _sg_validate_begin_pass(pass)) {\r\n        _sg.pass_valid = true;\r\n        sg_pass_action pa;\r\n        _sg_resolve_default_pass_action(pass_action, &pa);\r\n        const _sg_image_t* img = _sg_pass_color_image(pass, 0);\r\n        SOKOL_ASSERT(img);\r\n        const int w = img->cmn.width;\r\n        const int h = img->cmn.height;\r\n        _sg_begin_pass(pass, &pa, w, h);\r\n        _SG_TRACE_ARGS(begin_pass, pass_id, pass_action);\r\n    }\r\n    else {\r\n        _sg.pass_valid = false;\r\n        _SG_TRACE_NOARGS(err_pass_invalid);\r\n    }\r\n}\r\n\r\nSOKOL_API_IMPL void sg_apply_viewport(int x, int y, int width, int height, bool origin_top_left) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    if (!_sg.pass_valid) {\r\n        _SG_TRACE_NOARGS(err_pass_invalid);\r\n        return;\r\n    }\r\n    _sg_apply_viewport(x, y, width, height, origin_top_left);\r\n    _SG_TRACE_ARGS(apply_viewport, x, y, width, height, origin_top_left);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_apply_scissor_rect(int x, int y, int width, int height, bool origin_top_left) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    if (!_sg.pass_valid) {\r\n        _SG_TRACE_NOARGS(err_pass_invalid);\r\n        return;\r\n    }\r\n    _sg_apply_scissor_rect(x, y, width, height, origin_top_left);\r\n    _SG_TRACE_ARGS(apply_scissor_rect, x, y, width, height, origin_top_left);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_apply_pipeline(sg_pipeline pip_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg.bindings_valid = false;\r\n    if (!_sg_validate_apply_pipeline(pip_id)) {\r\n        _sg.next_draw_valid = false;\r\n        _SG_TRACE_NOARGS(err_draw_invalid);\r\n        return;\r\n    }\r\n    if (!_sg.pass_valid) {\r\n        _SG_TRACE_NOARGS(err_pass_invalid);\r\n        return;\r\n    }\r\n    _sg.cur_pipeline = pip_id;\r\n    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);\r\n    SOKOL_ASSERT(pip);\r\n    _sg.next_draw_valid = (SG_RESOURCESTATE_VALID == pip->slot.state);\r\n    SOKOL_ASSERT(pip->shader && (pip->shader->slot.id == pip->cmn.shader_id.id));\r\n    _sg_apply_pipeline(pip);\r\n    _SG_TRACE_ARGS(apply_pipeline, pip_id);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_apply_bindings(const sg_bindings* bindings) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(bindings);\r\n    SOKOL_ASSERT((bindings->_start_canary == 0) && (bindings->_end_canary==0));\r\n    if (!_sg_validate_apply_bindings(bindings)) {\r\n        _sg.next_draw_valid = false;\r\n        _SG_TRACE_NOARGS(err_draw_invalid);\r\n        return;\r\n    }\r\n    _sg.bindings_valid = true;\r\n\r\n    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, _sg.cur_pipeline.id);\r\n    SOKOL_ASSERT(pip);\r\n\r\n    _sg_buffer_t* vbs[SG_MAX_SHADERSTAGE_BUFFERS] = { 0 };\r\n    int num_vbs = 0;\r\n    for (int i = 0; i < SG_MAX_SHADERSTAGE_BUFFERS; i++, num_vbs++) {\r\n        if (bindings->vertex_buffers[i].id) {\r\n            vbs[i] = _sg_lookup_buffer(&_sg.pools, bindings->vertex_buffers[i].id);\r\n            SOKOL_ASSERT(vbs[i]);\r\n            _sg.next_draw_valid &= (SG_RESOURCESTATE_VALID == vbs[i]->slot.state);\r\n            _sg.next_draw_valid &= !vbs[i]->cmn.append_overflow;\r\n        }\r\n        else {\r\n            break;\r\n        }\r\n    }\r\n\r\n    _sg_buffer_t* ib = 0;\r\n    if (bindings->index_buffer.id) {\r\n        ib = _sg_lookup_buffer(&_sg.pools, bindings->index_buffer.id);\r\n        SOKOL_ASSERT(ib);\r\n        _sg.next_draw_valid &= (SG_RESOURCESTATE_VALID == ib->slot.state);\r\n        _sg.next_draw_valid &= !ib->cmn.append_overflow;\r\n    }\r\n\r\n    _sg_image_t* vs_imgs[SG_MAX_SHADERSTAGE_IMAGES] = { 0 };\r\n    int num_vs_imgs = 0;\r\n    for (int i = 0; i < SG_MAX_SHADERSTAGE_IMAGES; i++, num_vs_imgs++) {\r\n        if (bindings->vs_images[i].id) {\r\n            vs_imgs[i] = _sg_lookup_image(&_sg.pools, bindings->vs_images[i].id);\r\n            SOKOL_ASSERT(vs_imgs[i]);\r\n            _sg.next_draw_valid &= (SG_RESOURCESTATE_VALID == vs_imgs[i]->slot.state);\r\n        }\r\n        else {\r\n            break;\r\n        }\r\n    }\r\n\r\n    _sg_image_t* fs_imgs[SG_MAX_SHADERSTAGE_IMAGES] = { 0 };\r\n    int num_fs_imgs = 0;\r\n    for (int i = 0; i < SG_MAX_SHADERSTAGE_IMAGES; i++, num_fs_imgs++) {\r\n        if (bindings->fs_images[i].id) {\r\n            fs_imgs[i] = _sg_lookup_image(&_sg.pools, bindings->fs_images[i].id);\r\n            SOKOL_ASSERT(fs_imgs[i]);\r\n            _sg.next_draw_valid &= (SG_RESOURCESTATE_VALID == fs_imgs[i]->slot.state);\r\n        }\r\n        else {\r\n            break;\r\n        }\r\n    }\r\n    if (_sg.next_draw_valid) {\r\n        const int* vb_offsets = bindings->vertex_buffer_offsets;\r\n        int ib_offset = bindings->index_buffer_offset;\r\n        _sg_apply_bindings(pip, vbs, vb_offsets, num_vbs, ib, ib_offset, vs_imgs, num_vs_imgs, fs_imgs, num_fs_imgs);\r\n        _SG_TRACE_ARGS(apply_bindings, bindings);\r\n    }\r\n    else {\r\n        _SG_TRACE_NOARGS(err_draw_invalid);\r\n    }\r\n}\r\n\r\nSOKOL_API_IMPL void sg_apply_uniforms(sg_shader_stage stage, int ub_index, const void* data, int num_bytes) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT((stage == SG_SHADERSTAGE_VS) || (stage == SG_SHADERSTAGE_FS));\r\n    SOKOL_ASSERT((ub_index >= 0) && (ub_index < SG_MAX_SHADERSTAGE_UBS));\r\n    SOKOL_ASSERT(data && (num_bytes > 0));\r\n    if (!_sg_validate_apply_uniforms(stage, ub_index, data, num_bytes)) {\r\n        _sg.next_draw_valid = false;\r\n        _SG_TRACE_NOARGS(err_draw_invalid);\r\n        return;\r\n    }\r\n    if (!_sg.pass_valid) {\r\n        _SG_TRACE_NOARGS(err_pass_invalid);\r\n        return;\r\n    }\r\n    if (!_sg.next_draw_valid) {\r\n        _SG_TRACE_NOARGS(err_draw_invalid);\r\n    }\r\n    _sg_apply_uniforms(stage, ub_index, data, num_bytes);\r\n    _SG_TRACE_ARGS(apply_uniforms, stage, ub_index, data, num_bytes);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_draw(int base_element, int num_elements, int num_instances) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    #if defined(SOKOL_DEBUG)\r\n        if (!_sg.bindings_valid) {\r\n            SOKOL_LOG(\"attempting to draw without resource bindings\");\r\n        }\r\n    #endif\r\n    if (!_sg.pass_valid) {\r\n        _SG_TRACE_NOARGS(err_pass_invalid);\r\n        return;\r\n    }\r\n    if (!_sg.next_draw_valid) {\r\n        _SG_TRACE_NOARGS(err_draw_invalid);\r\n        return;\r\n    }\r\n    if (!_sg.bindings_valid) {\r\n        _SG_TRACE_NOARGS(err_bindings_invalid);\r\n        return;\r\n    }\r\n    _sg_draw(base_element, num_elements, num_instances);\r\n    _SG_TRACE_ARGS(draw, base_element, num_elements, num_instances);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_end_pass(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    if (!_sg.pass_valid) {\r\n        _SG_TRACE_NOARGS(err_pass_invalid);\r\n        return;\r\n    }\r\n    _sg_end_pass();\r\n    _sg.cur_pass.id = SG_INVALID_ID;\r\n    _sg.cur_pipeline.id = SG_INVALID_ID;\r\n    _sg.pass_valid = false;\r\n    _SG_TRACE_NOARGS(end_pass);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_commit(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_commit();\r\n    _SG_TRACE_NOARGS(commit);\r\n    _sg.frame_index++;\r\n}\r\n\r\nSOKOL_API_IMPL void sg_reset_state_cache(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_reset_state_cache();\r\n    _SG_TRACE_NOARGS(reset_state_cache);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_update_buffer(sg_buffer buf_id, const void* data, int num_bytes) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);\r\n    if ((num_bytes > 0) && buf && (buf->slot.state == SG_RESOURCESTATE_VALID)) {\r\n        if (_sg_validate_update_buffer(buf, data, num_bytes)) {\r\n            SOKOL_ASSERT(num_bytes <= buf->cmn.size);\r\n            /* only one update allowed per buffer and frame */\r\n            SOKOL_ASSERT(buf->cmn.update_frame_index != _sg.frame_index);\r\n            /* update and append on same buffer in same frame not allowed */\r\n            SOKOL_ASSERT(buf->cmn.append_frame_index != _sg.frame_index);\r\n            _sg_update_buffer(buf, data, (uint32_t)num_bytes);\r\n            buf->cmn.update_frame_index = _sg.frame_index;\r\n        }\r\n    }\r\n    _SG_TRACE_ARGS(update_buffer, buf_id, data, num_bytes);\r\n}\r\n\r\nSOKOL_API_IMPL int sg_append_buffer(sg_buffer buf_id, const void* data, int num_bytes) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);\r\n    int result;\r\n    if (buf) {\r\n        /* rewind append cursor in a new frame */\r\n        if (buf->cmn.append_frame_index != _sg.frame_index) {\r\n            buf->cmn.append_pos = 0;\r\n            buf->cmn.append_overflow = false;\r\n        }\r\n        if ((buf->cmn.append_pos + _sg_roundup(num_bytes, 4)) > buf->cmn.size) {\r\n            buf->cmn.append_overflow = true;\r\n        }\r\n        const int start_pos = buf->cmn.append_pos;\r\n        if (buf->slot.state == SG_RESOURCESTATE_VALID) {\r\n            if (_sg_validate_append_buffer(buf, data, num_bytes)) {\r\n                if (!buf->cmn.append_overflow && (num_bytes > 0)) {\r\n                    /* update and append on same buffer in same frame not allowed */\r\n                    SOKOL_ASSERT(buf->cmn.update_frame_index != _sg.frame_index);\r\n                    uint32_t copied_num_bytes = _sg_append_buffer(buf, data, (uint32_t)num_bytes, buf->cmn.append_frame_index != _sg.frame_index);\r\n                    buf->cmn.append_pos += copied_num_bytes;\r\n                    buf->cmn.append_frame_index = _sg.frame_index;\r\n                }\r\n            }\r\n        }\r\n        result = start_pos;\r\n    }\r\n    else {\r\n        /* FIXME: should we return -1 here? */\r\n        result = 0;\r\n    }\r\n    _SG_TRACE_ARGS(append_buffer, buf_id, data, num_bytes, result);\r\n    return result;\r\n}\r\n\r\nSOKOL_API_IMPL bool sg_query_buffer_overflow(sg_buffer buf_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);\r\n    bool result = buf ? buf->cmn.append_overflow : false;\r\n    return result;\r\n}\r\n\r\nSOKOL_API_IMPL void sg_update_image(sg_image img_id, const sg_image_content* data) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);\r\n    if (img && img->slot.state == SG_RESOURCESTATE_VALID) {\r\n        if (_sg_validate_update_image(img, data)) {\r\n            SOKOL_ASSERT(img->cmn.upd_frame_index != _sg.frame_index);\r\n            _sg_update_image(img, data);\r\n            img->cmn.upd_frame_index = _sg.frame_index;\r\n        }\r\n    }\r\n    _SG_TRACE_ARGS(update_image, img_id, data);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_push_debug_group(const char* name) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    SOKOL_ASSERT(name);\r\n    _SOKOL_UNUSED(name);\r\n    _SG_TRACE_ARGS(push_debug_group, name);\r\n}\r\n\r\nSOKOL_API_IMPL void sg_pop_debug_group(void) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    _SG_TRACE_NOARGS(pop_debug_group);\r\n}\r\n\r\nSOKOL_API_IMPL sg_buffer_info sg_query_buffer_info(sg_buffer buf_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_buffer_info info;\r\n    memset(&info, 0, sizeof(info));\r\n    const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);\r\n    if (buf) {\r\n        info.slot.state = buf->slot.state;\r\n        info.slot.res_id = buf->slot.id;\r\n        info.slot.ctx_id = buf->slot.ctx_id;\r\n        info.update_frame_index = buf->cmn.update_frame_index;\r\n        info.append_frame_index = buf->cmn.append_frame_index;\r\n        info.append_pos = buf->cmn.append_pos;\r\n        info.append_overflow = buf->cmn.append_overflow;\r\n        #if defined(SOKOL_D3D11)\r\n        info.num_slots = 1;\r\n        info.active_slot = 0;\r\n        #else\r\n        info.num_slots = buf->cmn.num_slots;\r\n        info.active_slot = buf->cmn.active_slot;\r\n        #endif\r\n    }\r\n    return info;\r\n}\r\n\r\nSOKOL_API_IMPL sg_image_info sg_query_image_info(sg_image img_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_image_info info;\r\n    memset(&info, 0, sizeof(info));\r\n    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);\r\n    if (img) {\r\n        info.slot.state = img->slot.state;\r\n        info.slot.res_id = img->slot.id;\r\n        info.slot.ctx_id = img->slot.ctx_id;\r\n        #if defined(SOKOL_D3D11)\r\n        info.num_slots = 1;\r\n        info.active_slot = 0;\r\n        #else\r\n        info.num_slots = img->cmn.num_slots;\r\n        info.active_slot = img->cmn.active_slot;\r\n        #endif\r\n        info.width = img->cmn.width;\r\n        info.height = img->cmn.height;\r\n    }\r\n    return info;\r\n}\r\n\r\nSOKOL_API_IMPL sg_shader_info sg_query_shader_info(sg_shader shd_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_shader_info info;\r\n    memset(&info, 0, sizeof(info));\r\n    const _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);\r\n    if (shd) {\r\n        info.slot.state = shd->slot.state;\r\n        info.slot.res_id = shd->slot.id;\r\n        info.slot.ctx_id = shd->slot.ctx_id;\r\n    }\r\n    return info;\r\n}\r\n\r\nSOKOL_API_IMPL sg_pipeline_info sg_query_pipeline_info(sg_pipeline pip_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_pipeline_info info;\r\n    memset(&info, 0, sizeof(info));\r\n    const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);\r\n    if (pip) {\r\n        info.slot.state = pip->slot.state;\r\n        info.slot.res_id = pip->slot.id;\r\n        info.slot.ctx_id = pip->slot.ctx_id;\r\n    }\r\n    return info;\r\n}\r\n\r\nSOKOL_API_IMPL sg_pass_info sg_query_pass_info(sg_pass pass_id) {\r\n    SOKOL_ASSERT(_sg.valid);\r\n    sg_pass_info info;\r\n    memset(&info, 0, sizeof(info));\r\n    const _sg_pass_t* pass = _sg_lookup_pass(&_sg.pools, pass_id.id);\r\n    if (pass) {\r\n        info.slot.state = pass->slot.state;\r\n        info.slot.res_id = pass->slot.id;\r\n        info.slot.ctx_id = pass->slot.ctx_id;\r\n    }\r\n    return info;\r\n}\r\n\r\nSOKOL_API_IMPL sg_buffer_desc sg_query_buffer_defaults(const sg_buffer_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid && desc);\r\n    return _sg_buffer_desc_defaults(desc);\r\n}\r\n\r\nSOKOL_API_IMPL sg_image_desc sg_query_image_defaults(const sg_image_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid && desc);\r\n    return _sg_image_desc_defaults(desc);\r\n}\r\n\r\nSOKOL_API_IMPL sg_shader_desc sg_query_shader_defaults(const sg_shader_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid && desc);\r\n    return _sg_shader_desc_defaults(desc);\r\n}\r\n\r\nSOKOL_API_IMPL sg_pipeline_desc sg_query_pipeline_defaults(const sg_pipeline_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid && desc);\r\n    return _sg_pipeline_desc_defaults(desc);\r\n}\r\n\r\nSOKOL_API_IMPL sg_pass_desc sg_query_pass_defaults(const sg_pass_desc* desc) {\r\n    SOKOL_ASSERT(_sg.valid && desc);\r\n    return _sg_pass_desc_defaults(desc);\r\n}\r\n\r\nSOKOL_API_IMPL const void* sg_mtl_render_command_encoder(void) {\r\n    #if defined(SOKOL_METAL)\r\n        if (nil != _sg.mtl.cmd_encoder) {\r\n            return (__bridge const void*) _sg.mtl.cmd_encoder;\r\n        }\r\n        else {\r\n            return 0;\r\n        }\r\n    #else\r\n        return 0;\r\n    #endif\r\n}\r\n\r\n#ifdef _MSC_VER\r\n#pragma warning(pop)\r\n#endif\r\n\r\n#endif /* SOKOL_IMPL */\r\n","//------------------------------------------------------------------------------\r\n//  cube-wgpu.c\r\n//  Rendering with uniform updates.\r\n//------------------------------------------------------------------------------\r\n#define HANDMADE_MATH_IMPLEMENTATION\r\n#define HANDMADE_MATH_NO_SSE\r\n#include \"HandmadeMath.h\"\r\n#define SOKOL_IMPL\r\n#define SOKOL_WGPU\r\n#include \"sokol_gfx.h\"\r\n#include \"wgpu_entry.h\"\r\n#include \"cube-wgpu.glsl.h\"\r\n\r\n#define SAMPLE_COUNT (4)\r\n\r\nstatic struct {\r\n    float rx, ry;\r\n    sg_pass_action pass_action;\r\n    sg_pipeline pip;\r\n    sg_bindings bind;\r\n} state = {\r\n    .pass_action = {\r\n        .colors[0] = { .action = SG_ACTION_CLEAR, .val = { 0.25f, 0.5f, 0.75f, 1.0f } }\r\n    }\r\n};\r\n\r\nvoid init(void) {\r\n    sg_setup(&(sg_desc){\r\n        .context = wgpu_get_context()\r\n    });\r\n\r\n    /* cube vertex buffer */\r\n    float vertices[] = {\r\n        -1.0, -1.0, -1.0,   1.0, 0.0, 0.0, 1.0,\r\n         1.0, -1.0, -1.0,   1.0, 0.0, 0.0, 1.0,\r\n         1.0,  1.0, -1.0,   1.0, 0.0, 0.0, 1.0,\r\n        -1.0,  1.0, -1.0,   1.0, 0.0, 0.0, 1.0,\r\n\r\n        -1.0, -1.0,  1.0,   0.0, 1.0, 0.0, 1.0,\r\n         1.0, -1.0,  1.0,   0.0, 1.0, 0.0, 1.0,\r\n         1.0,  1.0,  1.0,   0.0, 1.0, 0.0, 1.0,\r\n        -1.0,  1.0,  1.0,   0.0, 1.0, 0.0, 1.0,\r\n\r\n        -1.0, -1.0, -1.0,   0.0, 0.0, 1.0, 1.0,\r\n        -1.0,  1.0, -1.0,   0.0, 0.0, 1.0, 1.0,\r\n        -1.0,  1.0,  1.0,   0.0, 0.0, 1.0, 1.0,\r\n        -1.0, -1.0,  1.0,   0.0, 0.0, 1.0, 1.0,\r\n\r\n        1.0, -1.0, -1.0,    1.0, 0.5, 0.0, 1.0,\r\n        1.0,  1.0, -1.0,    1.0, 0.5, 0.0, 1.0,\r\n        1.0,  1.0,  1.0,    1.0, 0.5, 0.0, 1.0,\r\n        1.0, -1.0,  1.0,    1.0, 0.5, 0.0, 1.0,\r\n\r\n        -1.0, -1.0, -1.0,   0.0, 0.5, 1.0, 1.0,\r\n        -1.0, -1.0,  1.0,   0.0, 0.5, 1.0, 1.0,\r\n         1.0, -1.0,  1.0,   0.0, 0.5, 1.0, 1.0,\r\n         1.0, -1.0, -1.0,   0.0, 0.5, 1.0, 1.0,\r\n\r\n        -1.0,  1.0, -1.0,   1.0, 0.0, 0.5, 1.0,\r\n        -1.0,  1.0,  1.0,   1.0, 0.0, 0.5, 1.0,\r\n         1.0,  1.0,  1.0,   1.0, 0.0, 0.5, 1.0,\r\n         1.0,  1.0, -1.0,   1.0, 0.0, 0.5, 1.0\r\n    };\r\n    sg_buffer vbuf = sg_make_buffer(&(sg_buffer_desc){\r\n        .size = sizeof(vertices),\r\n        .content = vertices,\r\n        .label = \"cube-vertices\"\r\n    });\r\n\r\n    /* create an index buffer for the cube */\r\n    uint16_t indices[] = {\r\n        0, 1, 2,  0, 2, 3,\r\n        6, 5, 4,  7, 6, 4,\r\n        8, 9, 10,  8, 10, 11,\r\n        14, 13, 12,  15, 14, 12,\r\n        16, 17, 18,  16, 18, 19,\r\n        22, 21, 20,  23, 22, 20\r\n    };\r\n    sg_buffer ibuf = sg_make_buffer(&(sg_buffer_desc){\r\n        .type = SG_BUFFERTYPE_INDEXBUFFER,\r\n        .size = sizeof(indices),\r\n        .content = indices,\r\n        .label = \"cube-indices\"\r\n    });\r\n\r\n    /* create shader */\r\n    sg_shader shd = sg_make_shader(cube_shader_desc());\r\n\r\n    /* create pipeline object */\r\n    state.pip = sg_make_pipeline(&(sg_pipeline_desc){\r\n        .layout = {\r\n            /* test to provide buffer stride, but no attr offsets */\r\n            .buffers[0].stride = 28,\r\n            .attrs = {\r\n                [ATTR_vs_position].format = SG_VERTEXFORMAT_FLOAT3,\r\n                [ATTR_vs_color0].format   = SG_VERTEXFORMAT_FLOAT4\r\n            }\r\n        },\r\n        .shader = shd,\r\n        .index_type = SG_INDEXTYPE_UINT16,\r\n        .depth_stencil = {\r\n            .depth_compare_func = SG_COMPAREFUNC_LESS_EQUAL,\r\n            .depth_write_enabled = true,\r\n        },\r\n        .rasterizer.cull_mode = SG_CULLMODE_BACK,\r\n        .label = \"cube-pipeline\"\r\n    });\r\n\r\n    /* setup resource bindings */\r\n    state.bind = (sg_bindings) {\r\n        .vertex_buffers[0] = vbuf,\r\n        .index_buffer = ibuf\r\n    };\r\n}\r\n\r\nvoid frame(void) {\r\n    /* NOTE: the vs_params_t struct has been code-generated by the shader-code-gen */\r\n    vs_params_t vs_params;\r\n    const float w = (float) wgpu_width();\r\n    const float h = (float) wgpu_height();\r\n    hmm_mat4 proj = HMM_Perspective(60.0f, w/h, 0.01f, 10.0f);\r\n    hmm_mat4 view = HMM_LookAt(HMM_Vec3(0.0f, 1.5f, 6.0f), HMM_Vec3(0.0f, 0.0f, 0.0f), HMM_Vec3(0.0f, 1.0f, 0.0f));\r\n    hmm_mat4 view_proj = HMM_MultiplyMat4(proj, view);\r\n    state.rx += 1.0f; state.ry += 2.0f;\r\n    hmm_mat4 rxm = HMM_Rotate(state.rx, HMM_Vec3(1.0f, 0.0f, 0.0f));\r\n    hmm_mat4 rym = HMM_Rotate(state.ry, HMM_Vec3(0.0f, 1.0f, 0.0f));\r\n    hmm_mat4 model = HMM_MultiplyMat4(rxm, rym);\r\n    vs_params.mvp = HMM_MultiplyMat4(view_proj, model);\r\n\r\n    sg_begin_default_pass(&state.pass_action, (int)w, (int)h);\r\n    sg_apply_pipeline(state.pip);\r\n    sg_apply_bindings(&state.bind);\r\n    sg_apply_uniforms(SG_SHADERSTAGE_VS, SLOT_vs_params, &vs_params, sizeof(vs_params));\r\n    sg_draw(0, 36, 1);\r\n    sg_end_pass();\r\n    sg_commit();\r\n}\r\n\r\nvoid _shutdown(void) {\r\n    sg_shutdown();\r\n}\r\n\r\nint main() {\r\n    wgpu_start(&(wgpu_desc_t){\r\n        .init_cb = init,\r\n        .frame_cb = frame,\r\n        .shutdown_cb = _shutdown,\r\n        .width = 640,\r\n        .height = 480,\r\n        .sample_count = SAMPLE_COUNT,\r\n        .title = \"cube-wgpu\"\r\n    });\r\n    return 0;\r\n}\r\n","#pragma once\r\n/*\r\n    #version:1# (machine generated, don't edit!)\r\n\r\n    Generated by sokol-shdc (https://github.com/floooh/sokol-tools)\r\n\r\n    Overview:\r\n\r\n        Shader program 'cube':\r\n            Get shader desc: cube_shader_desc()\r\n            Vertex shader: vs\r\n                Attribute slots:\r\n                    ATTR_vs_position = 0\r\n                    ATTR_vs_color0 = 1\r\n                Uniform block 'vs_params':\r\n                    C struct: vs_params_t\r\n                    Bind slot: SLOT_vs_params = 0\r\n            Fragment shader: fs\r\n\r\n\r\n    Shader descriptor structs:\r\n\r\n        sg_shader cube = sg_make_shader(cube_shader_desc());\r\n\r\n    Vertex attribute locations for vertex shader 'vs':\r\n\r\n        sg_pipeline pip = sg_make_pipeline(&(sg_pipeline_desc){\r\n            .layout = {\r\n                .attrs = {\r\n                    [ATTR_vs_position] = { ... },\r\n                    [ATTR_vs_color0] = { ... },\r\n                },\r\n            },\r\n            ...});\r\n\r\n    Image bind slots, use as index in sg_bindings.vs_images[] or .fs_images[]\r\n\r\n\r\n    Bind slot and C-struct for uniform block 'vs_params':\r\n\r\n        vs_params_t vs_params = {\r\n            .mvp = ...;\r\n        };\r\n        sg_apply_uniforms(SG_SHADERSTAGE_[VS|FS], SLOT_vs_params, &vs_params, sizeof(vs_params));\r\n\r\n*/\r\n#include <stdint.h>\r\n#include <stdbool.h>\r\n#if !defined(SOKOL_SHDC_ALIGN)\r\n  #if defined(_MSC_VER)\r\n    #define SOKOL_SHDC_ALIGN(a) __declspec(align(a))\r\n  #else\r\n    #define SOKOL_SHDC_ALIGN(a) __attribute__((aligned(a)))\r\n  #endif\r\n#endif\r\n#define ATTR_vs_position (0)\r\n#define ATTR_vs_color0 (1)\r\n#define SLOT_vs_params (0)\r\n#pragma pack(push,1)\r\nSOKOL_SHDC_ALIGN(16) typedef struct vs_params_t {\r\n    hmm_mat4 mvp;\r\n} vs_params_t;\r\n#pragma pack(pop)\r\n#if defined(SOKOL_GLCORE33)\r\n/*\r\n    #version 330\r\n    \r\n    uniform vec4 vs_params[4];\r\n    layout(location = 0) in vec4 position;\r\n    out vec4 color;\r\n    layout(location = 1) in vec4 color0;\r\n    \r\n    void main()\r\n    {\r\n        gl_Position = mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3]) * position;\r\n        color = color0;\r\n    }\r\n    \r\n*/\r\nstatic const char vs_source_glsl330[263] = {\r\n    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x33,0x30,0x0a,0x0a,0x75,0x6e,\r\n    0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,0x5f,0x70,0x61,\r\n    0x72,0x61,0x6d,0x73,0x5b,0x34,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,\r\n    0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x69,0x6e,\r\n    0x20,0x76,0x65,0x63,0x34,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,\r\n    0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x34,0x20,0x63,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,\r\n    0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,\r\n    0x3d,0x20,0x31,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x34,0x20,0x63,0x6f,0x6c,\r\n    0x6f,0x72,0x30,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,\r\n    0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,\r\n    0x69,0x6f,0x6e,0x20,0x3d,0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,\r\n    0x72,0x61,0x6d,0x73,0x5b,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,\r\n    0x6d,0x73,0x5b,0x31,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,\r\n    0x5b,0x32,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,\r\n    0x5d,0x29,0x20,0x2a,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x20,\r\n    0x20,0x20,0x20,0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x6f,0x72,\r\n    0x30,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,\r\n};\r\n/*\r\n    #version 330\r\n    \r\n    layout(location = 0) out vec4 frag_color;\r\n    in vec4 color;\r\n    \r\n    void main()\r\n    {\r\n        frag_color = color;\r\n    }\r\n    \r\n*/\r\nstatic const char fs_source_glsl330[114] = {\r\n    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x33,0x30,0x0a,0x0a,0x6c,0x61,\r\n    0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,\r\n    0x30,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x34,0x20,0x66,0x72,0x61,0x67,\r\n    0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x69,0x6e,0x20,0x76,0x65,0x63,0x34,0x20,\r\n    0x63,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,\r\n    0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,\r\n    0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x7d,0x0a,\r\n    0x0a,0x00,\r\n};\r\n#endif /* SOKOL_GLCORE33 */\r\n#if defined(SOKOL_GLES2)\r\n/*\r\n    #version 100\r\n    \r\n    uniform vec4 vs_params[4];\r\n    attribute vec4 position;\r\n    varying vec4 color;\r\n    attribute vec4 color0;\r\n    \r\n    void main()\r\n    {\r\n        gl_Position = mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3]) * position;\r\n        color = color0;\r\n    }\r\n    \r\n*/\r\nstatic const char vs_source_glsl100[239] = {\r\n    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x31,0x30,0x30,0x0a,0x0a,0x75,0x6e,\r\n    0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,0x5f,0x70,0x61,\r\n    0x72,0x61,0x6d,0x73,0x5b,0x34,0x5d,0x3b,0x0a,0x61,0x74,0x74,0x72,0x69,0x62,0x75,\r\n    0x74,0x65,0x20,0x76,0x65,0x63,0x34,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,\r\n    0x3b,0x0a,0x76,0x61,0x72,0x79,0x69,0x6e,0x67,0x20,0x76,0x65,0x63,0x34,0x20,0x63,\r\n    0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x61,0x74,0x74,0x72,0x69,0x62,0x75,0x74,0x65,0x20,\r\n    0x76,0x65,0x63,0x34,0x20,0x63,0x6f,0x6c,0x6f,0x72,0x30,0x3b,0x0a,0x0a,0x76,0x6f,\r\n    0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,\r\n    0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x6d,0x61,\r\n    0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x30,0x5d,0x2c,\r\n    0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x5d,0x2c,0x20,0x76,\r\n    0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x32,0x5d,0x2c,0x20,0x76,0x73,0x5f,\r\n    0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,0x5d,0x29,0x20,0x2a,0x20,0x70,0x6f,0x73,\r\n    0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x20,0x20,0x20,0x20,0x63,0x6f,0x6c,0x6f,0x72,\r\n    0x20,0x3d,0x20,0x63,0x6f,0x6c,0x6f,0x72,0x30,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,\r\n};\r\n/*\r\n    #version 100\r\n    precision mediump float;\r\n    precision highp int;\r\n    \r\n    varying highp vec4 color;\r\n    \r\n    void main()\r\n    {\r\n        gl_FragData[0] = color;\r\n    }\r\n    \r\n*/\r\nstatic const char fs_source_glsl100[133] = {\r\n    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x31,0x30,0x30,0x0a,0x70,0x72,0x65,\r\n    0x63,0x69,0x73,0x69,0x6f,0x6e,0x20,0x6d,0x65,0x64,0x69,0x75,0x6d,0x70,0x20,0x66,\r\n    0x6c,0x6f,0x61,0x74,0x3b,0x0a,0x70,0x72,0x65,0x63,0x69,0x73,0x69,0x6f,0x6e,0x20,\r\n    0x68,0x69,0x67,0x68,0x70,0x20,0x69,0x6e,0x74,0x3b,0x0a,0x0a,0x76,0x61,0x72,0x79,\r\n    0x69,0x6e,0x67,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x34,0x20,0x63,\r\n    0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,\r\n    0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x46,0x72,0x61,0x67,\r\n    0x44,0x61,0x74,0x61,0x5b,0x30,0x5d,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x6f,0x72,0x3b,\r\n    0x0a,0x7d,0x0a,0x0a,0x00,\r\n};\r\n#endif /* SOKOL_GLES2 */\r\n#if defined(SOKOL_GLES3)\r\n/*\r\n    #version 300 es\r\n    \r\n    uniform vec4 vs_params[4];\r\n    layout(location = 0) in vec4 position;\r\n    out vec4 color;\r\n    layout(location = 1) in vec4 color0;\r\n    \r\n    void main()\r\n    {\r\n        gl_Position = mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3]) * position;\r\n        color = color0;\r\n    }\r\n    \r\n*/\r\nstatic const char vs_source_glsl300es[266] = {\r\n    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,\r\n    0x0a,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,\r\n    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x34,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,\r\n    0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,\r\n    0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x34,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,\r\n    0x6e,0x3b,0x0a,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x34,0x20,0x63,0x6f,0x6c,0x6f,\r\n    0x72,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,\r\n    0x6f,0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x34,0x20,\r\n    0x63,0x6f,0x6c,0x6f,0x72,0x30,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,\r\n    0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,\r\n    0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,\r\n    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,\r\n    0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,\r\n    0x61,0x6d,0x73,0x5b,0x32,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,\r\n    0x73,0x5b,0x33,0x5d,0x29,0x20,0x2a,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,\r\n    0x3b,0x0a,0x20,0x20,0x20,0x20,0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x63,0x6f,\r\n    0x6c,0x6f,0x72,0x30,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,\r\n};\r\n/*\r\n    #version 300 es\r\n    precision mediump float;\r\n    precision highp int;\r\n    \r\n    layout(location = 0) out highp vec4 frag_color;\r\n    in highp vec4 color;\r\n    \r\n    void main()\r\n    {\r\n        frag_color = color;\r\n    }\r\n    \r\n*/\r\nstatic const char fs_source_glsl300es[175] = {\r\n    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,\r\n    0x70,0x72,0x65,0x63,0x69,0x73,0x69,0x6f,0x6e,0x20,0x6d,0x65,0x64,0x69,0x75,0x6d,\r\n    0x70,0x20,0x66,0x6c,0x6f,0x61,0x74,0x3b,0x0a,0x70,0x72,0x65,0x63,0x69,0x73,0x69,\r\n    0x6f,0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x69,0x6e,0x74,0x3b,0x0a,0x0a,0x6c,\r\n    0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,\r\n    0x20,0x30,0x29,0x20,0x6f,0x75,0x74,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,\r\n    0x63,0x34,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x69,\r\n    0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x34,0x20,0x63,0x6f,0x6c,\r\n    0x6f,0x72,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,\r\n    0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,\r\n    0x72,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,\r\n};\r\n#endif /* SOKOL_GLES3 */\r\n#if !defined(SOKOL_GFX_INCLUDED)\r\n  #error \"Please include sokol_gfx.h before cube-wgpu.glsl.h\"\r\n#endif\r\nstatic inline const sg_shader_desc* cube_shader_desc(void) {\r\n  #if defined(SOKOL_GLCORE33)\r\n  if (sg_query_backend() == SG_BACKEND_GLCORE33) {\r\n    static sg_shader_desc desc;\r\n    static bool valid;\r\n    if (!valid) {\r\n      valid = true;\r\n      desc.attrs[0].name = \"position\";\r\n      desc.attrs[1].name = \"color0\";\r\n      desc.vs.source = vs_source_glsl330;\r\n      desc.vs.entry = \"main\";\r\n      desc.vs.uniform_blocks[0].size = 64;\r\n      desc.vs.uniform_blocks[0].uniforms[0].name = \"vs_params\";\r\n      desc.vs.uniform_blocks[0].uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;\r\n      desc.vs.uniform_blocks[0].uniforms[0].array_count = 4;\r\n      desc.fs.source = fs_source_glsl330;\r\n      desc.fs.entry = \"main\";\r\n      desc.label = \"cube_shader\";\r\n    };\r\n    return &desc;\r\n  }\r\n  #endif /* SOKOL_GLCORE33 */\r\n  #if defined(SOKOL_GLES2)\r\n  if (sg_query_backend() == SG_BACKEND_GLES2) {\r\n    static sg_shader_desc desc;\r\n    static bool valid;\r\n    if (!valid) {\r\n      valid = true;\r\n      desc.attrs[0].name = \"position\";\r\n      desc.attrs[1].name = \"color0\";\r\n      desc.vs.source = vs_source_glsl100;\r\n      desc.vs.entry = \"main\";\r\n      desc.vs.uniform_blocks[0].size = 64;\r\n      desc.vs.uniform_blocks[0].uniforms[0].name = \"vs_params\";\r\n      desc.vs.uniform_blocks[0].uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;\r\n      desc.vs.uniform_blocks[0].uniforms[0].array_count = 4;\r\n      desc.fs.source = fs_source_glsl100;\r\n      desc.fs.entry = \"main\";\r\n      desc.label = \"cube_shader\";\r\n    };\r\n    return &desc;\r\n  }\r\n  #endif /* SOKOL_GLES2 */\r\n  #if defined(SOKOL_GLES3)\r\n  if (sg_query_backend() == SG_BACKEND_GLES3) {\r\n    static sg_shader_desc desc;\r\n    static bool valid;\r\n    if (!valid) {\r\n      valid = true;\r\n      desc.attrs[0].name = \"position\";\r\n      desc.attrs[1].name = \"color0\";\r\n      desc.vs.source = vs_source_glsl300es;\r\n      desc.vs.entry = \"main\";\r\n      desc.vs.uniform_blocks[0].size = 64;\r\n      desc.vs.uniform_blocks[0].uniforms[0].name = \"vs_params\";\r\n      desc.vs.uniform_blocks[0].uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;\r\n      desc.vs.uniform_blocks[0].uniforms[0].array_count = 4;\r\n      desc.fs.source = fs_source_glsl300es;\r\n      desc.fs.entry = \"main\";\r\n      desc.label = \"cube_shader\";\r\n    };\r\n    return &desc;\r\n  }\r\n  #endif /* SOKOL_GLES3 */\r\n  return 0; /* can't happen */\r\n}\r\n","/* platform-agnostic WGPU demo scaffold functions */\r\n\r\n#include \"sokol_gfx.h\"\r\n#include \"wgpu_entry.h\"\r\n#include <assert.h>\r\n\r\nwgpu_state_t wgpu_state;\r\n\r\n#define wgpu_def(val, def) ((val==0)?def:val)\r\n\r\nvoid wgpu_start(const wgpu_desc_t* desc) {\r\n    assert(desc);\r\n    assert(desc->title);\r\n    assert((desc->width > 0) && (desc->height > 0));\r\n    assert(desc->init_cb && desc->frame_cb && desc->shutdown_cb);\r\n    wgpu_state.desc = *desc;\r\n    wgpu_state.desc.sample_count = wgpu_def(wgpu_state.desc.sample_count, 1);\r\n    wgpu_platform_start(desc);\r\n}\r\n\r\nint wgpu_width(void) {\r\n    return wgpu_state.width;\r\n}\r\n\r\nint wgpu_height(void) {\r\n    return wgpu_state.height;\r\n}\r\n\r\nstatic const void* wgpu_get_render_view(void* user_data) {\r\n    assert((void*)0xABADF00D == user_data);\r\n    if (wgpu_state.desc.sample_count > 1) {\r\n        assert(wgpu_state.msaa_view);\r\n        return (const void*) wgpu_state.msaa_view;\r\n    }\r\n    else {\r\n        assert(wgpu_state.swapchain_view);\r\n        return (const void*) wgpu_state.swapchain_view;\r\n    }\r\n}\r\n\r\nstatic const void* wgpu_get_resolve_view(void* user_data) {\r\n    assert((void*)0xABADF00D == user_data);\r\n    if (wgpu_state.desc.sample_count > 1) {\r\n        assert(wgpu_state.swapchain_view);\r\n        return (const void*) wgpu_state.swapchain_view;\r\n    }\r\n    else {\r\n        return 0;\r\n    }\r\n}\r\n\r\nstatic const void* wgpu_get_depth_stencil_view(void* user_data) {\r\n    assert((void*)0xABADF00D == user_data);\r\n    return (const void*) wgpu_state.depth_stencil_view;\r\n}\r\n\r\nstatic sg_pixel_format wgpu_get_color_format(void) {\r\n    switch (wgpu_state.render_format) {\r\n            case WGPUTextureFormat_RGBA8Unorm:  return SG_PIXELFORMAT_RGBA8;\r\n            case WGPUTextureFormat_BGRA8Unorm:  return SG_PIXELFORMAT_BGRA8;\r\n            /* this shouldn't happen */\r\n            default: return SG_PIXELFORMAT_NONE;\r\n    }\r\n}\r\n\r\nsg_context_desc wgpu_get_context(void) {\r\n    return (sg_context_desc) {\r\n        .color_format = wgpu_get_color_format(),\r\n        .sample_count = wgpu_state.desc.sample_count,\r\n        .wgpu = {\r\n            .device = (const void*) wgpu_state.dev,\r\n            .render_view_userdata_cb = wgpu_get_render_view,\r\n            .resolve_view_userdata_cb = wgpu_get_resolve_view,\r\n            .depth_stencil_view_userdata_cb = wgpu_get_depth_stencil_view,\r\n            .user_data = 0xABADF00D\r\n        }\r\n    };\r\n}\r\n\r\nvoid wgpu_swapchain_init(void) {\r\n    assert(wgpu_state.swapchain);\r\n    assert((wgpu_state.width > 0) && (wgpu_state.height > 0));\r\n\r\n    /* create depth-stencil texture and view */\r\n    WGPUTextureDescriptor ds_desc = {\r\n        .usage = WGPUTextureUsage_OutputAttachment,\r\n        .dimension = WGPUTextureDimension_2D,\r\n        .size = {\r\n            .width = (uint32_t) wgpu_state.width,\r\n            .height = (uint32_t) wgpu_state.height,\r\n            .depth = 1,\r\n        },\r\n        .arrayLayerCount = 1,\r\n        .format = WGPUTextureFormat_Depth24PlusStencil8,\r\n        .mipLevelCount = 1,\r\n        .sampleCount = wgpu_state.desc.sample_count\r\n    };\r\n    wgpu_state.depth_stencil_tex = wgpuDeviceCreateTexture(wgpu_state.dev, &ds_desc);\r\n    wgpu_state.depth_stencil_view = wgpuTextureCreateView(wgpu_state.depth_stencil_tex, 0);\r\n\r\n    /* create optional MSAA surface and view */\r\n    if (wgpu_state.desc.sample_count > 1) {\r\n        WGPUTextureDescriptor msaa_desc = {\r\n            .usage = WGPUTextureUsage_OutputAttachment,\r\n            .dimension = WGPUTextureDimension_2D,\r\n            .size = {\r\n                .width = (uint32_t) wgpu_state.width,\r\n                .height = (uint32_t) wgpu_state.height,\r\n                .depth = 1,\r\n            },\r\n            .arrayLayerCount = 1,\r\n            .format = wgpu_state.render_format,\r\n            .mipLevelCount = 1,\r\n            .sampleCount = wgpu_state.desc.sample_count\r\n        };\r\n        wgpu_state.msaa_tex = wgpuDeviceCreateTexture(wgpu_state.dev, &msaa_desc);\r\n        wgpu_state.msaa_view = wgpuTextureCreateView(wgpu_state.msaa_tex, 0);\r\n    }\r\n}\r\n\r\nvoid wgpu_swapchain_next_frame(void) {\r\n    if (wgpu_state.swapchain_view) {\r\n        wgpuTextureViewRelease(wgpu_state.swapchain_view);\r\n    }\r\n    wgpu_state.swapchain_view = wgpuSwapChainGetCurrentTextureView(wgpu_state.swapchain);\r\n}\r\n\r\nvoid wgpu_swapchain_discard(void) {\r\n    if (wgpu_state.msaa_tex) {\r\n        wgpuTextureRelease(wgpu_state.msaa_tex);\r\n    }\r\n    if (wgpu_state.msaa_view) {\r\n        wgpuTextureViewRelease(wgpu_state.msaa_view);\r\n    }\r\n    wgpuTextureViewRelease(wgpu_state.swapchain_view);\r\n    wgpuTextureViewRelease(wgpu_state.depth_stencil_view);\r\n    wgpuTextureRelease(wgpu_state.depth_stencil_tex);\r\n}\r\n","/* WASM specific WGPU demo scaffold functions */\r\n#if !defined(__EMSCRIPTEN__)\r\n#error \"please compile this file in Emscripten!\"\r\n#endif\r\n#include \"sokol_gfx.h\"\r\n#include <stdio.h>\r\n#include <emscripten/emscripten.h>\r\n#include <emscripten/html5.h>\r\n#include \"wgpu_entry.h\"\r\n\r\nstatic struct {\r\n    int frame_state;\r\n} emsc;\r\n\r\nstatic void emsc_update_canvas_size(void) {\r\n    double w, h;\r\n    emscripten_get_element_css_size(\"canvas\", &w, &h);\r\n    emscripten_set_canvas_element_size(\"canvas\", w, h);\r\n    wgpu_state.width = (int) w;\r\n    wgpu_state.height = (int) h;\r\n    printf(\"canvas size updated: %d %d\\n\", wgpu_state.width, wgpu_state.height);\r\n}\r\n\r\nstatic EM_BOOL emsc_size_changed(int event_type, const EmscriptenUiEvent* ui_event, void* user_data) {\r\n    emsc_update_canvas_size();\r\n    return true;\r\n}\r\n\r\nEMSCRIPTEN_KEEPALIVE void emsc_device_ready(int device_id, int swapchain_id, int swapchain_fmt) {\r\nprintf(\"emsc_device_ready\\n\");\r\n    wgpu_state.dev = (WGPUDevice) device_id;\r\n    wgpu_state.swapchain = (WGPUSwapChain) swapchain_id;\r\n    wgpu_state.render_format = (WGPUTextureFormat) swapchain_fmt;\r\n}\r\n\r\n/* Javascript function to wrap asynchronous device and swapchain setup */\r\nEM_JS(void, emsc_async_js_setup, (), {\r\n console.log(\"emsc_async_js_setup \" );\r\n    WebGPU.initManagers();\r\n\t console.log(\"initManagers \" );\r\n    navigator.gpu.requestAdapter().then(function(adapter) {\r\n\tconsole.log(\"requestAdapter \" );\r\n        console.log(\"adapter extensions: \" + adapter.extensions);\r\n        adapter.requestDevice().then(function(device) {\r\n            console.log(\"device extensions: \" + device.extensions);\r\n            var gpuContext = document.getElementById(\"canvas\").getContext(\"gpupresent\");\r\n            gpuContext.getSwapChainPreferredFormat(device).then(function(fmt) {\r\n                var swapChainDescriptor = { device: device, format: fmt };\r\n                var swapChain = gpuContext.configureSwapChain(swapChainDescriptor);\r\n                var deviceId = WebGPU.mgrDevice.create(device);\r\n                var swapChainId = WebGPU.mgrSwapChain.create(swapChain);\r\n                var fmtId = WebGPU.TextureFormat.findIndex(function(elm) { return elm==fmt; });\r\n                console.log(\"device: \" + device);\r\n                console.log(\"swap chain: \" + swapChain);\r\n                console.log(\"preferred format: \" + fmt + \" (\" + fmtId + \")\");\r\n                _emsc_device_ready(deviceId, swapChainId, fmtId);\r\n            });\r\n        });\r\n    });\r\n});\r\n\r\nstatic EM_BOOL emsc_frame(double time, void* user_data) {\r\n    switch (emsc.frame_state) {\r\n        case 0:\r\n\t\t\tprintf(\"Zero\\n\");\r\n            emsc_async_js_setup();\r\n            emsc.frame_state = 1;\r\n            break;\r\n        case 1:\r\n\t\t\r\n            if (wgpu_state.dev) {\r\n\t\t\tprintf(\"One\\n\");\r\n                wgpu_swapchain_init();\r\n                wgpu_state.desc.init_cb();\r\n                emsc.frame_state = 2;\r\n            }\r\n            break;\r\n        case 2:\r\n\t\tprintf(\"Two\\n\");\r\n            wgpu_swapchain_next_frame();\r\n            wgpu_state.desc.frame_cb();\r\n            break;\r\n    }\r\n    return EM_TRUE;\r\n}\r\n\r\nvoid wgpu_platform_start(const wgpu_desc_t* desc) {\r\n    emsc_update_canvas_size();\r\n    emscripten_set_resize_callback(\"canvas\", 0, false, emsc_size_changed);\r\n    emscripten_request_animation_frame_loop(emsc_frame, 0);\r\n}\r\n"]}